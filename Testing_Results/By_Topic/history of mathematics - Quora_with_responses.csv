Authors,Time,Questions,Answers,api_response,originality_score
Oscar Tay,Updated 2y,Why do we generally use the letter ‘X’ in an equation instead of another letter?,"Because a French guy decided it should be that way, possibly because his printer ran out of letters.

Once, a French man wrote a book. Specifically, this French man:

That’s René Descartes. Besides Napoleon, he is arguably the most famous French person. He’s responsible for things like modern philosophy and the saying Cogito ergo sum (“I think, therefore I am”).

Another thing he’s responsible for - well, several things, really - is one of the greatest contributions to math not made by a Greek person. He needed to tell people about these things, so he wrote some books. He needed to make lots of copies of the books, so he got them printed. (The alternative, and the main method in Europe before Gutenberg invented the printing press, was to write everything out by hand, over and over again.)

In his book La Géométrie, Descartes uses x, y, and z to represent unknown quantities. We’re not completely sure why he did this - it may have just been because those letters come at the end of the alphabet - but according to one theory, it was because his printer had lots of extras of those letters.

Back then, printers weren’t machines; they were people who would take letters out of boxes and arrange them into giant stamps, which could then be used to print things on pieces of paper.

Printers at work. From Wikipedia
.

(Interesting side note: The smaller letters, which were used more, were kept in the bottom row of boxes to make them easier for the printer to access, so they were lower case letters. The capital letters, since they were used less, were kept in the top row, so they were upper case. This is where we get those terms from.)

In French, the letters X, Y, and Z are uncommon, so the printers were less likely to run out of them than any other letters (besides K). The theory says that Descartes chose them to represent unknown quantities not only because they come in order at the end of the alphabet, but also due to the printers’ advice.

Whether or not this is true, the first use of X, Y, and Z in this way is found in La Géométrie, a book that tied geometry and algebra together and contributed to the development of calculus.

There are also other theories that suggest it’s an abbreviation of the Greek xenos (“unknown”) or a Spanish abbreviation of the transliteration of the Arabic word al-shalan (see here
), but there’s little evidence for either and it’s mostly speculation. The first appearance with evidence is La Géométrie.

Since then, it’s evolved to stand for the unknown in popular culture, eg. the X-Files and the X-Men.

Thanks for asking!","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/1fkm09xhgybdj2ns', 'title': 'Why do we generally use the letter ‘X’ in an equation instead of another letter?', 'score': {'original': 0.9989, 'ai': 0.0011}, 'blocks': [{'text': 'Because a French guy decided it should be that way, possibly because his printer ran out of letters.\n\nOnce, a French man wrote a book. Specifically, this French man:\n\nThat’s René Descartes. Besides Napoleon, he is arguably the most famous French person. He’s responsible for things like modern philosophy and the saying Cogito ergo sum (“I think, therefore I am”).\n\nAnother thing he’s responsible for - well, several things, really - is one of the greatest contributions to math not made by a Greek person. He needed to tell people about these things, so he wrote some books. He needed to make lots of copies of the books, so he got them printed. (The alternative, and the main method in Europe before Gutenberg invented the printing press, was to write everything out by hand, over and over again.)\n\nIn his book La Géométrie, Descartes uses x, y, and z to represent unknown quantities. We’re not completely sure why he did this - it may have just been because those letters come at the end of the alphabet - but according to one theory, it was because his printer had lots of extras of those letters.\n\nBack then, printers weren’t machines; they were people who would take letters out of boxes and arrange them into giant stamps, which could then be used to print things on pieces of paper.\n\nPrinters at work. From Wikipedia\n.\n\n(Interesting side note: The smaller letters, which were used more, were kept in the bottom row of boxes to make them easier for the printer to access, so they were lower case letters. The capital letters, since they were used less, were kept in the top row, so they were upper case. This is where we get those terms from.)\n\nIn French, the letters X, Y, and Z are uncommon, so the printers were less likely to run out of them than any other letters (besides K). The theory says that Descartes chose them to represent unknown quantities not only because they come in order at the end of the alphabet, but also due to the printers’ advice.\n\nWhether or not this is true, the first use of X, Y, and Z in this way is found in La Géométrie, a book that tied geometry and algebra together and contributed to the development of calculus.\n\nThere are also other theories that suggest it’s an abbreviation of the Greek xenos (“unknown”) or a Spanish abbreviation of the transliteration of the Arabic word al-shalan (see here\n), but there’s little evidence for either and it’s mostly speculation. The first appearance with evidence is La Géométrie.\n\nSince then, it’s evolved to stand for the unknown in popular culture, eg. the X-Files and the X-Men.\n\nThanks for asking!', 'result': {'fake': 0.0011, 'real': 0.9989}, 'status': 'success'}], 'credits_used': 5, 'credits': 1995055, 'subscription': 0, 'content': 'Because a French guy decided it should be that way, possibly because his printer ran out of letters.\n\nOnce, a French man wrote a book. Specifically, this French man:\n\nThat’s René Descartes. Besides Napoleon, he is arguably the most famous French person. He’s responsible for things like modern philosophy and the saying Cogito ergo sum (“I think, therefore I am”).\n\nAnother thing he’s responsible for - well, several things, really - is one of the greatest contributions to math not made by a Greek person. He needed to tell people about these things, so he wrote some books. He needed to make lots of copies of the books, so he got them printed. (The alternative, and the main method in Europe before Gutenberg invented the printing press, was to write everything out by hand, over and over again.)\n\nIn his book La Géométrie, Descartes uses x, y, and z to represent unknown quantities. We’re not completely sure why he did this - it may have just been because those letters come at the end of the alphabet - but according to one theory, it was because his printer had lots of extras of those letters.\n\nBack then, printers weren’t machines; they were people who would take letters out of boxes and arrange them into giant stamps, which could then be used to print things on pieces of paper.\n\nPrinters at work. From Wikipedia\n.\n\n(Interesting side note: The smaller letters, which were used more, were kept in the bottom row of boxes to make them easier for the printer to access, so they were lower case letters. The capital letters, since they were used less, were kept in the top row, so they were upper case. This is where we get those terms from.)\n\nIn French, the letters X, Y, and Z are uncommon, so the printers were less likely to run out of them than any other letters (besides K). The theory says that Descartes chose them to represent unknown quantities not only because they come in order at the end of the alphabet, but also due to the printers’ advice.\n\nWhether or not this is true, the first use of X, Y, and Z in this way is found in La Géométrie, a book that tied geometry and algebra together and contributed to the development of calculus.\n\nThere are also other theories that suggest it’s an abbreviation of the Greek xenos (“unknown”) or a Spanish abbreviation of the transliteration of the Arabic word al-shalan (see here\n), but there’s little evidence for either and it’s mostly speculation. The first appearance with evidence is La Géométrie.\n\nSince then, it’s evolved to stand for the unknown in popular culture, eg. the X-Files and the X-Men.\n\nThanks for asking!', 'aiModelVersion': '1'}",0.9989
Alon Amit,Updated 3y,"By not publishing some of his results, was Andrew Wiles being ‘unfair’ to other mathematicians who could have used it to participate in the solution of FLT?","Let’s step back from Andrew Wiles and consider mathematics in general. Actually, let’s step back from mathematics and consider human endeavors in general.

Every day, today and throughout history, millions of people are pursuing a dream, large or small, of creating something new. An artist labors to paint the ceiling of the sistine chapel, or fashions an original sculpture. A composer works on a piano concerto. A software engineer is typing away in the proverbial garage, hoping to build a successful business around some idea or other. Artists, scientists, entrepreneurs, engineers, what have you – many people are on a creative journey, sometimes for a week, sometimes for three decades.

In almost all cases there’s a dilemma of when and what and with whom to share. Do you work in complete solitude? Do you bring in a few good friends whom you trust and whose help you need? Do you start a company and bring in investors, employees, customers? Different people make different choices, and this is an important freedom. “Fairness” isn’t something you can decide for others, and is not reasonably standardized or formalized.

Companies are allowed to develop software without open-sourcing it. Are they being “unfair”? Surely others could have learned from their efforts early on. And yet, we allow companies to do that.

Artists are allowed to work on a piece of art for years in complete secrecy. Are they being “unfair”? Surely others could have mimicked their work and create valuable variations or spin-offs. And yet, we don’t demand artists to share drafts with the public.

Mathematicians are allowed to work on a proof, in solitude. Are they being “unfair”? Surely others could learn from their ideas and progress and use them to participate in the ultimate solution of the problem. And yet, we choose to support those personal journeys.

This is as it should be, and is very much the world I wish to live in. A world in which solitude is disallowed and everything should be shared within a day, a week, or a year – such a world scares me, and I think it scares (or should scare) most everyone. The freedom to quietly pursue our own ideas and take them however far we perceive is appropriate is one of the most profound fundamental freedoms of any reasonable human society.

So no, Wiles wasn’t being “unfair” to anyone. It would be massively unreasonable, or “unfair”, to require him to regularly share his progress. His freedom to pursue a lifelong dream is a fundamental right.

Mathematics is a human endeavor, not just a set of formal results. As any human endeavor it has culture and etiquette. One of the profound unwritten rules is this: if someone shares an idea or direction with you by way of friendly dissemination of ideas, you do not lock yourself up and try to pursue that same idea by yourself in order to scoop them. I know people who were violated in this way, and it caused them untold pain over very long periods of time.

As a result of such violations, some people choose to remain very guarded. It’s understandable, and reasonable. In the software industry, it is common practice to announce that you are “working on something” and everyone understands it’s not their place to probe further. In the mathematical research community it’s not even common to make such announcements. You simply work on it, alone or with a few close collaborators. Sometimes you feel it is useful to announce partial progress, or a research plan – that’s great, and is often done, but it is completely your choice, not anyone else’s.

This, precisely, is “fair”.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/em2uf7zg4r0bcahk', 'title': 'By not publishing some of his results, was Andrew Wiles being ‘unfair’ to other mathematicians who could have used it to participate in the solution of FLT?', 'score': {'original': 0.80225, 'ai': 0.19775}, 'blocks': [{'text': 'Let’s step back from Andrew Wiles and consider mathematics in general. Actually, let’s step back from mathematics and consider human endeavors in general.\n\nEvery day, today and throughout history, millions of people are pursuing a dream, large or small, of creating something new. An artist labors to paint the ceiling of the sistine chapel, or fashions an original sculpture. A composer works on a piano concerto. A software engineer is typing away in the proverbial garage, hoping to build a successful business around some idea or other. Artists, scientists, entrepreneurs, engineers, what have you – many people are on a creative journey, sometimes for a week, sometimes for three decades.\n\nIn almost all cases there’s a dilemma of when and what and with whom to share. Do you work in complete solitude? Do you bring in a few good friends whom you trust and whose help you need? Do you start a company and bring in investors, employees, customers? Different people make different choices, and this is an important freedom. “Fairness” isn’t something you can decide for others, and is not reasonably standardized or formalized.\n\nCompanies are allowed to develop software without open-sourcing it. Are they being “unfair”? Surely others could have learned from their efforts early on. And yet, we allow companies to do that.\n\nArtists are allowed to work on a piece of art for years in complete secrecy. Are they being “unfair”? Surely others could have mimicked their work and create valuable variations or spin-offs. And yet, we don’t demand artists to share drafts with the public.\n\nMathematicians are allowed to work on a proof, in solitude. Are they being “unfair”? Surely others could learn from their ideas and progress and use them to participate in the ultimate solution of the problem. And yet, we choose to support those personal journeys.\n\nThis is as it should be, and is very much the world I wish to live in. A world in which solitude is disallowed and everything should be shared within a day, a week, or a year – such a world scares me, and I think it scares (or should scare) most everyone. The freedom to quietly pursue our own ideas and take them however far we perceive is appropriate is one of the most profound fundamental freedoms of any reasonable human society.\n\nSo no, Wiles wasn’t being “unfair” to anyone. It would be massively unreasonable, or “unfair”, to require him to regularly share his progress. His freedom to pursue a lifelong dream is a fundamental right.\n\nMathematics is a human endeavor, not just a set of formal results. As any human endeavor it has culture and etiquette. One of the profound unwritten rules is this: if someone shares an idea or direction with you by way of friendly dissemination of ideas, you do not lock yourself up and try to pursue that same idea by yourself in order to scoop them. I know people who were violated in this way, and it caused them untold pain over very long periods of time.\n\nAs a result of such violations, some people choose to remain very guarded. It’s', 'result': {'fake': 0.0103, 'real': 0.9897}, 'status': 'success'}, {'text': 'understandable, and reasonable. In the software industry, it is common practice to announce that you are “working on something” and everyone understands it’s not their place to probe further. In the mathematical research community it’s not even common to make such announcements. You simply work on it, alone or with a few close collaborators. Sometimes you feel it is useful to announce partial progress, or a research plan – that’s great, and is often done, but it is completely your choice, not anyone else’s.\n\nThis, precisely, is “fair”.', 'result': {'fake': 0.3716, 'real': 0.6284}, 'status': 'success'}], 'credits_used': 7, 'credits': 1995048, 'subscription': 0, 'content': 'Let’s step back from Andrew Wiles and consider mathematics in general. Actually, let’s step back from mathematics and consider human endeavors in general.\n\nEvery day, today and throughout history, millions of people are pursuing a dream, large or small, of creating something new. An artist labors to paint the ceiling of the sistine chapel, or fashions an original sculpture. A composer works on a piano concerto. A software engineer is typing away in the proverbial garage, hoping to build a successful business around some idea or other. Artists, scientists, entrepreneurs, engineers, what have you – many people are on a creative journey, sometimes for a week, sometimes for three decades.\n\nIn almost all cases there’s a dilemma of when and what and with whom to share. Do you work in complete solitude? Do you bring in a few good friends whom you trust and whose help you need? Do you start a company and bring in investors, employees, customers? Different people make different choices, and this is an important freedom. “Fairness” isn’t something you can decide for others, and is not reasonably standardized or formalized.\n\nCompanies are allowed to develop software without open-sourcing it. Are they being “unfair”? Surely others could have learned from their efforts early on. And yet, we allow companies to do that.\n\nArtists are allowed to work on a piece of art for years in complete secrecy. Are they being “unfair”? Surely others could have mimicked their work and create valuable variations or spin-offs. And yet, we don’t demand artists to share drafts with the public.\n\nMathematicians are allowed to work on a proof, in solitude. Are they being “unfair”? Surely others could learn from their ideas and progress and use them to participate in the ultimate solution of the problem. And yet, we choose to support those personal journeys.\n\nThis is as it should be, and is very much the world I wish to live in. A world in which solitude is disallowed and everything should be shared within a day, a week, or a year – such a world scares me, and I think it scares (or should scare) most everyone. The freedom to quietly pursue our own ideas and take them however far we perceive is appropriate is one of the most profound fundamental freedoms of any reasonable human society.\n\nSo no, Wiles wasn’t being “unfair” to anyone. It would be massively unreasonable, or “unfair”, to require him to regularly share his progress. His freedom to pursue a lifelong dream is a fundamental right.\n\nMathematics is a human endeavor, not just a set of formal results. As any human endeavor it has culture and etiquette. One of the profound unwritten rules is this: if someone shares an idea or direction with you by way of friendly dissemination of ideas, you do not lock yourself up and try to pursue that same idea by yourself in order to scoop them. I know people who were violated in this way, and it caused them untold pain over very long periods of time.\n\nAs a result of such violations, some people choose to remain very guarded. It’s understandable, and reasonable. In the software industry, it is common practice to announce that you are “working on something” and everyone understands it’s not their place to probe further. In the mathematical research community it’s not even common to make such announcements. You simply work on it, alone or with a few close collaborators. Sometimes you feel it is useful to announce partial progress, or a research plan – that’s great, and is often done, but it is completely your choice, not anyone else’s.\n\nThis, precisely, is “fair”.', 'aiModelVersion': '1'}",0.80225
Molly Carter,Updated 5y,Who is the most mysterious man to have ever lived?,"Short answer: L’Inconnue de la Seine, aka the Unknown Woman of the Seine.

I know this is a woman instead of a man, but this is an interesting story nonetheless, so stick with me for a minute or two.

In the 1880s, a woman’s body was found dead, floating in the Seine River. Estimated age 16. Her body showed no signs of foul play and, because of this, it was assumed her death was a suicide.

Her body was taken to the coroner’s office. The coroner must have thought she was pretty and spent hours crafting a death mask of the girl’s face. Legend has him quoted, saying:

Her beauty was breathtaking, and showed few signs of distress at the time of passing. So bewitching that I knew beauty as such must be preserved.

(Death mask: A wax or plaster cast of a dead person’s face, most often taken from the corpse. These masks were used as either mementos or for portraits)

Now, you should know that death masks were sort of a thing, especially of famous people, and people, in general, were kind of morbid back then (now we’re nice and civilized).

So, somehow, people saw the death mask of this unknown drowned lady and they wanted their own death mask of her face. Well, as you can imagine, when you’re a guy who makes molds of dead people’s faces and you suddenly have a face that everyone wants, you sell that shit.

The woman’s death mask soon became mass produced and, by 1900, everyone who was anyone in Germany and France owned one.

Fast forward nearly 100 years to Norway. It’s 1958 and you’re a toy maker by trade and have just created the world’s first CPR dummy. And you need to put a face on it. What face do you choose? You guessed it, the unknown woman of the Seine.

Why, you may ask?

Maybe he didn’t know what to make the dummy look like. Maybe, like that coroner back in Paris, he had a thing for dead girls (I didn’t really mean that the way it sounded). Maybe the death mask his great grandfather had purchased from a coroner while visiting France was hanging on the wall in his workshop.

Now, nearly 60 years later, this same face graces CPR dummies around the world. And still, nobody knows who the hell she is.

Although this woman obviously had a turn of bad luck, after all, it’s not good luck that ends up with you floating in a river, she, postmortem, has become rather popular.

Just imagine the number of people who have laid their lips on hers.

Thanks for the A2A Steven Harris!","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/38zpiwdsyntql5ju', 'title': 'Who is the most mysterious man to have ever lived?', 'score': {'original': 0.9998, 'ai': 0.0002}, 'blocks': [{'text': 'Short answer: L’Inconnue de la Seine, aka the Unknown Woman of the Seine.\n\nI know this is a woman instead of a man, but this is an interesting story nonetheless, so stick with me for a minute or two.\n\nIn the 1880s, a woman’s body was found dead, floating in the Seine River. Estimated age 16. Her body showed no signs of foul play and, because of this, it was assumed her death was a suicide.\n\nHer body was taken to the coroner’s office. The coroner must have thought she was pretty and spent hours crafting a death mask of the girl’s face. Legend has him quoted, saying:\n\nHer beauty was breathtaking, and showed few signs of distress at the time of passing. So bewitching that I knew beauty as such must be preserved.\n\n(Death mask: A wax or plaster cast of a dead person’s face, most often taken from the corpse. These masks were used as either mementos or for portraits)\n\nNow, you should know that death masks were sort of a thing, especially of famous people, and people, in general, were kind of morbid back then (now we’re nice and civilized).\n\nSo, somehow, people saw the death mask of this unknown drowned lady and they wanted their own death mask of her face. Well, as you can imagine, when you’re a guy who makes molds of dead people’s faces and you suddenly have a face that everyone wants, you sell that shit.\n\nThe woman’s death mask soon became mass produced and, by 1900, everyone who was anyone in Germany and France owned one.\n\nFast forward nearly 100 years to Norway. It’s 1958 and you’re a toy maker by trade and have just created the world’s first CPR dummy. And you need to put a face on it. What face do you choose? You guessed it, the unknown woman of the Seine.\n\nWhy, you may ask?\n\nMaybe he didn’t know what to make the dummy look like. Maybe, like that coroner back in Paris, he had a thing for dead girls (I didn’t really mean that the way it sounded). Maybe the death mask his great grandfather had purchased from a coroner while visiting France was hanging on the wall in his workshop.\n\nNow, nearly 60 years later, this same face graces CPR dummies around the world. And still, nobody knows who the hell she is.\n\nAlthough this woman obviously had a turn of bad luck, after all, it’s not good luck that ends up with you floating in a river, she, postmortem, has become rather popular.\n\nJust imagine the number of people who have laid their lips on hers.\n\nThanks for the A2A Steven Harris!', 'result': {'fake': 0.0002, 'real': 0.9998}, 'status': 'success'}], 'credits_used': 5, 'credits': 1995043, 'subscription': 0, 'content': 'Short answer: L’Inconnue de la Seine, aka the Unknown Woman of the Seine.\n\nI know this is a woman instead of a man, but this is an interesting story nonetheless, so stick with me for a minute or two.\n\nIn the 1880s, a woman’s body was found dead, floating in the Seine River. Estimated age 16. Her body showed no signs of foul play and, because of this, it was assumed her death was a suicide.\n\nHer body was taken to the coroner’s office. The coroner must have thought she was pretty and spent hours crafting a death mask of the girl’s face. Legend has him quoted, saying:\n\nHer beauty was breathtaking, and showed few signs of distress at the time of passing. So bewitching that I knew beauty as such must be preserved.\n\n(Death mask: A wax or plaster cast of a dead person’s face, most often taken from the corpse. These masks were used as either mementos or for portraits)\n\nNow, you should know that death masks were sort of a thing, especially of famous people, and people, in general, were kind of morbid back then (now we’re nice and civilized).\n\nSo, somehow, people saw the death mask of this unknown drowned lady and they wanted their own death mask of her face. Well, as you can imagine, when you’re a guy who makes molds of dead people’s faces and you suddenly have a face that everyone wants, you sell that shit.\n\nThe woman’s death mask soon became mass produced and, by 1900, everyone who was anyone in Germany and France owned one.\n\nFast forward nearly 100 years to Norway. It’s 1958 and you’re a toy maker by trade and have just created the world’s first CPR dummy. And you need to put a face on it. What face do you choose? You guessed it, the unknown woman of the Seine.\n\nWhy, you may ask?\n\nMaybe he didn’t know what to make the dummy look like. Maybe, like that coroner back in Paris, he had a thing for dead girls (I didn’t really mean that the way it sounded). Maybe the death mask his great grandfather had purchased from a coroner while visiting France was hanging on the wall in his workshop.\n\nNow, nearly 60 years later, this same face graces CPR dummies around the world. And still, nobody knows who the hell she is.\n\nAlthough this woman obviously had a turn of bad luck, after all, it’s not good luck that ends up with you floating in a river, she, postmortem, has become rather popular.\n\nJust imagine the number of people who have laid their lips on hers.\n\nThanks for the A2A Steven Harris!', 'aiModelVersion': '1'}",0.9998
Franklin Veaux,4y,Who decided that everything multiplied by zero equals zero?,"If I have three boxes, and each box has five gold bars in it, how many gold bars do I have? Fifteen.

If I have zero boxes, and each box has five gold bars in it, how many gold bars do I have? As it turns out, I have zero gold bars.

I know this because I counted them. Yep, still zero. I have no gold bars.

Nobody “decided” it. It’s an observable fact.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/x3tpguczoef9m4wk', 'title': 'Who decided that everything multiplied by zero equals zero?', 'score': {'original': 0.4803, 'ai': 0.5197}, 'blocks': [{'text': 'If I have three boxes, and each box has five gold bars in it, how many gold bars do I have? Fifteen.\n\nIf I have zero boxes, and each box has five gold bars in it, how many gold bars do I have? As it turns out, I have zero gold bars.\n\nI know this because I counted them. Yep, still zero. I have no gold bars.\n\nNobody “decided” it. It’s an observable fact.', 'result': {'fake': 0.5197, 'real': 0.4803}, 'status': 'success'}], 'credits_used': 1, 'credits': 1995042, 'subscription': 0, 'content': 'If I have three boxes, and each box has five gold bars in it, how many gold bars do I have? Fifteen.\n\nIf I have zero boxes, and each box has five gold bars in it, how many gold bars do I have? As it turns out, I have zero gold bars.\n\nI know this because I counted them. Yep, still zero. I have no gold bars.\n\nNobody “decided” it. It’s an observable fact.', 'aiModelVersion': '1'}",0.4803
Tom Robinson,Updated 3y,What are some of the most audacious calculations in the history of mathematics?,"In the history of mathematics, it can be difficult to match the sheer audacity of the great minds of Ancient Greece. At a time before the invention of notebook paper—even before the invention of zero—several visionary Greeks managed to calculate aspects of the natural world that remain staggering to this day.

I will focus on two such audacious calculations from two of the greatest minds ever to grace this Earth with their consideration. Both lived in the 3rd Century BCE, and though neither one lived in modern-day Greece (one was born in Libya and worked in Egypt, the other was from Sicily), they both fall squarely under the umbrella of Greek thought and study. Both had the audacity to reach for the impossible, and both used unparalleled brilliance to reach their conclusions.

So let me address each in turn.

Eratosthenes of Cyrene

Image Credit[1]

Eratosthenes may not have been the most attractive dude on the block, but boy was he ever smart. In fact, smart doesn’t really cover what Eratosthenes was. Born in Cyrene, on the northern coast of Africa, Eratosthenes’ education brought him eventually to Athens, where he studied philosophy first under the Stoic Zeno of Citium[2] and then under the Stoic/Cynic Aristo of Chios.[3] During this time, he began to write mathematical analysis of Plato’s postulates and even began writing poetry on the side.

His poetry was so good that it began to get him some recognition, and in time even crossed the sea to reach the halls of the Pharaohs in Egypt. Ptolemy III Euergetes invited him to be the head Librarian of the Great Library at Alexandria. As head Librarian, he did a great deal to expand the library’s already-unparalleled collection of knowledge. He also invented an early cataloguing system, so that scrolls could more easily be found within the library’s extensive archives.

It is clear that, throughout his tenure as librarian, he did more than simply copy and tag texts. Finding himself with access to more knowledge than perhaps any other man on Earth at the time, Eratosthenes seems to have recognized his privilege, and at the same time allowed his curiosity to run wild as he sought to amass as much knowledge and understanding as could be fit within a human mind.

His studies led to some answers but, like any great scholar, he always found himself with a surplus of questions that surpassed even his his knowledge to address. One question in particular would lead him to a calculative effort that is truly exquisite in its audacity. It is a question that would likely tax even you—dear reader—living in the modern world of calculators, textbooks, and mathematical concepts that would not be devised until centuries after his death:

How large is the Earth?

Take a moment to consider how you might try to answer that question if you were deprived of the access to any authority that could simply hand the answer to you on a platter. If you had to calculate the size of the Earth without looking it up, how confident do you feel that you could do so, even with modern technology? How would you prove it?

Now imagine that you are living in a world without the internet, without calculators, without pens and paper, without zero, and without anyone who has ever even tried to make this calculation before, and you can perhaps begin to understand the conditions which were met by Eratosthenes. Would you even begin to know where or how to start?

Before I begin on his calculation, I should take a moment to dispel a myth. It is often taught in America that back in Columbus’s day, everyone thought that the world was flat. That is, for lack of a better word, a lie. People had understood that the Earth was a sphere since well before Eratosthenes, and by his day every educated Greek was well aware of the globular Earth. That is remarkably important if we are to sensibly examine his calculation of its circumference.

It is hard to say how exactly the process began, but Eratosthenes set out to make this unfathomably audacious calculation for himself. There was a single piece of information that passed through his grasp as he studied in his library, and he had the presence of mind to recognize it as the pivotal fact that it was in his pursuit.

At some point, Eratosthanes read the account of someone who had travelled through the city of Syene, in southern Egypt (a short way south of the modern city of Aswan, the location of Syene is now under the waters of Lake Nasser, which was created by the Aswan Dam in order to bring hydroelectric power to Egypt). The account said that there was a deep well in Syene in which, at noon on the Summer Solstice, the sun shone all the way to the bottom without casting any shadow.

That might not sound like much to you, dear reader, but Eratosthenes recognized it for the exquisite datum that it was. That meant that on the Summer Solstice, the sun stood directly above the city of Syene at noon, meaning that Syene must lie exactly on the Tropic of Cancer.[4] From there, all it would take to calculate the circumference of the Earth was patience and mathematics.

Those unfamiliar with Greek often spend their lives blissfully unaware of the fact that the word “geometry” literally means “earth-measuring,” and it was Eratosthenes who first exemplified its capability to accomplish that end. He commissioned a long wooden pole to be crafted, perfectly straight and with a length that was measured exactly. This pole he had erected in Alexandria as close to perfectly vertical as the tools of his day would allow. Now he only had to wait.

On the Summer Solstice, he had the greatest masters of measurement in the land wait for the sun to reach its apex. At exactly noon, measurements were taken of the shadow cast by the pole. More mathematically-minded readers will likely have worked out the rest of the calculation for themselves, but I am more than happy to explain it for the rest of us.

The length of the pole (which he knew) and the length of the shadow (which had just been measured) provided two sides of a right triangle. From there, the trigonometric principles established by Pythagoras and embellished upon by those who came after him allowed Eratosthenes to calculate the angle at which the same sun that sat vertically above Syene cast its rays upon Alexandria, and thereby to determine the angular degrees that divided the two cities in the greater sphere of the Earth.

Image Credit[5]

Once he had calculated the angular distance between Alexandria and Syene from the perspective of the Earth’s core, all Eratosthenes needed was the distance between the two to extrapolate the total circumference of the Earth. In this regard, he had a great deal of luck on his side. For all its twists, turns, and cataracts, the Nile River, on which both cities were situated, runs a remarkably longitudinal course throughout all of Egypt. Taken as a whole, its adherence to a perfectly south-to-north course is almost uncanny. Furthermore, as the most trafficked river of trade in the world (at the time) there were already extensive and continually-updated documents measuring the distances between all of its major ports of trade.

And Eratosthenes was the overseer of the greatest compilation of knowledge on Earth, and in Egypt most particularly.

So it was that Eratosthenes, using only the facts he had read, his own grasp of the principles of mathematics, and a bit of on-the-fly thinking, calculated the circumference of the entire planet more than seventeen centuries before Columbus would drastically underestimate that same calculation and believe that he had found India when he was actually in the Dominican Republic.

By modern calculations, Eratosthenes’ calculation was only off by about 41 miles,[6] roughly the distance from San Jose to San Francisco.

(The circle above has a diameter of 41 miles) Also, not sure if I need to source a screenshot, but here is the site I used.[7]

Now if you ask me, that is pretty effing audacious. To stare down a calculation that had never even been attempted and to work it out so perfectly with means so limited is truly a testament to the ambitious ingenuity of the human mind.

But Eratosthenes was not alone, and my next entry might even outdo him on sheer audacity, so let’s keep going.

Archimedes of Syracuse

Image Source[8]

Now when it comes to ultra-badass scientists/mathematicians, there really may be no parallel to Archimedes. His brilliance—matched only by his ultra-badassery—is so intense that there is still some skepticism regarding the assertion that anyone could ever have truly been as much of a baller as Archimedes appears to have been every single day.

Among his myriad* accomplishments not to be examined in this answer, you will find:

An efficient water-pump that still bears his name (and which, for the record, was apparently invented to pump water from the hull of a warship he had invented, which just so happened to be the largest in the history of the Ancient World).[9]
The use of mirrors to literally set enemy ships on fire, which still—twenty-three centuries later—continues to bear the unbelievably sci-fi name of the “Archimedes Heat Ray.”

A Renaissance Painting of the Heat Ray from Wikimedia Commons, still inspiring fear and awe 1800 years later.

Devising a way to calculate the density of an object by combining the measurement of its displacement in a measured quantity of water with its mass, now known as Archimedes' principle
 (the discovery of which was apparently made while he was in the bath, leading him to famously shout “Eureka!” (or, more properly, “εὕρηκα,” meaning, “I’ve found it,”) while running naked around the building which contained the bath that no longer contained the ecstatic Archimedes).

But, worthy as all those discoveries were, they are subjects for another day. Now we are looking at something that somehow manages to be more audacious than sprinting naked through the halls of academia, pumping water from the bellies of gargantuan warships, or even—somehow, bafflingly—setting enemy fleets on fire with nothing but a mirror and the Sun.

As I have already mentioned, the mathematicians of the Hellenistic period
, for all their brilliance and far-sightedness, were working with a vastly inferior set of tools than those with which I empower my Second-Graders every day in math class. Indeed, every day I teach place value to a group of seven-and-eight year olds who already seem to think that it is kids stuff. The concept of zero, and the magical way that it allows a mere ten digits (itself included) to express an infinite spectrum of numerical value is so ingrained on us these days that it seems quite basic, even to children.

That’s why I always love to tell them about Archimedes.

See, in Archimedes’ day, the numbers didn’t go on forever like they do now. Of course, people recognized that there was no “highest number,” but even within the culture of mathematics that had the likes of Euclid and Pythagoras for inspiration, it was widely accepted that some numbers were just too high to be discussed in any kind of a constructive manner. Greek Numerals were drastically different than the numbers we know and love today. The concept of zero and the place-value it empowered would not even be invented in India until about six centuries after Archimedes’ death, and the Arabs wouldn’t bring it to prominence in Europe until centuries thereafter.

The Ancient Greeks did math with letters. While they used the Greek alphabet, their system can be transferred to our own Latin alphabet without much effort for the ease of explanation. To put it in our own letters, the Greek system would use the first nine letters (a, b, c, d, e, f, g, h, and i) to represent the numbers 1–9. Then the following letters could be used to represent the next order of magnitude, so that j, k, l, m, n, o, p, q, and r would represent 10–90 respectively. As numbers got higher, it was decided that not every one of the nine non-zero numerals requires representation. But still, the problem of simply running out of letters remained.

As such, Greek Numerals had an upper bound, above which the numerals had yet to be invented to express such a quantity. For the Greeks, as for a remarkable number of other contemporary cultures, the greatest expressible number was 10,000, which they called “μυριάς” (myrias). Anything above 10,000 was considered an uncountable multitude, which is why we still use the term “myriad” to mean “innumerable” in modern English.[10]

(Note: I discuss this a bit in another answer on a very different subject, but one well worth a read.)

One of the common analogies in Archimedes’ day was that the number of grains of sand on a beach was something that could never be mathematically expressed with any degree of exactitude. It was simply, “a lot,” and everyone should be content to leave it at that.

As it happens, Archimedes didn’t like other people telling him what was beyond the bounds of his ability to calculate or express. Not only did he scoff at the idea of the grains of sand on a beach defying his calculative abilities, but he decided to take the proposed impossibility about ten-trillion steps further.

“The grains of sand on a beach are too numerous to be calculated, you say?” Archimedes quipped. “Hold my fermented grape mash. I’m gonna calculate how many grains of sand it would take to fill the universe!”

Of course, those weren’t his exact words, nor even any kind of close translation, but I nonetheless feel that the sheer audacity of Archimedes’ mathematical cojones are accurately conveyed in the lines above. Not only did he reject the innumerable quantity of sand on a beach, he jumped straight to the whole damn universe (as he understood it, of course).

But to do that, he first had to invent his own number system.

Without spending too much time going into the details of his invention, Archimedes saw that the numerical systems of his day could be extrapolated out exponentially to the point that they could encompass numbers on a scale that we still haven’t come up with specific names for.

(Note: as much of a Greek purist as I tend to be, I will transition all of the terms in the following section into English for you, dear reader. You’re welcome.)

Archimedes figured that if myriad was the highest number, then he could start working from there. Myriad—which is to say 10,000—became his “number of the first order.” You could have one myriad, two myriad, three… I’m just playing. You could go all the way up to a myriad myriad, also known as 
10
8
108
, which could then be used as a new substitute for myriad. He named this new quantity as his “number of the second order.” And then the pattern continued.

This system allowed Archimedes to succinctly write numbers ranging up to 
(
(
10
8
)
(
10
8
)
)
10
8
((108)(108))108
 . As someone with very little experience with LaTeX math coding, I hope that comes out coherently, but in case it doesn’t, that is a one with eighty-quadrillion (80,000,000,000,000,000) zeroes.

That’s a pretty effing huge number, and the fact that Archimedes took the Greek Numeral system all the way from 10,000 to 
10
79
,
999
,
999
,
999
,
999
,
996
1079,999,999,999,999,996
 times as much is pretty hardcore if you ask me.

But that is not all.

Now that he had invented super-huge numbers, Archimedes had to calculate the size of the universe, and even in that small step, he was so far ahead of his time that it is difficult to even fathom just how insanely right he was.

But first, let’s take a moment to examine what a word like “universe” would mean to an ancient Greek. To Archimedes, the “universe” was generally confined to what we would now call the solar system. The universe had a single sphere at its center, and a whole host of planets circulating around it. Beyond that was a spherical edge painted with stars. The very concept of foreign galaxies was yet to be devised.

Indeed, for the greater part of the next two millennia, it would be held as an indisputable fact that the Earth was the center of the universe, and even 1800 years after the death of Archimedes, the assertion that it might be otherwise would remain so revolutionary as to merit oppression against those who spoke it. When Copernicus’ heliocentric theories were first printed—more than eighteen centuries after the death of Archimedes—they were enormously controversial.

Not to Archimedes.

Indeed, the works of the first great heliocentric astronomer, Aristarchus of Samos
, who I discuss in this remarkably popular answer, were lost to history entirely, and it is entirely through the work of Archimedes that we know of his brilliance at all. Were it not for his incredible work, even educated people would still blithely assert that Copernicus was the first to posit that the Earth orbited the Sun, and the depth of Greek insight into the matter would lie in the darkened vaults of unrecorded history.

While I may not be able to solidly attribute Archimedes’ reason for believing that the Earth revolved around the Sun, it is undoubtedly true that he accepted the heliocentric model of Aristarchus as the one by which he ought to make his calculations.

Armed with his new form of advanced large-number mathematics and his unbelievably-prescient Aristarchan Heliocentric model, Archimedes determined that the number of grains of sand that it would take to fill the universe (a.k.a. the Solar System) was approximately 
10
64
1064
.

I would comment on the accuracy of that calculation if I was anywhere near brilliant enough to do so. As it stands, all I can really say is, “damn, that Archimedes dude was smart as hell!”

Conclusion

I have always thought that there was something staggeringly audacious about the very premise of mathematics. Terms like infinity, which are beyond the scale of the human mind to comprehend, get thrown around in school classrooms like Halloween candy. Every so often, I have a student ask me the remarkable question, “how high can you count?” The truth of the answer, that I could keep counting not only for the rest of my life, but for the length of time that the universe has existed without even nearly exhausting the list of numbers whose names I have already learned in my infinitesimal time on Earth almost moves me to tears.

Numbers are a different dimension. We can write them, but after a certain point, we lose our ability to even conceptualize their scale or scope. I can talk about 7.5ish Billion people on Earth, but that number means literally nothing more to me than μυριάς did to the Greeks. At that point, it’s all just “a friggin lot.”

I would therefore posit that a huge percentage of the mathematical calculations that a high school calculus student makes over the course of a single standard class exist on a level of audacity that they will never fully realize.

This is why I like to teach children about the history of mathematics. Algebra is so much more beautiful when you see it through the eyes of Muhammad ibn Musa al-Khwarizmi
, and when you know the words from which its name was taken: “calculation through the completion and balance of broken things.” I am sure that my translation is less-than-perfectly accurate, but it bears a portion of the beauty that is lost on algebra students.

If I am honest, I don’t think that the most audacious mathematical calculations are confined to the Ancient World. Truly I believe that mankind’s most audacious calculations are still ahead. I am so confident as to be pretty-well positive that what we have yet to learn will dwarf the whole monumental mass of what we have learned so far.

So I say we keep our eyes on the horizon. I say we keep our minds to the Aristarchuses of our time, and dare to believe in their monumental hypotheses. I say we take the word “incalculable” out of our personal lexicons, and set ourselves to the task of continuing the path of brilliance that has carried us this far.

After all, we are humanity. We may be small, but look what we’ve done so far!

Just imagine what we can do next.

Thank’s for reading.

Now it’s your turn.

*See what I did there?

Note: Somehow, bafflingly, I managed to get through this whole answer without mentioning that the name of Archimedes’ revolutionary text, originally called Ψαμμίτης (Psammites) is usually translated into English as the incredibly awesome-sounding title: The Sand Reckoner.

Here is an annotated translation: Archimedes, Sand-Reckoner, Intro.

Update: So this answer seems to have rather inexplicably gotten some traction, and I have several comments questioning how reasonable Archimedes’ calculation of the number of grains of sand that could fit into the Solar System/Universe (which had a radius of around one lightyear, by his estimation) was, and several comments have claimed that he was off by many orders of magnitude.

Rather than arguing Archimedes’ rigor or accuracy, I would rather like to point out that a “grain of sand” has no officially established size, and that the grains with which Archimedes performed his calculations were likely quite a bit smaller than those being perceived by dissenters.

Indeed, given that Archimedes was conducting his work well after that of Democritus and Epicurus, I am not entirely convinced that the “grains of sand” to which Archimedes refers were not essentially synonymous to atoms in his mind.

Of course, that only makes him more incorrect, but if we take into account the sort of limited perception the Ancient Greeks had about atoms, I think it makes the whole calculation a great deal more sensible. The word “atom” comes from the Greek for “unbreakable.” The prefix a- (as in atheist) is negatory, and the root “-tom” (as in lobotomy) means “to cut.”

The root of Greek Atomic Theory was that microscopic infinity just didn’t make sense. If everything could be broken, then everything would be insubstantial. Democritus and Epicurus held that there must be a smallest form of matter, beyond which it could no longer be broken down.

I think that Archimedes’ calculation played upon this theory by using the smallest possible grain of sand as its calculative unit rather than the average grain. Indeed, Archimedes posited that a myriad (ten-thousand) grains of sand could fit into a single poppy-seed. If you know how small a poppy-seed is, then you can hopefully conceptualize just how small Archimedes’ grains of sand are, and hopefully understand my assertion that they may have been a filler-term for atoms.

Here it is in the annotated translation of his own words:

With some of these supposed and others demonstrated, the proposed claim will be proved. For since it is supposed that the diameter of the poppy-seed is not less than a fortieth-part of an inch, it is clear that the sphere having an inch diameter is not larger than can contain six-ten-thousand and four-thousand poppy-seeds. For they are multiples of the sphere having its diameter a fortieth-part of an inch by the stated number. For it has been proved that spheres have the triplicate ratio to one another of their diameters. It is clear that if a sphere having an inch diameter is filled with sand, the number of the sand would not be larger than ten-thousand-times six-ten-thousand and four-thousand.[11]

I hope this clears some things up. I doubt it, but I hope…

Footnotes

[1] Biography of Eratosthenes, Greek Mathematician and Geographer
[2] Zeno of Citium - Wikipedia
[3] Aristo of Chios - Wikipedia
[4] Tropic of Cancer - Wikipedia
[5] Eratosthenes | Biography, Discoveries, & Facts
[6] Eratosthenes - Wikipedia
[7] Draw a circle with a radius on a map
[8] Archimedes | Facts & Biography
[9] Archimedes' screw - Wikipedia
[10] myriad - Wiktionary
[11] Archimedes, Sand-Reckoner, ch. 4","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/vsiq2e4c75y0xojm', 'title': 'What are some of the most audacious calculations in the history of mathematics?', 'score': {'original': 0.850775, 'ai': 0.149225}, 'blocks': [{'text': 'In the history of mathematics, it can be difficult to match the sheer audacity of the great minds of Ancient Greece. At a time before the invention of notebook paper—even before the invention of zero—several visionary Greeks managed to calculate aspects of the natural world that remain staggering to this day.\n\nI will focus on two such audacious calculations from two of the greatest minds ever to grace this Earth with their consideration. Both lived in the 3rd Century BCE, and though neither one lived in modern-day Greece (one was born in Libya and worked in Egypt, the other was from Sicily), they both fall squarely under the umbrella of Greek thought and study. Both had the audacity to reach for the impossible, and both used unparalleled brilliance to reach their conclusions.\n\nSo let me address each in turn.\n\nEratosthenes of Cyrene\n\nImage Credit[1]\n\nEratosthenes may not have been the most attractive dude on the block, but boy was he ever smart. In fact, smart doesn’t really cover what Eratosthenes was. Born in Cyrene, on the northern coast of Africa, Eratosthenes’ education brought him eventually to Athens, where he studied philosophy first under the Stoic Zeno of Citium[2] and then under the Stoic/Cynic Aristo of Chios.[3] During this time, he began to write mathematical analysis of Plato’s postulates and even began writing poetry on the side.\n\nHis poetry was so good that it began to get him some recognition, and in time even crossed the sea to reach the halls of the Pharaohs in Egypt. Ptolemy III Euergetes invited him to be the head Librarian of the Great Library at Alexandria. As head Librarian, he did a great deal to expand the library’s already-unparalleled collection of knowledge. He also invented an early cataloguing system, so that scrolls could more easily be found within the library’s extensive archives.\n\nIt is clear that, throughout his tenure as librarian, he did more than simply copy and tag texts. Finding himself with access to more knowledge than perhaps any other man on Earth at the time, Eratosthenes seems to have recognized his privilege, and at the same time allowed his curiosity to run wild as he sought to amass as much knowledge and understanding as could be fit within a human mind.\n\nHis studies led to some answers but, like any great scholar, he always found himself with a surplus of questions that surpassed even his his knowledge to address. One question in particular would lead him to a calculative effort that is truly exquisite in its audacity. It is a question that would likely tax even you—dear reader—living in the modern world of calculators, textbooks, and mathematical concepts that would not be devised until centuries after his death:\n\nHow large is the Earth?\n\nTake a moment to consider how you might try to answer that question if you were deprived of the access to any authority that could simply hand the answer to you on a platter. If you had to calculate the size of the Earth without looking it up, how confident do you feel that you could do so, even with modern technology?', 'result': {'fake': 0.0004, 'real': 0.9996}, 'status': 'success'}, {'text': 'How would you prove it?\n\nNow imagine that you are living in a world without the internet, without calculators, without pens and paper, without zero, and without anyone who has ever even tried to make this calculation before, and you can perhaps begin to understand the conditions which were met by Eratosthenes. Would you even begin to know where or how to start?\n\nBefore I begin on his calculation, I should take a moment to dispel a myth. It is often taught in America that back in Columbus’s day, everyone thought that the world was flat. That is, for lack of a better word, a lie. People had understood that the Earth was a sphere since well before Eratosthenes, and by his day every educated Greek was well aware of the globular Earth. That is remarkably important if we are to sensibly examine his calculation of its circumference.\n\nIt is hard to say how exactly the process began, but Eratosthenes set out to make this unfathomably audacious calculation for himself. There was a single piece of information that passed through his grasp as he studied in his library, and he had the presence of mind to recognize it as the pivotal fact that it was in his pursuit.\n\nAt some point, Eratosthanes read the account of someone who had travelled through the city of Syene, in southern Egypt (a short way south of the modern city of Aswan, the location of Syene is now under the waters of Lake Nasser, which was created by the Aswan Dam in order to bring hydroelectric power to Egypt). The account said that there was a deep well in Syene in which, at noon on the Summer Solstice, the sun shone all the way to the bottom without casting any shadow.\n\nThat might not sound like much to you, dear reader, but Eratosthenes recognized it for the exquisite datum that it was. That meant that on the Summer Solstice, the sun stood directly above the city of Syene at noon, meaning that Syene must lie exactly on the Tropic of Cancer.[4] From there, all it would take to calculate the circumference of the Earth was patience and mathematics.\n\nThose unfamiliar with Greek often spend their lives blissfully unaware of the fact that the word “geometry” literally means “earth-measuring,” and it was Eratosthenes who first exemplified its capability to accomplish that end. He commissioned a long wooden pole to be crafted, perfectly straight and with a length that was measured exactly. This pole he had erected in Alexandria as close to perfectly vertical as the tools of his day would allow. Now he only had to wait.\n\nOn the Summer Solstice, he had the greatest masters of measurement in the land wait for the sun to reach its apex. At exactly noon, measurements were taken of the shadow cast by the pole. More mathematically-minded readers will likely have worked out the rest of the calculation for themselves, but I am more than happy to explain it for the rest of us.\n\nThe length of the pole (which he knew) and the length of the shadow', 'result': {'fake': 0.0186, 'real': 0.9814}, 'status': 'success'}, {'text': '(which had just been measured) provided two sides of a right triangle. From there, the trigonometric principles established by Pythagoras and embellished upon by those who came after him allowed Eratosthenes to calculate the angle at which the same sun that sat vertically above Syene cast its rays upon Alexandria, and thereby to determine the angular degrees that divided the two cities in the greater sphere of the Earth.\n\nImage Credit[5]\n\nOnce he had calculated the angular distance between Alexandria and Syene from the perspective of the Earth’s core, all Eratosthenes needed was the distance between the two to extrapolate the total circumference of the Earth. In this regard, he had a great deal of luck on his side. For all its twists, turns, and cataracts, the Nile River, on which both cities were situated, runs a remarkably longitudinal course throughout all of Egypt. Taken as a whole, its adherence to a perfectly south-to-north course is almost uncanny. Furthermore, as the most trafficked river of trade in the world (at the time) there were already extensive and continually-updated documents measuring the distances between all of its major ports of trade.\n\nAnd Eratosthenes was the overseer of the greatest compilation of knowledge on Earth, and in Egypt most particularly.\n\nSo it was that Eratosthenes, using only the facts he had read, his own grasp of the principles of mathematics, and a bit of on-the-fly thinking, calculated the circumference of the entire planet more than seventeen centuries before Columbus would drastically underestimate that same calculation and believe that he had found India when he was actually in the Dominican Republic.\n\nBy modern calculations, Eratosthenes’ calculation was only off by about 41 miles,[6] roughly the distance from San Jose to San Francisco.\n\n(The circle above has a diameter of 41 miles) Also, not sure if I need to source a screenshot, but here is the site I used.[7]\n\nNow if you ask me, that is pretty effing audacious. To stare down a calculation that had never even been attempted and to work it out so perfectly with means so limited is truly a testament to the ambitious ingenuity of the human mind.\n\nBut Eratosthenes was not alone, and my next entry might even outdo him on sheer audacity, so let’s keep going.\n\nArchimedes of Syracuse\n\nImage Source[8]\n\nNow when it comes to ultra-badass scientists/mathematicians, there really may be no parallel to Archimedes. His brilliance—matched only by his ultra-badassery—is so intense that there is still some skepticism regarding the assertion that anyone could ever have truly been as much of a baller as Archimedes appears to have been every single day.\n\nAmong his myriad* accomplishments not to be examined in this answer, you will find:\n\nAn efficient water-pump that still bears his name (and which, for the record, was apparently invented to pump water from the hull of a warship he had invented, which just so happened to be the largest in the history of the Ancient World).[9]\nThe use of mirrors to literally set enemy ships on fire, which still—twenty-three centuries later—continues to bear the unbelievably sci-fi name of the “Archimedes Heat Ray.”\n\nA Renaissance Painting of the Heat Ray', 'result': {'fake': 0.1754, 'real': 0.8246}, 'status': 'success'}, {'text': ""from Wikimedia Commons, still inspiring fear and awe 1800 years later.\n\nDevising a way to calculate the density of an object by combining the measurement of its displacement in a measured quantity of water with its mass, now known as Archimedes' principle\n (the discovery of which was apparently made while he was in the bath, leading him to famously shout “Eureka!” (or, more properly, “εὕρηκα,” meaning, “I’ve found it,”) while running naked around the building which contained the bath that no longer contained the ecstatic Archimedes).\n\nBut, worthy as all those discoveries were, they are subjects for another day. Now we are looking at something that somehow manages to be more audacious than sprinting naked through the halls of academia, pumping water from the bellies of gargantuan warships, or even—somehow, bafflingly—setting enemy fleets on fire with nothing but a mirror and the Sun.\n\nAs I have already mentioned, the mathematicians of the Hellenistic period\n, for all their brilliance and far-sightedness, were working with a vastly inferior set of tools than those with which I empower my Second-Graders every day in math class. Indeed, every day I teach place value to a group of seven-and-eight year olds who already seem to think that it is kids stuff. The concept of zero, and the magical way that it allows a mere ten digits (itself included) to express an infinite spectrum of numerical value is so ingrained on us these days that it seems quite basic, even to children.\n\nThat’s why I always love to tell them about Archimedes.\n\nSee, in Archimedes’ day, the numbers didn’t go on forever like they do now. Of course, people recognized that there was no “highest number,” but even within the culture of mathematics that had the likes of Euclid and Pythagoras for inspiration, it was widely accepted that some numbers were just too high to be discussed in any kind of a constructive manner. Greek Numerals were drastically different than the numbers we know and love today. The concept of zero and the place-value it empowered would not even be invented in India until about six centuries after Archimedes’ death, and the Arabs wouldn’t bring it to prominence in Europe until centuries thereafter.\n\nThe Ancient Greeks did math with letters. While they used the Greek alphabet, their system can be transferred to our own Latin alphabet without much effort for the ease of explanation. To put it in our own letters, the Greek system would use the first nine letters (a, b, c, d, e, f, g, h, and i) to represent the numbers 1–9. Then the following letters could be used to represent the next order of magnitude, so that j, k, l, m, n, o, p, q, and r would represent 10–90 respectively. As numbers got higher, it was decided that not every one of the nine non-zero numerals requires representation. But still, the problem of simply running out of letters remained.\n\nAs such, Greek Numerals had an upper bound, above which the numerals had yet to be invented to express such a quantity. For the Greeks, as for a remarkable number of"", 'result': {'fake': 0.0072, 'real': 0.9928}, 'status': 'success'}, {'text': 'other contemporary cultures, the greatest expressible number was 10,000, which they called “μυριάς” (myrias). Anything above 10,000 was considered an uncountable multitude, which is why we still use the term “myriad” to mean “innumerable” in modern English.[10]\n\n(Note: I discuss this a bit in another answer on a very different subject, but one well worth a read.)\n\nOne of the common analogies in Archimedes’ day was that the number of grains of sand on a beach was something that could never be mathematically expressed with any degree of exactitude. It was simply, “a lot,” and everyone should be content to leave it at that.\n\nAs it happens, Archimedes didn’t like other people telling him what was beyond the bounds of his ability to calculate or express. Not only did he scoff at the idea of the grains of sand on a beach defying his calculative abilities, but he decided to take the proposed impossibility about ten-trillion steps further.\n\n“The grains of sand on a beach are too numerous to be calculated, you say?” Archimedes quipped. “Hold my fermented grape mash. I’m gonna calculate how many grains of sand it would take to fill the universe!”\n\nOf course, those weren’t his exact words, nor even any kind of close translation, but I nonetheless feel that the sheer audacity of Archimedes’ mathematical cojones are accurately conveyed in the lines above. Not only did he reject the innumerable quantity of sand on a beach, he jumped straight to the whole damn universe (as he understood it, of course).\n\nBut to do that, he first had to invent his own number system.\n\nWithout spending too much time going into the details of his invention, Archimedes saw that the numerical systems of his day could be extrapolated out exponentially to the point that they could encompass numbers on a scale that we still haven’t come up with specific names for.\n\n(Note: as much of a Greek purist as I tend to be, I will transition all of the terms in the following section into English for you, dear reader. You’re welcome.)\n\nArchimedes figured that if myriad was the highest number, then he could start working from there. Myriad—which is to say 10,000—became his “number of the first order.” You could have one myriad, two myriad, three… I’m just playing. You could go all the way up to a myriad myriad, also known as \n10\n8\n108\n, which could then be used as a new substitute for myriad. He named this new quantity as his “number of the second order.” And then the pattern continued.\n\nThis system allowed Archimedes to succinctly write numbers ranging up to \n(\n(\n10\n8\n)\n(\n10\n8\n)\n)\n10\n8\n((108)(108))108\n . As someone with very little experience with LaTeX math coding, I hope that comes out coherently, but in case it doesn’t, that is a one with eighty-quadrillion (80,000,000,000,000,000) zeroes.\n\nThat’s a pretty effing huge number, and the fact that Archimedes took the Greek Numeral system all the way from 10,000 to \n10\n79\n,\n999\n,\n999\n,\n999\n,\n999\n,\n996\n1079,999,999,999,999,996\n times as much is pretty hardcore if you ask me.\n\nBut that is not all.\n\nNow that he had invented super-huge numbers, Archimedes had to calculate the size of the universe, and even', 'result': {'fake': 0.0905, 'real': 0.9095}, 'status': 'success'}, {'text': 'in that small step, he was so far ahead of his time that it is difficult to even fathom just how insanely right he was.\n\nBut first, let’s take a moment to examine what a word like “universe” would mean to an ancient Greek. To Archimedes, the “universe” was generally confined to what we would now call the solar system. The universe had a single sphere at its center, and a whole host of planets circulating around it. Beyond that was a spherical edge painted with stars. The very concept of foreign galaxies was yet to be devised.\n\nIndeed, for the greater part of the next two millennia, it would be held as an indisputable fact that the Earth was the center of the universe, and even 1800 years after the death of Archimedes, the assertion that it might be otherwise would remain so revolutionary as to merit oppression against those who spoke it. When Copernicus’ heliocentric theories were first printed—more than eighteen centuries after the death of Archimedes—they were enormously controversial.\n\nNot to Archimedes.\n\nIndeed, the works of the first great heliocentric astronomer, Aristarchus of Samos\n, who I discuss in this remarkably popular answer, were lost to history entirely, and it is entirely through the work of Archimedes that we know of his brilliance at all. Were it not for his incredible work, even educated people would still blithely assert that Copernicus was the first to posit that the Earth orbited the Sun, and the depth of Greek insight into the matter would lie in the darkened vaults of unrecorded history.\n\nWhile I may not be able to solidly attribute Archimedes’ reason for believing that the Earth revolved around the Sun, it is undoubtedly true that he accepted the heliocentric model of Aristarchus as the one by which he ought to make his calculations.\n\nArmed with his new form of advanced large-number mathematics and his unbelievably-prescient Aristarchan Heliocentric model, Archimedes determined that the number of grains of sand that it would take to fill the universe (a.k.a. the Solar System) was approximately \n10\n64\n1064\n.\n\nI would comment on the accuracy of that calculation if I was anywhere near brilliant enough to do so. As it stands, all I can really say is, “damn, that Archimedes dude was smart as hell!”\n\nConclusion\n\nI have always thought that there was something staggeringly audacious about the very premise of mathematics. Terms like infinity, which are beyond the scale of the human mind to comprehend, get thrown around in school classrooms like Halloween candy. Every so often, I have a student ask me the remarkable question, “how high can you count?” The truth of the answer, that I could keep counting not only for the rest of my life, but for the length of time that the universe has existed without even nearly exhausting the list of numbers whose names I have already learned in my infinitesimal time on Earth almost moves me to tears.\n\nNumbers are a different dimension. We can write them, but after a certain point, we lose our ability to even conceptualize their scale or scope. I can talk about 7.5ish Billion', 'result': {'fake': 0.0307, 'real': 0.9693}, 'status': 'success'}, {'text': 'people on Earth, but that number means literally nothing more to me than μυριάς did to the Greeks. At that point, it’s all just “a friggin lot.”\n\nI would therefore posit that a huge percentage of the mathematical calculations that a high school calculus student makes over the course of a single standard class exist on a level of audacity that they will never fully realize.\n\nThis is why I like to teach children about the history of mathematics. Algebra is so much more beautiful when you see it through the eyes of Muhammad ibn Musa al-Khwarizmi\n, and when you know the words from which its name was taken: “calculation through the completion and balance of broken things.” I am sure that my translation is less-than-perfectly accurate, but it bears a portion of the beauty that is lost on algebra students.\n\nIf I am honest, I don’t think that the most audacious mathematical calculations are confined to the Ancient World. Truly I believe that mankind’s most audacious calculations are still ahead. I am so confident as to be pretty-well positive that what we have yet to learn will dwarf the whole monumental mass of what we have learned so far.\n\nSo I say we keep our eyes on the horizon. I say we keep our minds to the Aristarchuses of our time, and dare to believe in their monumental hypotheses. I say we take the word “incalculable” out of our personal lexicons, and set ourselves to the task of continuing the path of brilliance that has carried us this far.\n\nAfter all, we are humanity. We may be small, but look what we’ve done so far!\n\nJust imagine what we can do next.\n\nThank’s for reading.\n\nNow it’s your turn.\n\n*See what I did there?\n\nNote: Somehow, bafflingly, I managed to get through this whole answer without mentioning that the name of Archimedes’ revolutionary text, originally called Ψαμμίτης (Psammites) is usually translated into English as the incredibly awesome-sounding title: The Sand Reckoner.\n\nHere is an annotated translation: Archimedes, Sand-Reckoner, Intro.\n\nUpdate: So this answer seems to have rather inexplicably gotten some traction, and I have several comments questioning how reasonable Archimedes’ calculation of the number of grains of sand that could fit into the Solar System/Universe (which had a radius of around one lightyear, by his estimation) was, and several comments have claimed that he was off by many orders of magnitude.\n\nRather than arguing Archimedes’ rigor or accuracy, I would rather like to point out that a “grain of sand” has no officially established size, and that the grains with which Archimedes performed his calculations were likely quite a bit smaller than those being perceived by dissenters.\n\nIndeed, given that Archimedes was conducting his work well after that of Democritus and Epicurus, I am not entirely convinced that the “grains of sand” to which Archimedes refers were not essentially synonymous to atoms in his mind.\n\nOf course, that only makes him more incorrect, but if we take into account the sort of limited perception the Ancient Greeks had about atoms, I think it makes the whole calculation a great deal more sensible. The word “atom” comes', 'result': {'fake': 0.7918, 'real': 0.2082}, 'status': 'success'}, {'text': ""from the Greek for “unbreakable.” The prefix a- (as in atheist) is negatory, and the root “-tom” (as in lobotomy) means “to cut.”\n\nThe root of Greek Atomic Theory was that microscopic infinity just didn’t make sense. If everything could be broken, then everything would be insubstantial. Democritus and Epicurus held that there must be a smallest form of matter, beyond which it could no longer be broken down.\n\nI think that Archimedes’ calculation played upon this theory by using the smallest possible grain of sand as its calculative unit rather than the average grain. Indeed, Archimedes posited that a myriad (ten-thousand) grains of sand could fit into a single poppy-seed. If you know how small a poppy-seed is, then you can hopefully conceptualize just how small Archimedes’ grains of sand are, and hopefully understand my assertion that they may have been a filler-term for atoms.\n\nHere it is in the annotated translation of his own words:\n\nWith some of these supposed and others demonstrated, the proposed claim will be proved. For since it is supposed that the diameter of the poppy-seed is not less than a fortieth-part of an inch, it is clear that the sphere having an inch diameter is not larger than can contain six-ten-thousand and four-thousand poppy-seeds. For they are multiples of the sphere having its diameter a fortieth-part of an inch by the stated number. For it has been proved that spheres have the triplicate ratio to one another of their diameters. It is clear that if a sphere having an inch diameter is filled with sand, the number of the sand would not be larger than ten-thousand-times six-ten-thousand and four-thousand.[11]\n\nI hope this clears some things up. I doubt it, but I hope…\n\nFootnotes\n\n[1] Biography of Eratosthenes, Greek Mathematician and Geographer\n[2] Zeno of Citium - Wikipedia\n[3] Aristo of Chios - Wikipedia\n[4] Tropic of Cancer - Wikipedia\n[5] Eratosthenes | Biography, Discoveries, & Facts\n[6] Eratosthenes - Wikipedia\n[7] Draw a circle with a radius on a map\n[8] Archimedes | Facts & Biography\n[9] Archimedes' screw - Wikipedia\n[10] myriad - Wiktionary\n[11] Archimedes, Sand-Reckoner, ch. 4"", 'result': {'fake': 0.0183, 'real': 0.9817}, 'status': 'success'}], 'credits_used': 41, 'credits': 1995001, 'subscription': 0, 'content': ""In the history of mathematics, it can be difficult to match the sheer audacity of the great minds of Ancient Greece. At a time before the invention of notebook paper—even before the invention of zero—several visionary Greeks managed to calculate aspects of the natural world that remain staggering to this day.\n\nI will focus on two such audacious calculations from two of the greatest minds ever to grace this Earth with their consideration. Both lived in the 3rd Century BCE, and though neither one lived in modern-day Greece (one was born in Libya and worked in Egypt, the other was from Sicily), they both fall squarely under the umbrella of Greek thought and study. Both had the audacity to reach for the impossible, and both used unparalleled brilliance to reach their conclusions.\n\nSo let me address each in turn.\n\nEratosthenes of Cyrene\n\nImage Credit[1]\n\nEratosthenes may not have been the most attractive dude on the block, but boy was he ever smart. In fact, smart doesn’t really cover what Eratosthenes was. Born in Cyrene, on the northern coast of Africa, Eratosthenes’ education brought him eventually to Athens, where he studied philosophy first under the Stoic Zeno of Citium[2] and then under the Stoic/Cynic Aristo of Chios.[3] During this time, he began to write mathematical analysis of Plato’s postulates and even began writing poetry on the side.\n\nHis poetry was so good that it began to get him some recognition, and in time even crossed the sea to reach the halls of the Pharaohs in Egypt. Ptolemy III Euergetes invited him to be the head Librarian of the Great Library at Alexandria. As head Librarian, he did a great deal to expand the library’s already-unparalleled collection of knowledge. He also invented an early cataloguing system, so that scrolls could more easily be found within the library’s extensive archives.\n\nIt is clear that, throughout his tenure as librarian, he did more than simply copy and tag texts. Finding himself with access to more knowledge than perhaps any other man on Earth at the time, Eratosthenes seems to have recognized his privilege, and at the same time allowed his curiosity to run wild as he sought to amass as much knowledge and understanding as could be fit within a human mind.\n\nHis studies led to some answers but, like any great scholar, he always found himself with a surplus of questions that surpassed even his his knowledge to address. One question in particular would lead him to a calculative effort that is truly exquisite in its audacity. It is a question that would likely tax even you—dear reader—living in the modern world of calculators, textbooks, and mathematical concepts that would not be devised until centuries after his death:\n\nHow large is the Earth?\n\nTake a moment to consider how you might try to answer that question if you were deprived of the access to any authority that could simply hand the answer to you on a platter. If you had to calculate the size of the Earth without looking it up, how confident do you feel that you could do so, even with modern technology? How would you prove it?\n\nNow imagine that you are living in a world without the internet, without calculators, without pens and paper, without zero, and without anyone who has ever even tried to make this calculation before, and you can perhaps begin to understand the conditions which were met by Eratosthenes. Would you even begin to know where or how to start?\n\nBefore I begin on his calculation, I should take a moment to dispel a myth. It is often taught in America that back in Columbus’s day, everyone thought that the world was flat. That is, for lack of a better word, a lie. People had understood that the Earth was a sphere since well before Eratosthenes, and by his day every educated Greek was well aware of the globular Earth. That is remarkably important if we are to sensibly examine his calculation of its circumference.\n\nIt is hard to say how exactly the process began, but Eratosthenes set out to make this unfathomably audacious calculation for himself. There was a single piece of information that passed through his grasp as he studied in his library, and he had the presence of mind to recognize it as the pivotal fact that it was in his pursuit.\n\nAt some point, Eratosthanes read the account of someone who had travelled through the city of Syene, in southern Egypt (a short way south of the modern city of Aswan, the location of Syene is now under the waters of Lake Nasser, which was created by the Aswan Dam in order to bring hydroelectric power to Egypt). The account said that there was a deep well in Syene in which, at noon on the Summer Solstice, the sun shone all the way to the bottom without casting any shadow.\n\nThat might not sound like much to you, dear reader, but Eratosthenes recognized it for the exquisite datum that it was. That meant that on the Summer Solstice, the sun stood directly above the city of Syene at noon, meaning that Syene must lie exactly on the Tropic of Cancer.[4] From there, all it would take to calculate the circumference of the Earth was patience and mathematics.\n\nThose unfamiliar with Greek often spend their lives blissfully unaware of the fact that the word “geometry” literally means “earth-measuring,” and it was Eratosthenes who first exemplified its capability to accomplish that end. He commissioned a long wooden pole to be crafted, perfectly straight and with a length that was measured exactly. This pole he had erected in Alexandria as close to perfectly vertical as the tools of his day would allow. Now he only had to wait.\n\nOn the Summer Solstice, he had the greatest masters of measurement in the land wait for the sun to reach its apex. At exactly noon, measurements were taken of the shadow cast by the pole. More mathematically-minded readers will likely have worked out the rest of the calculation for themselves, but I am more than happy to explain it for the rest of us.\n\nThe length of the pole (which he knew) and the length of the shadow (which had just been measured) provided two sides of a right triangle. From there, the trigonometric principles established by Pythagoras and embellished upon by those who came after him allowed Eratosthenes to calculate the angle at which the same sun that sat vertically above Syene cast its rays upon Alexandria, and thereby to determine the angular degrees that divided the two cities in the greater sphere of the Earth.\n\nImage Credit[5]\n\nOnce he had calculated the angular distance between Alexandria and Syene from the perspective of the Earth’s core, all Eratosthenes needed was the distance between the two to extrapolate the total circumference of the Earth. In this regard, he had a great deal of luck on his side. For all its twists, turns, and cataracts, the Nile River, on which both cities were situated, runs a remarkably longitudinal course throughout all of Egypt. Taken as a whole, its adherence to a perfectly south-to-north course is almost uncanny. Furthermore, as the most trafficked river of trade in the world (at the time) there were already extensive and continually-updated documents measuring the distances between all of its major ports of trade.\n\nAnd Eratosthenes was the overseer of the greatest compilation of knowledge on Earth, and in Egypt most particularly.\n\nSo it was that Eratosthenes, using only the facts he had read, his own grasp of the principles of mathematics, and a bit of on-the-fly thinking, calculated the circumference of the entire planet more than seventeen centuries before Columbus would drastically underestimate that same calculation and believe that he had found India when he was actually in the Dominican Republic.\n\nBy modern calculations, Eratosthenes’ calculation was only off by about 41 miles,[6] roughly the distance from San Jose to San Francisco.\n\n(The circle above has a diameter of 41 miles) Also, not sure if I need to source a screenshot, but here is the site I used.[7]\n\nNow if you ask me, that is pretty effing audacious. To stare down a calculation that had never even been attempted and to work it out so perfectly with means so limited is truly a testament to the ambitious ingenuity of the human mind.\n\nBut Eratosthenes was not alone, and my next entry might even outdo him on sheer audacity, so let’s keep going.\n\nArchimedes of Syracuse\n\nImage Source[8]\n\nNow when it comes to ultra-badass scientists/mathematicians, there really may be no parallel to Archimedes. His brilliance—matched only by his ultra-badassery—is so intense that there is still some skepticism regarding the assertion that anyone could ever have truly been as much of a baller as Archimedes appears to have been every single day.\n\nAmong his myriad* accomplishments not to be examined in this answer, you will find:\n\nAn efficient water-pump that still bears his name (and which, for the record, was apparently invented to pump water from the hull of a warship he had invented, which just so happened to be the largest in the history of the Ancient World).[9]\nThe use of mirrors to literally set enemy ships on fire, which still—twenty-three centuries later—continues to bear the unbelievably sci-fi name of the “Archimedes Heat Ray.”\n\nA Renaissance Painting of the Heat Ray from Wikimedia Commons, still inspiring fear and awe 1800 years later.\n\nDevising a way to calculate the density of an object by combining the measurement of its displacement in a measured quantity of water with its mass, now known as Archimedes' principle\n (the discovery of which was apparently made while he was in the bath, leading him to famously shout “Eureka!” (or, more properly, “εὕρηκα,” meaning, “I’ve found it,”) while running naked around the building which contained the bath that no longer contained the ecstatic Archimedes).\n\nBut, worthy as all those discoveries were, they are subjects for another day. Now we are looking at something that somehow manages to be more audacious than sprinting naked through the halls of academia, pumping water from the bellies of gargantuan warships, or even—somehow, bafflingly—setting enemy fleets on fire with nothing but a mirror and the Sun.\n\nAs I have already mentioned, the mathematicians of the Hellenistic period\n, for all their brilliance and far-sightedness, were working with a vastly inferior set of tools than those with which I empower my Second-Graders every day in math class. Indeed, every day I teach place value to a group of seven-and-eight year olds who already seem to think that it is kids stuff. The concept of zero, and the magical way that it allows a mere ten digits (itself included) to express an infinite spectrum of numerical value is so ingrained on us these days that it seems quite basic, even to children.\n\nThat’s why I always love to tell them about Archimedes.\n\nSee, in Archimedes’ day, the numbers didn’t go on forever like they do now. Of course, people recognized that there was no “highest number,” but even within the culture of mathematics that had the likes of Euclid and Pythagoras for inspiration, it was widely accepted that some numbers were just too high to be discussed in any kind of a constructive manner. Greek Numerals were drastically different than the numbers we know and love today. The concept of zero and the place-value it empowered would not even be invented in India until about six centuries after Archimedes’ death, and the Arabs wouldn’t bring it to prominence in Europe until centuries thereafter.\n\nThe Ancient Greeks did math with letters. While they used the Greek alphabet, their system can be transferred to our own Latin alphabet without much effort for the ease of explanation. To put it in our own letters, the Greek system would use the first nine letters (a, b, c, d, e, f, g, h, and i) to represent the numbers 1–9. Then the following letters could be used to represent the next order of magnitude, so that j, k, l, m, n, o, p, q, and r would represent 10–90 respectively. As numbers got higher, it was decided that not every one of the nine non-zero numerals requires representation. But still, the problem of simply running out of letters remained.\n\nAs such, Greek Numerals had an upper bound, above which the numerals had yet to be invented to express such a quantity. For the Greeks, as for a remarkable number of other contemporary cultures, the greatest expressible number was 10,000, which they called “μυριάς” (myrias). Anything above 10,000 was considered an uncountable multitude, which is why we still use the term “myriad” to mean “innumerable” in modern English.[10]\n\n(Note: I discuss this a bit in another answer on a very different subject, but one well worth a read.)\n\nOne of the common analogies in Archimedes’ day was that the number of grains of sand on a beach was something that could never be mathematically expressed with any degree of exactitude. It was simply, “a lot,” and everyone should be content to leave it at that.\n\nAs it happens, Archimedes didn’t like other people telling him what was beyond the bounds of his ability to calculate or express. Not only did he scoff at the idea of the grains of sand on a beach defying his calculative abilities, but he decided to take the proposed impossibility about ten-trillion steps further.\n\n“The grains of sand on a beach are too numerous to be calculated, you say?” Archimedes quipped. “Hold my fermented grape mash. I’m gonna calculate how many grains of sand it would take to fill the universe!”\n\nOf course, those weren’t his exact words, nor even any kind of close translation, but I nonetheless feel that the sheer audacity of Archimedes’ mathematical cojones are accurately conveyed in the lines above. Not only did he reject the innumerable quantity of sand on a beach, he jumped straight to the whole damn universe (as he understood it, of course).\n\nBut to do that, he first had to invent his own number system.\n\nWithout spending too much time going into the details of his invention, Archimedes saw that the numerical systems of his day could be extrapolated out exponentially to the point that they could encompass numbers on a scale that we still haven’t come up with specific names for.\n\n(Note: as much of a Greek purist as I tend to be, I will transition all of the terms in the following section into English for you, dear reader. You’re welcome.)\n\nArchimedes figured that if myriad was the highest number, then he could start working from there. Myriad—which is to say 10,000—became his “number of the first order.” You could have one myriad, two myriad, three… I’m just playing. You could go all the way up to a myriad myriad, also known as \n10\n8\n108\n, which could then be used as a new substitute for myriad. He named this new quantity as his “number of the second order.” And then the pattern continued.\n\nThis system allowed Archimedes to succinctly write numbers ranging up to \n(\n(\n10\n8\n)\n(\n10\n8\n)\n)\n10\n8\n((108)(108))108\n . As someone with very little experience with LaTeX math coding, I hope that comes out coherently, but in case it doesn’t, that is a one with eighty-quadrillion (80,000,000,000,000,000) zeroes.\n\nThat’s a pretty effing huge number, and the fact that Archimedes took the Greek Numeral system all the way from 10,000 to \n10\n79\n,\n999\n,\n999\n,\n999\n,\n999\n,\n996\n1079,999,999,999,999,996\n times as much is pretty hardcore if you ask me.\n\nBut that is not all.\n\nNow that he had invented super-huge numbers, Archimedes had to calculate the size of the universe, and even in that small step, he was so far ahead of his time that it is difficult to even fathom just how insanely right he was.\n\nBut first, let’s take a moment to examine what a word like “universe” would mean to an ancient Greek. To Archimedes, the “universe” was generally confined to what we would now call the solar system. The universe had a single sphere at its center, and a whole host of planets circulating around it. Beyond that was a spherical edge painted with stars. The very concept of foreign galaxies was yet to be devised.\n\nIndeed, for the greater part of the next two millennia, it would be held as an indisputable fact that the Earth was the center of the universe, and even 1800 years after the death of Archimedes, the assertion that it might be otherwise would remain so revolutionary as to merit oppression against those who spoke it. When Copernicus’ heliocentric theories were first printed—more than eighteen centuries after the death of Archimedes—they were enormously controversial.\n\nNot to Archimedes.\n\nIndeed, the works of the first great heliocentric astronomer, Aristarchus of Samos\n, who I discuss in this remarkably popular answer, were lost to history entirely, and it is entirely through the work of Archimedes that we know of his brilliance at all. Were it not for his incredible work, even educated people would still blithely assert that Copernicus was the first to posit that the Earth orbited the Sun, and the depth of Greek insight into the matter would lie in the darkened vaults of unrecorded history.\n\nWhile I may not be able to solidly attribute Archimedes’ reason for believing that the Earth revolved around the Sun, it is undoubtedly true that he accepted the heliocentric model of Aristarchus as the one by which he ought to make his calculations.\n\nArmed with his new form of advanced large-number mathematics and his unbelievably-prescient Aristarchan Heliocentric model, Archimedes determined that the number of grains of sand that it would take to fill the universe (a.k.a. the Solar System) was approximately \n10\n64\n1064\n.\n\nI would comment on the accuracy of that calculation if I was anywhere near brilliant enough to do so. As it stands, all I can really say is, “damn, that Archimedes dude was smart as hell!”\n\nConclusion\n\nI have always thought that there was something staggeringly audacious about the very premise of mathematics. Terms like infinity, which are beyond the scale of the human mind to comprehend, get thrown around in school classrooms like Halloween candy. Every so often, I have a student ask me the remarkable question, “how high can you count?” The truth of the answer, that I could keep counting not only for the rest of my life, but for the length of time that the universe has existed without even nearly exhausting the list of numbers whose names I have already learned in my infinitesimal time on Earth almost moves me to tears.\n\nNumbers are a different dimension. We can write them, but after a certain point, we lose our ability to even conceptualize their scale or scope. I can talk about 7.5ish Billion people on Earth, but that number means literally nothing more to me than μυριάς did to the Greeks. At that point, it’s all just “a friggin lot.”\n\nI would therefore posit that a huge percentage of the mathematical calculations that a high school calculus student makes over the course of a single standard class exist on a level of audacity that they will never fully realize.\n\nThis is why I like to teach children about the history of mathematics. Algebra is so much more beautiful when you see it through the eyes of Muhammad ibn Musa al-Khwarizmi\n, and when you know the words from which its name was taken: “calculation through the completion and balance of broken things.” I am sure that my translation is less-than-perfectly accurate, but it bears a portion of the beauty that is lost on algebra students.\n\nIf I am honest, I don’t think that the most audacious mathematical calculations are confined to the Ancient World. Truly I believe that mankind’s most audacious calculations are still ahead. I am so confident as to be pretty-well positive that what we have yet to learn will dwarf the whole monumental mass of what we have learned so far.\n\nSo I say we keep our eyes on the horizon. I say we keep our minds to the Aristarchuses of our time, and dare to believe in their monumental hypotheses. I say we take the word “incalculable” out of our personal lexicons, and set ourselves to the task of continuing the path of brilliance that has carried us this far.\n\nAfter all, we are humanity. We may be small, but look what we’ve done so far!\n\nJust imagine what we can do next.\n\nThank’s for reading.\n\nNow it’s your turn.\n\n*See what I did there?\n\nNote: Somehow, bafflingly, I managed to get through this whole answer without mentioning that the name of Archimedes’ revolutionary text, originally called Ψαμμίτης (Psammites) is usually translated into English as the incredibly awesome-sounding title: The Sand Reckoner.\n\nHere is an annotated translation: Archimedes, Sand-Reckoner, Intro.\n\nUpdate: So this answer seems to have rather inexplicably gotten some traction, and I have several comments questioning how reasonable Archimedes’ calculation of the number of grains of sand that could fit into the Solar System/Universe (which had a radius of around one lightyear, by his estimation) was, and several comments have claimed that he was off by many orders of magnitude.\n\nRather than arguing Archimedes’ rigor or accuracy, I would rather like to point out that a “grain of sand” has no officially established size, and that the grains with which Archimedes performed his calculations were likely quite a bit smaller than those being perceived by dissenters.\n\nIndeed, given that Archimedes was conducting his work well after that of Democritus and Epicurus, I am not entirely convinced that the “grains of sand” to which Archimedes refers were not essentially synonymous to atoms in his mind.\n\nOf course, that only makes him more incorrect, but if we take into account the sort of limited perception the Ancient Greeks had about atoms, I think it makes the whole calculation a great deal more sensible. The word “atom” comes from the Greek for “unbreakable.” The prefix a- (as in atheist) is negatory, and the root “-tom” (as in lobotomy) means “to cut.”\n\nThe root of Greek Atomic Theory was that microscopic infinity just didn’t make sense. If everything could be broken, then everything would be insubstantial. Democritus and Epicurus held that there must be a smallest form of matter, beyond which it could no longer be broken down.\n\nI think that Archimedes’ calculation played upon this theory by using the smallest possible grain of sand as its calculative unit rather than the average grain. Indeed, Archimedes posited that a myriad (ten-thousand) grains of sand could fit into a single poppy-seed. If you know how small a poppy-seed is, then you can hopefully conceptualize just how small Archimedes’ grains of sand are, and hopefully understand my assertion that they may have been a filler-term for atoms.\n\nHere it is in the annotated translation of his own words:\n\nWith some of these supposed and others demonstrated, the proposed claim will be proved. For since it is supposed that the diameter of the poppy-seed is not less than a fortieth-part of an inch, it is clear that the sphere having an inch diameter is not larger than can contain six-ten-thousand and four-thousand poppy-seeds. For they are multiples of the sphere having its diameter a fortieth-part of an inch by the stated number. For it has been proved that spheres have the triplicate ratio to one another of their diameters. It is clear that if a sphere having an inch diameter is filled with sand, the number of the sand would not be larger than ten-thousand-times six-ten-thousand and four-thousand.[11]\n\nI hope this clears some things up. I doubt it, but I hope…\n\nFootnotes\n\n[1] Biography of Eratosthenes, Greek Mathematician and Geographer\n[2] Zeno of Citium - Wikipedia\n[3] Aristo of Chios - Wikipedia\n[4] Tropic of Cancer - Wikipedia\n[5] Eratosthenes | Biography, Discoveries, & Facts\n[6] Eratosthenes - Wikipedia\n[7] Draw a circle with a radius on a map\n[8] Archimedes | Facts & Biography\n[9] Archimedes' screw - Wikipedia\n[10] myriad - Wiktionary\n[11] Archimedes, Sand-Reckoner, ch. 4"", 'aiModelVersion': '1'}",0.850775
Brian Empey,Updated 5y,Who is the most mysterious man to have ever lived?,"Has anyone talked about the Kenora Bank Robber? The one who was blown up by his own bomb (strapped around his waist) after being shot by the Kenora Police?
The largest part of him was most of one leg. Police scrambled across the roofs of nearby buildings, trying to collect fingers before the sea-gulls made off with them. (I think they got a few). But no matches to the finger-prints were made.

There have been at least 2 books written about this crazy event back in 1973, when a man walked into the Canadian Imperial Bank of Commerce (CIBC) on Kenora’s Main Street, fired a round into the ceiling to get everyone’s attention, and demanded that all the bank’s money be loaded into duffle bags.

A police officer carries duffel bags of cash towards the Atamaniuk family’s Pontiac with the bomber behind. The Dodge pickup belongs to the city and will be the “getaway vehicle” driven by the officer, who volunteered for the task.

The robber’s handgun is circled in this photo. He’s wearing a balaclava, and has a clothes-peg in his mouth with terminals at the far end wired to the explosives. This was a second before he was shot.

Sgt. Robert Letain was back at the main corner (to the right in these photos) not far from me when he fired a single shot from his rifle. The robber fell to the ground, and then the detonator went off.

The Pontiac sedan (in the prior photo) was written off by the insurance company. Visually, it looked like all the windows were blown out with little damage otherwise. But the entire car, including the frame, was twisted and it was unrepairable. The Dodge pickup was destroyed as well.

The police officer carrying the money, Constable Donald Milliard, had his lower clothes blown off from the force of the explosion, but survived. I suspect that the duffel-bags of cash, carried over his back, saved his life.

They still don’t know who he was. My friend Clair’s mother Jan had checked him into the Kenricia Hotel, where she ran the front desk, a couple of days earlier. She was one of the few in town who talked to him.

I was at the corner of Main and 2nd Avenue on my 10-speed bike. When the explosion went off, the sky turned green in an instant. I was stunned by the explosion, and didn’t realize that the green sky was money from the duffel-bags.

I also didn’t realize that the airborne item that looked like a large, wet rag, that narrowly missed me and landed on the road with a “splat” and rolled slightly, was a large chunk of human meat. A piece of the bomber. Roughly the size of a human arm, but likely a section of the body with no bone, based on how it twisted after hitting the ground. And there was no skin on it at all.

Here’s a video montage of photos, with the Radio coverage from CJRL AM-1220, who’s studio and offices were on the second floor, directly across the street from the bank. I actually snuck up there during the event (not knowing what was going on) to pick up the box of potato chips that I had won the night before for correctly identifying the song being played as “Midnight Train to Georgia”. I was shooed away. And I never did collect my prize.

Kenora,Ontario bank robber blows himself up - video dailymotion

Here’s more on the event, and the book “Devil’s Gap” chronicling the robbery and the mysterious bomber.

True story of robbery, explosion in 1970s Kenora, Ont., recounted in new book | CBC News","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/iacyzpqm2rh8tb9d', 'title': 'Who is the most mysterious man to have ever lived?', 'score': {'original': 0.96355, 'ai': 0.03645}, 'blocks': [{'text': 'Has anyone talked about the Kenora Bank Robber? The one who was blown up by his own bomb (strapped around his waist) after being shot by the Kenora Police?\nThe largest part of him was most of one leg. Police scrambled across the roofs of nearby buildings, trying to collect fingers before the sea-gulls made off with them. (I think they got a few). But no matches to the finger-prints were made.\n\nThere have been at least 2 books written about this crazy event back in 1973, when a man walked into the Canadian Imperial Bank of Commerce (CIBC) on Kenora’s Main Street, fired a round into the ceiling to get everyone’s attention, and demanded that all the bank’s money be loaded into duffle bags.\n\nA police officer carries duffel bags of cash towards the Atamaniuk family’s Pontiac with the bomber behind. The Dodge pickup belongs to the city and will be the “getaway vehicle” driven by the officer, who volunteered for the task.\n\nThe robber’s handgun is circled in this photo. He’s wearing a balaclava, and has a clothes-peg in his mouth with terminals at the far end wired to the explosives. This was a second before he was shot.\n\nSgt. Robert Letain was back at the main corner (to the right in these photos) not far from me when he fired a single shot from his rifle. The robber fell to the ground, and then the detonator went off.\n\nThe Pontiac sedan (in the prior photo) was written off by the insurance company. Visually, it looked like all the windows were blown out with little damage otherwise. But the entire car, including the frame, was twisted and it was unrepairable. The Dodge pickup was destroyed as well.\n\nThe police officer carrying the money, Constable Donald Milliard, had his lower clothes blown off from the force of the explosion, but survived. I suspect that the duffel-bags of cash, carried over his back, saved his life.\n\nThey still don’t know who he was. My friend Clair’s mother Jan had checked him into the Kenricia Hotel, where she ran the front desk, a couple of days earlier. She was one of the few in town who talked to him.\n\nI was at the corner of Main and 2nd Avenue on my 10-speed bike. When the explosion went off, the sky turned green in an instant. I was stunned by the explosion, and didn’t realize that the green sky was money from the duffel-bags.\n\nI also didn’t realize that the airborne item that looked like a large, wet rag, that narrowly missed me and landed on the road with a “splat” and rolled slightly, was a large chunk of human meat. A piece of the bomber. Roughly the size of a human arm, but likely a section of the body with no bone, based on how it twisted after hitting the ground. And there was no skin on it at all.\n\nHere’s a video montage of photos, with the Radio coverage from CJRL AM-1220, who’s studio and offices were on the second floor, directly across the street from the bank. I actually snuck up there', 'result': {'fake': 0.0006, 'real': 0.9994}, 'status': 'success'}, {'text': 'during the event (not knowing what was going on) to pick up the box of potato chips that I had won the night before for correctly identifying the song being played as “Midnight Train to Georgia”. I was shooed away. And I never did collect my prize.\n\nKenora,Ontario bank robber blows himself up - video dailymotion\n\nHere’s more on the event, and the book “Devil’s Gap” chronicling the robbery and the mysterious bomber.\n\nTrue story of robbery, explosion in 1970s Kenora, Ont., recounted in new book | CBC News', 'result': {'fake': 0.0084, 'real': 0.9916}, 'status': 'success'}], 'credits_used': 7, 'credits': 1994994, 'subscription': 0, 'content': 'Has anyone talked about the Kenora Bank Robber? The one who was blown up by his own bomb (strapped around his waist) after being shot by the Kenora Police?\nThe largest part of him was most of one leg. Police scrambled across the roofs of nearby buildings, trying to collect fingers before the sea-gulls made off with them. (I think they got a few). But no matches to the finger-prints were made.\n\nThere have been at least 2 books written about this crazy event back in 1973, when a man walked into the Canadian Imperial Bank of Commerce (CIBC) on Kenora’s Main Street, fired a round into the ceiling to get everyone’s attention, and demanded that all the bank’s money be loaded into duffle bags.\n\nA police officer carries duffel bags of cash towards the Atamaniuk family’s Pontiac with the bomber behind. The Dodge pickup belongs to the city and will be the “getaway vehicle” driven by the officer, who volunteered for the task.\n\nThe robber’s handgun is circled in this photo. He’s wearing a balaclava, and has a clothes-peg in his mouth with terminals at the far end wired to the explosives. This was a second before he was shot.\n\nSgt. Robert Letain was back at the main corner (to the right in these photos) not far from me when he fired a single shot from his rifle. The robber fell to the ground, and then the detonator went off.\n\nThe Pontiac sedan (in the prior photo) was written off by the insurance company. Visually, it looked like all the windows were blown out with little damage otherwise. But the entire car, including the frame, was twisted and it was unrepairable. The Dodge pickup was destroyed as well.\n\nThe police officer carrying the money, Constable Donald Milliard, had his lower clothes blown off from the force of the explosion, but survived. I suspect that the duffel-bags of cash, carried over his back, saved his life.\n\nThey still don’t know who he was. My friend Clair’s mother Jan had checked him into the Kenricia Hotel, where she ran the front desk, a couple of days earlier. She was one of the few in town who talked to him.\n\nI was at the corner of Main and 2nd Avenue on my 10-speed bike. When the explosion went off, the sky turned green in an instant. I was stunned by the explosion, and didn’t realize that the green sky was money from the duffel-bags.\n\nI also didn’t realize that the airborne item that looked like a large, wet rag, that narrowly missed me and landed on the road with a “splat” and rolled slightly, was a large chunk of human meat. A piece of the bomber. Roughly the size of a human arm, but likely a section of the body with no bone, based on how it twisted after hitting the ground. And there was no skin on it at all.\n\nHere’s a video montage of photos, with the Radio coverage from CJRL AM-1220, who’s studio and offices were on the second floor, directly across the street from the bank. I actually snuck up there during the event (not knowing what was going on) to pick up the box of potato chips that I had won the night before for correctly identifying the song being played as “Midnight Train to Georgia”. I was shooed away. And I never did collect my prize.\n\nKenora,Ontario bank robber blows himself up - video dailymotion\n\nHere’s more on the event, and the book “Devil’s Gap” chronicling the robbery and the mysterious bomber.\n\nTrue story of robbery, explosion in 1970s Kenora, Ont., recounted in new book | CBC News', 'aiModelVersion': '1'}",0.96355
Alexander Farrugia,4y,How would I know that a theorem in mathematics has been discovered previously or not?,"This is not an easy job, not even for mathematicians, sometimes.

One mathematician submits a paper in a journal. The journal referees accept the paper. The mathematician happily goes to a conference to present his findings. There, a disgruntled mathematician tells him “did you read my paper I published in journal X in 2012 that has basically the same result?”

This happens more often than it should, unfortunately.

Even experts in a particular field sometimes miss results that were published in their own field. This could be for various reasons: the result may have been published in a relatively obscure journal, or the mathematician himself or herself wasn’t very famous when he or she published the result, or it could have been simply overlooked innocuously.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/h7q653v4uwtmkrgn', 'title': 'How would I know that a theorem in mathematics has been discovered previously or not?', 'score': {'original': 0.9943, 'ai': 0.0057}, 'blocks': [{'text': 'This is not an easy job, not even for mathematicians, sometimes.\n\nOne mathematician submits a paper in a journal. The journal referees accept the paper. The mathematician happily goes to a conference to present his findings. There, a disgruntled mathematician tells him “did you read my paper I published in journal X in 2012 that has basically the same result?”\n\nThis happens more often than it should, unfortunately.\n\nEven experts in a particular field sometimes miss results that were published in their own field. This could be for various reasons: the result may have been published in a relatively obscure journal, or the mathematician himself or herself wasn’t very famous when he or she published the result, or it could have been simply overlooked innocuously.', 'result': {'fake': 0.0057, 'real': 0.9943}, 'status': 'success'}], 'credits_used': 2, 'credits': 1994992, 'subscription': 0, 'content': 'This is not an easy job, not even for mathematicians, sometimes.\n\nOne mathematician submits a paper in a journal. The journal referees accept the paper. The mathematician happily goes to a conference to present his findings. There, a disgruntled mathematician tells him “did you read my paper I published in journal X in 2012 that has basically the same result?”\n\nThis happens more often than it should, unfortunately.\n\nEven experts in a particular field sometimes miss results that were published in their own field. This could be for various reasons: the result may have been published in a relatively obscure journal, or the mathematician himself or herself wasn’t very famous when he or she published the result, or it could have been simply overlooked innocuously.', 'aiModelVersion': '1'}",0.9943
Alon Amit,Updated Jan 2,Who were the great Spanish mathematicians?,"There weren’t any.

I’m sorry. I know this sounds awful. But here is what I mean by that: if you asked people with knowledge of mathematics and its history to make a list of the most influential, important, prolific, or otherwise “great” mathematicians, it is quite likely that nobody from Spain would make that list. This is strange and surprising, but there’s no way around it. It’s how it is.

(Note: the wording of the question as I answered it was about great mathematicians. It now reads “greatest”, which means something quite different.)

To be clear, this says exactly nothing about the intelligence, skill, talent or anything else to do with the Spanish people. The cultures of nations and countries move in different directions for many different reasons, often haphazardly. A single person may be responsible for establishing a tradition of learning and excellence in a particular field somewhere, and such a legacy may survive for decades or more, localized to a region or country.

For whatever reason, Spain as whole – as a country, a nation, a culture – never veered towards mathematics. This is quite striking when contrasted with some of its neighbors: France, Germany, Italy or the UK are close to Spain in many ways, but in mathematics the difference is stark.

Compare:

Every student of mathematics, and most educated people in general, would be familiar with most of the names on the French and German lists, and with many additional names that didn’t make the top of those random search results.

The Spanish list is obscure even to most professional mathematicians. Echegaray
 was a Nobel laureate in literature, and his mark on the history of mathematics is, I’m sorry to say, negligible. Bar Hiyya and ibn Aflah, respectively Jewish and Muslim scholars, lived almost 1,000 years ago, and they too aren’t exactly household names in mathematics. Rey Pastor, Santaló and Ríos were accomplished mathematicians but are largely unknown to anyone whose specialty doesn’t happen to significantly overlap with theirs.

An undeniably large proportion of historically impactful mathematicians have been Jewish. I’m not qualified to judge if Spain’s 1492 expulsion of its Jews
 influenced the development of mathematics in that country, but I would cautiously suggest that it didn’t help. There may have been other factors. I don’t know why that is, but the empirical evidence is irrefutable.

More than 10 Fields medalists
 are French. None are Spanish. Wolf prize
, none. Abel prize
, none. Xavier Tolsa
, a prominent Catalan mathematician, won the Salem Prize
 in 2002 – alone from his country.

In previous answers I cautioned against using IMO success as some sort of indicator for the quality of research mathematics in a country, but it’s a data point nonetheless. You can see Spain’s performance here
. It’s not great.

I think it’s fair to say that Spain hasn’t developed as strong a culture of mathematical scholarship as some of its neighbors, neither in the past nor in the present. I would personally hope to see this change, but it’s not an easy change to drive, and I don’t know if the Spanish government or thought leaders are interested in affecting such change.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/4ytceljfx6b8ki03', 'title': 'Who were the great Spanish mathematicians?', 'score': {'original': 0.4993, 'ai': 0.5007}, 'blocks': [{'text': 'There weren’t any.\n\nI’m sorry. I know this sounds awful. But here is what I mean by that: if you asked people with knowledge of mathematics and its history to make a list of the most influential, important, prolific, or otherwise “great” mathematicians, it is quite likely that nobody from Spain would make that list. This is strange and surprising, but there’s no way around it. It’s how it is.\n\n(Note: the wording of the question as I answered it was about great mathematicians. It now reads “greatest”, which means something quite different.)\n\nTo be clear, this says exactly nothing about the intelligence, skill, talent or anything else to do with the Spanish people. The cultures of nations and countries move in different directions for many different reasons, often haphazardly. A single person may be responsible for establishing a tradition of learning and excellence in a particular field somewhere, and such a legacy may survive for decades or more, localized to a region or country.\n\nFor whatever reason, Spain as whole – as a country, a nation, a culture – never veered towards mathematics. This is quite striking when contrasted with some of its neighbors: France, Germany, Italy or the UK are close to Spain in many ways, but in mathematics the difference is stark.\n\nCompare:\n\nEvery student of mathematics, and most educated people in general, would be familiar with most of the names on the French and German lists, and with many additional names that didn’t make the top of those random search results.\n\nThe Spanish list is obscure even to most professional mathematicians. Echegaray\n was a Nobel laureate in literature, and his mark on the history of mathematics is, I’m sorry to say, negligible. Bar Hiyya and ibn Aflah, respectively Jewish and Muslim scholars, lived almost 1,000 years ago, and they too aren’t exactly household names in mathematics. Rey Pastor, Santaló and Ríos were accomplished mathematicians but are largely unknown to anyone whose specialty doesn’t happen to significantly overlap with theirs.\n\nAn undeniably large proportion of historically impactful mathematicians have been Jewish. I’m not qualified to judge if Spain’s 1492 expulsion of its Jews\n influenced the development of mathematics in that country, but I would cautiously suggest that it didn’t help. There may have been other factors. I don’t know why that is, but the empirical evidence is irrefutable.\n\nMore than 10 Fields medalists\n are French. None are Spanish. Wolf prize\n, none. Abel prize\n, none. Xavier Tolsa\n, a prominent Catalan mathematician, won the Salem Prize\n in 2002 – alone from his country.\n\nIn previous answers I cautioned against using IMO success as some sort of indicator for the quality of research mathematics in a country, but it’s a data point nonetheless. You can see Spain’s performance here\n. It’s not great.\n\nI think it’s fair to say that Spain hasn’t developed as strong a culture of mathematical scholarship as some of its neighbors, neither in the past nor in the present. I would personally hope to see this change, but it’s not an easy change to drive, and I don’t know if the Spanish government or thought leaders are interested in affecting', 'result': {'fake': 0.0073, 'real': 0.9927}, 'status': 'success'}, {'text': 'such change.', 'result': {'fake': 0.9981, 'real': 0.0019}, 'status': 'success'}], 'credits_used': 6, 'credits': 1994986, 'subscription': 0, 'content': 'There weren’t any.\n\nI’m sorry. I know this sounds awful. But here is what I mean by that: if you asked people with knowledge of mathematics and its history to make a list of the most influential, important, prolific, or otherwise “great” mathematicians, it is quite likely that nobody from Spain would make that list. This is strange and surprising, but there’s no way around it. It’s how it is.\n\n(Note: the wording of the question as I answered it was about great mathematicians. It now reads “greatest”, which means something quite different.)\n\nTo be clear, this says exactly nothing about the intelligence, skill, talent or anything else to do with the Spanish people. The cultures of nations and countries move in different directions for many different reasons, often haphazardly. A single person may be responsible for establishing a tradition of learning and excellence in a particular field somewhere, and such a legacy may survive for decades or more, localized to a region or country.\n\nFor whatever reason, Spain as whole – as a country, a nation, a culture – never veered towards mathematics. This is quite striking when contrasted with some of its neighbors: France, Germany, Italy or the UK are close to Spain in many ways, but in mathematics the difference is stark.\n\nCompare:\n\nEvery student of mathematics, and most educated people in general, would be familiar with most of the names on the French and German lists, and with many additional names that didn’t make the top of those random search results.\n\nThe Spanish list is obscure even to most professional mathematicians. Echegaray\n was a Nobel laureate in literature, and his mark on the history of mathematics is, I’m sorry to say, negligible. Bar Hiyya and ibn Aflah, respectively Jewish and Muslim scholars, lived almost 1,000 years ago, and they too aren’t exactly household names in mathematics. Rey Pastor, Santaló and Ríos were accomplished mathematicians but are largely unknown to anyone whose specialty doesn’t happen to significantly overlap with theirs.\n\nAn undeniably large proportion of historically impactful mathematicians have been Jewish. I’m not qualified to judge if Spain’s 1492 expulsion of its Jews\n influenced the development of mathematics in that country, but I would cautiously suggest that it didn’t help. There may have been other factors. I don’t know why that is, but the empirical evidence is irrefutable.\n\nMore than 10 Fields medalists\n are French. None are Spanish. Wolf prize\n, none. Abel prize\n, none. Xavier Tolsa\n, a prominent Catalan mathematician, won the Salem Prize\n in 2002 – alone from his country.\n\nIn previous answers I cautioned against using IMO success as some sort of indicator for the quality of research mathematics in a country, but it’s a data point nonetheless. You can see Spain’s performance here\n. It’s not great.\n\nI think it’s fair to say that Spain hasn’t developed as strong a culture of mathematical scholarship as some of its neighbors, neither in the past nor in the present. I would personally hope to see this change, but it’s not an easy change to drive, and I don’t know if the Spanish government or thought leaders are interested in affecting such change.', 'aiModelVersion': '1'}",0.4993
David Joyce,4y,Why is the Bolzano theorem important? Isn't it just common sense?,"You ask why Bolzano’s theorem, also called the Intermediate Value Theorem (IVT), is important, and you also say it’s just common sense.

The statement says that if a function is continuous and takes on two values, then it takes on all intermediate values. More precisely, if 
f
f
 is a continuous function on a closed interval 
[
a
,
b
]
[a,b]
 and if 
y
y
 is a number between 
f
(
a
)
f(a)
 and 
f
(
b
)
,
f(b),
 there there is a number 
c
c
 between 
a
a
 and 
b
b
 such that 
f
(
c
)
=
y
.
f(c)=y.

Notice the word “continuous” in the statement of the theorem. The primary importance of the theorem is that continuous functions have this intermediate property. In order to prove the theorem, in fact, just to be able to state the theorem, you have to have a precise definition of what it means for a function to be continuous. There are functions that don’t have the intermediate property.

One question posed by Lagrange and others at the beginning of the 1800s was what characterized functions that have this intermediate property. The concept of function changed in the 1700s to include functions besides formulaic functions, those being functions described by formulas such as 
y
=
sin
√
x
2
+
1
.
y=sin⁡x2+1.
 Once other functions were accepted as functions, such as those defined by Fourier series, it was recognized that these new functions didn’t have to have the intermediate property; they had jumps in their graphs.

An earlier definition of continuous function was one that has the intermediate property. That’s a precise definition, and with that as a definition, this theorem is nothing but a tautology: a function that has the intermediate property has the intermediate property.

So, to be an interesting theorem and not just a tautology, the concept of continuous function has to be defined in some other way. The concept of limit was being developed at this time. Before it had been rather intuitive, but at least it was recognized that limits were related to continuous functions. To say that a function 
f
f
 was continuous at 
x
=
a
x=a
 meant that if 
x
x
 approached 
a
,
a,
 then 
f
(
x
)
f(x)
 approaches 
f
(
a
)
.
f(a).
 That doesn’t happen if 
f
f
 jumps right at 
a
.
a.

Thus, if a precise definition for limits could be found, that would give a different, and more fundamental, definition for continuous function, and, then, the IVT would require an actual proof and no longer be a tautology.

In fact, Bolzano and others did find a definition for limits, the definition known as the epsilon-delta definition in calculus. And they found proofs for the IVT.

A logically rigorous proof of the IVT requires axioms for the real numbers, in particular, some completeness axiom. (One that’s often used is the least upper bound property as an axiom.)

The axioms of real numbers, the epsilon-delta definition of limits, the definition of function, and the definition of continuous function in terms of limits are not obvious. The proof of the IVT from them is not easy.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/l1eoqm4wtif8cxn5', 'title': ""Why is the Bolzano theorem important? Isn't it just common sense?"", 'score': {'original': 0.5008, 'ai': 0.4992}, 'blocks': [{'text': 'You ask why Bolzano’s theorem, also called the Intermediate Value Theorem (IVT), is important, and you also say it’s just common sense.\n\nThe statement says that if a function is continuous and takes on two values, then it takes on all intermediate values. More precisely, if \nf\nf\n is a continuous function on a closed interval \n[\na\n,\nb\n]\n[a,b]\n and if \ny\ny\n is a number between \nf\n(\na\n)\nf(a)\n and \nf\n(\nb\n)\n,\nf(b),\n there there is a number \nc\nc\n between \na\na\n and \nb\nb\n such that \nf\n(\nc\n)\n=\ny\n.\nf(c)=y.\n\nNotice the word “continuous” in the statement of the theorem. The primary importance of the theorem is that continuous functions have this intermediate property. In order to prove the theorem, in fact, just to be able to state the theorem, you have to have a precise definition of what it means for a function to be continuous. There are functions that don’t have the intermediate property.\n\nOne question posed by Lagrange and others at the beginning of the 1800s was what characterized functions that have this intermediate property. The concept of function changed in the 1700s to include functions besides formulaic functions, those being functions described by formulas such as \ny\n=\nsin\n√\nx\n2\n+\n1\n.\ny=sin\u2061x2+1.\n Once other functions were accepted as functions, such as those defined by Fourier series, it was recognized that these new functions didn’t have to have the intermediate property; they had jumps in their graphs.\n\nAn earlier definition of continuous function was one that has the intermediate property. That’s a precise definition, and with that as a definition, this theorem is nothing but a tautology: a function that has the intermediate property has the intermediate property.\n\nSo, to be an interesting theorem and not just a tautology, the concept of continuous function has to be defined in some other way. The concept of limit was being developed at this time. Before it had been rather intuitive, but at least it was recognized that limits were related to continuous functions. To say that a function \nf\nf\n was continuous at \nx\n=\na\nx=a\n meant that if \nx\nx\n approached \na\n,\na,\n then \nf\n(\nx\n)\nf(x)\n approaches \nf\n(\na\n)\n.\nf(a).\n That doesn’t happen if \nf\nf\n jumps right at \na\n.\na.\n\nThus, if a precise definition for limits could be found, that would give a different, and more fundamental, definition for continuous function, and, then, the IVT would require an actual proof and no longer be a tautology.\n\nIn fact, Bolzano and others did find a definition for limits, the definition known as the epsilon-delta definition in calculus. And they found proofs for the IVT.\n\nA logically rigorous proof of the IVT requires axioms for the real numbers, in particular, some completeness axiom. (One that’s often used is the least upper bound property as an axiom.)\n\nThe axioms of real numbers, the epsilon-delta definition of limits, the definition of function, and the definition of continuous function in terms of limits are not obvious. The proof of the IVT from them is not easy.', 'result': {'fake': 0.0009, 'real': 0.9991}, 'status': 'success'}], 'credits_used': 6, 'credits': 1994980, 'subscription': 0, 'content': 'You ask why Bolzano’s theorem, also called the Intermediate Value Theorem (IVT), is important, and you also say it’s just common sense.\n\nThe statement says that if a function is continuous and takes on two values, then it takes on all intermediate values. More precisely, if \nf\nf\n is a continuous function on a closed interval \n[\na\n,\nb\n]\n[a,b]\n and if \ny\ny\n is a number between \nf\n(\na\n)\nf(a)\n and \nf\n(\nb\n)\n,\nf(b),\n there there is a number \nc\nc\n between \na\na\n and \nb\nb\n such that \nf\n(\nc\n)\n=\ny\n.\nf(c)=y.\n\nNotice the word “continuous” in the statement of the theorem. The primary importance of the theorem is that continuous functions have this intermediate property. In order to prove the theorem, in fact, just to be able to state the theorem, you have to have a precise definition of what it means for a function to be continuous. There are functions that don’t have the intermediate property.\n\nOne question posed by Lagrange and others at the beginning of the 1800s was what characterized functions that have this intermediate property. The concept of function changed in the 1700s to include functions besides formulaic functions, those being functions described by formulas such as \ny\n=\nsin\n√\nx\n2\n+\n1\n.\ny=sin\u2061x2+1.\n Once other functions were accepted as functions, such as those defined by Fourier series, it was recognized that these new functions didn’t have to have the intermediate property; they had jumps in their graphs.\n\nAn earlier definition of continuous function was one that has the intermediate property. That’s a precise definition, and with that as a definition, this theorem is nothing but a tautology: a function that has the intermediate property has the intermediate property.\n\nSo, to be an interesting theorem and not just a tautology, the concept of continuous function has to be defined in some other way. The concept of limit was being developed at this time. Before it had been rather intuitive, but at least it was recognized that limits were related to continuous functions. To say that a function \nf\nf\n was continuous at \nx\n=\na\nx=a\n meant that if \nx\nx\n approached \na\n,\na,\n then \nf\n(\nx\n)\nf(x)\n approaches \nf\n(\na\n)\n.\nf(a).\n That doesn’t happen if \nf\nf\n jumps right at \na\n.\na.\n\nThus, if a precise definition for limits could be found, that would give a different, and more fundamental, definition for continuous function, and, then, the IVT would require an actual proof and no longer be a tautology.\n\nIn fact, Bolzano and others did find a definition for limits, the definition known as the epsilon-delta definition in calculus. And they found proofs for the IVT.\n\nA logically rigorous proof of the IVT requires axioms for the real numbers, in particular, some completeness axiom. (One that’s often used is the least upper bound property as an axiom.)\n\nThe axioms of real numbers, the epsilon-delta definition of limits, the definition of function, and the definition of continuous function in terms of limits are not obvious. The proof of the IVT from them is not easy.', 'aiModelVersion': '1'}",0.5008
Alon Amit,4y,Why did mathematics become increasingly abstract throughout the 20th century?,"Because everything did, and because math had even more reason than most disciplines.

Everything did

It started earlier, but trends of abstraction flourished throughout the 20th century in the visual arts, in music, in literature, in architecture – in most ways people explore and express, interpret and create. Part of this was wriggling free from the shackles of the past. Part was just pure bursts of creativity. And yet another part was reaction to the horrors of the wars. When your world descends into savage absurdity, mimesis quickly loses its appeal; some choose to portray the unspeakable, some seek solace in imagined vistas. In both cases, the creative self is drawn into surrealistic, non-representational symbols and evocative Impressionism.

(Art by Klee, music by Stockhausen).

Observe the overt pacifism of Hardy, Russell, or Grothendieck, compared with the receptive pragmatism of Fourier, Laplace, Monge, or even Euler. Shunning “applications” influenced the careers of many 20th century mathematicians in ways large and small. This, on top of the natural interplay between math and the arts – more than one author compared parts of modern mathematics to jazz.

Abstraction was a powerful creative force in the 20th century, and mathematics was not left out. But math has other reasons, which are hard to discern in those other disciplines.

It works

Abstractions in math simplify and unify, and beyond that they were found to be extremely powerful in solving the most concrete problems (as well as, of course, the increasingly abstract ones).

Cantor introduced cardinals while working on convergence questions in Fourier series. Riemann surfaces, manifolds, symplectic geometry and algebraic topology were motivated (in part) by questions in classical mechanics. Deeper and deeper abstractions in commutative algebra, algebraic geometry and category theory were natural outcomes of the search for analogies and extensions which let us solve ancient problems in number theory and geometry. Quantum mechanics forced us to understand Hilbert spaces and von Neumann algebras. Representation theory started with the computation of a determinant, and very naturally expanded into some of the purest, prettiest vistas in math.

This is just a tiny sampling. Almost all of deepest abstractions in math were guided by the same forces that have always shaped mathematics: the desire to solve problems and to understand why things are the way they are. Kummer introduced ideals not because he wanted to escape reality: he needed them to factor algebraic numbers. This occurred in the 19th century already; like art, math did not wait until 1900 to leave the concrete and the mundane.

I think those are two of the main reasons, but there are surely other ways to read the developments of the 20th century in math, physics and the arts.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/vxu0jh3afb7wqpnk', 'title': 'Why did mathematics become increasingly abstract throughout the 20th century?', 'score': {'original': 0.9998, 'ai': 0.0002}, 'blocks': [{'text': 'Because everything did, and because math had even more reason than most disciplines.\n\nEverything did\n\nIt started earlier, but trends of abstraction flourished throughout the 20th century in the visual arts, in music, in literature, in architecture – in most ways people explore and express, interpret and create. Part of this was wriggling free from the shackles of the past. Part was just pure bursts of creativity. And yet another part was reaction to the horrors of the wars. When your world descends into savage absurdity, mimesis quickly loses its appeal; some choose to portray the unspeakable, some seek solace in imagined vistas. In both cases, the creative self is drawn into surrealistic, non-representational symbols and evocative Impressionism.\n\n(Art by Klee, music by Stockhausen).\n\nObserve the overt pacifism of Hardy, Russell, or Grothendieck, compared with the receptive pragmatism of Fourier, Laplace, Monge, or even Euler. Shunning “applications” influenced the careers of many 20th century mathematicians in ways large and small. This, on top of the natural interplay between math and the arts – more than one author compared parts of modern mathematics to jazz.\n\nAbstraction was a powerful creative force in the 20th century, and mathematics was not left out. But math has other reasons, which are hard to discern in those other disciplines.\n\nIt works\n\nAbstractions in math simplify and unify, and beyond that they were found to be extremely powerful in solving the most concrete problems (as well as, of course, the increasingly abstract ones).\n\nCantor introduced cardinals while working on convergence questions in Fourier series. Riemann surfaces, manifolds, symplectic geometry and algebraic topology were motivated (in part) by questions in classical mechanics. Deeper and deeper abstractions in commutative algebra, algebraic geometry and category theory were natural outcomes of the search for analogies and extensions which let us solve ancient problems in number theory and geometry. Quantum mechanics forced us to understand Hilbert spaces and von Neumann algebras. Representation theory started with the computation of a determinant, and very naturally expanded into some of the purest, prettiest vistas in math.\n\nThis is just a tiny sampling. Almost all of deepest abstractions in math were guided by the same forces that have always shaped mathematics: the desire to solve problems and to understand why things are the way they are. Kummer introduced ideals not because he wanted to escape reality: he needed them to factor algebraic numbers. This occurred in the 19th century already; like art, math did not wait until 1900 to leave the concrete and the mundane.\n\nI think those are two of the main reasons, but there are surely other ways to read the developments of the 20th century in math, physics and the arts.', 'result': {'fake': 0.0002, 'real': 0.9998}, 'status': 'success'}], 'credits_used': 5, 'credits': 1994975, 'subscription': 0, 'content': 'Because everything did, and because math had even more reason than most disciplines.\n\nEverything did\n\nIt started earlier, but trends of abstraction flourished throughout the 20th century in the visual arts, in music, in literature, in architecture – in most ways people explore and express, interpret and create. Part of this was wriggling free from the shackles of the past. Part was just pure bursts of creativity. And yet another part was reaction to the horrors of the wars. When your world descends into savage absurdity, mimesis quickly loses its appeal; some choose to portray the unspeakable, some seek solace in imagined vistas. In both cases, the creative self is drawn into surrealistic, non-representational symbols and evocative Impressionism.\n\n(Art by Klee, music by Stockhausen).\n\nObserve the overt pacifism of Hardy, Russell, or Grothendieck, compared with the receptive pragmatism of Fourier, Laplace, Monge, or even Euler. Shunning “applications” influenced the careers of many 20th century mathematicians in ways large and small. This, on top of the natural interplay between math and the arts – more than one author compared parts of modern mathematics to jazz.\n\nAbstraction was a powerful creative force in the 20th century, and mathematics was not left out. But math has other reasons, which are hard to discern in those other disciplines.\n\nIt works\n\nAbstractions in math simplify and unify, and beyond that they were found to be extremely powerful in solving the most concrete problems (as well as, of course, the increasingly abstract ones).\n\nCantor introduced cardinals while working on convergence questions in Fourier series. Riemann surfaces, manifolds, symplectic geometry and algebraic topology were motivated (in part) by questions in classical mechanics. Deeper and deeper abstractions in commutative algebra, algebraic geometry and category theory were natural outcomes of the search for analogies and extensions which let us solve ancient problems in number theory and geometry. Quantum mechanics forced us to understand Hilbert spaces and von Neumann algebras. Representation theory started with the computation of a determinant, and very naturally expanded into some of the purest, prettiest vistas in math.\n\nThis is just a tiny sampling. Almost all of deepest abstractions in math were guided by the same forces that have always shaped mathematics: the desire to solve problems and to understand why things are the way they are. Kummer introduced ideals not because he wanted to escape reality: he needed them to factor algebraic numbers. This occurred in the 19th century already; like art, math did not wait until 1900 to leave the concrete and the mundane.\n\nI think those are two of the main reasons, but there are surely other ways to read the developments of the 20th century in math, physics and the arts.', 'aiModelVersion': '1'}",0.9998
David Joyce,4y,What started calculus?,"The problem of varying velocities started calculus, and it is quite old. The Greek geometers, even Archimedes, couldn’t deal with it. They had no difficulty with constant speeds either when an object moved in a straight line or in a circle, but they couldn’t deal with changing velocities. In Europe, it was Bradwardine, Heytesbury, Swineshead, and Dumbleton who tackled the problem of changing velocities in the first half of the 1300s at Oxford. They didn’t solve it for all changing velocities, but they did manage one case, that case being when the velocities themselves had a constant rate of change, that is, when the acceleration was constant. (They called that “uniformly difform motion”.) They discovered the “mean speed theorem”: the distance travelled by an object undergoing constant acceleration or constant deceleration was the same distance as that traveling at a constant velocity equal to the average of the initial and final velocities. A few years later, about 1350, Oresme, in Paris, tackled the general problem. He developed a theory which answered the question of how far an object goes when its velocity changes. Draw a graph of the velocity where the horizontal axis is time and at each point in time, draw a vertical line above the axis representing the velocity at that instant. That produces a figure that Oresme called a “form”. The area of that figure, then, is the distance travelled. That is the Fundamental Theorem of Calculus, which, when written in modern notation says ∫baf′(x)dx=f(b)−f(a).∫abf′(x)dx=f(b)−f(a).\displaystyle\int_a^b f’(x)\,dx=f(b)-f(a).\tag*{} The Black Plague hit Europe just at that time, and that severely held back progress. Nonetheless, others including Galileo, Cavalieri, and Torricelli in Italy, Wallace and Gregory in Britain, Pascal, Descartes, and Fermat in France, as well as others in Germany and Spain developed the concepts and proved theorems during the succeeding 300 years. By 1650 mathematical analysis was fairly well developed. It was helped along by the development of symbolic algebra in the 1500s and by the analytic geometry of Fermat and Descartes in the couple of decades before 1650. It is often said that Leibniz and Newton invented calculus, but much of it was developed before them.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/85bpsyloikhame9v', 'title': 'What started calculus?', 'score': {'original': 0.9995, 'ai': 0.0005}, 'blocks': [{'text': 'The problem of varying velocities started calculus, and it is quite old. The Greek geometers, even Archimedes, couldn’t deal with it. They had no difficulty with constant speeds either when an object moved in a straight line or in a circle, but they couldn’t deal with changing velocities. In Europe, it was Bradwardine, Heytesbury, Swineshead, and Dumbleton who tackled the problem of changing velocities in the first half of the 1300s at Oxford. They didn’t solve it for all changing velocities, but they did manage one case, that case being when the velocities themselves had a constant rate of change, that is, when the acceleration was constant. (They called that “uniformly difform motion”.) They discovered the “mean speed theorem”: the distance travelled by an object undergoing constant acceleration or constant deceleration was the same distance as that traveling at a constant velocity equal to the average of the initial and final velocities. A few years later, about 1350, Oresme, in Paris, tackled the general problem. He developed a theory which answered the question of how far an object goes when its velocity changes. Draw a graph of the velocity where the horizontal axis is time and at each point in time, draw a vertical line above the axis representing the velocity at that instant. That produces a figure that Oresme called a “form”. The area of that figure, then, is the distance travelled. That is the Fundamental Theorem of Calculus, which, when written in modern notation says ∫baf′(x)dx=f(b)−f(a).∫abf′(x)dx=f(b)−f(a).\\displaystyle\\int_a^b f’(x)\\,dx=f(b)-f(a).\\tag*{} The Black Plague hit Europe just at that time, and that severely held back progress. Nonetheless, others including Galileo, Cavalieri, and Torricelli in Italy, Wallace and Gregory in Britain, Pascal, Descartes, and Fermat in France, as well as others in Germany and Spain developed the concepts and proved theorems during the succeeding 300 years. By 1650 mathematical analysis was fairly well developed. It was helped along by the development of symbolic algebra in the 1500s and by the analytic geometry of Fermat and Descartes in the couple of decades before 1650. It is often said that Leibniz and Newton invented calculus, but much of it was developed before them.', 'result': {'fake': 0.0005, 'real': 0.9995}, 'status': 'success'}], 'credits_used': 4, 'credits': 1994971, 'subscription': 0, 'content': 'The problem of varying velocities started calculus, and it is quite old. The Greek geometers, even Archimedes, couldn’t deal with it. They had no difficulty with constant speeds either when an object moved in a straight line or in a circle, but they couldn’t deal with changing velocities. In Europe, it was Bradwardine, Heytesbury, Swineshead, and Dumbleton who tackled the problem of changing velocities in the first half of the 1300s at Oxford. They didn’t solve it for all changing velocities, but they did manage one case, that case being when the velocities themselves had a constant rate of change, that is, when the acceleration was constant. (They called that “uniformly difform motion”.) They discovered the “mean speed theorem”: the distance travelled by an object undergoing constant acceleration or constant deceleration was the same distance as that traveling at a constant velocity equal to the average of the initial and final velocities. A few years later, about 1350, Oresme, in Paris, tackled the general problem. He developed a theory which answered the question of how far an object goes when its velocity changes. Draw a graph of the velocity where the horizontal axis is time and at each point in time, draw a vertical line above the axis representing the velocity at that instant. That produces a figure that Oresme called a “form”. The area of that figure, then, is the distance travelled. That is the Fundamental Theorem of Calculus, which, when written in modern notation says ∫baf′(x)dx=f(b)−f(a).∫abf′(x)dx=f(b)−f(a).\\displaystyle\\int_a^b f’(x)\\,dx=f(b)-f(a).\\tag*{} The Black Plague hit Europe just at that time, and that severely held back progress. Nonetheless, others including Galileo, Cavalieri, and Torricelli in Italy, Wallace and Gregory in Britain, Pascal, Descartes, and Fermat in France, as well as others in Germany and Spain developed the concepts and proved theorems during the succeeding 300 years. By 1650 mathematical analysis was fairly well developed. It was helped along by the development of symbolic algebra in the 1500s and by the analytic geometry of Fermat and Descartes in the couple of decades before 1650. It is often said that Leibniz and Newton invented calculus, but much of it was developed before them.', 'aiModelVersion': '1'}",0.9995
Håkon Hapnes Strand,1y,"If Evariste Galois understood that his chances at the duel were not high, why couldn't he simply not show up?","Evariste Galois was 20 years old when he died. A mere child.

Boys that age, no matter how intelligent, are incredibly immature. It's only when approaching 30 that their brain matures to the point that we can consider them grown up men. If I think back at all the stupid stuff I did myself at the age of 20, it's a wonder I survived at all.

Of course, the contradiction with Galois is that his contributions to mathematics at that age was already greater than what the vast majority of mathematicians are able to achieve within a lifetime.

Galois was clearly a genius, but he was also a troubled mind. His father had committed suicide when he was 17, and this affected Evariste deeply. Some time later, he attempted to take his own life by stabbing himself.

He had lost his beloved father, his mathematical ideas were being rejected, he was being (at least in his own mind) politically persecuted and he had few real friends. That's the place he was coming when showing up to that fateful duel.

Unlike the extremely lethal rapier duels of the 17th and 18th century, the pistol duels of Galois’ time actually had a fairly good chance of survival, with as few as 5% or less of them resulting in a lethal outcome. Most ended in misses from both sides.

Duels were mostly a way to gain “satisfaction”. Galois had entered a love affair with the fiancée of his opponent, and this was a way to resolve the offense. If he had not shown up for the duel, it's likely that something bad would have happened to him in any case.

At the same time, Galois clearly realized there was some risk, considering the famous notes he hastily wrote down the night before. In the lower left of this page, we can see the words “Une femme”, referring to his lover.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/7n5r3gs8jq4vkx2h', 'title': ""If Evariste Galois understood that his chances at the duel were not high, why couldn't he simply not show up?"", 'score': {'original': 0.9995, 'ai': 0.0005}, 'blocks': [{'text': ""Evariste Galois was 20 years old when he died. A mere child.\n\nBoys that age, no matter how intelligent, are incredibly immature. It's only when approaching 30 that their brain matures to the point that we can consider them grown up men. If I think back at all the stupid stuff I did myself at the age of 20, it's a wonder I survived at all.\n\nOf course, the contradiction with Galois is that his contributions to mathematics at that age was already greater than what the vast majority of mathematicians are able to achieve within a lifetime.\n\nGalois was clearly a genius, but he was also a troubled mind. His father had committed suicide when he was 17, and this affected Evariste deeply. Some time later, he attempted to take his own life by stabbing himself.\n\nHe had lost his beloved father, his mathematical ideas were being rejected, he was being (at least in his own mind) politically persecuted and he had few real friends. That's the place he was coming when showing up to that fateful duel.\n\nUnlike the extremely lethal rapier duels of the 17th and 18th century, the pistol duels of Galois’ time actually had a fairly good chance of survival, with as few as 5% or less of them resulting in a lethal outcome. Most ended in misses from both sides.\n\nDuels were mostly a way to gain “satisfaction”. Galois had entered a love affair with the fiancée of his opponent, and this was a way to resolve the offense. If he had not shown up for the duel, it's likely that something bad would have happened to him in any case.\n\nAt the same time, Galois clearly realized there was some risk, considering the famous notes he hastily wrote down the night before. In the lower left of this page, we can see the words “Une femme”, referring to his lover."", 'result': {'fake': 0.0005, 'real': 0.9995}, 'status': 'success'}], 'credits_used': 4, 'credits': 1994967, 'subscription': 0, 'content': ""Evariste Galois was 20 years old when he died. A mere child.\n\nBoys that age, no matter how intelligent, are incredibly immature. It's only when approaching 30 that their brain matures to the point that we can consider them grown up men. If I think back at all the stupid stuff I did myself at the age of 20, it's a wonder I survived at all.\n\nOf course, the contradiction with Galois is that his contributions to mathematics at that age was already greater than what the vast majority of mathematicians are able to achieve within a lifetime.\n\nGalois was clearly a genius, but he was also a troubled mind. His father had committed suicide when he was 17, and this affected Evariste deeply. Some time later, he attempted to take his own life by stabbing himself.\n\nHe had lost his beloved father, his mathematical ideas were being rejected, he was being (at least in his own mind) politically persecuted and he had few real friends. That's the place he was coming when showing up to that fateful duel.\n\nUnlike the extremely lethal rapier duels of the 17th and 18th century, the pistol duels of Galois’ time actually had a fairly good chance of survival, with as few as 5% or less of them resulting in a lethal outcome. Most ended in misses from both sides.\n\nDuels were mostly a way to gain “satisfaction”. Galois had entered a love affair with the fiancée of his opponent, and this was a way to resolve the offense. If he had not shown up for the duel, it's likely that something bad would have happened to him in any case.\n\nAt the same time, Galois clearly realized there was some risk, considering the famous notes he hastily wrote down the night before. In the lower left of this page, we can see the words “Une femme”, referring to his lover."", 'aiModelVersion': '1'}",0.9995
Alex Eustis,Updated 3y,What made the quaternions a great discovery?,"There is a famous story about the discovery of the quaternions by Sir William Rowan Hamilton in 1843. It would simply not do to leave it out.

At the time, it was well known that complex numbers could be interpreted as points in a two-dimensional plane, and that both addition and multiplication could be given geometric interpretations as transformations of that plane: translation and rotation/scaling, respectively.

Naturally, Hamilton wondered if the same could be done with the three-dimensional space in which we live. Is there some way to interpret points (or vectors) in 3D as geometric transformations? Addition of vectors is still translation, of course, but what about multiplication? How do you multiply vectors?

You may know of the cross product in 3D, which is crucially important in many ways, particularly Vector Geometry and Physics. The cross product is very closely related to quaternion multiplication, and Hamilton himself is usually credited with introducing both the dot and cross products in their modern form, as two pieces of how quaternion multiplication works: namely, through the beautiful formula

[
0
,
v
]
[
0
,
w
]
=
[
−
v
⋅
w
,
v
×
w
]
[0,v][0,w]=[−v⋅w,v×w]

which describes the “vector part” of quaternion multiplication.

But… the cross product alone is not the answer Hamilton was seeking, as to how multiplication could be interpreted geometrically in 3D.

Why not? The cross product of two vectors is a vector, and it has other nice properties including the distributive property over addition, making it seem like the perfect candidate.

One answer to this is that the cross product is non-associative. Any binary operation that can be viewed as a “transformation”, geometric or otherwise, has to be associative. For example in 
C
C
, we can view the complex number 
r
e
i
θ
reiθ
 as a combination of scaling by r and rotation through angle 
θ
θ
. In this way, multiplication of complex numbers corresponds exactly to composition of transformations. This is just like how matrix multiplication represents a composition of linear transformations. Again, because function composition is always associative, it is simply not possible to map a group of transformations onto a set with a non-associative operation.

Hamilton himself knew this. Returning to the aforementioned “famous story”, Hamilton one day found himself taking a walk with his wife and pondering — as you do — the nature of 3D space and how to characterize 3D geometry algebraically. Having been previously unable to come up with a satisfactory answer, the reason for this now took shape in his mind, and he found himself so moved by this realization that he stopped to carve the defining formula for quaternion multiplication onto the Brougham Bridge:

i
2
=
j
2
=
k
2
=
i
j
k
=
−
1
i2=j2=k2=ijk=−1
.

Although the carving has faded, a plaque now commemorates the event.

The following day, he would write in a letter:

And here there dawned on me the notion that we must admit, in some sense, a fourth dimension of space for the purpose of calculating with triples.

Wait… what? “Must admit a fourth dimension of space for the purpose of calculating with triples?” If I didn't know better, I would be reasonably worried that these were the ravings of a madman. It's like if I told you:

“Eureka! Finally, I've discovered the Ultimate Fundamental Truth of counting to three! The secret of counting to three is…

… counting to four!”

And yet — there is a certain mathematically precise sense in which Hamilton is completely, indisputably correct! Then, now, and forever! Three-dimensional space simply does not admit of “calculating” in this sense!

Wouldn't you like to know what that sense is? Of course you would. But to do so, we will need to discuss a bit of Abstract Algebra. This is the only context in which we can fully and properly understand Hamilton's “flash of genius”, or at least the ultimate source of his difficulty in working with “triples”.

Let's return to the question Hamilton was pondering; that of calculating “geometrically” analogously to how we calculate in 
C
C
. With the benefit of hindsight, let's not restrict ourselves to two or three or four dimensions, but take the leap into 
n
n
 dimensional space. Notice that 
C
C
 is a two-dimensional vector space over 
R
R
, with basis 
{
1
,
i
}
{1,i}
. That is, each complex number has a unique representation in the form 
a
+
b
i
a+bi
. Similarly, 
H
H
 has the basis 
{
1
,
i
,
j
,
k
}
{1,i,j,k}
. A vector space comes with the operations of addition and scalar multiplication, which are componentwise, easily understood, and boring.

The interesting operation is the vector multiplication: the part Hamilton carved into the bridge. Let's denote this vector multiplication by 
∗
∗
, so if 
v
,
w
∈
R
n
v,w∈Rn
 then 
v
∗
w
∈
R
n
v∗w∈Rn
. We'll insist on the following axioms: For all 
v
,
w
,
x
∈
R
n
v,w,x∈Rn
 and all 
a
∈
R
a∈R
:

Distributive property (left and right):

v
∗
(
w
+
x
)
=
v
∗
w
+
v
∗
x
v∗(w+x)=v∗w+v∗x

(
w
+
x
)
∗
v
=
w
∗
v
+
x
∗
v
(w+x)∗v=w∗v+x∗v

Compatibility with scalar multiplication:

a
(
v
∗
w
)
=
(
a
v
)
∗
w
=
v
∗
(
a
w
)
a(v∗w)=(av)∗w=v∗(aw)

Multiplicative Identity:

There exists 
e
∈
R
n
e∈Rn
 with

e
∗
v
=
v
∗
e
=
v
e∗v=v∗e=v
 for all 
v
∈
R
v∈R
. (Furthermore we abuse notation and write the vector 
a
e
ae
 as just 
a
a
, and 
e
e
 as 
1
1
.)

Associative property:

(
v
∗
w
)
∗
x
=
v
∗
(
w
∗
x
)
(v∗w)∗x=v∗(w∗x)

Multiplicative inverses:

For all 
v
≠
0
v≠0
 there exists 
w
w
 such that

v
∗
w
=
w
∗
v
=
e
v∗w=w∗v=e
.

If all of these axioms are satisfied by the operation 
∗
∗
, the resulting structure is called an (n-dimensional) real division algebra.

Before I reveal the punchline, which is the Frobenius theorem (real division algebras) - Wikipedia
, let's discuss these axioms a bit. The first two (distributive property, compatibility with with scalars) are “easy”. It turns out that you can choose a basis for 
R
n
Rn
, define multiplication of basis vectors arbitrarily and this extends uniquely to all vectors such a way that the first two axioms are satisfied. In other words, there's nothing stopping me from carving some arbitrary equations on a bridge, like

i
2
=
j
2
=
−
1
,
i2=j2=−1,

i
∗
j
=
3.7
,
j
∗
i
=
1
+
2
i
−
3
j
i∗j=3.7,j∗i=1+2i−3j

and this defines a 3-dimensional 
R
R
-algebra with basis 
{
1
,
i
,
j
}
{1,i,j}
. It'll satisfy distributivity and compatibility no problem, and the vector 1 (whose multiplication table is implied) is even a bona fide identity. However, there's no guarantee I will get the last two axioms: associativity and inverses.

You might recognize the last 3 axioms as the axioms for a Group (mathematics) - Wikipedia
 . So let's be a little more clever and borrow the multiplication table for the cyclic group 
Z
3
Z3
. This time I'll simply carve

g
3
=
1
g3=1

onto the bridge, implicitly defining a 3-dimensional 
R
R
-algebra with basis 
{
1
,
g
,
g
2
}
{1,g,g2}
. I guarantee you that Hamilton must have tried this at some point (sans the bridge vandalism). In fact this construction has a name: it's known as the group algebra 
R
Z
3
RZ3
, and it can be used with any group whatsoever. I get the distributive and compatibility axioms “for free”. Because I decided to steal a group structure, it turns out that I will also inherit the identity and associativity axioms from the corresponding group axioms. So what's missing? The last axiom of course: inverses. Although each basis vector has an inverse, this unfortunately does not imply that every nonzero vector has an inverse. For instance, it is easy to show that the vector 
1
+
g
+
g
2
1+g+g2
, multiplied by an arbitrary vector 
a
+
b
g
+
c
g
2
a+bg+cg2
, is equal to 
(
a
+
b
+
c
)
(
1
+
g
+
g
2
)
(a+b+c)(1+g+g2)
 which is evidently not equal to 1. Therefore 
1
+
g
+
g
2
1+g+g2
 has no inverse.

The reason why we might insist on inverses in this context, is the same reason we might insist on associativity: because we want to be able to interpret vector multiplication as composition of geometric transformations. Ideally, we'd want each transformation to be an isometry, or an isometry composed with a dilation as in the case of 
C
C
. We might be okay with “just” a linear transformation, as long as it's invertible. However, if it's not invertible, it must be projecting 
R
n
Rn
 into some smaller-dimensional subspace. In 
R
Z
3
RZ3
 above, we saw that 
(
1
+
g
+
g
2
)
(1+g+g2)
 projects 
R
3
R3
 onto a line. That's not a translation, or rotation, or anything. It's degenerate, so we'll turn our noses up and insist on a division algebra.

Okay, ready for the big reveal? Frobenius (1877) proved there are only three finite-dimensional real division algebras, up to isomorphism: 
R
R
 itself, 
C
C
, and 
H
H
, the Hamiltonian quaternions.

Only those!

As you know, 
R
R
 and 
C
C
 are both fields, which gives 
H
H
 the unique distinction of being the only real division algebra which is not a field (i.e. not commutative). We can even say that every finite-dimensional real division algebra embeds into 
H
H
, though not uniquely. In Abstract Algebra, any algebraic structure which is uniquely characterized up to isomorphism in such a way should be considered fundamental and important.

As for Hamilton's curious remark about “needing to admit a fourth dimension of space”, well… Frobenius absolutely proved it! The thing that Hamilton spent so long looking for — a geometric definition of vector multiplication in the associative, invertible sense of 
C
C
 and 
H
H
 — simply does not exist in three dimensions. But it does exist in four!

And get this: the multiplicative structure of 
H
H
 actually describes the geometry of 
R
3
R3
! This is most likely what he actually meant by that comment. It's not very reasonable to assume that he was somehow prophesizing some version of Frobenius' theorem.

To complete this answer, I'll describe what that means in more rigorous terms. It works almost exactly the same as it does for 
C
C
. In two dimensions, the group of rotations about a fixed point (the origin) is called 
S
O
(
2
)
SO(2)
, or simply the circle group. Well guess what: it's isomorphic to the group of complex numbers of magnitude 1. The isomorphism was already described above: 
e
i
θ
eiθ
 corresponds to a rotation through angle 
θ
θ
.

Now, in three dimensions, the group of rotations about the origin is called 
S
O
(
3
)
SO(3)
. And as above, it's isomorphic to the group of unit quaternions… almost.

I'll get to the “almost” bit in a moment, but first just be amazed at how cool that is! 
S
O
(
3
)
SO(3)
 is kind of crazy. In three dimensions, you don't just select an angle, you select an axis and an angle. When you compose two such rotations with different axes, you do get another rotation, but there's no “basic"" rule that says you just add the angles or whatever. (Well, actually there is, if you allow that rule to be quaternion multiplication itself!) Furthermore, 
S
O
(
3
)
SO(3)
 is non-commutative, so the answer depends on which order you compose them!

The fact that you can characterize 3D rotations as unit quaternions is incredibly useful in math, physics, and even 3D graphics! 3D graphics engines, almost without exception, use quaternions for their computation of how things are to be oriented in space.

The actual isomorphism (well actually it's a 2-to-1 homomorphism) from the unit quaternions onto 
S
O
(
3
)
SO(3)
 is not even that difficult to describe. Given a quaternion, write it in vector form 
[
a
,
v
]
[a,v]
 (where 
v
v
 is the 
b
i
+
c
j
+
d
k
bi+cj+dk
 part). If it's a unit quaternion, that means we can write it in the form

q
=
[
cos
θ
,
(
sin
θ
)
u
]
q=[cos⁡θ,(sin⁡θ)u]

where 
u
u
 is a unit vector. Written in this form, we define the image 
ϕ
(
q
)
ϕ(q)
 to be the (right-handed) rotation by angle 
2
θ
2θ
 about the axis 
u
u
. It turns out that this is a well-defined homomorphism with kernel 
{
1
,
−
1
}
{1,−1}
. For instance, the quaternion 
i
i
 represents a half-turn about the x-axis, as does 
−
i
−i
. Or, 
±
(
1
/
√
2
)
(
1
+
j
)
±(1/2)(1+j)
 represents a quarter-turn about the y-axis. The actual formula for computing the rotation of a given quaternion 
q
q
 on a given vector 
v
∈
R
3
v∈R3
 is the following:

ϕ
(
q
)
(
v
)
=
q
v
q
−
1
ϕ(q)(v)=qvq−1

with 
v
v
 being interpreted as a quaternion with real part equal to zero. It can be shown that 
q
v
q
−
1
qvq−1
 also necessarily has real part equal to zero, so it corresponds to the image vector in 
R
3
R3
.

Anyways, this answer has gotten pretty long, but I felt it was necessary to do this topic justice. The quarternions were an amazing discovery indeed!","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/4p2r8nja60ogc1ks', 'title': 'What made the quaternions a great discovery?', 'score': {'original': 0.60412, 'ai': 0.39588}, 'blocks': [{'text': ""There is a famous story about the discovery of the quaternions by Sir William Rowan Hamilton in 1843. It would simply not do to leave it out.\n\nAt the time, it was well known that complex numbers could be interpreted as points in a two-dimensional plane, and that both addition and multiplication could be given geometric interpretations as transformations of that plane: translation and rotation/scaling, respectively.\n\nNaturally, Hamilton wondered if the same could be done with the three-dimensional space in which we live. Is there some way to interpret points (or vectors) in 3D as geometric transformations? Addition of vectors is still translation, of course, but what about multiplication? How do you multiply vectors?\n\nYou may know of the cross product in 3D, which is crucially important in many ways, particularly Vector Geometry and Physics. The cross product is very closely related to quaternion multiplication, and Hamilton himself is usually credited with introducing both the dot and cross products in their modern form, as two pieces of how quaternion multiplication works: namely, through the beautiful formula\n\n[\n0\n,\nv\n]\n[\n0\n,\nw\n]\n=\n[\n−\nv\n⋅\nw\n,\nv\n×\nw\n]\n[0,v][0,w]=[−v⋅w,v×w]\n\nwhich describes the “vector part” of quaternion multiplication.\n\nBut… the cross product alone is not the answer Hamilton was seeking, as to how multiplication could be interpreted geometrically in 3D.\n\nWhy not? The cross product of two vectors is a vector, and it has other nice properties including the distributive property over addition, making it seem like the perfect candidate.\n\nOne answer to this is that the cross product is non-associative. Any binary operation that can be viewed as a “transformation”, geometric or otherwise, has to be associative. For example in \nC\nC\n, we can view the complex number \nr\ne\ni\nθ\nreiθ\n as a combination of scaling by r and rotation through angle \nθ\nθ\n. In this way, multiplication of complex numbers corresponds exactly to composition of transformations. This is just like how matrix multiplication represents a composition of linear transformations. Again, because function composition is always associative, it is simply not possible to map a group of transformations onto a set with a non-associative operation.\n\nHamilton himself knew this. Returning to the aforementioned “famous story”, Hamilton one day found himself taking a walk with his wife and pondering — as you do — the nature of 3D space and how to characterize 3D geometry algebraically. Having been previously unable to come up with a satisfactory answer, the reason for this now took shape in his mind, and he found himself so moved by this realization that he stopped to carve the defining formula for quaternion multiplication onto the Brougham Bridge:\n\ni\n2\n=\nj\n2\n=\nk\n2\n=\ni\nj\nk\n=\n−\n1\ni2=j2=k2=ijk=−1\n.\n\nAlthough the carving has faded, a plaque now commemorates the event.\n\nThe following day, he would write in a letter:\n\nAnd here there dawned on me the notion that we must admit, in some sense, a fourth dimension of space for the purpose of calculating with triples.\n\nWait… what? “Must admit a fourth dimension of space for the purpose of calculating with triples?” If I didn't know better, I would be reasonably worried that these were the ravings of a madman. It's like if I told you:\n\n“Eureka! Finally, I've discovered the Ultimate Fundamental Truth of counting to three! The secret of"", 'result': {'fake': 0.0401, 'real': 0.9599}, 'status': 'success'}, {'text': ""counting to three is…\n\n… counting to four!”\n\nAnd yet — there is a certain mathematically precise sense in which Hamilton is completely, indisputably correct! Then, now, and forever! Three-dimensional space simply does not admit of “calculating” in this sense!\n\nWouldn't you like to know what that sense is? Of course you would. But to do so, we will need to discuss a bit of Abstract Algebra. This is the only context in which we can fully and properly understand Hamilton's “flash of genius”, or at least the ultimate source of his difficulty in working with “triples”.\n\nLet's return to the question Hamilton was pondering; that of calculating “geometrically” analogously to how we calculate in \nC\nC\n. With the benefit of hindsight, let's not restrict ourselves to two or three or four dimensions, but take the leap into \nn\nn\n dimensional space. Notice that \nC\nC\n is a two-dimensional vector space over \nR\nR\n, with basis \n{\n1\n,\ni\n}\n{1,i}\n. That is, each complex number has a unique representation in the form \na\n+\nb\ni\na+bi\n. Similarly, \nH\nH\n has the basis \n{\n1\n,\ni\n,\nj\n,\nk\n}\n{1,i,j,k}\n. A vector space comes with the operations of addition and scalar multiplication, which are componentwise, easily understood, and boring.\n\nThe interesting operation is the vector multiplication: the part Hamilton carved into the bridge. Let's denote this vector multiplication by \n∗\n∗\n, so if \nv\n,\nw\n∈\nR\nn\nv,w∈Rn\n then \nv\n∗\nw\n∈\nR\nn\nv∗w∈Rn\n. We'll insist on the following axioms: For all \nv\n,\nw\n,\nx\n∈\nR\nn\nv,w,x∈Rn\n and all \na\n∈\nR\na∈R\n:\n\nDistributive property (left and right):\n\nv\n∗\n(\nw\n+\nx\n)\n=\nv\n∗\nw\n+\nv\n∗\nx\nv∗(w+x)=v∗w+v∗x\n\n(\nw\n+\nx\n)\n∗\nv\n=\nw\n∗\nv\n+\nx\n∗\nv\n(w+x)∗v=w∗v+x∗v\n\nCompatibility with scalar multiplication:\n\na\n(\nv\n∗\nw\n)\n=\n(\na\nv\n)\n∗\nw\n=\nv\n∗\n(\na\nw\n)\na(v∗w)=(av)∗w=v∗(aw)\n\nMultiplicative Identity:\n\nThere exists \ne\n∈\nR\nn\ne∈Rn\n with\n\ne\n∗\nv\n=\nv\n∗\ne\n=\nv\ne∗v=v∗e=v\n for all \nv\n∈\nR\nv∈R\n. (Furthermore we abuse notation and write the vector \na\ne\nae\n as just \na\na\n, and \ne\ne\n as \n1\n1\n.)\n\nAssociative property:\n\n(\nv\n∗\nw\n)\n∗\nx\n=\nv\n∗\n(\nw\n∗\nx\n)\n(v∗w)∗x=v∗(w∗x)\n\nMultiplicative inverses:\n\nFor all \nv\n≠\n0\nv≠0\n there exists \nw\nw\n such that\n\nv\n∗\nw\n=\nw\n∗\nv\n=\ne\nv∗w=w∗v=e\n.\n\nIf all of these axioms are satisfied by the operation \n∗\n∗\n, the resulting structure is called an (n-dimensional) real division algebra.\n\nBefore I reveal the punchline, which is the Frobenius theorem (real division algebras) - Wikipedia\n, let's discuss these axioms a bit. The first two (distributive property, compatibility with with scalars) are “easy”. It turns out that you can choose a basis for \nR\nn\nRn\n, define multiplication of basis vectors arbitrarily and this extends uniquely to all vectors such a way that the first two axioms are satisfied. In other words, there's nothing stopping me from carving some arbitrary equations on a bridge, like\n\ni\n2\n=\nj\n2\n=\n−\n1\n,\ni2=j2=−1,\n\ni\n∗\nj\n=\n3.7\n,\nj\n∗\ni\n=\n1\n+\n2\ni\n−\n3\nj\ni∗j=3.7,j∗i=1+2i−3j\n\nand this defines a 3-dimensional \nR\nR\n-algebra with basis \n{\n1\n,\ni\n,\nj\n}\n{1,i,j}\n. It'll satisfy distributivity and compatibility no problem, and the vector 1 (whose multiplication table is implied) is even a bona fide identity. However, there's no guarantee I will get the last two axioms: associativity and inverses.\n\nYou might recognize the last 3 axioms as the axioms for a Group (mathematics) - Wikipedia\n . So let's be a little more clever and borrow the multiplication table for the cyclic group \nZ\n3\nZ3\n. This time I'll simply carve\n\ng\n3\n=\n1\ng3=1\n\nonto the bridge, implicitly defining a 3-dimensional \nR\nR\n-algebra with basis \n{\n1\n,\ng\n,\ng\n2\n}\n{1,g,g2}\n. I guarantee you that Hamilton must have tried this at some point (sans the bridge vandalism). In fact this construction has a name: it's known as the group algebra \nR\nZ\n3\nRZ3\n, and it can be used with any group whatsoever. I get the distributive and compatibility axioms “for free”. Because I decided to steal a group structure,"", 'result': {'fake': 0.0145, 'real': 0.9855}, 'status': 'success'}, {'text': ""it turns out that I will also inherit the identity and associativity axioms from the corresponding group axioms. So what's missing? The last axiom of course: inverses. Although each basis vector has an inverse, this unfortunately does not imply that every nonzero vector has an inverse. For instance, it is easy to show that the vector \n1\n+\ng\n+\ng\n2\n1+g+g2\n, multiplied by an arbitrary vector \na\n+\nb\ng\n+\nc\ng\n2\na+bg+cg2\n, is equal to \n(\na\n+\nb\n+\nc\n)\n(\n1\n+\ng\n+\ng\n2\n)\n(a+b+c)(1+g+g2)\n which is evidently not equal to 1. Therefore \n1\n+\ng\n+\ng\n2\n1+g+g2\n has no inverse.\n\nThe reason why we might insist on inverses in this context, is the same reason we might insist on associativity: because we want to be able to interpret vector multiplication as composition of geometric transformations. Ideally, we'd want each transformation to be an isometry, or an isometry composed with a dilation as in the case of \nC\nC\n. We might be okay with “just” a linear transformation, as long as it's invertible. However, if it's not invertible, it must be projecting \nR\nn\nRn\n into some smaller-dimensional subspace. In \nR\nZ\n3\nRZ3\n above, we saw that \n(\n1\n+\ng\n+\ng\n2\n)\n(1+g+g2)\n projects \nR\n3\nR3\n onto a line. That's not a translation, or rotation, or anything. It's degenerate, so we'll turn our noses up and insist on a division algebra.\n\nOkay, ready for the big reveal? Frobenius (1877) proved there are only three finite-dimensional real division algebras, up to isomorphism: \nR\nR\n itself, \nC\nC\n, and \nH\nH\n, the Hamiltonian quaternions.\n\nOnly those!\n\nAs you know, \nR\nR\n and \nC\nC\n are both fields, which gives \nH\nH\n the unique distinction of being the only real division algebra which is not a field (i.e. not commutative). We can even say that every finite-dimensional real division algebra embeds into \nH\nH\n, though not uniquely. In Abstract Algebra, any algebraic structure which is uniquely characterized up to isomorphism in such a way should be considered fundamental and important.\n\nAs for Hamilton's curious remark about “needing to admit a fourth dimension of space”, well… Frobenius absolutely proved it! The thing that Hamilton spent so long looking for — a geometric definition of vector multiplication in the associative, invertible sense of \nC\nC\n and \nH\nH\n — simply does not exist in three dimensions. But it does exist in four!\n\nAnd get this: the multiplicative structure of \nH\nH\n actually describes the geometry of \nR\n3\nR3\n! This is most likely what he actually meant by that comment. It's not very reasonable to assume that he was somehow prophesizing some version of Frobenius' theorem.\n\nTo complete this answer, I'll describe what that means in more rigorous terms. It works almost exactly the same as it does for \nC\nC\n. In two dimensions, the group of rotations about a fixed point (the origin) is called \nS\nO\n(\n2\n)\nSO(2)\n, or simply the circle group. Well guess what: it's isomorphic to the group of complex numbers of magnitude 1. The isomorphism was already described above: \ne\ni\nθ\neiθ\n corresponds to a rotation through angle \nθ\nθ\n.\n\nNow, in three dimensions, the group of rotations about the origin is called \nS\nO\n(\n3\n)\nSO(3)\n. And as above, it's isomorphic to the group of unit quaternions… almost.\n\nI'll get to the “almost” bit in a moment, but first just be amazed at how cool that is! \nS\nO\n(\n3\n)\nSO(3)\n is kind of crazy. In three"", 'result': {'fake': 0.0763, 'real': 0.9237}, 'status': 'success'}, {'text': 'dimensions, you don\'t just select an angle, you select an axis and an angle. When you compose two such rotations with different axes, you do get another rotation, but there\'s no “basic"" rule that says you just add the angles or whatever. (Well, actually there is, if you allow that rule to be quaternion multiplication itself!) Furthermore, \nS\nO\n(\n3\n)\nSO(3)\n is non-commutative, so the answer depends on which order you compose them!\n\nThe fact that you can characterize 3D rotations as unit quaternions is incredibly useful in math, physics, and even 3D graphics! 3D graphics engines, almost without exception, use quaternions for their computation of how things are to be oriented in space.\n\nThe actual isomorphism (well actually it\'s a 2-to-1 homomorphism) from the unit quaternions onto \nS\nO\n(\n3\n)\nSO(3)\n is not even that difficult to describe. Given a quaternion, write it in vector form \n[\na\n,\nv\n]\n[a,v]\n (where \nv\nv\n is the \nb\ni\n+\nc\nj\n+\nd\nk\nbi+cj+dk\n part). If it\'s a unit quaternion, that means we can write it in the form\n\nq\n=\n[\ncos\nθ\n,\n(\nsin\nθ\n)\nu\n]\nq=[cos\u2061θ,(sin\u2061θ)u]\n\nwhere \nu\nu\n is a unit vector. Written in this form, we define the image \nϕ\n(\nq\n)\nϕ(q)\n to be the (right-handed) rotation by angle \n2\nθ\n2θ\n about the axis \nu\nu\n. It turns out that this is a well-defined homomorphism with kernel \n{\n1\n,\n−\n1\n}\n{1,−1}\n. For instance, the quaternion \ni\ni\n represents a half-turn about the x-axis, as does \n−\ni\n−i\n. Or, \n±\n(\n1\n/\n√\n2\n)\n(\n1\n+\nj\n)\n±(1/2)(1+j)\n represents a quarter-turn about the y-axis. The actual formula for computing the rotation of a given quaternion \nq\nq\n on a given vector \nv\n∈\nR\n3\nv∈R3\n is the following:\n\nϕ\n(\nq\n)\n(\nv\n)\n=\nq\nv\nq\n−\n1\nϕ(q)(v)=qvq−1\n\nwith \nv\nv\n being interpreted as a quaternion with real part equal to zero. It can be shown that \nq\nv\nq\n−\n1\nqvq−1\n also necessarily has real part equal to zero, so it corresponds to the image vector in \nR\n3\nR3\n.\n\nAnyways, this answer has gotten pretty long, but I felt it was necessary to do this topic justice. The quarternions were an amazing discovery indeed!', 'result': {'fake': 0.9339, 'real': 0.0661}, 'status': 'success'}], 'credits_used': 22, 'credits': 1994945, 'subscription': 0, 'content': 'There is a famous story about the discovery of the quaternions by Sir William Rowan Hamilton in 1843. It would simply not do to leave it out.\n\nAt the time, it was well known that complex numbers could be interpreted as points in a two-dimensional plane, and that both addition and multiplication could be given geometric interpretations as transformations of that plane: translation and rotation/scaling, respectively.\n\nNaturally, Hamilton wondered if the same could be done with the three-dimensional space in which we live. Is there some way to interpret points (or vectors) in 3D as geometric transformations? Addition of vectors is still translation, of course, but what about multiplication? How do you multiply vectors?\n\nYou may know of the cross product in 3D, which is crucially important in many ways, particularly Vector Geometry and Physics. The cross product is very closely related to quaternion multiplication, and Hamilton himself is usually credited with introducing both the dot and cross products in their modern form, as two pieces of how quaternion multiplication works: namely, through the beautiful formula\n\n[\n0\n,\nv\n]\n[\n0\n,\nw\n]\n=\n[\n−\nv\n⋅\nw\n,\nv\n×\nw\n]\n[0,v][0,w]=[−v⋅w,v×w]\n\nwhich describes the “vector part” of quaternion multiplication.\n\nBut… the cross product alone is not the answer Hamilton was seeking, as to how multiplication could be interpreted geometrically in 3D.\n\nWhy not? The cross product of two vectors is a vector, and it has other nice properties including the distributive property over addition, making it seem like the perfect candidate.\n\nOne answer to this is that the cross product is non-associative. Any binary operation that can be viewed as a “transformation”, geometric or otherwise, has to be associative. For example in \nC\nC\n, we can view the complex number \nr\ne\ni\nθ\nreiθ\n as a combination of scaling by r and rotation through angle \nθ\nθ\n. In this way, multiplication of complex numbers corresponds exactly to composition of transformations. This is just like how matrix multiplication represents a composition of linear transformations. Again, because function composition is always associative, it is simply not possible to map a group of transformations onto a set with a non-associative operation.\n\nHamilton himself knew this. Returning to the aforementioned “famous story”, Hamilton one day found himself taking a walk with his wife and pondering — as you do — the nature of 3D space and how to characterize 3D geometry algebraically. Having been previously unable to come up with a satisfactory answer, the reason for this now took shape in his mind, and he found himself so moved by this realization that he stopped to carve the defining formula for quaternion multiplication onto the Brougham Bridge:\n\ni\n2\n=\nj\n2\n=\nk\n2\n=\ni\nj\nk\n=\n−\n1\ni2=j2=k2=ijk=−1\n.\n\nAlthough the carving has faded, a plaque now commemorates the event.\n\nThe following day, he would write in a letter:\n\nAnd here there dawned on me the notion that we must admit, in some sense, a fourth dimension of space for the purpose of calculating with triples.\n\nWait… what? “Must admit a fourth dimension of space for the purpose of calculating with triples?” If I didn\'t know better, I would be reasonably worried that these were the ravings of a madman. It\'s like if I told you:\n\n“Eureka! Finally, I\'ve discovered the Ultimate Fundamental Truth of counting to three! The secret of counting to three is…\n\n… counting to four!”\n\nAnd yet — there is a certain mathematically precise sense in which Hamilton is completely, indisputably correct! Then, now, and forever! Three-dimensional space simply does not admit of “calculating” in this sense!\n\nWouldn\'t you like to know what that sense is? Of course you would. But to do so, we will need to discuss a bit of Abstract Algebra. This is the only context in which we can fully and properly understand Hamilton\'s “flash of genius”, or at least the ultimate source of his difficulty in working with “triples”.\n\nLet\'s return to the question Hamilton was pondering; that of calculating “geometrically” analogously to how we calculate in \nC\nC\n. With the benefit of hindsight, let\'s not restrict ourselves to two or three or four dimensions, but take the leap into \nn\nn\n dimensional space. Notice that \nC\nC\n is a two-dimensional vector space over \nR\nR\n, with basis \n{\n1\n,\ni\n}\n{1,i}\n. That is, each complex number has a unique representation in the form \na\n+\nb\ni\na+bi\n. Similarly, \nH\nH\n has the basis \n{\n1\n,\ni\n,\nj\n,\nk\n}\n{1,i,j,k}\n. A vector space comes with the operations of addition and scalar multiplication, which are componentwise, easily understood, and boring.\n\nThe interesting operation is the vector multiplication: the part Hamilton carved into the bridge. Let\'s denote this vector multiplication by \n∗\n∗\n, so if \nv\n,\nw\n∈\nR\nn\nv,w∈Rn\n then \nv\n∗\nw\n∈\nR\nn\nv∗w∈Rn\n. We\'ll insist on the following axioms: For all \nv\n,\nw\n,\nx\n∈\nR\nn\nv,w,x∈Rn\n and all \na\n∈\nR\na∈R\n:\n\nDistributive property (left and right):\n\nv\n∗\n(\nw\n+\nx\n)\n=\nv\n∗\nw\n+\nv\n∗\nx\nv∗(w+x)=v∗w+v∗x\n\n(\nw\n+\nx\n)\n∗\nv\n=\nw\n∗\nv\n+\nx\n∗\nv\n(w+x)∗v=w∗v+x∗v\n\nCompatibility with scalar multiplication:\n\na\n(\nv\n∗\nw\n)\n=\n(\na\nv\n)\n∗\nw\n=\nv\n∗\n(\na\nw\n)\na(v∗w)=(av)∗w=v∗(aw)\n\nMultiplicative Identity:\n\nThere exists \ne\n∈\nR\nn\ne∈Rn\n with\n\ne\n∗\nv\n=\nv\n∗\ne\n=\nv\ne∗v=v∗e=v\n for all \nv\n∈\nR\nv∈R\n. (Furthermore we abuse notation and write the vector \na\ne\nae\n as just \na\na\n, and \ne\ne\n as \n1\n1\n.)\n\nAssociative property:\n\n(\nv\n∗\nw\n)\n∗\nx\n=\nv\n∗\n(\nw\n∗\nx\n)\n(v∗w)∗x=v∗(w∗x)\n\nMultiplicative inverses:\n\nFor all \nv\n≠\n0\nv≠0\n there exists \nw\nw\n such that\n\nv\n∗\nw\n=\nw\n∗\nv\n=\ne\nv∗w=w∗v=e\n.\n\nIf all of these axioms are satisfied by the operation \n∗\n∗\n, the resulting structure is called an (n-dimensional) real division algebra.\n\nBefore I reveal the punchline, which is the Frobenius theorem (real division algebras) - Wikipedia\n, let\'s discuss these axioms a bit. The first two (distributive property, compatibility with with scalars) are “easy”. It turns out that you can choose a basis for \nR\nn\nRn\n, define multiplication of basis vectors arbitrarily and this extends uniquely to all vectors such a way that the first two axioms are satisfied. In other words, there\'s nothing stopping me from carving some arbitrary equations on a bridge, like\n\ni\n2\n=\nj\n2\n=\n−\n1\n,\ni2=j2=−1,\n\ni\n∗\nj\n=\n3.7\n,\nj\n∗\ni\n=\n1\n+\n2\ni\n−\n3\nj\ni∗j=3.7,j∗i=1+2i−3j\n\nand this defines a 3-dimensional \nR\nR\n-algebra with basis \n{\n1\n,\ni\n,\nj\n}\n{1,i,j}\n. It\'ll satisfy distributivity and compatibility no problem, and the vector 1 (whose multiplication table is implied) is even a bona fide identity. However, there\'s no guarantee I will get the last two axioms: associativity and inverses.\n\nYou might recognize the last 3 axioms as the axioms for a Group (mathematics) - Wikipedia\n . So let\'s be a little more clever and borrow the multiplication table for the cyclic group \nZ\n3\nZ3\n. This time I\'ll simply carve\n\ng\n3\n=\n1\ng3=1\n\nonto the bridge, implicitly defining a 3-dimensional \nR\nR\n-algebra with basis \n{\n1\n,\ng\n,\ng\n2\n}\n{1,g,g2}\n. I guarantee you that Hamilton must have tried this at some point (sans the bridge vandalism). In fact this construction has a name: it\'s known as the group algebra \nR\nZ\n3\nRZ3\n, and it can be used with any group whatsoever. I get the distributive and compatibility axioms “for free”. Because I decided to steal a group structure, it turns out that I will also inherit the identity and associativity axioms from the corresponding group axioms. So what\'s missing? The last axiom of course: inverses. Although each basis vector has an inverse, this unfortunately does not imply that every nonzero vector has an inverse. For instance, it is easy to show that the vector \n1\n+\ng\n+\ng\n2\n1+g+g2\n, multiplied by an arbitrary vector \na\n+\nb\ng\n+\nc\ng\n2\na+bg+cg2\n, is equal to \n(\na\n+\nb\n+\nc\n)\n(\n1\n+\ng\n+\ng\n2\n)\n(a+b+c)(1+g+g2)\n which is evidently not equal to 1. Therefore \n1\n+\ng\n+\ng\n2\n1+g+g2\n has no inverse.\n\nThe reason why we might insist on inverses in this context, is the same reason we might insist on associativity: because we want to be able to interpret vector multiplication as composition of geometric transformations. Ideally, we\'d want each transformation to be an isometry, or an isometry composed with a dilation as in the case of \nC\nC\n. We might be okay with “just” a linear transformation, as long as it\'s invertible. However, if it\'s not invertible, it must be projecting \nR\nn\nRn\n into some smaller-dimensional subspace. In \nR\nZ\n3\nRZ3\n above, we saw that \n(\n1\n+\ng\n+\ng\n2\n)\n(1+g+g2)\n projects \nR\n3\nR3\n onto a line. That\'s not a translation, or rotation, or anything. It\'s degenerate, so we\'ll turn our noses up and insist on a division algebra.\n\nOkay, ready for the big reveal? Frobenius (1877) proved there are only three finite-dimensional real division algebras, up to isomorphism: \nR\nR\n itself, \nC\nC\n, and \nH\nH\n, the Hamiltonian quaternions.\n\nOnly those!\n\nAs you know, \nR\nR\n and \nC\nC\n are both fields, which gives \nH\nH\n the unique distinction of being the only real division algebra which is not a field (i.e. not commutative). We can even say that every finite-dimensional real division algebra embeds into \nH\nH\n, though not uniquely. In Abstract Algebra, any algebraic structure which is uniquely characterized up to isomorphism in such a way should be considered fundamental and important.\n\nAs for Hamilton\'s curious remark about “needing to admit a fourth dimension of space”, well… Frobenius absolutely proved it! The thing that Hamilton spent so long looking for — a geometric definition of vector multiplication in the associative, invertible sense of \nC\nC\n and \nH\nH\n — simply does not exist in three dimensions. But it does exist in four!\n\nAnd get this: the multiplicative structure of \nH\nH\n actually describes the geometry of \nR\n3\nR3\n! This is most likely what he actually meant by that comment. It\'s not very reasonable to assume that he was somehow prophesizing some version of Frobenius\' theorem.\n\nTo complete this answer, I\'ll describe what that means in more rigorous terms. It works almost exactly the same as it does for \nC\nC\n. In two dimensions, the group of rotations about a fixed point (the origin) is called \nS\nO\n(\n2\n)\nSO(2)\n, or simply the circle group. Well guess what: it\'s isomorphic to the group of complex numbers of magnitude 1. The isomorphism was already described above: \ne\ni\nθ\neiθ\n corresponds to a rotation through angle \nθ\nθ\n.\n\nNow, in three dimensions, the group of rotations about the origin is called \nS\nO\n(\n3\n)\nSO(3)\n. And as above, it\'s isomorphic to the group of unit quaternions… almost.\n\nI\'ll get to the “almost” bit in a moment, but first just be amazed at how cool that is! \nS\nO\n(\n3\n)\nSO(3)\n is kind of crazy. In three dimensions, you don\'t just select an angle, you select an axis and an angle. When you compose two such rotations with different axes, you do get another rotation, but there\'s no “basic"" rule that says you just add the angles or whatever. (Well, actually there is, if you allow that rule to be quaternion multiplication itself!) Furthermore, \nS\nO\n(\n3\n)\nSO(3)\n is non-commutative, so the answer depends on which order you compose them!\n\nThe fact that you can characterize 3D rotations as unit quaternions is incredibly useful in math, physics, and even 3D graphics! 3D graphics engines, almost without exception, use quaternions for their computation of how things are to be oriented in space.\n\nThe actual isomorphism (well actually it\'s a 2-to-1 homomorphism) from the unit quaternions onto \nS\nO\n(\n3\n)\nSO(3)\n is not even that difficult to describe. Given a quaternion, write it in vector form \n[\na\n,\nv\n]\n[a,v]\n (where \nv\nv\n is the \nb\ni\n+\nc\nj\n+\nd\nk\nbi+cj+dk\n part). If it\'s a unit quaternion, that means we can write it in the form\n\nq\n=\n[\ncos\nθ\n,\n(\nsin\nθ\n)\nu\n]\nq=[cos\u2061θ,(sin\u2061θ)u]\n\nwhere \nu\nu\n is a unit vector. Written in this form, we define the image \nϕ\n(\nq\n)\nϕ(q)\n to be the (right-handed) rotation by angle \n2\nθ\n2θ\n about the axis \nu\nu\n. It turns out that this is a well-defined homomorphism with kernel \n{\n1\n,\n−\n1\n}\n{1,−1}\n. For instance, the quaternion \ni\ni\n represents a half-turn about the x-axis, as does \n−\ni\n−i\n. Or, \n±\n(\n1\n/\n√\n2\n)\n(\n1\n+\nj\n)\n±(1/2)(1+j)\n represents a quarter-turn about the y-axis. The actual formula for computing the rotation of a given quaternion \nq\nq\n on a given vector \nv\n∈\nR\n3\nv∈R3\n is the following:\n\nϕ\n(\nq\n)\n(\nv\n)\n=\nq\nv\nq\n−\n1\nϕ(q)(v)=qvq−1\n\nwith \nv\nv\n being interpreted as a quaternion with real part equal to zero. It can be shown that \nq\nv\nq\n−\n1\nqvq−1\n also necessarily has real part equal to zero, so it corresponds to the image vector in \nR\n3\nR3\n.\n\nAnyways, this answer has gotten pretty long, but I felt it was necessary to do this topic justice. The quarternions were an amazing discovery indeed!', 'aiModelVersion': '1'}",0.60412
David Joyce,Updated Oct 6,Why did some mathematicians reject Calculus after Newton published it?,"One mathematician who rejected calculus was the French mathematician Michel Rolle (1652–1719). He is the very mathematician known for Rolle’s theorem, an important theorem for the foundations of calculus, so it’s surprising that he rejected calculus. By the way, it wasn’t called “Rolle’s theorem” until the 1800s.

Rolle appreciated the rigor of geometry of Euclid, Archimedes, and the many who followed the formal tradition of mathematics. It had the ability to prove without flaws. He also was enamored of symbolic algebra which was still being developed in his time. He’s known for popularizing the equal sign 
=
=
 and inventing the notation 
n
√
x
xn
 for roots higher than the square root.

Rolle’s theorem is his theorem, at least for polynomials, but he didn’t state it in terms of derivatives, and he didn’t use calculus to prove it. He was interested in developing an algorithm for finding roots of polynomials, and in the process he used what he called the cascade of a polynomial, but we know it as derivative of the polynomial. If you have two roots 
a
a
 and 
b
b
 of a polynomial 
f
(
x
)
,
f(x),
 then the cascade, which I’ll write as 
f
′
(
x
)
,
f′(x),
 has a lower degree than 
f
(
x
)
,
f(x),
 and it has a root between 
a
a
 and 
b
.
b.
 Knowing the roots of 
f
′
(
x
)
f′(x)
 is central to his algorithm for finding the roots of 
f
(
x
)
.
f(x).
 To find the roots of 
f
′
(
x
)
,
f′(x),
 take its cascade 
f
′′
(
x
)
f″(x)
 which has a lower degree so it’s easier to find its roots. Keep going until you get a linear function whose root is easy to find, and work your way back up.

What Rolle didn’t like about infinitesimal calculus was the infinitesimals. There are no infinitesimals in geometry. Calculus at the time was not rigorous. There was no basis—no axioms—for infinitesimal calculus. When Newton wrote his Principia Mathematica, Newton knew it had no basis, so he proved all his theorems by geometry. On the other hand, Leibniz’ calculus blatantly used infinitesimals, but there was no proof that it worked, and not even a formal definition for infinitesimals.

One particular statement that Rolle found difficult to accept was this “axiom” from l’Hôpital who used Leibniz’ infinitesimals as a basis for calculus:

Grant that two quantities whose difference is an infinitely small quantity may be taken (or used) indifferently for each other; or (which is the same thing) that a quantity which is increased or decreased only by an infinitesimally small quantity may be considered as remaining the same.

Does that even make sense? L’Hôpital was the first to write a book on calculus, so Rolle’s criticism was warranted.

Nonetheless, because calculus worked, it’s flaws were ignored. It wasn’t until the 1800s that solid foundations were developed for calculus. That required finding foundations for real numbers, for arithmetic, and for logic itself.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/clygenk6j3u4q5x9', 'title': 'Why did some mathematicians reject Calculus after Newton published it?', 'score': {'original': 0.9987, 'ai': 0.0013}, 'blocks': [{'text': 'One mathematician who rejected calculus was the French mathematician Michel Rolle (1652–1719). He is the very mathematician known for Rolle’s theorem, an important theorem for the foundations of calculus, so it’s surprising that he rejected calculus. By the way, it wasn’t called “Rolle’s theorem” until the 1800s.\n\nRolle appreciated the rigor of geometry of Euclid, Archimedes, and the many who followed the formal tradition of mathematics. It had the ability to prove without flaws. He also was enamored of symbolic algebra which was still being developed in his time. He’s known for popularizing the equal sign \n=\n=\n and inventing the notation \nn\n√\nx\nxn\n for roots higher than the square root.\n\nRolle’s theorem is his theorem, at least for polynomials, but he didn’t state it in terms of derivatives, and he didn’t use calculus to prove it. He was interested in developing an algorithm for finding roots of polynomials, and in the process he used what he called the cascade of a polynomial, but we know it as derivative of the polynomial. If you have two roots \na\na\n and \nb\nb\n of a polynomial \nf\n(\nx\n)\n,\nf(x),\n then the cascade, which I’ll write as \nf\n′\n(\nx\n)\n,\nf′(x),\n has a lower degree than \nf\n(\nx\n)\n,\nf(x),\n and it has a root between \na\na\n and \nb\n.\nb.\n Knowing the roots of \nf\n′\n(\nx\n)\nf′(x)\n is central to his algorithm for finding the roots of \nf\n(\nx\n)\n.\nf(x).\n To find the roots of \nf\n′\n(\nx\n)\n,\nf′(x),\n take its cascade \nf\n′′\n(\nx\n)\nf″(x)\n which has a lower degree so it’s easier to find its roots. Keep going until you get a linear function whose root is easy to find, and work your way back up.\n\nWhat Rolle didn’t like about infinitesimal calculus was the infinitesimals. There are no infinitesimals in geometry. Calculus at the time was not rigorous. There was no basis—no axioms—for infinitesimal calculus. When Newton wrote his Principia Mathematica, Newton knew it had no basis, so he proved all his theorems by geometry. On the other hand, Leibniz’ calculus blatantly used infinitesimals, but there was no proof that it worked, and not even a formal definition for infinitesimals.\n\nOne particular statement that Rolle found difficult to accept was this “axiom” from l’Hôpital who used Leibniz’ infinitesimals as a basis for calculus:\n\nGrant that two quantities whose difference is an infinitely small quantity may be taken (or used) indifferently for each other; or (which is the same thing) that a quantity which is increased or decreased only by an infinitesimally small quantity may be considered as remaining the same.\n\nDoes that even make sense? L’Hôpital was the first to write a book on calculus, so Rolle’s criticism was warranted.\n\nNonetheless, because calculus worked, it’s flaws were ignored. It wasn’t until the 1800s that solid foundations were developed for calculus. That required finding foundations for real numbers, for arithmetic, and for logic itself.', 'result': {'fake': 0.0013, 'real': 0.9987}, 'status': 'success'}], 'credits_used': 6, 'credits': 1994939, 'subscription': 0, 'content': 'One mathematician who rejected calculus was the French mathematician Michel Rolle (1652–1719). He is the very mathematician known for Rolle’s theorem, an important theorem for the foundations of calculus, so it’s surprising that he rejected calculus. By the way, it wasn’t called “Rolle’s theorem” until the 1800s.\n\nRolle appreciated the rigor of geometry of Euclid, Archimedes, and the many who followed the formal tradition of mathematics. It had the ability to prove without flaws. He also was enamored of symbolic algebra which was still being developed in his time. He’s known for popularizing the equal sign \n=\n=\n and inventing the notation \nn\n√\nx\nxn\n for roots higher than the square root.\n\nRolle’s theorem is his theorem, at least for polynomials, but he didn’t state it in terms of derivatives, and he didn’t use calculus to prove it. He was interested in developing an algorithm for finding roots of polynomials, and in the process he used what he called the cascade of a polynomial, but we know it as derivative of the polynomial. If you have two roots \na\na\n and \nb\nb\n of a polynomial \nf\n(\nx\n)\n,\nf(x),\n then the cascade, which I’ll write as \nf\n′\n(\nx\n)\n,\nf′(x),\n has a lower degree than \nf\n(\nx\n)\n,\nf(x),\n and it has a root between \na\na\n and \nb\n.\nb.\n Knowing the roots of \nf\n′\n(\nx\n)\nf′(x)\n is central to his algorithm for finding the roots of \nf\n(\nx\n)\n.\nf(x).\n To find the roots of \nf\n′\n(\nx\n)\n,\nf′(x),\n take its cascade \nf\n′′\n(\nx\n)\nf″(x)\n which has a lower degree so it’s easier to find its roots. Keep going until you get a linear function whose root is easy to find, and work your way back up.\n\nWhat Rolle didn’t like about infinitesimal calculus was the infinitesimals. There are no infinitesimals in geometry. Calculus at the time was not rigorous. There was no basis—no axioms—for infinitesimal calculus. When Newton wrote his Principia Mathematica, Newton knew it had no basis, so he proved all his theorems by geometry. On the other hand, Leibniz’ calculus blatantly used infinitesimals, but there was no proof that it worked, and not even a formal definition for infinitesimals.\n\nOne particular statement that Rolle found difficult to accept was this “axiom” from l’Hôpital who used Leibniz’ infinitesimals as a basis for calculus:\n\nGrant that two quantities whose difference is an infinitely small quantity may be taken (or used) indifferently for each other; or (which is the same thing) that a quantity which is increased or decreased only by an infinitesimally small quantity may be considered as remaining the same.\n\nDoes that even make sense? L’Hôpital was the first to write a book on calculus, so Rolle’s criticism was warranted.\n\nNonetheless, because calculus worked, it’s flaws were ignored. It wasn’t until the 1800s that solid foundations were developed for calculus. That required finding foundations for real numbers, for arithmetic, and for logic itself.', 'aiModelVersion': '1'}",0.9987
Christian Santangelo,Updated 3y,Why aren't mathematicians scientists?,"Before answering this question, I have to say that there is overlap between what scientists do and what mathematicians do and any generalizations only apply - if they apply - in the aggregate. Before getting into it, let me ask you to complete the sequence: 1, 2, 4, 8 Mathematics is deductive. A mathematician starts with definitions and assumptions and deduces from those things that must be true. For a mathematician, the specific sequence cannot be completed because the next term could be anything. Anything. In the absence of information, the next term could be “blue fish”. Let’s contrast that with how a scientist might approach the problem. Looking at the digits in the sequence, I can think of several simple rules that could lead to those first four numbers, but none simpler than 20202^0, 21212^1, 22222^2, 23232^3. Therefore, I would hypothesize that 2n2n2^n is the rule and predict that the next term was 16, then 32, and so on. The next step is to perform the experiment and acquire the next term. Aha! It’s 16. And so on. Every term I find that agrees with my rule provides more confidence that my original guess at the rule was right. It’s like the old jab about engineers, physicists and mathematicians traveling on a train through Scotland. The engineer looks out the window, sees a single black sheep, and says “Oh, the sheep in Scotland are black!”. The physicist responds, “No, my friend, all we know is that at least one sheep in Scotland is black.” The mathematician scoffs, “On the contrary, all we know is that at least one side of one sheep in Scotland is black.” This is a joke at mathematicians’ expense, of course (and maybe physicists’ expense). That’s because it runs afoul of Occam’s razor, which says that the most likely rule is the simplest rule. But a mathematician might say, “What does simple mean?” The truth is, it isn’t well-defined at all, and by some definitions of simple, I would argue that Ptolemy’s model of the solar system beats Kepler’s (people back then were not idiots by any stretch of the imagination). But even with a proper definition of simple, Occam’s razor is an assumption about how the universe itself works which may or may not be true. None of this is a problem for science - we’re often looking for what we think of as the simplest models that get us good quantitative agreement with future experiments and, arguably, it matters less if those models are correct. In most problems, we don’t throw out Newton’s equations just because Einstein came up with better ones. In the end, though, the mathematicians are right, at least about math. The world of mathematics is littered with things that are true for many examples but not in general. Consider, as one example, the Borwein integral, a pattern which fails completely at the 8th step (and in fact, this example can be modified to persist as long as you want). Here is another example. Consider li(x)=∫x0dtlntli(x)=∫0xdtln⁡t\textrm{li}(x) = \int_0^x \frac{dt}{\ln t} Apparently this number is larger than the number of prime numbers less than x, as has been confirmed numerically .. up until somewhere around x=10316x=10316x = 10^{316}. (John Baez has a nice description of both of these pattern failures.) Finally, I present to you the case of the shortest math paper, which is also a good example of a pattern failing:In practice, the way scientists and mathematicians approach problems is less different than you might think based on these examples. The key word in the shortest paper is “conjecture”. A conjecture is precisely what scientists do. I can verify from experience that mathematicians and physicists often think about problems in a similar intuitive way. The difference is in the standard of proof and what kind of reasoning (deductive, inductive, etc.) is considered publishable.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/3ua8nqp1ehsryjlg', 'title': ""Why aren't mathematicians scientists?"", 'score': {'original': 0.50315, 'ai': 0.49685}, 'blocks': [{'text': 'Before answering this question, I have to say that there is overlap between what scientists do and what mathematicians do and any generalizations only apply - if they apply - in the aggregate. Before getting into it, let me ask you to complete the sequence: 1, 2, 4, 8 Mathematics is deductive. A mathematician starts with definitions and assumptions and deduces from those things that must be true. For a mathematician, the specific sequence cannot be completed because the next term could be anything. Anything. In the absence of information, the next term could be “blue fish”. Let’s contrast that with how a scientist might approach the problem. Looking at the digits in the sequence, I can think of several simple rules that could lead to those first four numbers, but none simpler than 20202^0, 21212^1, 22222^2, 23232^3. Therefore, I would hypothesize that 2n2n2^n is the rule and predict that the next term was 16, then 32, and so on. The next step is to perform the experiment and acquire the next term. Aha! It’s 16. And so on. Every term I find that agrees with my rule provides more confidence that my original guess at the rule was right. It’s like the old jab about engineers, physicists and mathematicians traveling on a train through Scotland. The engineer looks out the window, sees a single black sheep, and says “Oh, the sheep in Scotland are black!”. The physicist responds, “No, my friend, all we know is that at least one sheep in Scotland is black.” The mathematician scoffs, “On the contrary, all we know is that at least one side of one sheep in Scotland is black.” This is a joke at mathematicians’ expense, of course (and maybe physicists’ expense). That’s because it runs afoul of Occam’s razor, which says that the most likely rule is the simplest rule. But a mathematician might say, “What does simple mean?” The truth is, it isn’t well-defined at all, and by some definitions of simple, I would argue that Ptolemy’s model of the solar system beats Kepler’s (people back then were not idiots by any stretch of the imagination). But even with a proper definition of simple, Occam’s razor is an assumption about how the universe itself works which may or may not be true. None of this is a problem for science - we’re often looking for what we think of as the simplest models that get us good quantitative agreement with future experiments and, arguably, it matters less if those models are correct. In most problems, we don’t throw out Newton’s equations just because Einstein came up with better ones. In the end, though, the mathematicians are right, at least about math. The world of mathematics is littered with things that are true for many examples but not in general. Consider, as one example, the Borwein integral, a pattern which fails completely at the 8th step (and in fact, this example can be modified to persist as long as you want). Here is another example. Consider li(x)=∫x0dtlntli(x)=∫0xdtln\u2061t\\textrm{li}(x) = \\int_0^x \\frac{dt}{\\ln t} Apparently this', 'result': {'fake': 0.0145, 'real': 0.9855}, 'status': 'success'}, {'text': 'number is larger than the number of prime numbers less than x, as has been confirmed numerically .. up until somewhere around x=10316x=10316x = 10^{316}. (John Baez has a nice description of both of these pattern failures.) Finally, I present to you the case of the shortest math paper, which is also a good example of a pattern failing:In practice, the way scientists and mathematicians approach problems is less different than you might think based on these examples. The key word in the shortest paper is “conjecture”. A conjecture is precisely what scientists do. I can verify from experience that mathematicians and physicists often think about problems in a similar intuitive way. The difference is in the standard of proof and what kind of reasoning (deductive, inductive, etc.) is considered publishable.', 'result': {'fake': 0.9792, 'real': 0.0208}, 'status': 'success'}], 'credits_used': 7, 'credits': 1994932, 'subscription': 0, 'content': 'Before answering this question, I have to say that there is overlap between what scientists do and what mathematicians do and any generalizations only apply - if they apply - in the aggregate. Before getting into it, let me ask you to complete the sequence: 1, 2, 4, 8 Mathematics is deductive. A mathematician starts with definitions and assumptions and deduces from those things that must be true. For a mathematician, the specific sequence cannot be completed because the next term could be anything. Anything. In the absence of information, the next term could be “blue fish”. Let’s contrast that with how a scientist might approach the problem. Looking at the digits in the sequence, I can think of several simple rules that could lead to those first four numbers, but none simpler than 20202^0, 21212^1, 22222^2, 23232^3. Therefore, I would hypothesize that 2n2n2^n is the rule and predict that the next term was 16, then 32, and so on. The next step is to perform the experiment and acquire the next term. Aha! It’s 16. And so on. Every term I find that agrees with my rule provides more confidence that my original guess at the rule was right. It’s like the old jab about engineers, physicists and mathematicians traveling on a train through Scotland. The engineer looks out the window, sees a single black sheep, and says “Oh, the sheep in Scotland are black!”. The physicist responds, “No, my friend, all we know is that at least one sheep in Scotland is black.” The mathematician scoffs, “On the contrary, all we know is that at least one side of one sheep in Scotland is black.” This is a joke at mathematicians’ expense, of course (and maybe physicists’ expense). That’s because it runs afoul of Occam’s razor, which says that the most likely rule is the simplest rule. But a mathematician might say, “What does simple mean?” The truth is, it isn’t well-defined at all, and by some definitions of simple, I would argue that Ptolemy’s model of the solar system beats Kepler’s (people back then were not idiots by any stretch of the imagination). But even with a proper definition of simple, Occam’s razor is an assumption about how the universe itself works which may or may not be true. None of this is a problem for science - we’re often looking for what we think of as the simplest models that get us good quantitative agreement with future experiments and, arguably, it matters less if those models are correct. In most problems, we don’t throw out Newton’s equations just because Einstein came up with better ones. In the end, though, the mathematicians are right, at least about math. The world of mathematics is littered with things that are true for many examples but not in general. Consider, as one example, the Borwein integral, a pattern which fails completely at the 8th step (and in fact, this example can be modified to persist as long as you want). Here is another example. Consider li(x)=∫x0dtlntli(x)=∫0xdtln\u2061t\\textrm{li}(x) = \\int_0^x \\frac{dt}{\\ln t} Apparently this number is larger than the number of prime numbers less than x, as has been confirmed numerically .. up until somewhere around x=10316x=10316x = 10^{316}. (John Baez has a nice description of both of these pattern failures.) Finally, I present to you the case of the shortest math paper, which is also a good example of a pattern failing:In practice, the way scientists and mathematicians approach problems is less different than you might think based on these examples. The key word in the shortest paper is “conjecture”. A conjecture is precisely what scientists do. I can verify from experience that mathematicians and physicists often think about problems in a similar intuitive way. The difference is in the standard of proof and what kind of reasoning (deductive, inductive, etc.) is considered publishable.', 'aiModelVersion': '1'}",0.50315
Senia Sheydvasser,Updated 7y,Is it true that calculus was invented before Leibniz and Newton in India?,"My typical answer to this is that Leibniz and Newton invented calculus, but they did not invent derivatives, integration, Taylor series, or even the Fundamental Theorem of Calculus.

Indeed, a very rough notion of integration goes back to the ancient Greeks. Archimedes already developed the method of exhaustion to the point where he could compute the volume of a cone, sphere, etc.

Likewise, Bhaskaracharya II made many remarkable improvements upon existing knowledge, and worked with what we today would recognize as derivatives and integrals. He even had a preliminary notion of infinitesimals.

There are other people whose contributions should be noted. Madhava of Sangamagrama
 had a concept of Taylor series, and his name now adorns what used to be known as the Leibniz series. There was also a generation of European mathematicians that predated Leibniz and Newton that made various refinements and extensions to all of the preceding notions—among them: Barrow, Fermat, Pascal, and Descartes (without Cartesian geometry, calculus would have been impossible).

A rudimentary form of the Fundamental Theorem of Calculus was stated and proved by James Gregory, and then generalized and improved by Barrow.

One might well wonder what on earth Newton and Leibniz contributed, in that case. The answer is that Newton and Leibniz were the first that took all of these disparate results and ideas and formed them into a coherent framework; in particular, theirs is the first work to deal with infinitesimal quantities in a reasonably systematic and formal way (which wound up being completely reworked and then re-reworked later, but such is the fate of most foundational results).

As a result, they were able to prove more general results than anyone who had preceded them, and they opened the door to the next generation of mathematicians who built up a mighty fortress upon the foundations of Newton and Leibniz.

History—especially popular history—has a tendency to attribute whole theories and results to singular individuals. The truth, however, is that usually there is a long history of preceding results that made these accomplishments possible.

Or, in Newton’s own words, ""If I have seen further, it is by standing on the shoulders of giants.""","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/toemki50swn986xj', 'title': 'Is it true that calculus was invented before Leibniz and Newton in India?', 'score': {'original': 0.9993, 'ai': 0.0007}, 'blocks': [{'text': 'My typical answer to this is that Leibniz and Newton invented calculus, but they did not invent derivatives, integration, Taylor series, or even the Fundamental Theorem of Calculus.\n\nIndeed, a very rough notion of integration goes back to the ancient Greeks. Archimedes already developed the method of exhaustion to the point where he could compute the volume of a cone, sphere, etc.\n\nLikewise, Bhaskaracharya II made many remarkable improvements upon existing knowledge, and worked with what we today would recognize as derivatives and integrals. He even had a preliminary notion of infinitesimals.\n\nThere are other people whose contributions should be noted. Madhava of Sangamagrama\n had a concept of Taylor series, and his name now adorns what used to be known as the Leibniz series. There was also a generation of European mathematicians that predated Leibniz and Newton that made various refinements and extensions to all of the preceding notions—among them: Barrow, Fermat, Pascal, and Descartes (without Cartesian geometry, calculus would have been impossible).\n\nA rudimentary form of the Fundamental Theorem of Calculus was stated and proved by James Gregory, and then generalized and improved by Barrow.\n\nOne might well wonder what on earth Newton and Leibniz contributed, in that case. The answer is that Newton and Leibniz were the first that took all of these disparate results and ideas and formed them into a coherent framework; in particular, theirs is the first work to deal with infinitesimal quantities in a reasonably systematic and formal way (which wound up being completely reworked and then re-reworked later, but such is the fate of most foundational results).\n\nAs a result, they were able to prove more general results than anyone who had preceded them, and they opened the door to the next generation of mathematicians who built up a mighty fortress upon the foundations of Newton and Leibniz.\n\nHistory—especially popular history—has a tendency to attribute whole theories and results to singular individuals. The truth, however, is that usually there is a long history of preceding results that made these accomplishments possible.\n\nOr, in Newton’s own words, ""If I have seen further, it is by standing on the shoulders of giants.""', 'result': {'fake': 0.0014, 'real': 0.9986}, 'status': 'success'}], 'credits_used': 4, 'credits': 1994928, 'subscription': 0, 'content': 'My typical answer to this is that Leibniz and Newton invented calculus, but they did not invent derivatives, integration, Taylor series, or even the Fundamental Theorem of Calculus.\n\nIndeed, a very rough notion of integration goes back to the ancient Greeks. Archimedes already developed the method of exhaustion to the point where he could compute the volume of a cone, sphere, etc.\n\nLikewise, Bhaskaracharya II made many remarkable improvements upon existing knowledge, and worked with what we today would recognize as derivatives and integrals. He even had a preliminary notion of infinitesimals.\n\nThere are other people whose contributions should be noted. Madhava of Sangamagrama\n had a concept of Taylor series, and his name now adorns what used to be known as the Leibniz series. There was also a generation of European mathematicians that predated Leibniz and Newton that made various refinements and extensions to all of the preceding notions—among them: Barrow, Fermat, Pascal, and Descartes (without Cartesian geometry, calculus would have been impossible).\n\nA rudimentary form of the Fundamental Theorem of Calculus was stated and proved by James Gregory, and then generalized and improved by Barrow.\n\nOne might well wonder what on earth Newton and Leibniz contributed, in that case. The answer is that Newton and Leibniz were the first that took all of these disparate results and ideas and formed them into a coherent framework; in particular, theirs is the first work to deal with infinitesimal quantities in a reasonably systematic and formal way (which wound up being completely reworked and then re-reworked later, but such is the fate of most foundational results).\n\nAs a result, they were able to prove more general results than anyone who had preceded them, and they opened the door to the next generation of mathematicians who built up a mighty fortress upon the foundations of Newton and Leibniz.\n\nHistory—especially popular history—has a tendency to attribute whole theories and results to singular individuals. The truth, however, is that usually there is a long history of preceding results that made these accomplishments possible.\n\nOr, in Newton’s own words, ""If I have seen further, it is by standing on the shoulders of giants.""', 'aiModelVersion': '1'}",0.9993
Senia Sheydvasser,1y,"In the centuries before cryptography was invented, did number theory have any applications?","This started as a comment on Peter’s answer[1], but I decided that it would be better fleshed out as its own answer. The first thing to note is that elementary number theory became important to computer science before cryptography did. The RSA algorithm was publically described in 1977. Clifford Cocks had come up with an equivalent system in 1973, but that was classified until 1997. But, in either case, already in 1974, Donald Knuth wrote that “virtually every theorem in elementary number theory arises in a natural, motivated way in connection with the problem of making computers do high-speed numerical calculations.” And this was correct: in fact, most integer arithmetic on a computer is really modular arithmetic under the hood, and the techniques and proofs of correctness were developed by number theorists. Usually, this happens at a lower level than where most programmers work. But if you start digging into what your compiler does to your code, there can be some fun surprises along the way.[2] But, you did ask about the centuries before cryptography was invented. And I will freely admit that prior to 1950 or so, they were very thin on the ground. Even so, there were a few. Let’s talk about the Stern-Brocot tree[3] for a bit. It was originally described by number theorist Moritz Stern in 1858. (Don’t worry: we’ll get to the Brocot part later.) Here’s how to construct it. Start by considering the sequence 0,10,10,1, with both written in lowest terms. {01,11}.{01,11}.\displaystyle \left\{\frac{0}{1},\frac{1}{1}\right\}. \tag*{} Now, take their mediant, defined as follows: given two positive rational numbers a/ba/ba/b, c/dc/dc/d, written in lowest terms, their mediant is a/b⊕c/d=(a+c)/(b+d)a/b⊕c/d=(a+c)/(b+d)a/b \oplus c/d = (a + c)/(b + d). In this case, it is (0+1)/(1+1)=1/2(0+1)/(1+1)=1/2(0 + 1)/(1 + 1) = 1/2. {01,12,11}.{01,12,11}.\displaystyle \left\{\frac{0}{1},\mathbf{\frac{1}{2}},\frac{1}{1}\right\}. \tag*{} Cool. Now take the mediants of every consecutive pair in this new sequence. This adds two new members. {01,13,12,23,11}.{01,13,12,23,11}.\displaystyle \left\{\frac{0}{1},\mathbf{\frac{1}{3}},\frac{1}{2},\mathbf{\frac{2}{3}},\frac{1}{1}\right\}. \tag*{} Do that again. {01,14,13,25,12,35,23,34,11}.{01,14,13,25,12,35,23,34,11}.\displaystyle \left\{\frac{0}{1},\mathbf{\frac{1}{4}},\frac{1}{3},\mathbf{\frac{2}{5}},\frac{1}{2},\mathbf{\frac{3}{5}},\frac{2}{3},\mathbf{\frac{3}{4}},\frac{1}{1}\right\}. \tag*{} And again. {01,15,14,27,13,38,25,37,12,47,35,58,23,57,34,45,11}.{01,15,14,27,13,38,25,37,12,47,35,58,23,57,34,45,11}.\displaystyle \left\{\frac{0}{1},\mathbf{\frac{1}{5}},\frac{1}{4},\mathbf{\frac{2}{7}},\frac{1}{3},\mathbf{\frac{3}{8}},\frac{2}{5},\mathbf{\frac{3}{7}},\frac{1}{2},\mathbf{\frac{4}{7}},\frac{3}{5},\mathbf{\frac{5}{8}},\frac{2}{3},\mathbf{\frac{5}{7}},\frac{3}{4},\mathbf{\frac{4}{5}},\frac{1}{1}\right\}. \tag*{} And so on. As we’ll see in a second, this is already useful as is. However, it is even better to draw this in the form of a tree, as follows: write the newly added terms on separate lines, and connect them if you can get from one to the next via a mediant. This is easiest to understand with a picture.This is (a piece of) the Stern-Brocot tree. Now, some interesting facts about this construction:Each new term that we add as a mediant is automatically in lowest terms, so the Stern-Brocot tree is really easy to compute.Each new mediant is between its parents in size, so these lists that we produce are automatically ordered.Every rational number between 000 and 111 appears on the Stern-Brocot tree exactly once.Thus, this gives a very easy way to list all of the positive rationals between 000 and 111 in lowest terms. Moreover, we get the nice structure of a binary search tree. If we want to find where, say, 3/83/83/8 is in this tree, we don’t have to search through all of the entries to look at it. We start at the top, at 1/21/21/2. 3/8<1/23/8<1/23/8 < 1/2, so we move to the left. 3/8>1/33/8>1/33/8 > 1/3, so we move to the right. 3/8<2/53/8<2/53/8 < 2/5, so we move to the left… and we are done! This process can be generalized even for irrational numbers, with the understanding that the process will never terminate—it will just get you rational numbers that are closer and closer to the desired irrational. The path that you take through the tree also has some fascinating properties. Let’s look at, say 3/5→4/73/5→4/73/5 \rightarrow 4/7.We compute that ∣∣∣47−35∣∣∣=135,|47−35|=135,\displaystyle \left|\frac{4}{7} - \frac{3}{5}\right| = \frac{1}{35}, \tag*{} which means that 3/53/53/5 is really quite a good approximation for 4/74/74/7. But there’s more to it than that. You can check directly that ∣∣∣47−ab∣∣∣≥135|47−ab|≥135\displaystyle \left|\frac{4}{7} - \frac{a}{b}\right| \geq \frac{1}{35} \tag*{} for all integers a,ba,ba,b with b≤5b≤5b \leq 5, which means that among rational numbers with denominators no bigger than 555, 3/53/53/5 is the closest approximation to 4/74/74/7. We say that it is a best rational approximation. This is, in fact, always true: if a/ba/ba/b, c/dc/dc/d are a child-parent pair in the Stern-Brocot tree (written in lowest terms, as always), then ∣∣ab−cd∣∣=1bd,|ab−cd|=1bd,\displaystyle \left|\frac{a}{b} - \frac{c}{d}\right| = \frac{1}{bd}, \tag*{} and ∣∣∣ab−ef∣∣∣≥1bd|ab−ef|≥1bd\displaystyle \left|\frac{a}{b} - \frac{e}{f}\right| \geq \frac{1}{bd} \tag*{} for all integers e,fe,fe,f with f≤df≤df \leq d—that is, c/dc/dc/d will always be a best rational approximation for a/ba/ba/b. You can take it further: if you start at some rational number a/ba/ba/b in the tree, then the path up from that point will contain all of the best rational approximations for a/ba/ba/b. This observation works even if you replace the rational number a/ba/ba/b with an irrational number αα\alpha—the path in question is just infinite now, instead. Here is an example with α=1/√2α=1/2\alpha = 1/\sqrt{2}.The red path is the path through the Stern-Brocot tree corresponding to 1/√21/21/\sqrt{2}. The circled rational numbers are best rational approximations of 1/√21/21/\sqrt{2}. In particular, 1/√2−12/17≈0.0012<1/1721/2−12/17≈0.0012<1/1721/\sqrt{2} - 12/17 \approx 0.0012 < 1/17^2, which is quite an impressive approximation for such a small denominator. OK. All of that is very beautiful number theory, but why would it ever be useful to anyone? I said earlier that the Stern-Brocot tree was originally discovered by Stern in 1858. So who was Brocot? Achille Brocot was a French clockmaker. He was interested in an eminently practical problem: how do you efficiently build systems of gears that will get close to some desired gear ratio? For example, if you have a gear shaft that is rotating at some set speed, it is easy to connect it via gears to another shaft such that the new one will rotate half as fast: you just need one of the gears to have twice as many teeth as the other.Here, the blue gear has 17 teeth; the green one has 34. Note that the gear ratio is always going to be a rational number. Furthermore, for ease of construction, you would rather have gears with a smaller number of teeth if possible. Do you see where I am going with this? We would like to have some ideal gear ratio αα\alpha, which we can assume to be between 000 and 111. We might not be able to get it exactly (it might not even be rational!), but we only need to get close enough for practical purposes. However, to squeeze out as much precision as possible while only having to craft as few teeth as we can get away with, we would like a best rational approximation to αα\alpha. In other words, we want to consult the Stern-Brocot tree! And that is why Brocot independently rediscovered the Stern-Brocot tree in 1861, three years after Stern.Here is one of the clocks that Brocot built. Note that it incorporates not just the hours of the day and the days of the week, but also calendar day and the motion of moon. A day is 24 hours long, but a year is a bit more than 365 days; the ratio of days to years is probably not even rational, so you cannot build a collection of gears that will mimic it perfectly. The same goes for the moon rotating around the Earth. But you don’t need them to be perfect—you just need it good enough that the timepiece will only need very occasional maintenance. And this you can do with some technical know-how and a bit of number theory.Footnotes[1] Peter's answer to In the centuries before cryptography was invented, did number theory have any applications?[2] Senia Sheydvasser's answer to What are diophantine equations? Why would we ever use them in real life?[3] Stern–Brocot tree - Wikipedia","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/fdipoqnh9xk2457c', 'title': 'In the centuries before cryptography was invented, did number theory have any applications?', 'score': {'original': 0.81113333333333, 'ai': 0.18886666666667}, 'blocks': [{'text': 'This started as a comment on Peter’s answer[1], but I decided that it would be better fleshed out as its own answer. The first thing to note is that elementary number theory became important to computer science before cryptography did. The RSA algorithm was publically described in 1977. Clifford Cocks had come up with an equivalent system in 1973, but that was classified until 1997. But, in either case, already in 1974, Donald Knuth wrote that “virtually every theorem in elementary number theory arises in a natural, motivated way in connection with the problem of making computers do high-speed numerical calculations.” And this was correct: in fact, most integer arithmetic on a computer is really modular arithmetic under the hood, and the techniques and proofs of correctness were developed by number theorists. Usually, this happens at a lower level than where most programmers work. But if you start digging into what your compiler does to your code, there can be some fun surprises along the way.[2] But, you did ask about the centuries before cryptography was invented. And I will freely admit that prior to 1950 or so, they were very thin on the ground. Even so, there were a few. Let’s talk about the Stern-Brocot tree[3] for a bit. It was originally described by number theorist Moritz Stern in 1858. (Don’t worry: we’ll get to the Brocot part later.) Here’s how to construct it. Start by considering the sequence 0,10,10,1, with both written in lowest terms. {01,11}.{01,11}.\\displaystyle \\left\\{\\frac{0}{1},\\frac{1}{1}\\right\\}. \\tag*{} Now, take their mediant, defined as follows: given two positive rational numbers a/ba/ba/b, c/dc/dc/d, written in lowest terms, their mediant is a/b⊕c/d=(a+c)/(b+d)a/b⊕c/d=(a+c)/(b+d)a/b \\oplus c/d = (a + c)/(b + d). In this case, it is (0+1)/(1+1)=1/2(0+1)/(1+1)=1/2(0 + 1)/(1 + 1) = 1/2. {01,12,11}.{01,12,11}.\\displaystyle \\left\\{\\frac{0}{1},\\mathbf{\\frac{1}{2}},\\frac{1}{1}\\right\\}. \\tag*{} Cool. Now take the mediants of every consecutive pair in this new sequence. This adds two new members. {01,13,12,23,11}.{01,13,12,23,11}.\\displaystyle \\left\\{\\frac{0}{1},\\mathbf{\\frac{1}{3}},\\frac{1}{2},\\mathbf{\\frac{2}{3}},\\frac{1}{1}\\right\\}. \\tag*{} Do that again. {01,14,13,25,12,35,23,34,11}.{01,14,13,25,12,35,23,34,11}.\\displaystyle \\left\\{\\frac{0}{1},\\mathbf{\\frac{1}{4}},\\frac{1}{3},\\mathbf{\\frac{2}{5}},\\frac{1}{2},\\mathbf{\\frac{3}{5}},\\frac{2}{3},\\mathbf{\\frac{3}{4}},\\frac{1}{1}\\right\\}. \\tag*{} And again. {01,15,14,27,13,38,25,37,12,47,35,58,23,57,34,45,11}.{01,15,14,27,13,38,25,37,12,47,35,58,23,57,34,45,11}.\\displaystyle \\left\\{\\frac{0}{1},\\mathbf{\\frac{1}{5}},\\frac{1}{4},\\mathbf{\\frac{2}{7}},\\frac{1}{3},\\mathbf{\\frac{3}{8}},\\frac{2}{5},\\mathbf{\\frac{3}{7}},\\frac{1}{2},\\mathbf{\\frac{4}{7}},\\frac{3}{5},\\mathbf{\\frac{5}{8}},\\frac{2}{3},\\mathbf{\\frac{5}{7}},\\frac{3}{4},\\mathbf{\\frac{4}{5}},\\frac{1}{1}\\right\\}. \\tag*{} And so on. As we’ll see in a second, this is already useful as is. However, it is even better to draw this in the form of a tree, as follows: write the newly added terms on separate lines, and connect them if you can get from one to the next via a mediant. This is easiest to understand with a picture.This is (a piece of) the Stern-Brocot tree. Now, some interesting facts about this construction:Each new term that we add as a mediant is automatically in lowest terms, so the Stern-Brocot tree is really easy to compute.Each new mediant is between its parents in size, so these lists that we produce are automatically ordered.Every rational number between 000 and 111 appears on the Stern-Brocot tree exactly once.Thus, this gives a very easy way to list all of the positive rationals between 000 and 111 in lowest terms. Moreover, we get the nice structure of a binary search tree. If we want to find where, say, 3/83/83/8 is in this tree, we don’t have to search through all of the entries to look at it.', 'result': {'fake': 0.0799, 'real': 0.9201}, 'status': 'success'}, {'text': 'We start at the top, at 1/21/21/2. 3/8<1/23/8<1/23/8 < 1/2, so we move to the left. 3/8>1/33/8>1/33/8 > 1/3, so we move to the right. 3/8<2/53/8<2/53/8 < 2/5, so we move to the left… and we are done! This process can be generalized even for irrational numbers, with the understanding that the process will never terminate—it will just get you rational numbers that are closer and closer to the desired irrational. The path that you take through the tree also has some fascinating properties. Let’s look at, say 3/5→4/73/5→4/73/5 \\rightarrow 4/7.We compute that ∣∣∣47−35∣∣∣=135,|47−35|=135,\\displaystyle \\left|\\frac{4}{7} - \\frac{3}{5}\\right| = \\frac{1}{35}, \\tag*{} which means that 3/53/53/5 is really quite a good approximation for 4/74/74/7. But there’s more to it than that. You can check directly that ∣∣∣47−ab∣∣∣≥135|47−ab|≥135\\displaystyle \\left|\\frac{4}{7} - \\frac{a}{b}\\right| \\geq \\frac{1}{35} \\tag*{} for all integers a,ba,ba,b with b≤5b≤5b \\leq 5, which means that among rational numbers with denominators no bigger than 555, 3/53/53/5 is the closest approximation to 4/74/74/7. We say that it is a best rational approximation. This is, in fact, always true: if a/ba/ba/b, c/dc/dc/d are a child-parent pair in the Stern-Brocot tree (written in lowest terms, as always), then ∣∣ab−cd∣∣=1bd,|ab−cd|=1bd,\\displaystyle \\left|\\frac{a}{b} - \\frac{c}{d}\\right| = \\frac{1}{bd}, \\tag*{} and ∣∣∣ab−ef∣∣∣≥1bd|ab−ef|≥1bd\\displaystyle \\left|\\frac{a}{b} - \\frac{e}{f}\\right| \\geq \\frac{1}{bd} \\tag*{} for all integers e,fe,fe,f with f≤df≤df \\leq d—that is, c/dc/dc/d will always be a best rational approximation for a/ba/ba/b. You can take it further: if you start at some rational number a/ba/ba/b in the tree, then the path up from that point will contain all of the best rational approximations for a/ba/ba/b. This observation works even if you replace the rational number a/ba/ba/b with an irrational number αα\\alpha—the path in question is just infinite now, instead. Here is an example with α=1/√2α=1/2\\alpha = 1/\\sqrt{2}.The red path is the path through the Stern-Brocot tree corresponding to 1/√21/21/\\sqrt{2}. The circled rational numbers are best rational approximations of 1/√21/21/\\sqrt{2}. In particular, 1/√2−12/17≈0.0012<1/1721/2−12/17≈0.0012<1/1721/\\sqrt{2} - 12/17 \\approx 0.0012 < 1/17^2, which is quite an impressive approximation for such a small denominator. OK. All of that is very beautiful number theory, but why would it ever be useful to anyone? I said earlier that the Stern-Brocot tree was originally discovered by Stern in 1858. So who was Brocot? Achille Brocot was a French clockmaker. He was interested in an eminently practical problem: how do you efficiently build systems of gears that will get close to some desired gear ratio? For example, if you have a gear shaft that is rotating at some set speed, it is easy to connect it via gears to another shaft such that the new one will rotate half as fast: you just need one of the gears to have twice as many teeth as the other.Here, the blue gear has 17 teeth; the green one has 34. Note that the gear ratio is always going to be a rational number. Furthermore, for ease of construction, you would rather have gears with a smaller number of teeth if possible. Do you see where I am going with this? We would like to have some ideal gear ratio αα\\alpha,', 'result': {'fake': 0.0045, 'real': 0.9955}, 'status': 'success'}, {'text': ""which we can assume to be between 000 and 111. We might not be able to get it exactly (it might not even be rational!), but we only need to get close enough for practical purposes. However, to squeeze out as much precision as possible while only having to craft as few teeth as we can get away with, we would like a best rational approximation to αα\\alpha. In other words, we want to consult the Stern-Brocot tree! And that is why Brocot independently rediscovered the Stern-Brocot tree in 1861, three years after Stern.Here is one of the clocks that Brocot built. Note that it incorporates not just the hours of the day and the days of the week, but also calendar day and the motion of moon. A day is 24 hours long, but a year is a bit more than 365 days; the ratio of days to years is probably not even rational, so you cannot build a collection of gears that will mimic it perfectly. The same goes for the moon rotating around the Earth. But you don’t need them to be perfect—you just need it good enough that the timepiece will only need very occasional maintenance. And this you can do with some technical know-how and a bit of number theory.Footnotes[1] Peter's answer to In the centuries before cryptography was invented, did number theory have any applications?[2] Senia Sheydvasser's answer to What are diophantine equations? Why would we ever use them in real life?[3] Stern–Brocot tree - Wikipedia"", 'result': {'fake': 0.4673, 'real': 0.5327}, 'status': 'success'}], 'credits_used': 14, 'credits': 1994914, 'subscription': 0, 'content': ""This started as a comment on Peter’s answer[1], but I decided that it would be better fleshed out as its own answer. The first thing to note is that elementary number theory became important to computer science before cryptography did. The RSA algorithm was publically described in 1977. Clifford Cocks had come up with an equivalent system in 1973, but that was classified until 1997. But, in either case, already in 1974, Donald Knuth wrote that “virtually every theorem in elementary number theory arises in a natural, motivated way in connection with the problem of making computers do high-speed numerical calculations.” And this was correct: in fact, most integer arithmetic on a computer is really modular arithmetic under the hood, and the techniques and proofs of correctness were developed by number theorists. Usually, this happens at a lower level than where most programmers work. But if you start digging into what your compiler does to your code, there can be some fun surprises along the way.[2] But, you did ask about the centuries before cryptography was invented. And I will freely admit that prior to 1950 or so, they were very thin on the ground. Even so, there were a few. Let’s talk about the Stern-Brocot tree[3] for a bit. It was originally described by number theorist Moritz Stern in 1858. (Don’t worry: we’ll get to the Brocot part later.) Here’s how to construct it. Start by considering the sequence 0,10,10,1, with both written in lowest terms. {01,11}.{01,11}.\\displaystyle \\left\\{\\frac{0}{1},\\frac{1}{1}\\right\\}. \\tag*{} Now, take their mediant, defined as follows: given two positive rational numbers a/ba/ba/b, c/dc/dc/d, written in lowest terms, their mediant is a/b⊕c/d=(a+c)/(b+d)a/b⊕c/d=(a+c)/(b+d)a/b \\oplus c/d = (a + c)/(b + d). In this case, it is (0+1)/(1+1)=1/2(0+1)/(1+1)=1/2(0 + 1)/(1 + 1) = 1/2. {01,12,11}.{01,12,11}.\\displaystyle \\left\\{\\frac{0}{1},\\mathbf{\\frac{1}{2}},\\frac{1}{1}\\right\\}. \\tag*{} Cool. Now take the mediants of every consecutive pair in this new sequence. This adds two new members. {01,13,12,23,11}.{01,13,12,23,11}.\\displaystyle \\left\\{\\frac{0}{1},\\mathbf{\\frac{1}{3}},\\frac{1}{2},\\mathbf{\\frac{2}{3}},\\frac{1}{1}\\right\\}. \\tag*{} Do that again. {01,14,13,25,12,35,23,34,11}.{01,14,13,25,12,35,23,34,11}.\\displaystyle \\left\\{\\frac{0}{1},\\mathbf{\\frac{1}{4}},\\frac{1}{3},\\mathbf{\\frac{2}{5}},\\frac{1}{2},\\mathbf{\\frac{3}{5}},\\frac{2}{3},\\mathbf{\\frac{3}{4}},\\frac{1}{1}\\right\\}. \\tag*{} And again. {01,15,14,27,13,38,25,37,12,47,35,58,23,57,34,45,11}.{01,15,14,27,13,38,25,37,12,47,35,58,23,57,34,45,11}.\\displaystyle \\left\\{\\frac{0}{1},\\mathbf{\\frac{1}{5}},\\frac{1}{4},\\mathbf{\\frac{2}{7}},\\frac{1}{3},\\mathbf{\\frac{3}{8}},\\frac{2}{5},\\mathbf{\\frac{3}{7}},\\frac{1}{2},\\mathbf{\\frac{4}{7}},\\frac{3}{5},\\mathbf{\\frac{5}{8}},\\frac{2}{3},\\mathbf{\\frac{5}{7}},\\frac{3}{4},\\mathbf{\\frac{4}{5}},\\frac{1}{1}\\right\\}. \\tag*{} And so on. As we’ll see in a second, this is already useful as is. However, it is even better to draw this in the form of a tree, as follows: write the newly added terms on separate lines, and connect them if you can get from one to the next via a mediant. This is easiest to understand with a picture.This is (a piece of) the Stern-Brocot tree. Now, some interesting facts about this construction:Each new term that we add as a mediant is automatically in lowest terms, so the Stern-Brocot tree is really easy to compute.Each new mediant is between its parents in size, so these lists that we produce are automatically ordered.Every rational number between 000 and 111 appears on the Stern-Brocot tree exactly once.Thus, this gives a very easy way to list all of the positive rationals between 000 and 111 in lowest terms. Moreover, we get the nice structure of a binary search tree. If we want to find where, say, 3/83/83/8 is in this tree, we don’t have to search through all of the entries to look at it. We start at the top, at 1/21/21/2. 3/8<1/23/8<1/23/8 < 1/2, so we move to the left. 3/8>1/33/8>1/33/8 > 1/3, so we move to the right. 3/8<2/53/8<2/53/8 < 2/5, so we move to the left… and we are done! This process can be generalized even for irrational numbers, with the understanding that the process will never terminate—it will just get you rational numbers that are closer and closer to the desired irrational. The path that you take through the tree also has some fascinating properties. Let’s look at, say 3/5→4/73/5→4/73/5 \\rightarrow 4/7.We compute that ∣∣∣47−35∣∣∣=135,|47−35|=135,\\displaystyle \\left|\\frac{4}{7} - \\frac{3}{5}\\right| = \\frac{1}{35}, \\tag*{} which means that 3/53/53/5 is really quite a good approximation for 4/74/74/7. But there’s more to it than that. You can check directly that ∣∣∣47−ab∣∣∣≥135|47−ab|≥135\\displaystyle \\left|\\frac{4}{7} - \\frac{a}{b}\\right| \\geq \\frac{1}{35} \\tag*{} for all integers a,ba,ba,b with b≤5b≤5b \\leq 5, which means that among rational numbers with denominators no bigger than 555, 3/53/53/5 is the closest approximation to 4/74/74/7. We say that it is a best rational approximation. This is, in fact, always true: if a/ba/ba/b, c/dc/dc/d are a child-parent pair in the Stern-Brocot tree (written in lowest terms, as always), then ∣∣ab−cd∣∣=1bd,|ab−cd|=1bd,\\displaystyle \\left|\\frac{a}{b} - \\frac{c}{d}\\right| = \\frac{1}{bd}, \\tag*{} and ∣∣∣ab−ef∣∣∣≥1bd|ab−ef|≥1bd\\displaystyle \\left|\\frac{a}{b} - \\frac{e}{f}\\right| \\geq \\frac{1}{bd} \\tag*{} for all integers e,fe,fe,f with f≤df≤df \\leq d—that is, c/dc/dc/d will always be a best rational approximation for a/ba/ba/b. You can take it further: if you start at some rational number a/ba/ba/b in the tree, then the path up from that point will contain all of the best rational approximations for a/ba/ba/b. This observation works even if you replace the rational number a/ba/ba/b with an irrational number αα\\alpha—the path in question is just infinite now, instead. Here is an example with α=1/√2α=1/2\\alpha = 1/\\sqrt{2}.The red path is the path through the Stern-Brocot tree corresponding to 1/√21/21/\\sqrt{2}. The circled rational numbers are best rational approximations of 1/√21/21/\\sqrt{2}. In particular, 1/√2−12/17≈0.0012<1/1721/2−12/17≈0.0012<1/1721/\\sqrt{2} - 12/17 \\approx 0.0012 < 1/17^2, which is quite an impressive approximation for such a small denominator. OK. All of that is very beautiful number theory, but why would it ever be useful to anyone? I said earlier that the Stern-Brocot tree was originally discovered by Stern in 1858. So who was Brocot? Achille Brocot was a French clockmaker. He was interested in an eminently practical problem: how do you efficiently build systems of gears that will get close to some desired gear ratio? For example, if you have a gear shaft that is rotating at some set speed, it is easy to connect it via gears to another shaft such that the new one will rotate half as fast: you just need one of the gears to have twice as many teeth as the other.Here, the blue gear has 17 teeth; the green one has 34. Note that the gear ratio is always going to be a rational number. Furthermore, for ease of construction, you would rather have gears with a smaller number of teeth if possible. Do you see where I am going with this? We would like to have some ideal gear ratio αα\\alpha, which we can assume to be between 000 and 111. We might not be able to get it exactly (it might not even be rational!), but we only need to get close enough for practical purposes. However, to squeeze out as much precision as possible while only having to craft as few teeth as we can get away with, we would like a best rational approximation to αα\\alpha. In other words, we want to consult the Stern-Brocot tree! And that is why Brocot independently rediscovered the Stern-Brocot tree in 1861, three years after Stern.Here is one of the clocks that Brocot built. Note that it incorporates not just the hours of the day and the days of the week, but also calendar day and the motion of moon. A day is 24 hours long, but a year is a bit more than 365 days; the ratio of days to years is probably not even rational, so you cannot build a collection of gears that will mimic it perfectly. The same goes for the moon rotating around the Earth. But you don’t need them to be perfect—you just need it good enough that the timepiece will only need very occasional maintenance. And this you can do with some technical know-how and a bit of number theory.Footnotes[1] Peter's answer to In the centuries before cryptography was invented, did number theory have any applications?[2] Senia Sheydvasser's answer to What are diophantine equations? Why would we ever use them in real life?[3] Stern–Brocot tree - Wikipedia"", 'aiModelVersion': '1'}",0.81113333333333
Alon Amit,4y,Which mathematical proof took the greatest number of years to be fully accepted?,"There have been cases where a proof was initially rejected or at least disregarded, and later vindicated by careful analysis. It’s impossible to rank those cases by numbers of years: it’s not usually clear when to start counting, when to stop counting, and what counts as “correct” vs “incomplete but repairable”.

Galois’ key manuscript, for example, was declared “incomprehensible” by Poisson in 1831, but essentially the same text was reviewed favorably by Liouville in 1843 and finally published in 1846. There’s no question that Galois’ presentation was difficult, but there’s also no question that he did create what is now known as Galois theory, a cornerstone of modern math.

In 1952, Kurt Heegner
 published a proof of Gauss’ class number 1 conjecture, but his paper was considered incorrect until at least 1967, or more definitively 1969. Heegner died in 1965.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/cw9tqy6vnp40rmbg', 'title': 'Which mathematical proof took the greatest number of years to be fully accepted?', 'score': {'original': 0.9963, 'ai': 0.0037}, 'blocks': [{'text': 'There have been cases where a proof was initially rejected or at least disregarded, and later vindicated by careful analysis. It’s impossible to rank those cases by numbers of years: it’s not usually clear when to start counting, when to stop counting, and what counts as “correct” vs “incomplete but repairable”.\n\nGalois’ key manuscript, for example, was declared “incomprehensible” by Poisson in 1831, but essentially the same text was reviewed favorably by Liouville in 1843 and finally published in 1846. There’s no question that Galois’ presentation was difficult, but there’s also no question that he did create what is now known as Galois theory, a cornerstone of modern math.\n\nIn 1952, Kurt Heegner\n published a proof of Gauss’ class number 1 conjecture, but his paper was considered incorrect until at least 1967, or more definitively 1969. Heegner died in 1965.', 'result': {'fake': 0.0037, 'real': 0.9963}, 'status': 'success'}], 'credits_used': 2, 'credits': 1994912, 'subscription': 0, 'content': 'There have been cases where a proof was initially rejected or at least disregarded, and later vindicated by careful analysis. It’s impossible to rank those cases by numbers of years: it’s not usually clear when to start counting, when to stop counting, and what counts as “correct” vs “incomplete but repairable”.\n\nGalois’ key manuscript, for example, was declared “incomprehensible” by Poisson in 1831, but essentially the same text was reviewed favorably by Liouville in 1843 and finally published in 1846. There’s no question that Galois’ presentation was difficult, but there’s also no question that he did create what is now known as Galois theory, a cornerstone of modern math.\n\nIn 1952, Kurt Heegner\n published a proof of Gauss’ class number 1 conjecture, but his paper was considered incorrect until at least 1967, or more definitively 1969. Heegner died in 1965.', 'aiModelVersion': '1'}",0.9963
Rajratna Adsul,1y,Can you give an example of an amateur mathematician making a contribution that was later accepted into the mainstream?,"English mathematical physicist [1] George Green comes to my mind. His contribution to mathematics and mathematical physics, which was largely acknowledged after his death, is highly significant. This is what the introductory paragraph on Wikipedia states.

Green's life story is remarkable in that he was almost entirely self-taught. He received only about one year of formal schooling as a child, between the ages of 8 and 9.

It is difficult to imagine much of vector analysis, differential equations, electromagnetic theory, potential theory, etc. without his fundamental results. Below shown is the cover of his work Essay and the remark about it.

The title page to George Green's original essay on what is now known as Green's theorem. It was published privately at the author's expense, because he thought it would be presumptuous for a person like himself, with no formal education in mathematics, to submit the paper to an established journal.

This looks quite pitiful if Greene had thought about himself that way.

(Ironically, nowadays “some” people with no thorough understanding of a subject go on publishing anything anywhere!).

Footnotes

[1] George Green (mathematician) - Wikipedia","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/10wnhsqdpicub58y', 'title': 'Can you give an example of an amateur mathematician making a contribution that was later accepted into the mainstream?', 'score': {'original': 0.9905, 'ai': 0.0095}, 'blocks': [{'text': ""English mathematical physicist [1] George Green comes to my mind. His contribution to mathematics and mathematical physics, which was largely acknowledged after his death, is highly significant. This is what the introductory paragraph on Wikipedia states.\n\nGreen's life story is remarkable in that he was almost entirely self-taught. He received only about one year of formal schooling as a child, between the ages of 8 and 9.\n\nIt is difficult to imagine much of vector analysis, differential equations, electromagnetic theory, potential theory, etc. without his fundamental results. Below shown is the cover of his work Essay and the remark about it.\n\nThe title page to George Green's original essay on what is now known as Green's theorem. It was published privately at the author's expense, because he thought it would be presumptuous for a person like himself, with no formal education in mathematics, to submit the paper to an established journal.\n\nThis looks quite pitiful if Greene had thought about himself that way.\n\n(Ironically, nowadays “some” people with no thorough understanding of a subject go on publishing anything anywhere!).\n\nFootnotes\n\n[1] George Green (mathematician) - Wikipedia"", 'result': {'fake': 0.0095, 'real': 0.9905}, 'status': 'success'}], 'credits_used': 2, 'credits': 1994910, 'subscription': 0, 'content': ""English mathematical physicist [1] George Green comes to my mind. His contribution to mathematics and mathematical physics, which was largely acknowledged after his death, is highly significant. This is what the introductory paragraph on Wikipedia states.\n\nGreen's life story is remarkable in that he was almost entirely self-taught. He received only about one year of formal schooling as a child, between the ages of 8 and 9.\n\nIt is difficult to imagine much of vector analysis, differential equations, electromagnetic theory, potential theory, etc. without his fundamental results. Below shown is the cover of his work Essay and the remark about it.\n\nThe title page to George Green's original essay on what is now known as Green's theorem. It was published privately at the author's expense, because he thought it would be presumptuous for a person like himself, with no formal education in mathematics, to submit the paper to an established journal.\n\nThis looks quite pitiful if Greene had thought about himself that way.\n\n(Ironically, nowadays “some” people with no thorough understanding of a subject go on publishing anything anywhere!).\n\nFootnotes\n\n[1] George Green (mathematician) - Wikipedia"", 'aiModelVersion': '1'}",0.9905
Alejandro Jenkins,Updated 5y,"Did Newton have direct mail exchange with Leibniz? If so, in which language did they write to each other?","Yes, Newton did correspond with Leibniz. They communicated in Latin, in which they were both perfectly fluent and which was as much the international language of science then as English is today.

It should be said that, contrary to the “bad Newton” picture that has become so widespread in popular histories of science, Newton actually had a cordial relation with Leibniz until at least 1695, well after publication of Leibniz’s papers on the calculus (in 1684, 1686, and 1693) and of Newton’s Principia (in 1687).

There are two famous and very important letters written by Newton for Leibniz in 1676, known as the epistola prior (“former letter”) and the epistola posterior (“latter letter”), which would play a major role in the calculus priority dispute of the 1710s. Those letters were not addressed to Leibniz directly, but rather to the secretary of the Royal Society Henry Oldenburg
, who forwarded copies to Leibniz. This was a commonly used method at the time to keep a verifiable record of the contents of scientific correspondence not otherwise published. Leibniz replied to Newton, also via Oldenburg, with letters that also contain important mathematical results. See, e.g., “The Inverse Method of Tangents: A Dialogue between Leibniz and Newton (1675-1677)
”, by the German mathematical historian Christoph Scriba
.

Here’s an image of the first couple of paragraphs of a modern transcription of a letter from 1693 that Newton sent directly to Leibniz, from vol. III of the Correspondence of Isaac Newton (Cambridge U. P., 1961), pp. 285–9:

This letter is addressed to the “renowned gentleman Gottfried Wilhelm Leibniz” and contains such diplomatic sentiments as “I have for many years considered you as one of the leading geometers of this century”, as well as “I hope indeed that I have written nothing to displease you, and if there is anything that you think deserves censure, please let me know of it by letter, since I value friends more highly than mathematical discoveries.”

The relationship between Newton and Leibniz started to sour circa 1696, largely due to the interventions of Johann Bernoulli
, a Leibnizian partisan who believed, or professed to believe, that Newton hadn’t really understood calculus when he wrote the Principia, so that Leibniz and his immediate disciples (including Bernoulli) could claim full credit for it. Johann Bernoulli, though a very capable mathematician, was a piece of work who ended up totally estranged from both his older brother Jacob
 and his own son Daniel
, two other great scientists with whom Johann clashed over issues of priority and also over the validity of Newtonian physics (which Johann stubbornly refused to grant). Leibniz himself was, in the words of science historian Rupert Hall, “not a modest man”, ever eager to promote his reputation and social standing.

Newton, for his part, was goaded into a confrontation with Leibniz by the Scottish mathematician John Keill
, who brought to Newton’s attention that the Leibnizians had insinuated in print that Newton had learned the calculus from Leibniz’s published works before claiming it as his own discovery. Keill then precipitated the showdown with Leibniz that ended so unedifyingly with Newton drafting the Royal Society’s report of 1712 that concluded (fairly) that Newton had worked out the calculus well before Leibniz and suggested (quite unfairly) that Leibniz might have plagiarized some of his work from Newton’s unpublished letters of the 1670s.

After about 1700 Newton was convinced (unfairly, but not without provocation) that Leibniz could not be trusted and there was no further communication between them. As Marc Bobro mentioned in his answer here, in the famous Leibniz–Clarke correspondence
 of 1715–6, the Newtonian side was represented by Newton’s friend and parish priest Samuel Clarke
.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/6qyzistpcxhvrfmo', 'title': 'Did Newton have direct mail exchange with Leibniz? If so, in which language did they write to each other?', 'score': {'original': 0.7741, 'ai': 0.2259}, 'blocks': [{'text': 'Yes, Newton did correspond with Leibniz. They communicated in Latin, in which they were both perfectly fluent and which was as much the international language of science then as English is today.\n\nIt should be said that, contrary to the “bad Newton” picture that has become so widespread in popular histories of science, Newton actually had a cordial relation with Leibniz until at least 1695, well after publication of Leibniz’s papers on the calculus (in 1684, 1686, and 1693) and of Newton’s Principia (in 1687).\n\nThere are two famous and very important letters written by Newton for Leibniz in 1676, known as the epistola prior (“former letter”) and the epistola posterior (“latter letter”), which would play a major role in the calculus priority dispute of the 1710s. Those letters were not addressed to Leibniz directly, but rather to the secretary of the Royal Society Henry Oldenburg\n, who forwarded copies to Leibniz. This was a commonly used method at the time to keep a verifiable record of the contents of scientific correspondence not otherwise published. Leibniz replied to Newton, also via Oldenburg, with letters that also contain important mathematical results. See, e.g., “The Inverse Method of Tangents: A Dialogue between Leibniz and Newton (1675-1677)\n”, by the German mathematical historian Christoph Scriba\n.\n\nHere’s an image of the first couple of paragraphs of a modern transcription of a letter from 1693 that Newton sent directly to Leibniz, from vol. III of the Correspondence of Isaac Newton (Cambridge U. P., 1961), pp. 285–9:\n\nThis letter is addressed to the “renowned gentleman Gottfried Wilhelm Leibniz” and contains such diplomatic sentiments as “I have for many years considered you as one of the leading geometers of this century”, as well as “I hope indeed that I have written nothing to displease you, and if there is anything that you think deserves censure, please let me know of it by letter, since I value friends more highly than mathematical discoveries.”\n\nThe relationship between Newton and Leibniz started to sour circa 1696, largely due to the interventions of Johann Bernoulli\n, a Leibnizian partisan who believed, or professed to believe, that Newton hadn’t really understood calculus when he wrote the Principia, so that Leibniz and his immediate disciples (including Bernoulli) could claim full credit for it. Johann Bernoulli, though a very capable mathematician, was a piece of work who ended up totally estranged from both his older brother Jacob\n and his own son Daniel\n, two other great scientists with whom Johann clashed over issues of priority and also over the validity of Newtonian physics (which Johann stubbornly refused to grant). Leibniz himself was, in the words of science historian Rupert Hall, “not a modest man”, ever eager to promote his reputation and social standing.\n\nNewton, for his part, was goaded into a confrontation with Leibniz by the Scottish mathematician John Keill\n, who brought to Newton’s attention that the Leibnizians had insinuated in print that Newton had learned the calculus from Leibniz’s published works before claiming it as his own discovery. Keill then precipitated the showdown with Leibniz that ended so unedifyingly with Newton drafting the Royal Society’s', 'result': {'fake': 0.0054, 'real': 0.9946}, 'status': 'success'}, {'text': 'report of 1712 that concluded (fairly) that Newton had worked out the calculus well before Leibniz and suggested (quite unfairly) that Leibniz might have plagiarized some of his work from Newton’s unpublished letters of the 1670s.\n\nAfter about 1700 Newton was convinced (unfairly, but not without provocation) that Leibniz could not be trusted and there was no further communication between them. As Marc Bobro mentioned in his answer here, in the famous Leibniz–Clarke correspondence\n of 1715–6, the Newtonian side was represented by Newton’s friend and parish priest Samuel Clarke\n.', 'result': {'fake': 0.5399, 'real': 0.4601}, 'status': 'success'}], 'credits_used': 7, 'credits': 1994903, 'subscription': 0, 'content': 'Yes, Newton did correspond with Leibniz. They communicated in Latin, in which they were both perfectly fluent and which was as much the international language of science then as English is today.\n\nIt should be said that, contrary to the “bad Newton” picture that has become so widespread in popular histories of science, Newton actually had a cordial relation with Leibniz until at least 1695, well after publication of Leibniz’s papers on the calculus (in 1684, 1686, and 1693) and of Newton’s Principia (in 1687).\n\nThere are two famous and very important letters written by Newton for Leibniz in 1676, known as the epistola prior (“former letter”) and the epistola posterior (“latter letter”), which would play a major role in the calculus priority dispute of the 1710s. Those letters were not addressed to Leibniz directly, but rather to the secretary of the Royal Society Henry Oldenburg\n, who forwarded copies to Leibniz. This was a commonly used method at the time to keep a verifiable record of the contents of scientific correspondence not otherwise published. Leibniz replied to Newton, also via Oldenburg, with letters that also contain important mathematical results. See, e.g., “The Inverse Method of Tangents: A Dialogue between Leibniz and Newton (1675-1677)\n”, by the German mathematical historian Christoph Scriba\n.\n\nHere’s an image of the first couple of paragraphs of a modern transcription of a letter from 1693 that Newton sent directly to Leibniz, from vol. III of the Correspondence of Isaac Newton (Cambridge U. P., 1961), pp. 285–9:\n\nThis letter is addressed to the “renowned gentleman Gottfried Wilhelm Leibniz” and contains such diplomatic sentiments as “I have for many years considered you as one of the leading geometers of this century”, as well as “I hope indeed that I have written nothing to displease you, and if there is anything that you think deserves censure, please let me know of it by letter, since I value friends more highly than mathematical discoveries.”\n\nThe relationship between Newton and Leibniz started to sour circa 1696, largely due to the interventions of Johann Bernoulli\n, a Leibnizian partisan who believed, or professed to believe, that Newton hadn’t really understood calculus when he wrote the Principia, so that Leibniz and his immediate disciples (including Bernoulli) could claim full credit for it. Johann Bernoulli, though a very capable mathematician, was a piece of work who ended up totally estranged from both his older brother Jacob\n and his own son Daniel\n, two other great scientists with whom Johann clashed over issues of priority and also over the validity of Newtonian physics (which Johann stubbornly refused to grant). Leibniz himself was, in the words of science historian Rupert Hall, “not a modest man”, ever eager to promote his reputation and social standing.\n\nNewton, for his part, was goaded into a confrontation with Leibniz by the Scottish mathematician John Keill\n, who brought to Newton’s attention that the Leibnizians had insinuated in print that Newton had learned the calculus from Leibniz’s published works before claiming it as his own discovery. Keill then precipitated the showdown with Leibniz that ended so unedifyingly with Newton drafting the Royal Society’s report of 1712 that concluded (fairly) that Newton had worked out the calculus well before Leibniz and suggested (quite unfairly) that Leibniz might have plagiarized some of his work from Newton’s unpublished letters of the 1670s.\n\nAfter about 1700 Newton was convinced (unfairly, but not without provocation) that Leibniz could not be trusted and there was no further communication between them. As Marc Bobro mentioned in his answer here, in the famous Leibniz–Clarke correspondence\n of 1715–6, the Newtonian side was represented by Newton’s friend and parish priest Samuel Clarke\n.', 'aiModelVersion': '1'}",0.7741
Andrew Winkler,1y,Which mathematical proof took the greatest number of years to be fully accepted?,"The case of Galois is an interesting one, because the reason it may have taken so long is instructive.

When you learn algebra as a youth, you likely are taught to think of a variable as representing an actual number which is at present unknown to you. What Galois seems to have realized, without grasping clearly that his contemporaries had not, was that it was better to think of variables as living in what today we would call a free commutative ring - a set having the same rules of commutativity, associativity, distributivity, etc that numbers have.

This means that you can always solve an equation, by simply reducing all expressions using the assumed equation. In modern terms this means taking the quotient ring by the ideal generated by the polynomial which is being equated to 0.

This, I suspect, is the meaning behind his “On vera” response to the criticism that he was assuming the existence of a solution, a fact that is not at all obvious in the first frame, but trivially so in the second.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/vkuihy0jw5l6sarx', 'title': 'Which mathematical proof took the greatest number of years to be fully accepted?', 'score': {'original': 0.9931, 'ai': 0.0069}, 'blocks': [{'text': 'The case of Galois is an interesting one, because the reason it may have taken so long is instructive.\n\nWhen you learn algebra as a youth, you likely are taught to think of a variable as representing an actual number which is at present unknown to you. What Galois seems to have realized, without grasping clearly that his contemporaries had not, was that it was better to think of variables as living in what today we would call a free commutative ring - a set having the same rules of commutativity, associativity, distributivity, etc that numbers have.\n\nThis means that you can always solve an equation, by simply reducing all expressions using the assumed equation. In modern terms this means taking the quotient ring by the ideal generated by the polynomial which is being equated to 0.\n\nThis, I suspect, is the meaning behind his “On vera” response to the criticism that he was assuming the existence of a solution, a fact that is not at all obvious in the first frame, but trivially so in the second.', 'result': {'fake': 0.0069, 'real': 0.9931}, 'status': 'success'}], 'credits_used': 2, 'credits': 1994901, 'subscription': 0, 'content': 'The case of Galois is an interesting one, because the reason it may have taken so long is instructive.\n\nWhen you learn algebra as a youth, you likely are taught to think of a variable as representing an actual number which is at present unknown to you. What Galois seems to have realized, without grasping clearly that his contemporaries had not, was that it was better to think of variables as living in what today we would call a free commutative ring - a set having the same rules of commutativity, associativity, distributivity, etc that numbers have.\n\nThis means that you can always solve an equation, by simply reducing all expressions using the assumed equation. In modern terms this means taking the quotient ring by the ideal generated by the polynomial which is being equated to 0.\n\nThis, I suspect, is the meaning behind his “On vera” response to the criticism that he was assuming the existence of a solution, a fact that is not at all obvious in the first frame, but trivially so in the second.', 'aiModelVersion': '1'}",0.9931
Jeffrey Wang,Updated 2y,What are some of the most ingenious calculations in history?,"These days, Edmund Halley is best known for the comet that is named after him—one which famously returns and grazes our night sky once every 75 years or so.

What many overlook, however, is that he was also an incredibly clever scientist—one with a knack for solving seemingly uncrackable problems. Among fellow scientists, he developed a reputation: give him a problem, and he would arrive at a solution (or at least try damn hard to reach one).

It was with this attitude in mind that the Royal Society approached him with a task in the early 1700’s. The English government had asked them for an estimate of the total landmass of England and Wales—and the Society was struggling.

Given the exceedingly unusual shape of the two countries, any physical survey would be exceedingly expensive. Similar issues impeded a traditional mathematical calculation of the landmass’s area.

Halley went about it in a very different way.

First, he found the most accurate map of the two countries available. Then, with the paper copy in hand, he cut out the shape of the two countries extremely carefully.

He then weighed the map piece with careful precision and noted the figure.

Finally, Halley cut out the largest complete circle he could from the center of the map piece and weighed that circle.

The radius of the final circle measured 69.33 miles. After comparing the measured weights, he figured that the map piece weighed roughly four times the circle. Hence, the combined area of England and Wales… was just four times the area of the circle.

His final measurement was only 1% off today’s figures.

It’s safe to say the fellows at the Royal Society were probably chuckling at themselves for that one.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/cazq80u5inhmg3vl', 'title': 'What are some of the most ingenious calculations in history?', 'score': {'original': 0.9989, 'ai': 0.0011}, 'blocks': [{'text': 'These days, Edmund Halley is best known for the comet that is named after him—one which famously returns and grazes our night sky once every 75 years or so.\n\nWhat many overlook, however, is that he was also an incredibly clever scientist—one with a knack for solving seemingly uncrackable problems. Among fellow scientists, he developed a reputation: give him a problem, and he would arrive at a solution (or at least try damn hard to reach one).\n\nIt was with this attitude in mind that the Royal Society approached him with a task in the early 1700’s. The English government had asked them for an estimate of the total landmass of England and Wales—and the Society was struggling.\n\nGiven the exceedingly unusual shape of the two countries, any physical survey would be exceedingly expensive. Similar issues impeded a traditional mathematical calculation of the landmass’s area.\n\nHalley went about it in a very different way.\n\nFirst, he found the most accurate map of the two countries available. Then, with the paper copy in hand, he cut out the shape of the two countries extremely carefully.\n\nHe then weighed the map piece with careful precision and noted the figure.\n\nFinally, Halley cut out the largest complete circle he could from the center of the map piece and weighed that circle.\n\nThe radius of the final circle measured 69.33 miles. After comparing the measured weights, he figured that the map piece weighed roughly four times the circle. Hence, the combined area of England and Wales… was just four times the area of the circle.\n\nHis final measurement was only 1% off today’s figures.\n\nIt’s safe to say the fellows at the Royal Society were probably chuckling at themselves for that one.', 'result': {'fake': 0.0011, 'real': 0.9989}, 'status': 'success'}], 'credits_used': 3, 'credits': 1994898, 'subscription': 0, 'content': 'These days, Edmund Halley is best known for the comet that is named after him—one which famously returns and grazes our night sky once every 75 years or so.\n\nWhat many overlook, however, is that he was also an incredibly clever scientist—one with a knack for solving seemingly uncrackable problems. Among fellow scientists, he developed a reputation: give him a problem, and he would arrive at a solution (or at least try damn hard to reach one).\n\nIt was with this attitude in mind that the Royal Society approached him with a task in the early 1700’s. The English government had asked them for an estimate of the total landmass of England and Wales—and the Society was struggling.\n\nGiven the exceedingly unusual shape of the two countries, any physical survey would be exceedingly expensive. Similar issues impeded a traditional mathematical calculation of the landmass’s area.\n\nHalley went about it in a very different way.\n\nFirst, he found the most accurate map of the two countries available. Then, with the paper copy in hand, he cut out the shape of the two countries extremely carefully.\n\nHe then weighed the map piece with careful precision and noted the figure.\n\nFinally, Halley cut out the largest complete circle he could from the center of the map piece and weighed that circle.\n\nThe radius of the final circle measured 69.33 miles. After comparing the measured weights, he figured that the map piece weighed roughly four times the circle. Hence, the combined area of England and Wales… was just four times the area of the circle.\n\nHis final measurement was only 1% off today’s figures.\n\nIt’s safe to say the fellows at the Royal Society were probably chuckling at themselves for that one.', 'aiModelVersion': '1'}",0.9989
Wairia,5y,Who are some of the unsung heroes of mathematics?,"Brahmagupta
 (India, 598-c.670)

A prominent astronomer, Brahmagupta wrote an extensive treatise covering such topics as the motions of the planets, eclipses, and the phases of the moon. But his genius emerged most prominently in mathematics. He introduced the idea of zero as a number like any other and discussed how to calculate with it. He was also the first to explain negative numbers, a concept thought by the Greeks to be “absurd.” Brahmagupta pointed out that multiplying two negative numbers (he called them “debts”) produced a positive number (in his terminology, a “fortune”).","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/6o4ys1zrbu7wv50n', 'title': 'Who are some of the unsung heroes of mathematics?', 'score': {'original': 0.9334, 'ai': 0.0666}, 'blocks': [{'text': 'Brahmagupta\n (India, 598-c.670)\n\nA prominent astronomer, Brahmagupta wrote an extensive treatise covering such topics as the motions of the planets, eclipses, and the phases of the moon. But his genius emerged most prominently in mathematics. He introduced the idea of zero as a number like any other and discussed how to calculate with it. He was also the first to explain negative numbers, a concept thought by the Greeks to be “absurd.” Brahmagupta pointed out that multiplying two negative numbers (he called them “debts”) produced a positive number (in his terminology, a “fortune”).', 'result': {'fake': 0.0666, 'real': 0.9334}, 'status': 'success'}], 'credits_used': 1, 'credits': 1994897, 'subscription': 0, 'content': 'Brahmagupta\n (India, 598-c.670)\n\nA prominent astronomer, Brahmagupta wrote an extensive treatise covering such topics as the motions of the planets, eclipses, and the phases of the moon. But his genius emerged most prominently in mathematics. He introduced the idea of zero as a number like any other and discussed how to calculate with it. He was also the first to explain negative numbers, a concept thought by the Greeks to be “absurd.” Brahmagupta pointed out that multiplying two negative numbers (he called them “debts”) produced a positive number (in his terminology, a “fortune”).', 'aiModelVersion': '1'}",0.9334
Alon Amit,8y,"What does it mean when people say that mathematics is the queen of the sciences? Also, why queen?","The source of this phrase is a quote attributed to Carl Friedrich Gauss
:

""Die Mathematik ist die Königin der Wissenschaften und die Zahlentheorie ist die Königin der Mathematik.""

(""Mathematics is the queen of the sciences and number theory is the queen of mathematics."")

The quote appears in Waltershausen's biography of Gauss, and it may well be authentic. Gauss was one of the greatest mathematicians of all time, in whatever way you wish to measure ""greatness"", and though he contributed profoundly to physics, astronomy and optics he was first and foremost a mathematician.

The quote actually has a second part which is rarely mentioned:

""She often condescends to render service to astronomy and other natural sciences, but in all relations she is entitled to the first rank.""

Mathematics isn't an empirical science in the way chemistry, physics and astronomy are (it is often not described as a ""science"" at all, for this reason). In this sense it is less beholden to the particular reality and universe we happen to inhabit. It explores ideas and worlds that are purely abstract and inherently beautiful and interesting. Some of them are inspired by physics, some are not.

The sentiment expressed by this phrase is more or less the same one described in xkcd: Purity
.


Regarding the usage of ""queen"": abstract entities are often described as feminine in art, poetry and literature. When writers refer to mathematics or nature as entities, they often refer to them as ""she"" (as in ""mother nature"", or for example in Dürer's Melencolia I
). To my ears it would seem more unusual for Gauss to refer to mathematics as a ""he"".","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/dlgws93jtmro7yxp', 'title': 'What does it mean when people say that mathematics is the queen of the sciences? Also, why queen?', 'score': {'original': 0.9992, 'ai': 0.0008}, 'blocks': [{'text': 'The source of this phrase is a quote attributed to Carl Friedrich Gauss\n:\n\n""Die Mathematik ist die Königin der Wissenschaften und die Zahlentheorie ist die Königin der Mathematik.""\n\n(""Mathematics is the queen of the sciences and number theory is the queen of mathematics."")\n\nThe quote appears in Waltershausen\'s biography of Gauss, and it may well be authentic. Gauss was one of the greatest mathematicians of all time, in whatever way you wish to measure ""greatness"", and though he contributed profoundly to physics, astronomy and optics he was first and foremost a mathematician.\n\nThe quote actually has a second part which is rarely mentioned:\n\n""She often condescends to render service to astronomy and other natural sciences, but in all relations she is entitled to the first rank.""\n\nMathematics isn\'t an empirical science in the way chemistry, physics and astronomy are (it is often not described as a ""science"" at all, for this reason). In this sense it is less beholden to the particular reality and universe we happen to inhabit. It explores ideas and worlds that are purely abstract and inherently beautiful and interesting. Some of them are inspired by physics, some are not.\n\nThe sentiment expressed by this phrase is more or less the same one described in xkcd: Purity\n.\n\n\nRegarding the usage of ""queen"": abstract entities are often described as feminine in art, poetry and literature. When writers refer to mathematics or nature as entities, they often refer to them as ""she"" (as in ""mother nature"", or for example in Dürer\'s Melencolia I\n). To my ears it would seem more unusual for Gauss to refer to mathematics as a ""he"".', 'result': {'fake': 0.002, 'real': 0.998}, 'status': 'success'}], 'credits_used': 3, 'credits': 1994894, 'subscription': 0, 'content': 'The source of this phrase is a quote attributed to Carl Friedrich Gauss\n:\n\n""Die Mathematik ist die Königin der Wissenschaften und die Zahlentheorie ist die Königin der Mathematik.""\n\n(""Mathematics is the queen of the sciences and number theory is the queen of mathematics."")\n\nThe quote appears in Waltershausen\'s biography of Gauss, and it may well be authentic. Gauss was one of the greatest mathematicians of all time, in whatever way you wish to measure ""greatness"", and though he contributed profoundly to physics, astronomy and optics he was first and foremost a mathematician.\n\nThe quote actually has a second part which is rarely mentioned:\n\n""She often condescends to render service to astronomy and other natural sciences, but in all relations she is entitled to the first rank.""\n\nMathematics isn\'t an empirical science in the way chemistry, physics and astronomy are (it is often not described as a ""science"" at all, for this reason). In this sense it is less beholden to the particular reality and universe we happen to inhabit. It explores ideas and worlds that are purely abstract and inherently beautiful and interesting. Some of them are inspired by physics, some are not.\n\nThe sentiment expressed by this phrase is more or less the same one described in xkcd: Purity\n.\n\n\nRegarding the usage of ""queen"": abstract entities are often described as feminine in art, poetry and literature. When writers refer to mathematics or nature as entities, they often refer to them as ""she"" (as in ""mother nature"", or for example in Dürer\'s Melencolia I\n). To my ears it would seem more unusual for Gauss to refer to mathematics as a ""he"".', 'aiModelVersion': '1'}",0.9992
Alon Amit,4y,What is currently an unsolved math problem and why?,"Example #1: The Riemann Hypothesis. Why? The Riemann zeta function is wild and subtle, and despite strenuous efforts over the past century and a half, we still have no idea how to prove that none of its roots strays off the good and proper path. Example #2: Factor 1010100+11010100+1\mathbf{10^{10^{100}}+1}. Why? The number is far too large, its unique structure is helpful but not helpful enough, and also, nobody cares. I just made this one up. Example #3: Determine all the ways an nnn-dimensional sphere can wrap around a kkk-dimensional sphere up to homotopy, which is like “allowing for smooth deformations”. In other words, determine πn(Sk)πn(Sk)\mathbf{\pi_n(S^k)} for all n,kn,k\mathbf{n,k}. Why? Despite their clean and natural description, the homotopy groups of spheres behave in a way which combines delicate order and ruthless chaos. We know a lot, and we know very little.There are thousands of open mathematical problems, some deep and famous, some arbitrary and uninteresting. We can never explain why something is difficult, we can only observe that it is, and over time learn to make inroads, mount assaults, fail, learn, and keep trying. The human urge to explore is just as tangible here as it is with sea travel and astrophysics, and we should expect this journey to outlast us and our successors, whatever they are.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/sjmr74genwd3lc60', 'title': 'What is currently an unsolved math problem and why?', 'score': {'original': 0.9959, 'ai': 0.0041}, 'blocks': [{'text': 'Example #1: The Riemann Hypothesis. Why? The Riemann zeta function is wild and subtle, and despite strenuous efforts over the past century and a half, we still have no idea how to prove that none of its roots strays off the good and proper path. Example #2: Factor 1010100+11010100+1\\mathbf{10^{10^{100}}+1}. Why? The number is far too large, its unique structure is helpful but not helpful enough, and also, nobody cares. I just made this one up. Example #3: Determine all the ways an nnn-dimensional sphere can wrap around a kkk-dimensional sphere up to homotopy, which is like “allowing for smooth deformations”. In other words, determine πn(Sk)πn(Sk)\\mathbf{\\pi_n(S^k)} for all n,kn,k\\mathbf{n,k}. Why? Despite their clean and natural description, the homotopy groups of spheres behave in a way which combines delicate order and ruthless chaos. We know a lot, and we know very little.There are thousands of open mathematical problems, some deep and famous, some arbitrary and uninteresting. We can never explain why something is difficult, we can only observe that it is, and over time learn to make inroads, mount assaults, fail, learn, and keep trying. The human urge to explore is just as tangible here as it is with sea travel and astrophysics, and we should expect this journey to outlast us and our successors, whatever they are.', 'result': {'fake': 0.0041, 'real': 0.9959}, 'status': 'success'}], 'credits_used': 3, 'credits': 1994891, 'subscription': 0, 'content': 'Example #1: The Riemann Hypothesis. Why? The Riemann zeta function is wild and subtle, and despite strenuous efforts over the past century and a half, we still have no idea how to prove that none of its roots strays off the good and proper path. Example #2: Factor 1010100+11010100+1\\mathbf{10^{10^{100}}+1}. Why? The number is far too large, its unique structure is helpful but not helpful enough, and also, nobody cares. I just made this one up. Example #3: Determine all the ways an nnn-dimensional sphere can wrap around a kkk-dimensional sphere up to homotopy, which is like “allowing for smooth deformations”. In other words, determine πn(Sk)πn(Sk)\\mathbf{\\pi_n(S^k)} for all n,kn,k\\mathbf{n,k}. Why? Despite their clean and natural description, the homotopy groups of spheres behave in a way which combines delicate order and ruthless chaos. We know a lot, and we know very little.There are thousands of open mathematical problems, some deep and famous, some arbitrary and uninteresting. We can never explain why something is difficult, we can only observe that it is, and over time learn to make inroads, mount assaults, fail, learn, and keep trying. The human urge to explore is just as tangible here as it is with sea travel and astrophysics, and we should expect this journey to outlast us and our successors, whatever they are.', 'aiModelVersion': '1'}",0.9959
Arjun Singh,Updated 6y,What is the toughest maths problem unsolved today?,"Collatz Conjecture

Pick any number. If that number is even, divide it by 2. If it's odd, multiply it by 3 and add 1. Now repeat the process with your new number. If you keep going, you'll eventually end up at 1. Every time.

Mathematicians have tried millions of numbers and they've never found a single one that didn't end up at 1 eventually. The thing is, they've never been able to prove that there isn't a special number out there that never leads to 1. It's possible that there's some really big number that goes to infinity instead, or maybe a number that gets stuck in a loop and never reaches 1. But no one has ever been able to prove that for certain.

Moving Sofa Problem

So you're moving into your new apartment, and you're trying to bring your sofa. The problem is, the hallway turns and you have to fit your sofa around a corner. If it's a small sofa, that might not be a problem, but a really big sofa is sure to get stuck. If you're a mathematician, you ask yourself: What's the largest sofa you could possibly fit around the corner? It doesn't have to be a rectangular sofa either, it can be any shape.

This is the essence of the moving sofa problem. Here are the specifics: the whole problem is in two dimensions, the corner is a 90-degree angle, and the width of the corridor is 1. What is the largest two-dimensional area that can fit around the corner?

The largest area that can fit around a corner is called—I kid you not—the sofa constant. Nobody knows for sure how big it is, but we have some pretty big sofas that do work, so we know it has to be at least as big as them. We also have some sofas that don't work, so it has to be smaller than those. All together, we know the sofa constant has to be between 2.2195 and 2.8284.

Perfect Cuboid Problem

Remember the pythagorean theorem, A²+B²=C² ?

The three letters correspond to the three sides of a right triangle. In a Pythagorean triangle, and all three sides are whole numbers. Let's extend this idea to three dimensions. In three dimensions, there are four numbers. In the image above, they are A, B, C, and G. The first three are the dimensions of a box, and G is the diagonal running from one of the top corners to the opposite bottom corner.

Just as there are some triangles where all three sides are whole numbers, there are also some boxes where the three sides and the spatial diagonal (A, B, C, and G) are whole numbers. But there are also three more diagonals on the three surfaces (D, E, and F) and that raises an interesting question: can there be a box where all seven of these lengths are integers?

The goal is to find a box where A²+B²+C²=G², and where all seven numbers are integers. This is called a perfect cuboid. Mathematicians have tried many different possibilities and have yet to find a single one that works. But they also haven't been able to prove that such a box doesn't exist, so the hunt is on for a perfect cuboid.

Inscribed Square Problem

Draw a closed loop. The loop doesn't have to be a circle, it can be any shape you want, but the beginning and the end have to meet and the loop can't cross itself. It should be possible to draw a square inside the loop so that all four corners of the square are touching the loop. According to the inscribed square hypothesis every closed loop (specifically every plane simple closed curve) should have an inscribed square, a square where all four corners lie somewhere on the loop.

This has already been solved for a number of other shapes, such as triangles and rectangles. But squares are tricky, and so far a formal proof has eluded mathematicians.

Happy Ending Problem

The happy ending problem is so named because it led to the marriage of two mathematicians who worked on it, George Szekeres and Esther Klein. Essentially, the problem works like this:

Make five dots at random places on a piece of paper. Assuming the dots aren't deliberately arranged—say, in a line—you should always be able to connect four of them to create a convex quadrilateral, which is a shape with four sides where all of the corners are less than 180 degrees. The gist of this theorem is that you'll always be able to create a convex quadrilateral with five random dots, regardless of where those dots are positioned.

So that's how it works for four sides. But for a pentagon, a five-sided shape, it turns out you need nine dots. For a hexagon, it's 17 dots. But beyond that, we don't know. It's a mystery how many dots is required to create a heptagon or any larger shapes. More importantly, there should be a formula to tell us how many dots are required for any shape. Mathematicians suspect the equation is M=1+2^n-2, where M is the number of dots and N is the number of sides in the shape. But as yet, they've only been able to prove that the answer is at least as big as the answer you get that way.

[SOURCE : GOOGLE]

EDIT : the moving sofa problem is solved now,

Thnx mrinal kumar for suggestion.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/s5or8x4aeb9d1nqu', 'title': 'What is the toughest maths problem unsolved today?', 'score': {'original': 0.13965, 'ai': 0.86035}, 'blocks': [{'text': ""Collatz Conjecture\n\nPick any number. If that number is even, divide it by 2. If it's odd, multiply it by 3 and add 1. Now repeat the process with your new number. If you keep going, you'll eventually end up at 1. Every time.\n\nMathematicians have tried millions of numbers and they've never found a single one that didn't end up at 1 eventually. The thing is, they've never been able to prove that there isn't a special number out there that never leads to 1. It's possible that there's some really big number that goes to infinity instead, or maybe a number that gets stuck in a loop and never reaches 1. But no one has ever been able to prove that for certain.\n\nMoving Sofa Problem\n\nSo you're moving into your new apartment, and you're trying to bring your sofa. The problem is, the hallway turns and you have to fit your sofa around a corner. If it's a small sofa, that might not be a problem, but a really big sofa is sure to get stuck. If you're a mathematician, you ask yourself: What's the largest sofa you could possibly fit around the corner? It doesn't have to be a rectangular sofa either, it can be any shape.\n\nThis is the essence of the moving sofa problem. Here are the specifics: the whole problem is in two dimensions, the corner is a 90-degree angle, and the width of the corridor is 1. What is the largest two-dimensional area that can fit around the corner?\n\nThe largest area that can fit around a corner is called—I kid you not—the sofa constant. Nobody knows for sure how big it is, but we have some pretty big sofas that do work, so we know it has to be at least as big as them. We also have some sofas that don't work, so it has to be smaller than those. All together, we know the sofa constant has to be between 2.2195 and 2.8284.\n\nPerfect Cuboid Problem\n\nRemember the pythagorean theorem, A²+B²=C² ?\n\nThe three letters correspond to the three sides of a right triangle. In a Pythagorean triangle, and all three sides are whole numbers. Let's extend this idea to three dimensions. In three dimensions, there are four numbers. In the image above, they are A, B, C, and G. The first three are the dimensions of a box, and G is the diagonal running from one of the top corners to the opposite bottom corner.\n\nJust as there are some triangles where all three sides are whole numbers, there are also some boxes where the three sides and the spatial diagonal (A, B, C, and G) are whole numbers. But there are also three more diagonals on the three surfaces (D, E, and F) and that raises an interesting question: can there be a box where all seven of these lengths are integers?\n\nThe goal is to find a box where A²+B²+C²=G², and where all seven numbers are integers. This is called a perfect cuboid. Mathematicians have tried many different possibilities and have yet to find a single one that works."", 'result': {'fake': 0.0337, 'real': 0.9663}, 'status': 'success'}, {'text': ""But they also haven't been able to prove that such a box doesn't exist, so the hunt is on for a perfect cuboid.\n\nInscribed Square Problem\n\nDraw a closed loop. The loop doesn't have to be a circle, it can be any shape you want, but the beginning and the end have to meet and the loop can't cross itself. It should be possible to draw a square inside the loop so that all four corners of the square are touching the loop. According to the inscribed square hypothesis every closed loop (specifically every plane simple closed curve) should have an inscribed square, a square where all four corners lie somewhere on the loop.\n\nThis has already been solved for a number of other shapes, such as triangles and rectangles. But squares are tricky, and so far a formal proof has eluded mathematicians.\n\nHappy Ending Problem\n\nThe happy ending problem is so named because it led to the marriage of two mathematicians who worked on it, George Szekeres and Esther Klein. Essentially, the problem works like this:\n\nMake five dots at random places on a piece of paper. Assuming the dots aren't deliberately arranged—say, in a line—you should always be able to connect four of them to create a convex quadrilateral, which is a shape with four sides where all of the corners are less than 180 degrees. The gist of this theorem is that you'll always be able to create a convex quadrilateral with five random dots, regardless of where those dots are positioned.\n\nSo that's how it works for four sides. But for a pentagon, a five-sided shape, it turns out you need nine dots. For a hexagon, it's 17 dots. But beyond that, we don't know. It's a mystery how many dots is required to create a heptagon or any larger shapes. More importantly, there should be a formula to tell us how many dots are required for any shape. Mathematicians suspect the equation is M=1+2^n-2, where M is the number of dots and N is the number of sides in the shape. But as yet, they've only been able to prove that the answer is at least as big as the answer you get that way.\n\n[SOURCE : GOOGLE]\n\nEDIT : the moving sofa problem is solved now,\n\nThnx mrinal kumar for suggestion."", 'result': {'fake': 0.0058, 'real': 0.9942}, 'status': 'success'}], 'credits_used': 10, 'credits': 1994881, 'subscription': 0, 'content': ""Collatz Conjecture\n\nPick any number. If that number is even, divide it by 2. If it's odd, multiply it by 3 and add 1. Now repeat the process with your new number. If you keep going, you'll eventually end up at 1. Every time.\n\nMathematicians have tried millions of numbers and they've never found a single one that didn't end up at 1 eventually. The thing is, they've never been able to prove that there isn't a special number out there that never leads to 1. It's possible that there's some really big number that goes to infinity instead, or maybe a number that gets stuck in a loop and never reaches 1. But no one has ever been able to prove that for certain.\n\nMoving Sofa Problem\n\nSo you're moving into your new apartment, and you're trying to bring your sofa. The problem is, the hallway turns and you have to fit your sofa around a corner. If it's a small sofa, that might not be a problem, but a really big sofa is sure to get stuck. If you're a mathematician, you ask yourself: What's the largest sofa you could possibly fit around the corner? It doesn't have to be a rectangular sofa either, it can be any shape.\n\nThis is the essence of the moving sofa problem. Here are the specifics: the whole problem is in two dimensions, the corner is a 90-degree angle, and the width of the corridor is 1. What is the largest two-dimensional area that can fit around the corner?\n\nThe largest area that can fit around a corner is called—I kid you not—the sofa constant. Nobody knows for sure how big it is, but we have some pretty big sofas that do work, so we know it has to be at least as big as them. We also have some sofas that don't work, so it has to be smaller than those. All together, we know the sofa constant has to be between 2.2195 and 2.8284.\n\nPerfect Cuboid Problem\n\nRemember the pythagorean theorem, A²+B²=C² ?\n\nThe three letters correspond to the three sides of a right triangle. In a Pythagorean triangle, and all three sides are whole numbers. Let's extend this idea to three dimensions. In three dimensions, there are four numbers. In the image above, they are A, B, C, and G. The first three are the dimensions of a box, and G is the diagonal running from one of the top corners to the opposite bottom corner.\n\nJust as there are some triangles where all three sides are whole numbers, there are also some boxes where the three sides and the spatial diagonal (A, B, C, and G) are whole numbers. But there are also three more diagonals on the three surfaces (D, E, and F) and that raises an interesting question: can there be a box where all seven of these lengths are integers?\n\nThe goal is to find a box where A²+B²+C²=G², and where all seven numbers are integers. This is called a perfect cuboid. Mathematicians have tried many different possibilities and have yet to find a single one that works. But they also haven't been able to prove that such a box doesn't exist, so the hunt is on for a perfect cuboid.\n\nInscribed Square Problem\n\nDraw a closed loop. The loop doesn't have to be a circle, it can be any shape you want, but the beginning and the end have to meet and the loop can't cross itself. It should be possible to draw a square inside the loop so that all four corners of the square are touching the loop. According to the inscribed square hypothesis every closed loop (specifically every plane simple closed curve) should have an inscribed square, a square where all four corners lie somewhere on the loop.\n\nThis has already been solved for a number of other shapes, such as triangles and rectangles. But squares are tricky, and so far a formal proof has eluded mathematicians.\n\nHappy Ending Problem\n\nThe happy ending problem is so named because it led to the marriage of two mathematicians who worked on it, George Szekeres and Esther Klein. Essentially, the problem works like this:\n\nMake five dots at random places on a piece of paper. Assuming the dots aren't deliberately arranged—say, in a line—you should always be able to connect four of them to create a convex quadrilateral, which is a shape with four sides where all of the corners are less than 180 degrees. The gist of this theorem is that you'll always be able to create a convex quadrilateral with five random dots, regardless of where those dots are positioned.\n\nSo that's how it works for four sides. But for a pentagon, a five-sided shape, it turns out you need nine dots. For a hexagon, it's 17 dots. But beyond that, we don't know. It's a mystery how many dots is required to create a heptagon or any larger shapes. More importantly, there should be a formula to tell us how many dots are required for any shape. Mathematicians suspect the equation is M=1+2^n-2, where M is the number of dots and N is the number of sides in the shape. But as yet, they've only been able to prove that the answer is at least as big as the answer you get that way.\n\n[SOURCE : GOOGLE]\n\nEDIT : the moving sofa problem is solved now,\n\nThnx mrinal kumar for suggestion."", 'aiModelVersion': '1'}",0.13965
Keith Ramsay,Updated 3y,What is the highest level of mathematics we have discovered so far?,"Beyond a certain point, perhaps just when people arrive at the research frontier, distinctions like higher and lower start carrying a touch of irony about them. It no longer is so clear what it should mean to say that one kind is higher than another.

Part of the time, “higher” implies “more complicated”, but complexity is not always a step forward. What makes it related sometimes is that sometimes one starts by solving the simple problems (low-hanging fruit) and then progresses to more advanced matters that are also more complex. In some cases, though, complexity is a bad sign, and finding a simpler approach is an advance. Perhaps it is part of the natural evolution of mathematics to go back and forth between simplicity and complexity.

Degree theory in logic (which studies “degrees of unsolvability”) had at one time a reputation for complexity. I recently saw a good article in the Notices of the AMS which described attempts to impose a kind of order on it, hoping to show in particular that the “naturally occurring” degrees are arranged in a much more orderly way than all the degrees which in principle exist.

John Conway is known among other things for discovering three of the sporadic finite simple groups. He gave a talk once where he praised the merits of simple questions and then proceeded to talk about the symmetries of space (a very thoroughly studied topic) for which he had a new notation. I somehow got the impression that he implied it was a sign of mathematical maturity not to disparage simple questions for being simple. I think this is correct.

I’m not familiar with the concept in set theory of a “morass”, only that the theory of morasses has a reputation for being especially complicated.

Someone asked a Harvard professor why Paul Erdős didn’t visit, and the professor explained that he did a different kind of mathematics than they did. Some people I suspect are more naturally fond of what people call “big machinery”. Erdős was not like that. Neither way is inherently better. Small machinery doesn’t necessarily mean that one’s reasoning isn’t complex, just that it relies on less infrastructure in the form of definitions.

Alexander Grothendieck is famous for the kind of machine-building that some people enjoy a lot. He did a lot of work at a very high level of generality. By some standards the work building on his work is some of the most advanced mathematics there is. Using category theory and homological algebra to study algebraic geometry just seems so gnarly. Of course I could easily be biased here.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/4fegrpzuxvm93j7a', 'title': 'What is the highest level of mathematics we have discovered so far?', 'score': {'original': 0.9997, 'ai': 0.0003}, 'blocks': [{'text': 'Beyond a certain point, perhaps just when people arrive at the research frontier, distinctions like higher and lower start carrying a touch of irony about them. It no longer is so clear what it should mean to say that one kind is higher than another.\n\nPart of the time, “higher” implies “more complicated”, but complexity is not always a step forward. What makes it related sometimes is that sometimes one starts by solving the simple problems (low-hanging fruit) and then progresses to more advanced matters that are also more complex. In some cases, though, complexity is a bad sign, and finding a simpler approach is an advance. Perhaps it is part of the natural evolution of mathematics to go back and forth between simplicity and complexity.\n\nDegree theory in logic (which studies “degrees of unsolvability”) had at one time a reputation for complexity. I recently saw a good article in the Notices of the AMS which described attempts to impose a kind of order on it, hoping to show in particular that the “naturally occurring” degrees are arranged in a much more orderly way than all the degrees which in principle exist.\n\nJohn Conway is known among other things for discovering three of the sporadic finite simple groups. He gave a talk once where he praised the merits of simple questions and then proceeded to talk about the symmetries of space (a very thoroughly studied topic) for which he had a new notation. I somehow got the impression that he implied it was a sign of mathematical maturity not to disparage simple questions for being simple. I think this is correct.\n\nI’m not familiar with the concept in set theory of a “morass”, only that the theory of morasses has a reputation for being especially complicated.\n\nSomeone asked a Harvard professor why Paul Erdős didn’t visit, and the professor explained that he did a different kind of mathematics than they did. Some people I suspect are more naturally fond of what people call “big machinery”. Erdős was not like that. Neither way is inherently better. Small machinery doesn’t necessarily mean that one’s reasoning isn’t complex, just that it relies on less infrastructure in the form of definitions.\n\nAlexander Grothendieck is famous for the kind of machine-building that some people enjoy a lot. He did a lot of work at a very high level of generality. By some standards the work building on his work is some of the most advanced mathematics there is. Using category theory and homological algebra to study algebraic geometry just seems so gnarly. Of course I could easily be biased here.', 'result': {'fake': 0.0003, 'real': 0.9997}, 'status': 'success'}], 'credits_used': 5, 'credits': 1994876, 'subscription': 0, 'content': 'Beyond a certain point, perhaps just when people arrive at the research frontier, distinctions like higher and lower start carrying a touch of irony about them. It no longer is so clear what it should mean to say that one kind is higher than another.\n\nPart of the time, “higher” implies “more complicated”, but complexity is not always a step forward. What makes it related sometimes is that sometimes one starts by solving the simple problems (low-hanging fruit) and then progresses to more advanced matters that are also more complex. In some cases, though, complexity is a bad sign, and finding a simpler approach is an advance. Perhaps it is part of the natural evolution of mathematics to go back and forth between simplicity and complexity.\n\nDegree theory in logic (which studies “degrees of unsolvability”) had at one time a reputation for complexity. I recently saw a good article in the Notices of the AMS which described attempts to impose a kind of order on it, hoping to show in particular that the “naturally occurring” degrees are arranged in a much more orderly way than all the degrees which in principle exist.\n\nJohn Conway is known among other things for discovering three of the sporadic finite simple groups. He gave a talk once where he praised the merits of simple questions and then proceeded to talk about the symmetries of space (a very thoroughly studied topic) for which he had a new notation. I somehow got the impression that he implied it was a sign of mathematical maturity not to disparage simple questions for being simple. I think this is correct.\n\nI’m not familiar with the concept in set theory of a “morass”, only that the theory of morasses has a reputation for being especially complicated.\n\nSomeone asked a Harvard professor why Paul Erdős didn’t visit, and the professor explained that he did a different kind of mathematics than they did. Some people I suspect are more naturally fond of what people call “big machinery”. Erdős was not like that. Neither way is inherently better. Small machinery doesn’t necessarily mean that one’s reasoning isn’t complex, just that it relies on less infrastructure in the form of definitions.\n\nAlexander Grothendieck is famous for the kind of machine-building that some people enjoy a lot. He did a lot of work at a very high level of generality. By some standards the work building on his work is some of the most advanced mathematics there is. Using category theory and homological algebra to study algebraic geometry just seems so gnarly. Of course I could easily be biased here.', 'aiModelVersion': '1'}",0.9997
David Joyce,Updated 4y,"How did Newton know that calculus was correct, if he himself didn't develop all the proofs supporting the results of calculus, which happened over the next 100 years?","Newton assumed various things about varying quantities. One was that changing variables had rates of change. In specific cases he determined what the rate of change was. He also assumed that the area under a curve existed, and in specific cases determined what that area was.

His methods were beyond reproach when it came to things like differentiation and integration of polynomials, rational functions, algebraic functions, trigonometric functions, exponential functions, and logarithms.

This was completely rigorous by the standards of the time. What happened in the 1700s was that the concept of function enlarged to include functions that didn’t have derivatives. In the 1800s a higher level of rigor was required, in part, to accommodate the wider concept for functions. It wasn’t assumed, like Newton had, that every function had derivatives and integrals.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/5qwxzphtyfl0ej93', 'title': ""How did Newton know that calculus was correct, if he himself didn't develop all the proofs supporting the results of calculus, which happened over the next 100 years?"", 'score': {'original': 0.9981, 'ai': 0.0019}, 'blocks': [{'text': 'Newton assumed various things about varying quantities. One was that changing variables had rates of change. In specific cases he determined what the rate of change was. He also assumed that the area under a curve existed, and in specific cases determined what that area was.\n\nHis methods were beyond reproach when it came to things like differentiation and integration of polynomials, rational functions, algebraic functions, trigonometric functions, exponential functions, and logarithms.\n\nThis was completely rigorous by the standards of the time. What happened in the 1700s was that the concept of function enlarged to include functions that didn’t have derivatives. In the 1800s a higher level of rigor was required, in part, to accommodate the wider concept for functions. It wasn’t assumed, like Newton had, that every function had derivatives and integrals.', 'result': {'fake': 0.0019, 'real': 0.9981}, 'status': 'success'}], 'credits_used': 2, 'credits': 1994874, 'subscription': 0, 'content': 'Newton assumed various things about varying quantities. One was that changing variables had rates of change. In specific cases he determined what the rate of change was. He also assumed that the area under a curve existed, and in specific cases determined what that area was.\n\nHis methods were beyond reproach when it came to things like differentiation and integration of polynomials, rational functions, algebraic functions, trigonometric functions, exponential functions, and logarithms.\n\nThis was completely rigorous by the standards of the time. What happened in the 1700s was that the concept of function enlarged to include functions that didn’t have derivatives. In the 1800s a higher level of rigor was required, in part, to accommodate the wider concept for functions. It wasn’t assumed, like Newton had, that every function had derivatives and integrals.', 'aiModelVersion': '1'}",0.9981
Liviu Nicolaescu,Updated 1y,Why did mathematics become increasingly abstract throughout the 20th century?,"Try reading a 19th century exposition of Galois theory and then switch to Emil Artin’s presentation see which is clearer. Abel-Jacobi’s famous theorem is an even more striking example of result whose true meaning requires the 20th century abstraction.

At the beginning of the 20th century there was so much accumulation of results, that certain patterns emerged. To paraphrase Bob Dylan “man gave names to all the animals” and certain “animals” were isolated as fundamental and given names: vector spaces, metric spaces, topological spaces, compactness, groups, rings, fields, etc.

Once Cantor isolated the concepts of sets and functions the whole Hell broke loose. Can you imagine that for centuries people derivated and integrated functions without worrying what they are. There are the usual functions of calculus, and and also the functionals of the calculus of variations. They’re both functions in the sense of Cantor.

Hilbert’s work on invariant theory is I think the first argument in favor of abstraction. The legend goes that Paul Gordan, the premier invariant theorist of his time, was so surprised by Hilbert’s argument that he proclaimed that “this is not mathematics, this is theology”.

Many of the fundamental questions in mathematics, some included in Hilbert’s famous list, lead to more concepts and required better language.

Think for example of the concept of dimension? Just asking this question as Poincare did at the beginning of the 20th century is a tremendous leap forward because until the second half of the 19th century people were not making a conscientious effort to think beyond our three dimensional space. What does it mean that “something” has dimension 23? Answering this lead to profound advances in algebra and topology.

In 1929 Bertrand Russel wrote about probability that “it is the most important concept in modern science, especially as nobody has the slightest notion of what it means.'' A few years later in 1933 Kolmogorov addressed definitively (from a mathematician’s point of view) this issue. However that was made possible because of the abstraction of measure theory and integration.

I have talked with a Chemist who was teaching a class about symmetries of molecules. I soon realized that is is really a class about representation theory of (mostly finite) groups. Only the word group is never used, but it appears in the guise of symmetry of type …. (The name indicates that that the group in question is a subgroup of an orthogonal group and describes its generators. ) I found the language extremely cumbersome and I wished they were aware it can be significantly streamlined.

It turned out that the the right language to express the principle of quantum mechanics is functional analysis, an abstraction that was contouring roughly as the same time as the physicists were uncovering the fundamentals of this strange quantum world.

The First World War was very devastating to the French mathematics: many promising young talents perished during that conflagration. Some of the survivors formed a group now known as Nicolas Bourbaki that aimed of writing a treatise of all the mathematics known at that time. In the process they changed the way we communicate mathematics. Abstraction is one of the requirements of this new style. Ours is a Bourbaki influenced way of presenting mathematics.

To use a beautiful analogy of the theoretical physicist Freeman Dyson, mathematicians are of two kinds, birds and frogs, or rather mixtures of both. Before the 20th century, most mathematicians were frogs, with some notable birds sprinkled in between: Newton, Gauss, Riemann and other usual suspects. To my mind Hilbert and Poincare were frogs that metamorphosed into birds, and dragged everybody up there with them, to have a birds-eye view of mathematics. Hence the 20th century abstraction. And the modern era mathematician has had to learn to fly a little bit, even those who, like Dyson, consider themselves frogs.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/53m7xakqoj6hc8pw', 'title': 'Why did mathematics become increasingly abstract throughout the 20th century?', 'score': {'original': 0.9665, 'ai': 0.0335}, 'blocks': [{'text': ""Try reading a 19th century exposition of Galois theory and then switch to Emil Artin’s presentation see which is clearer. Abel-Jacobi’s famous theorem is an even more striking example of result whose true meaning requires the 20th century abstraction.\n\nAt the beginning of the 20th century there was so much accumulation of results, that certain patterns emerged. To paraphrase Bob Dylan “man gave names to all the animals” and certain “animals” were isolated as fundamental and given names: vector spaces, metric spaces, topological spaces, compactness, groups, rings, fields, etc.\n\nOnce Cantor isolated the concepts of sets and functions the whole Hell broke loose. Can you imagine that for centuries people derivated and integrated functions without worrying what they are. There are the usual functions of calculus, and and also the functionals of the calculus of variations. They’re both functions in the sense of Cantor.\n\nHilbert’s work on invariant theory is I think the first argument in favor of abstraction. The legend goes that Paul Gordan, the premier invariant theorist of his time, was so surprised by Hilbert’s argument that he proclaimed that “this is not mathematics, this is theology”.\n\nMany of the fundamental questions in mathematics, some included in Hilbert’s famous list, lead to more concepts and required better language.\n\nThink for example of the concept of dimension? Just asking this question as Poincare did at the beginning of the 20th century is a tremendous leap forward because until the second half of the 19th century people were not making a conscientious effort to think beyond our three dimensional space. What does it mean that “something” has dimension 23? Answering this lead to profound advances in algebra and topology.\n\nIn 1929 Bertrand Russel wrote about probability that “it is the most important concept in modern science, especially as nobody has the slightest notion of what it means.'' A few years later in 1933 Kolmogorov addressed definitively (from a mathematician’s point of view) this issue. However that was made possible because of the abstraction of measure theory and integration.\n\nI have talked with a Chemist who was teaching a class about symmetries of molecules. I soon realized that is is really a class about representation theory of (mostly finite) groups. Only the word group is never used, but it appears in the guise of symmetry of type …. (The name indicates that that the group in question is a subgroup of an orthogonal group and describes its generators. ) I found the language extremely cumbersome and I wished they were aware it can be significantly streamlined.\n\nIt turned out that the the right language to express the principle of quantum mechanics is functional analysis, an abstraction that was contouring roughly as the same time as the physicists were uncovering the fundamentals of this strange quantum world.\n\nThe First World War was very devastating to the French mathematics: many promising young talents perished during that conflagration. Some of the survivors formed a group now known as Nicolas Bourbaki that aimed of writing a treatise of all the mathematics known at that time. In the process they changed the way we communicate mathematics. Abstraction"", 'result': {'fake': 0.0002, 'real': 0.9998}, 'status': 'success'}, {'text': 'is one of the requirements of this new style. Ours is a Bourbaki influenced way of presenting mathematics.\n\nTo use a beautiful analogy of the theoretical physicist Freeman Dyson, mathematicians are of two kinds, birds and frogs, or rather mixtures of both. Before the 20th century, most mathematicians were frogs, with some notable birds sprinkled in between: Newton, Gauss, Riemann and other usual suspects. To my mind Hilbert and Poincare were frogs that metamorphosed into birds, and dragged everybody up there with them, to have a birds-eye view of mathematics. Hence the 20th century abstraction. And the modern era mathematician has had to learn to fly a little bit, even those who, like Dyson, consider themselves frogs.', 'result': {'fake': 0.0269, 'real': 0.9731}, 'status': 'success'}], 'credits_used': 7, 'credits': 1994867, 'subscription': 0, 'content': ""Try reading a 19th century exposition of Galois theory and then switch to Emil Artin’s presentation see which is clearer. Abel-Jacobi’s famous theorem is an even more striking example of result whose true meaning requires the 20th century abstraction.\n\nAt the beginning of the 20th century there was so much accumulation of results, that certain patterns emerged. To paraphrase Bob Dylan “man gave names to all the animals” and certain “animals” were isolated as fundamental and given names: vector spaces, metric spaces, topological spaces, compactness, groups, rings, fields, etc.\n\nOnce Cantor isolated the concepts of sets and functions the whole Hell broke loose. Can you imagine that for centuries people derivated and integrated functions without worrying what they are. There are the usual functions of calculus, and and also the functionals of the calculus of variations. They’re both functions in the sense of Cantor.\n\nHilbert’s work on invariant theory is I think the first argument in favor of abstraction. The legend goes that Paul Gordan, the premier invariant theorist of his time, was so surprised by Hilbert’s argument that he proclaimed that “this is not mathematics, this is theology”.\n\nMany of the fundamental questions in mathematics, some included in Hilbert’s famous list, lead to more concepts and required better language.\n\nThink for example of the concept of dimension? Just asking this question as Poincare did at the beginning of the 20th century is a tremendous leap forward because until the second half of the 19th century people were not making a conscientious effort to think beyond our three dimensional space. What does it mean that “something” has dimension 23? Answering this lead to profound advances in algebra and topology.\n\nIn 1929 Bertrand Russel wrote about probability that “it is the most important concept in modern science, especially as nobody has the slightest notion of what it means.'' A few years later in 1933 Kolmogorov addressed definitively (from a mathematician’s point of view) this issue. However that was made possible because of the abstraction of measure theory and integration.\n\nI have talked with a Chemist who was teaching a class about symmetries of molecules. I soon realized that is is really a class about representation theory of (mostly finite) groups. Only the word group is never used, but it appears in the guise of symmetry of type …. (The name indicates that that the group in question is a subgroup of an orthogonal group and describes its generators. ) I found the language extremely cumbersome and I wished they were aware it can be significantly streamlined.\n\nIt turned out that the the right language to express the principle of quantum mechanics is functional analysis, an abstraction that was contouring roughly as the same time as the physicists were uncovering the fundamentals of this strange quantum world.\n\nThe First World War was very devastating to the French mathematics: many promising young talents perished during that conflagration. Some of the survivors formed a group now known as Nicolas Bourbaki that aimed of writing a treatise of all the mathematics known at that time. In the process they changed the way we communicate mathematics. Abstraction is one of the requirements of this new style. Ours is a Bourbaki influenced way of presenting mathematics.\n\nTo use a beautiful analogy of the theoretical physicist Freeman Dyson, mathematicians are of two kinds, birds and frogs, or rather mixtures of both. Before the 20th century, most mathematicians were frogs, with some notable birds sprinkled in between: Newton, Gauss, Riemann and other usual suspects. To my mind Hilbert and Poincare were frogs that metamorphosed into birds, and dragged everybody up there with them, to have a birds-eye view of mathematics. Hence the 20th century abstraction. And the modern era mathematician has had to learn to fly a little bit, even those who, like Dyson, consider themselves frogs."", 'aiModelVersion': '1'}",0.9665
Alon Amit,Updated 8y,Was it more difficult to learn mathematics in the past?,"I don't think it was more difficult to learn mathematics in the past.

I do think it's harder today to read a textbook from the 1920's - harder than it was for students at the time. The language, the notation, the style, all of these have evolved. But that doesn't mean things were more difficult then. They were just different.

Hardy's ""A Course of Pure Mathematics"" was written in 1908. I have the tenth edition, printed in 1950, and though I'm sure typesetting has changed and likely some revisions took place, the substance of the book remained unchanged. It's a wonderful, readable book - somewhat austere and definitely not easy going, but this reflects the personality and depth of the author.

Whoever studied with this book in 1910 didn't need to possess a higher IQ than modern students. The best teachers of the time, as today, were masters of their domain and excellent expositors and mentors; they knew how to inspire and delight students.





Observe how little math and how much prose there is on this page. Hardy takes the time to explain ideas and rationale, not just the dry definitions and theorems.

I wouldn't choose Hardy as a textbook today, but not because it's bad. It's just slightly anachronistic, the language feels a bit antiquated, it can't benefit from pretty LaTeX formatting and it can't provide beautiful visuals that would be easier to produce today.

Another textbook I'm looking at right now is Titchmarsh, ""The Theory of Functions"", from 1939. The first edition came out in 1932, and this is the second one. It's a great book, using terminology that is at times surprisingly modern (big-O) and at times horribly outdated (a fractional linear transformation is called linear). Again, I don't see any reason to believe that it was harder for that generation than a modern advanced textbook on real and complex analysis would be today. Some popular current textbooks are actually more turgid and opaque.





If you roll back your time machine to the 19th century, well, I'd argue that it was actually easier to learn math back then - there was just less of it to learn. Some of the standard material would seem obscure to modern students, because progress also eliminates things that are no longer deemed profound (the arc length of the lemniscate and resolvents, for example, would have been standard topics back then). But mastering all that was known then about Fourier series or even complex analysis was simply a lot less work.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/c9dgvarujylwim3n', 'title': 'Was it more difficult to learn mathematics in the past?', 'score': {'original': 0.9996, 'ai': 0.0004}, 'blocks': [{'text': 'I don\'t think it was more difficult to learn mathematics in the past.\n\nI do think it\'s harder today to read a textbook from the 1920\'s - harder than it was for students at the time. The language, the notation, the style, all of these have evolved. But that doesn\'t mean things were more difficult then. They were just different.\n\nHardy\'s ""A Course of Pure Mathematics"" was written in 1908. I have the tenth edition, printed in 1950, and though I\'m sure typesetting has changed and likely some revisions took place, the substance of the book remained unchanged. It\'s a wonderful, readable book - somewhat austere and definitely not easy going, but this reflects the personality and depth of the author.\n\nWhoever studied with this book in 1910 didn\'t need to possess a higher IQ than modern students. The best teachers of the time, as today, were masters of their domain and excellent expositors and mentors; they knew how to inspire and delight students.\n\n\n\n\n\nObserve how little math and how much prose there is on this page. Hardy takes the time to explain ideas and rationale, not just the dry definitions and theorems.\n\nI wouldn\'t choose Hardy as a textbook today, but not because it\'s bad. It\'s just slightly anachronistic, the language feels a bit antiquated, it can\'t benefit from pretty LaTeX formatting and it can\'t provide beautiful visuals that would be easier to produce today.\n\nAnother textbook I\'m looking at right now is Titchmarsh, ""The Theory of Functions"", from 1939. The first edition came out in 1932, and this is the second one. It\'s a great book, using terminology that is at times surprisingly modern (big-O) and at times horribly outdated (a fractional linear transformation is called linear). Again, I don\'t see any reason to believe that it was harder for that generation than a modern advanced textbook on real and complex analysis would be today. Some popular current textbooks are actually more turgid and opaque.\n\n\n\n\n\nIf you roll back your time machine to the 19th century, well, I\'d argue that it was actually easier to learn math back then - there was just less of it to learn. Some of the standard material would seem obscure to modern students, because progress also eliminates things that are no longer deemed profound (the arc length of the lemniscate and resolvents, for example, would have been standard topics back then). But mastering all that was known then about Fourier series or even complex analysis was simply a lot less work.', 'result': {'fake': 0.0005, 'real': 0.9995}, 'status': 'success'}], 'credits_used': 5, 'credits': 1994862, 'subscription': 0, 'content': 'I don\'t think it was more difficult to learn mathematics in the past.\n\nI do think it\'s harder today to read a textbook from the 1920\'s - harder than it was for students at the time. The language, the notation, the style, all of these have evolved. But that doesn\'t mean things were more difficult then. They were just different.\n\nHardy\'s ""A Course of Pure Mathematics"" was written in 1908. I have the tenth edition, printed in 1950, and though I\'m sure typesetting has changed and likely some revisions took place, the substance of the book remained unchanged. It\'s a wonderful, readable book - somewhat austere and definitely not easy going, but this reflects the personality and depth of the author.\n\nWhoever studied with this book in 1910 didn\'t need to possess a higher IQ than modern students. The best teachers of the time, as today, were masters of their domain and excellent expositors and mentors; they knew how to inspire and delight students.\n\n\n\n\n\nObserve how little math and how much prose there is on this page. Hardy takes the time to explain ideas and rationale, not just the dry definitions and theorems.\n\nI wouldn\'t choose Hardy as a textbook today, but not because it\'s bad. It\'s just slightly anachronistic, the language feels a bit antiquated, it can\'t benefit from pretty LaTeX formatting and it can\'t provide beautiful visuals that would be easier to produce today.\n\nAnother textbook I\'m looking at right now is Titchmarsh, ""The Theory of Functions"", from 1939. The first edition came out in 1932, and this is the second one. It\'s a great book, using terminology that is at times surprisingly modern (big-O) and at times horribly outdated (a fractional linear transformation is called linear). Again, I don\'t see any reason to believe that it was harder for that generation than a modern advanced textbook on real and complex analysis would be today. Some popular current textbooks are actually more turgid and opaque.\n\n\n\n\n\nIf you roll back your time machine to the 19th century, well, I\'d argue that it was actually easier to learn math back then - there was just less of it to learn. Some of the standard material would seem obscure to modern students, because progress also eliminates things that are no longer deemed profound (the arc length of the lemniscate and resolvents, for example, would have been standard topics back then). But mastering all that was known then about Fourier series or even complex analysis was simply a lot less work.', 'aiModelVersion': '1'}",0.9996
David Joyce,Updated 4y,In my history class we learned that algebra was created by the Arabs. If this is the case then how were Greek mathematicians such as Pythagoras able to come up with complex algebraic formulas/proofs?,"The algebra of al-Khwarizmi and others who wrote in Arabic was an algebra entirely in words. There were no symbols. Symbolic algebra was developed later in the 1500s. Al-Khwarizmi summarized the methods to solve linear and quadratic equations and he used words and full sentences.

In some ways, the lack of symbolism helps since it takes time to understand the symbols. In other ways, it’s a hindrance since it’s much easier to work with symbols once you understand them.

Greek mathematicians of two millennia ago approached algebra in a couple of ways. Diophantus had a symbolic algebra but it wasn’t as general as ours. For one thing, he could only have one unknown whereas with modern symbolic algebra you can have different variables for different unknown quantities. Mostly, Diophantus worked with polynomial equations in one unknown of various degrees, and he was remarkably successful. Linear and quadratic equations form a small part of his work.

The other approach, predating Diophantus, was to use geometry to solve algebraic questions. Lines represented constants and unknowns, rectangles represented products of two lines, and solids represented products of three lines. For the most part, they only dealt with linear and quadratic problems.

Algebra wasn’t just Greek. Linear and quadratic problems were solved in ancient India and China as well. By about a thousand years ago, the Chinese had methods to solve equations of arbitrarily high order, not just linear and quadratic equations.

Much earlier, about four thousand years ago, linear and quadratic problems were solved in Egypt and Babylonia. They had no symbolic algebra, but various methods were used, methods we call the rule of three and the method of false position.

Algebra is ancient. It was done in different ways in different places and time periods.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/swo7mq05iftdy2jh', 'title': 'In my history class we learned that algebra was created by the Arabs. If this is the case then how were Greek mathematicians such as Pythagoras able to come up with complex algebraic formulas/proofs?', 'score': {'original': 0.9971, 'ai': 0.0029}, 'blocks': [{'text': 'The algebra of al-Khwarizmi and others who wrote in Arabic was an algebra entirely in words. There were no symbols. Symbolic algebra was developed later in the 1500s. Al-Khwarizmi summarized the methods to solve linear and quadratic equations and he used words and full sentences.\n\nIn some ways, the lack of symbolism helps since it takes time to understand the symbols. In other ways, it’s a hindrance since it’s much easier to work with symbols once you understand them.\n\nGreek mathematicians of two millennia ago approached algebra in a couple of ways. Diophantus had a symbolic algebra but it wasn’t as general as ours. For one thing, he could only have one unknown whereas with modern symbolic algebra you can have different variables for different unknown quantities. Mostly, Diophantus worked with polynomial equations in one unknown of various degrees, and he was remarkably successful. Linear and quadratic equations form a small part of his work.\n\nThe other approach, predating Diophantus, was to use geometry to solve algebraic questions. Lines represented constants and unknowns, rectangles represented products of two lines, and solids represented products of three lines. For the most part, they only dealt with linear and quadratic problems.\n\nAlgebra wasn’t just Greek. Linear and quadratic problems were solved in ancient India and China as well. By about a thousand years ago, the Chinese had methods to solve equations of arbitrarily high order, not just linear and quadratic equations.\n\nMuch earlier, about four thousand years ago, linear and quadratic problems were solved in Egypt and Babylonia. They had no symbolic algebra, but various methods were used, methods we call the rule of three and the method of false position.\n\nAlgebra is ancient. It was done in different ways in different places and time periods.', 'result': {'fake': 0.0029, 'real': 0.9971}, 'status': 'success'}], 'credits_used': 3, 'credits': 1994859, 'subscription': 0, 'content': 'The algebra of al-Khwarizmi and others who wrote in Arabic was an algebra entirely in words. There were no symbols. Symbolic algebra was developed later in the 1500s. Al-Khwarizmi summarized the methods to solve linear and quadratic equations and he used words and full sentences.\n\nIn some ways, the lack of symbolism helps since it takes time to understand the symbols. In other ways, it’s a hindrance since it’s much easier to work with symbols once you understand them.\n\nGreek mathematicians of two millennia ago approached algebra in a couple of ways. Diophantus had a symbolic algebra but it wasn’t as general as ours. For one thing, he could only have one unknown whereas with modern symbolic algebra you can have different variables for different unknown quantities. Mostly, Diophantus worked with polynomial equations in one unknown of various degrees, and he was remarkably successful. Linear and quadratic equations form a small part of his work.\n\nThe other approach, predating Diophantus, was to use geometry to solve algebraic questions. Lines represented constants and unknowns, rectangles represented products of two lines, and solids represented products of three lines. For the most part, they only dealt with linear and quadratic problems.\n\nAlgebra wasn’t just Greek. Linear and quadratic problems were solved in ancient India and China as well. By about a thousand years ago, the Chinese had methods to solve equations of arbitrarily high order, not just linear and quadratic equations.\n\nMuch earlier, about four thousand years ago, linear and quadratic problems were solved in Egypt and Babylonia. They had no symbolic algebra, but various methods were used, methods we call the rule of three and the method of false position.\n\nAlgebra is ancient. It was done in different ways in different places and time periods.', 'aiModelVersion': '1'}",0.9971
Viktor T. Toth,1y,Why did mathematicians literally invent imaginary numbers instead of admitting that their theories could be wrong?,"Consider the following simple cubic equation: x3+6x−7=0.x3+6x−7=0.x^3 + 6x - 7 = 0.\tag*{} This equation has a single root at x=1,x=1,x=1, which can be seen simply by plotting the equation on graph paper:And indeed, it is not hard to see that x3+6x−7=(x−1)(x2+x+7),x3+6x−7=(x−1)(x2+x+7),x^3+6x-7 = (x-1)(x^2+x+7), and this expression is obviously 000 when x=1.x=1.x=1. How would we go about finding this root in some formal process? The general solution was discovered by Tartaglia and published by Cardano. In modern notation, the idea relates to the identity (u+v)3=u3+v3+3uv(u+v),(u+v)3=u3+v3+3uv(u+v),(u+v)^3=u^3 + v^3 + 3uv(u+v), which we can rewrite as (u+v)3−3uv(u+v)−(u3+v3)=0.(u+v)3−3uv(u+v)−(u3+v3)=0.(u+v)^3 - 3uv(u+v) - (u^3+v^3) = 0.\tag*{} Notice how similar the structure of this expression is to the cubic equation that I wrote down above. So if x=u+v,x=u+v,x = u+v, then −3uv=6−3uv=6-3uv = 6 and (u3+v3)=7.(u3+v3)=7.(u^3+v^3)=7. But if −3uv=6−3uv=6-3uv = 6 then u3v3=−8.u3v3=−8.u^3v^3 = -8. So we have two equations in the two unknowns u3u3u^3 and v3:v3:v^3: u3+v3=7,u3v3=−8.u3+v3=7,u3v3=−8.\begin{align*}u^3+v^3&{}=7,\\u^3v^3&{}=-8.\end{align*}\tag*{} This can be solved! Using v3=7−u3v3=7−u3v^3=7-u^3 from the first equation in the second equation, we get (u3)2−7u3+8=0.(u3)2−7u3+8=0.(u^3)^2 - 7u^3 + 8 = 0.\tag*{} This is a simple quadratic equation in u3,u3,u^3, the solutions of which are well known: u3=72±√494+8=72±92.u3=72±494+8=72±92.u^3 = \dfrac{7}{2} \pm \sqrt{\dfrac{49}{4}+8} = \dfrac{7}{2}\pm\dfrac{9}{2}.\tag*{} so v3=72∓92.v3=72∓92.v^3 = \dfrac{7}{2}\mp \dfrac{9}{2}.\tag*{} So between u3u3u^3 and v3,v3,v^3, one is 8,8,8, the other is −1−1-1 (they are interchangeable). So say, u=2,u=2,u=2, v=−1,v=−1,v=-1, and that means that x=u+v=1,x=u+v=1,x = u+v = 1, which is indeed the solution. So all this works beautifully. But then, how about the equation x3−32x+12=0?x3−32x+12=0?x^3-\frac{3}{2}x + \frac{1}{2} = 0?\tag*{} This equation has not one but three roots, as can be seen from this plot:How would we go about finding the roots? Let's do what we have done before: u3+v3=−12,u3v3=18.u3+v3=−12,u3v3=18.\begin{align*}u^3+v^3&{}=-\tfrac{1}{2},\\u^3v^3&{}=\tfrac{1}{8}.\end{align*}\tag*{} Again using v3=−12−u3,v3=−12−u3,v^3=-\frac{1}{2}-u^3, we get (u3)2+12u3+18=0.(u3)2+12u3+18=0.(u^3)^2+\frac{1}{2}u^3+\frac{1}{8} = 0.\tag*{} We know how to solve quadratic equations. But when we try to solve this particular equation, we run into a problem: u3=−14±√−14.u3=−14±−14.u^3 = -\dfrac{1}{4} \pm \dfrac{\sqrt{-1}}{4}.\tag*{} There you have it. The square root of −1.−1.-1. Does this mean the cubic has no solution? Of course not. It has three easily checkable solutions. But the formal process to find these solutions necessarily involves manipulating square roots of negative numbers halfway through, as we solve the intermediate quadratic equation. Never mind that in the end the result is real. The square roots of negative numbers cannot be avoided. Mathematicians like Cardano were not happy about this. Here's something frequently quoted from Cardano himself: ""thus far does arithmetical subtlety go, of which this, the extreme, is, as I have said, so subtle that it is useless"". But as it turns out, complex numbers are far from useless. Complex numbers are used not just in mathematics but also extensively in physics and engineering. Whether it is a radio engineer studying signal propagation or an engineer designing the optics for the camera of your new phone, they'd be using complex numbers every day.If you find my posts useful, please consider supporting my efforts.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/sajdq6zy5rv4uwmt', 'title': 'Why did mathematicians literally invent imaginary numbers instead of admitting that their theories could be wrong?', 'score': {'original': 0.2734, 'ai': 0.7266}, 'blocks': [{'text': 'Consider the following simple cubic equation: x3+6x−7=0.x3+6x−7=0.x^3 + 6x - 7 = 0.\\tag*{} This equation has a single root at x=1,x=1,x=1, which can be seen simply by plotting the equation on graph paper:And indeed, it is not hard to see that x3+6x−7=(x−1)(x2+x+7),x3+6x−7=(x−1)(x2+x+7),x^3+6x-7 = (x-1)(x^2+x+7), and this expression is obviously 000 when x=1.x=1.x=1. How would we go about finding this root in some formal process? The general solution was discovered by Tartaglia and published by Cardano. In modern notation, the idea relates to the identity (u+v)3=u3+v3+3uv(u+v),(u+v)3=u3+v3+3uv(u+v),(u+v)^3=u^3 + v^3 + 3uv(u+v), which we can rewrite as (u+v)3−3uv(u+v)−(u3+v3)=0.(u+v)3−3uv(u+v)−(u3+v3)=0.(u+v)^3 - 3uv(u+v) - (u^3+v^3) = 0.\\tag*{} Notice how similar the structure of this expression is to the cubic equation that I wrote down above. So if x=u+v,x=u+v,x = u+v, then −3uv=6−3uv=6-3uv = 6 and (u3+v3)=7.(u3+v3)=7.(u^3+v^3)=7. But if −3uv=6−3uv=6-3uv = 6 then u3v3=−8.u3v3=−8.u^3v^3 = -8. So we have two equations in the two unknowns u3u3u^3 and v3:v3:v^3: u3+v3=7,u3v3=−8.u3+v3=7,u3v3=−8.\\begin{align*}u^3+v^3&{}=7,\\\\u^3v^3&{}=-8.\\end{align*}\\tag*{} This can be solved! Using v3=7−u3v3=7−u3v^3=7-u^3 from the first equation in the second equation, we get (u3)2−7u3+8=0.(u3)2−7u3+8=0.(u^3)^2 - 7u^3 + 8 = 0.\\tag*{} This is a simple quadratic equation in u3,u3,u^3, the solutions of which are well known: u3=72±√494+8=72±92.u3=72±494+8=72±92.u^3 = \\dfrac{7}{2} \\pm \\sqrt{\\dfrac{49}{4}+8} = \\dfrac{7}{2}\\pm\\dfrac{9}{2}.\\tag*{} so v3=72∓92.v3=72∓92.v^3 = \\dfrac{7}{2}\\mp \\dfrac{9}{2}.\\tag*{} So between u3u3u^3 and v3,v3,v^3, one is 8,8,8, the other is −1−1-1 (they are interchangeable). So say, u=2,u=2,u=2, v=−1,v=−1,v=-1, and that means that x=u+v=1,x=u+v=1,x = u+v = 1, which is indeed the solution. So all this works beautifully. But then, how about the equation x3−32x+12=0?x3−32x+12=0?x^3-\\frac{3}{2}x + \\frac{1}{2} = 0?\\tag*{} This equation has not one but three roots, as can be seen from this plot:How would we go about finding the roots? Let\'s do what we have done before: u3+v3=−12,u3v3=18.u3+v3=−12,u3v3=18.\\begin{align*}u^3+v^3&{}=-\\tfrac{1}{2},\\\\u^3v^3&{}=\\tfrac{1}{8}.\\end{align*}\\tag*{} Again using v3=−12−u3,v3=−12−u3,v^3=-\\frac{1}{2}-u^3, we get (u3)2+12u3+18=0.(u3)2+12u3+18=0.(u^3)^2+\\frac{1}{2}u^3+\\frac{1}{8} = 0.\\tag*{} We know how to solve quadratic equations. But when we try to solve this particular equation, we run into a problem: u3=−14±√−14.u3=−14±−14.u^3 = -\\dfrac{1}{4} \\pm \\dfrac{\\sqrt{-1}}{4}.\\tag*{} There you have it. The square root of −1.−1.-1. Does this mean the cubic has no solution? Of course not. It has three easily checkable solutions. But the formal process to find these solutions necessarily involves manipulating square roots of negative numbers halfway through, as we solve the intermediate quadratic equation. Never mind that in the end the result is real. The square roots of negative numbers cannot be avoided. Mathematicians like Cardano were not happy about this. Here\'s something frequently quoted from Cardano himself: ""thus far does arithmetical subtlety go, of which this, the extreme, is, as I have said, so subtle that it is useless"". But as it turns out, complex numbers are far from useless. Complex numbers are used not just in mathematics but also extensively in physics and engineering. Whether it is a radio engineer studying signal propagation or an engineer designing the optics for the camera of your new phone, they\'d be using complex numbers every day.If you find my posts useful, please consider supporting my efforts.', 'result': {'fake': 0.6476, 'real': 0.3524}, 'status': 'success'}], 'credits_used': 7, 'credits': 1994852, 'subscription': 0, 'content': 'Consider the following simple cubic equation: x3+6x−7=0.x3+6x−7=0.x^3 + 6x - 7 = 0.\\tag*{} This equation has a single root at x=1,x=1,x=1, which can be seen simply by plotting the equation on graph paper:And indeed, it is not hard to see that x3+6x−7=(x−1)(x2+x+7),x3+6x−7=(x−1)(x2+x+7),x^3+6x-7 = (x-1)(x^2+x+7), and this expression is obviously 000 when x=1.x=1.x=1. How would we go about finding this root in some formal process? The general solution was discovered by Tartaglia and published by Cardano. In modern notation, the idea relates to the identity (u+v)3=u3+v3+3uv(u+v),(u+v)3=u3+v3+3uv(u+v),(u+v)^3=u^3 + v^3 + 3uv(u+v), which we can rewrite as (u+v)3−3uv(u+v)−(u3+v3)=0.(u+v)3−3uv(u+v)−(u3+v3)=0.(u+v)^3 - 3uv(u+v) - (u^3+v^3) = 0.\\tag*{} Notice how similar the structure of this expression is to the cubic equation that I wrote down above. So if x=u+v,x=u+v,x = u+v, then −3uv=6−3uv=6-3uv = 6 and (u3+v3)=7.(u3+v3)=7.(u^3+v^3)=7. But if −3uv=6−3uv=6-3uv = 6 then u3v3=−8.u3v3=−8.u^3v^3 = -8. So we have two equations in the two unknowns u3u3u^3 and v3:v3:v^3: u3+v3=7,u3v3=−8.u3+v3=7,u3v3=−8.\\begin{align*}u^3+v^3&{}=7,\\\\u^3v^3&{}=-8.\\end{align*}\\tag*{} This can be solved! Using v3=7−u3v3=7−u3v^3=7-u^3 from the first equation in the second equation, we get (u3)2−7u3+8=0.(u3)2−7u3+8=0.(u^3)^2 - 7u^3 + 8 = 0.\\tag*{} This is a simple quadratic equation in u3,u3,u^3, the solutions of which are well known: u3=72±√494+8=72±92.u3=72±494+8=72±92.u^3 = \\dfrac{7}{2} \\pm \\sqrt{\\dfrac{49}{4}+8} = \\dfrac{7}{2}\\pm\\dfrac{9}{2}.\\tag*{} so v3=72∓92.v3=72∓92.v^3 = \\dfrac{7}{2}\\mp \\dfrac{9}{2}.\\tag*{} So between u3u3u^3 and v3,v3,v^3, one is 8,8,8, the other is −1−1-1 (they are interchangeable). So say, u=2,u=2,u=2, v=−1,v=−1,v=-1, and that means that x=u+v=1,x=u+v=1,x = u+v = 1, which is indeed the solution. So all this works beautifully. But then, how about the equation x3−32x+12=0?x3−32x+12=0?x^3-\\frac{3}{2}x + \\frac{1}{2} = 0?\\tag*{} This equation has not one but three roots, as can be seen from this plot:How would we go about finding the roots? Let\'s do what we have done before: u3+v3=−12,u3v3=18.u3+v3=−12,u3v3=18.\\begin{align*}u^3+v^3&{}=-\\tfrac{1}{2},\\\\u^3v^3&{}=\\tfrac{1}{8}.\\end{align*}\\tag*{} Again using v3=−12−u3,v3=−12−u3,v^3=-\\frac{1}{2}-u^3, we get (u3)2+12u3+18=0.(u3)2+12u3+18=0.(u^3)^2+\\frac{1}{2}u^3+\\frac{1}{8} = 0.\\tag*{} We know how to solve quadratic equations. But when we try to solve this particular equation, we run into a problem: u3=−14±√−14.u3=−14±−14.u^3 = -\\dfrac{1}{4} \\pm \\dfrac{\\sqrt{-1}}{4}.\\tag*{} There you have it. The square root of −1.−1.-1. Does this mean the cubic has no solution? Of course not. It has three easily checkable solutions. But the formal process to find these solutions necessarily involves manipulating square roots of negative numbers halfway through, as we solve the intermediate quadratic equation. Never mind that in the end the result is real. The square roots of negative numbers cannot be avoided. Mathematicians like Cardano were not happy about this. Here\'s something frequently quoted from Cardano himself: ""thus far does arithmetical subtlety go, of which this, the extreme, is, as I have said, so subtle that it is useless"". But as it turns out, complex numbers are far from useless. Complex numbers are used not just in mathematics but also extensively in physics and engineering. Whether it is a radio engineer studying signal propagation or an engineer designing the optics for the camera of your new phone, they\'d be using complex numbers every day.If you find my posts useful, please consider supporting my efforts.', 'aiModelVersion': '1'}",0.2734
Vatsal Limbachia,Updated 5y,In what branch of mathematics did Maryam Mirzakhani become so outstanding? What progress in mathematics did she make?,"Hyperbolic and Symplectic geometry

Her PhD concerned the Riemann surfaces. Picture a surface with several holes in it, like that of a pretzel or two doughnuts stuck together, and then imagine trying to wrap a rubber band around the surface without it overlapping itself. Mirzakhani wanted to work out how many different ways this can be done for a rubber band of a given length.

She realized that she could flip the method. Instead of fixing a surface and counting the number of curves, she could find the average of all such numbers corresponding to points in the 'moduli space' of Riemann surfaces: a 'space', or set, of points, each of which represents one of the shapes a surface can take. Computing such an average requires one to calculate the 'volume', or size, of the space of Riemann surfaces that contain a curve of a certain length. A clever recursive formula for the volumes of various moduli spaces solved the problem. The solution had several stunning ramifications in seemingly distant fields. For example, it offered a new proof of a famous theorem by the Russian–French mathematician Maxim Kontsevich, which had implications in quantum field theory.

In later work, Mirzakhani studied the dynamics of a billiard ball, or point mass, moving in a polygon. A ball moves in a straight line until it hits the edge of the polygon; then it bounces back at the same angle at which it hit. A mathematician could ask several questions about such a system. For instance, is it possible for a ball to move inside a given polygon in such a way that the path it takes is eventually repeated — and, if so, how many such paths are there, and what do they look like? The problem of whether a repeating path exists for a general polygon is still unsolved.

In some cases, it is helpful to embed the space of certain billiard tables in a larger space in which every point is a surface that is locally either flat or cone-shaped. With Alex Eskin, a mathematician at the University of Chicago in Illinois, Mirzakhani used this method to prove, for such spaces, a version of a theorem about a group of symmetric geometric objects known as Lie groups. The theorem was proposed by Marina Ratner, another leading mathematician in the field who also died in July, aged 78. The proof — a monumental work written up in a 200-page paper (A. Eskin and M. Mirzakhani Preprint at https://arxiv.org/abs/1302.3320
; 2013) — tied together disparate fields including geometry, topology and dynamical systems, and spawned a field of its own. It has been dubbed the 'magic wand' theorem because it enabled many previously intractable mathematical problems to be solved.

Despite the fame and attention she received, Mirzakhani remained humble and grounded, always avoiding the spotlight. She listened to the work of other mathematicians with excitement and asked forward-looking questions that hinted at possible new directions. At conferences, she could be found talking with graduate students and Fields medalists alike. She generously shared her ideas with the community and helped others to further their careers.

Edit: Here’s a video by Seoul ICM","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/810w6ahv2g4i7lbf', 'title': 'In what branch of mathematics did Maryam Mirzakhani become so outstanding? What progress in mathematics did she make?', 'score': {'original': 0.31275, 'ai': 0.68725}, 'blocks': [{'text': ""Hyperbolic and Symplectic geometry\n\nHer PhD concerned the Riemann surfaces. Picture a surface with several holes in it, like that of a pretzel or two doughnuts stuck together, and then imagine trying to wrap a rubber band around the surface without it overlapping itself. Mirzakhani wanted to work out how many different ways this can be done for a rubber band of a given length.\n\nShe realized that she could flip the method. Instead of fixing a surface and counting the number of curves, she could find the average of all such numbers corresponding to points in the 'moduli space' of Riemann surfaces: a 'space', or set, of points, each of which represents one of the shapes a surface can take. Computing such an average requires one to calculate the 'volume', or size, of the space of Riemann surfaces that contain a curve of a certain length. A clever recursive formula for the volumes of various moduli spaces solved the problem. The solution had several stunning ramifications in seemingly distant fields. For example, it offered a new proof of a famous theorem by the Russian–French mathematician Maxim Kontsevich, which had implications in quantum field theory.\n\nIn later work, Mirzakhani studied the dynamics of a billiard ball, or point mass, moving in a polygon. A ball moves in a straight line until it hits the edge of the polygon; then it bounces back at the same angle at which it hit. A mathematician could ask several questions about such a system. For instance, is it possible for a ball to move inside a given polygon in such a way that the path it takes is eventually repeated — and, if so, how many such paths are there, and what do they look like? The problem of whether a repeating path exists for a general polygon is still unsolved.\n\nIn some cases, it is helpful to embed the space of certain billiard tables in a larger space in which every point is a surface that is locally either flat or cone-shaped. With Alex Eskin, a mathematician at the University of Chicago in Illinois, Mirzakhani used this method to prove, for such spaces, a version of a theorem about a group of symmetric geometric objects known as Lie groups. The theorem was proposed by Marina Ratner, another leading mathematician in the field who also died in July, aged 78. The proof — a monumental work written up in a 200-page paper (A. Eskin and M. Mirzakhani Preprint at https://arxiv.org/abs/1302.3320\n; 2013) — tied together disparate fields including geometry, topology and dynamical systems, and spawned a field of its own. It has been dubbed the 'magic wand' theorem because it enabled many previously intractable mathematical problems to be solved.\n\nDespite the fame and attention she received, Mirzakhani remained humble and grounded, always avoiding the spotlight. She listened to the work of other mathematicians with excitement and asked forward-looking questions that hinted at possible new directions. At conferences, she could be found talking with graduate students and Fields medalists alike. She generously shared her ideas with the community and helped others to further"", 'result': {'fake': 0.2211, 'real': 0.7789}, 'status': 'success'}, {'text': 'their careers.\n\nEdit: Here’s a video by Seoul ICM', 'result': {'fake': 0.9997, 'real': 0.0003}, 'status': 'success'}], 'credits_used': 6, 'credits': 1994846, 'subscription': 0, 'content': ""Hyperbolic and Symplectic geometry\n\nHer PhD concerned the Riemann surfaces. Picture a surface with several holes in it, like that of a pretzel or two doughnuts stuck together, and then imagine trying to wrap a rubber band around the surface without it overlapping itself. Mirzakhani wanted to work out how many different ways this can be done for a rubber band of a given length.\n\nShe realized that she could flip the method. Instead of fixing a surface and counting the number of curves, she could find the average of all such numbers corresponding to points in the 'moduli space' of Riemann surfaces: a 'space', or set, of points, each of which represents one of the shapes a surface can take. Computing such an average requires one to calculate the 'volume', or size, of the space of Riemann surfaces that contain a curve of a certain length. A clever recursive formula for the volumes of various moduli spaces solved the problem. The solution had several stunning ramifications in seemingly distant fields. For example, it offered a new proof of a famous theorem by the Russian–French mathematician Maxim Kontsevich, which had implications in quantum field theory.\n\nIn later work, Mirzakhani studied the dynamics of a billiard ball, or point mass, moving in a polygon. A ball moves in a straight line until it hits the edge of the polygon; then it bounces back at the same angle at which it hit. A mathematician could ask several questions about such a system. For instance, is it possible for a ball to move inside a given polygon in such a way that the path it takes is eventually repeated — and, if so, how many such paths are there, and what do they look like? The problem of whether a repeating path exists for a general polygon is still unsolved.\n\nIn some cases, it is helpful to embed the space of certain billiard tables in a larger space in which every point is a surface that is locally either flat or cone-shaped. With Alex Eskin, a mathematician at the University of Chicago in Illinois, Mirzakhani used this method to prove, for such spaces, a version of a theorem about a group of symmetric geometric objects known as Lie groups. The theorem was proposed by Marina Ratner, another leading mathematician in the field who also died in July, aged 78. The proof — a monumental work written up in a 200-page paper (A. Eskin and M. Mirzakhani Preprint at https://arxiv.org/abs/1302.3320\n; 2013) — tied together disparate fields including geometry, topology and dynamical systems, and spawned a field of its own. It has been dubbed the 'magic wand' theorem because it enabled many previously intractable mathematical problems to be solved.\n\nDespite the fame and attention she received, Mirzakhani remained humble and grounded, always avoiding the spotlight. She listened to the work of other mathematicians with excitement and asked forward-looking questions that hinted at possible new directions. At conferences, she could be found talking with graduate students and Fields medalists alike. She generously shared her ideas with the community and helped others to further their careers.\n\nEdit: Here’s a video by Seoul ICM"", 'aiModelVersion': '1'}",0.31275
Senia Sheydvasser,1y,"Is mathematics colonised, and how do you decolonise it?","It would be easy to dismissively answer “no” and move on.

This isn’t a position without merit: the concept of mathematical proof ought to be objective. It shouldn’t matter if some result was proved in France, or Australia, or Tanzania—it’s either true or it's not. In this sense, there should not be such a thing as a “French mathematics” or a “Tanzanian mathematics”, but merely mathematics, and so it wouldn’t appear for it to be possible for mathematics to be colonized or not colonized. Unlike fashion or religion, you cannot exactly replace one version with a different foreign version.

But I think that the reality is a little more complicated, because aside from mathematics as a study in and of itself, there is also the history of mathematics which is usually taught alongside it. And while I would not use the term “colonized” to describe how the history of mathematics is taught (in large part because it is simply too vague and nebulous), I think it is undeniable that some of the contributions of non-European mathematicians have been downplayed—often unintentionally.

Let me offer an example. You might be familiar with Fibonacci numbers, which are named after the Italian mathematician Leonardo of Pisa. He was the first European to popularize them—he wrote a book in 1202 in which he used them to compute the growth of rabbit populations. However, Leonardo was not the first to discover them: the Fibonacci numbers appeared in Indian mathematics at least five hundred years prior (they appear quite clearly in the writings of Virahanka), but may well have been known to Pingala, some 1500 years before Leonardo. But since Indian writings were not known in Europe, Fibonacci’s name was attached to the sequence instead, and so it has remained.

This is part of a larger historical trend of naming mathematical discoveries not after whoever was the first to find them, but after whoever was the first to popularize them in Europe. Another example: the Pell equation was studied in both ancient India and ancient Greece. Who was the first person to discover methods of solving it is probably not a question that we will ever be able to answer with total certainty, but we can say that it was definitely not John Pell.

John Pell was an English mathematician who, in 1668, revised a translation of a Swiss book that described William Brouncker’s solution to the Pell equation. (William Brouncker was an Irish mathematician.) Leonard Euler read this book, became interested in the problem, and wrote to other mathematicians about it. Unfortunately, he mistakenly thought that Pell was the one who came up with the solution, and so he referred to it as Pell’s equation. It would have been much more appropriate to name the equation after Brouncker, or Fermat (who posed solving it as a challenge to European mathematicians), or some earlier Indian or Greek mathematician. But, unfortunately, the name stuck, even though Pell really didn’t have anything to do with it at all.

There are legions of examples like this, and there is a commonality to them: because discoveries were named after those that European mathematicians were familiar with, this meant that the contributions of non-European cultures were not well represented—as mentioned above, even Greek contributions were partially neglected. This was primarily out of ignorance and not malice, but it has contributed to the appearance that other cultures did not aid mathematical development. This is not true: mathematics as it began to flourish in Europe during the Renaissance would not have been possible without the efforts of Greek, Indian, and Arabic mathematicians. Other ancient civilizations were more mathematically sophisticated than we sometimes give them credit for, as well.

In terms of how we combat this? There have been some efforts to try to rename the Fibonacci numbers and the Pell equation and some others. They have largely been unsuccessful—once something has been named, it is almost impossible to un-name it. The best that we can do, I think, is to teach the full history and acknowledge mathematics as our shared birthright, open for all mankind.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/q6rp9hin1bvoue8a', 'title': 'Is mathematics colonised, and how do you decolonise it?', 'score': {'original': 0.68355, 'ai': 0.31645}, 'blocks': [{'text': ""It would be easy to dismissively answer “no” and move on.\n\nThis isn’t a position without merit: the concept of mathematical proof ought to be objective. It shouldn’t matter if some result was proved in France, or Australia, or Tanzania—it’s either true or it's not. In this sense, there should not be such a thing as a “French mathematics” or a “Tanzanian mathematics”, but merely mathematics, and so it wouldn’t appear for it to be possible for mathematics to be colonized or not colonized. Unlike fashion or religion, you cannot exactly replace one version with a different foreign version.\n\nBut I think that the reality is a little more complicated, because aside from mathematics as a study in and of itself, there is also the history of mathematics which is usually taught alongside it. And while I would not use the term “colonized” to describe how the history of mathematics is taught (in large part because it is simply too vague and nebulous), I think it is undeniable that some of the contributions of non-European mathematicians have been downplayed—often unintentionally.\n\nLet me offer an example. You might be familiar with Fibonacci numbers, which are named after the Italian mathematician Leonardo of Pisa. He was the first European to popularize them—he wrote a book in 1202 in which he used them to compute the growth of rabbit populations. However, Leonardo was not the first to discover them: the Fibonacci numbers appeared in Indian mathematics at least five hundred years prior (they appear quite clearly in the writings of Virahanka), but may well have been known to Pingala, some 1500 years before Leonardo. But since Indian writings were not known in Europe, Fibonacci’s name was attached to the sequence instead, and so it has remained.\n\nThis is part of a larger historical trend of naming mathematical discoveries not after whoever was the first to find them, but after whoever was the first to popularize them in Europe. Another example: the Pell equation was studied in both ancient India and ancient Greece. Who was the first person to discover methods of solving it is probably not a question that we will ever be able to answer with total certainty, but we can say that it was definitely not John Pell.\n\nJohn Pell was an English mathematician who, in 1668, revised a translation of a Swiss book that described William Brouncker’s solution to the Pell equation. (William Brouncker was an Irish mathematician.) Leonard Euler read this book, became interested in the problem, and wrote to other mathematicians about it. Unfortunately, he mistakenly thought that Pell was the one who came up with the solution, and so he referred to it as Pell’s equation. It would have been much more appropriate to name the equation after Brouncker, or Fermat (who posed solving it as a challenge to European mathematicians), or some earlier Indian or Greek mathematician. But, unfortunately, the name stuck, even though Pell really didn’t have anything to do with it at all.\n\nThere are legions of examples like this, and there is a commonality to them: because discoveries were named after"", 'result': {'fake': 0.0029, 'real': 0.9971}, 'status': 'success'}, {'text': 'those that European mathematicians were familiar with, this meant that the contributions of non-European cultures were not well represented—as mentioned above, even Greek contributions were partially neglected. This was primarily out of ignorance and not malice, but it has contributed to the appearance that other cultures did not aid mathematical development. This is not true: mathematics as it began to flourish in Europe during the Renaissance would not have been possible without the efforts of Greek, Indian, and Arabic mathematicians. Other ancient civilizations were more mathematically sophisticated than we sometimes give them credit for, as well.\n\nIn terms of how we combat this? There have been some efforts to try to rename the Fibonacci numbers and the Pell equation and some others. They have largely been unsuccessful—once something has been named, it is almost impossible to un-name it. The best that we can do, I think, is to teach the full history and acknowledge mathematics as our shared birthright, open for all mankind.', 'result': {'fake': 0.9602, 'real': 0.0398}, 'status': 'success'}], 'credits_used': 7, 'credits': 1994839, 'subscription': 0, 'content': ""It would be easy to dismissively answer “no” and move on.\n\nThis isn’t a position without merit: the concept of mathematical proof ought to be objective. It shouldn’t matter if some result was proved in France, or Australia, or Tanzania—it’s either true or it's not. In this sense, there should not be such a thing as a “French mathematics” or a “Tanzanian mathematics”, but merely mathematics, and so it wouldn’t appear for it to be possible for mathematics to be colonized or not colonized. Unlike fashion or religion, you cannot exactly replace one version with a different foreign version.\n\nBut I think that the reality is a little more complicated, because aside from mathematics as a study in and of itself, there is also the history of mathematics which is usually taught alongside it. And while I would not use the term “colonized” to describe how the history of mathematics is taught (in large part because it is simply too vague and nebulous), I think it is undeniable that some of the contributions of non-European mathematicians have been downplayed—often unintentionally.\n\nLet me offer an example. You might be familiar with Fibonacci numbers, which are named after the Italian mathematician Leonardo of Pisa. He was the first European to popularize them—he wrote a book in 1202 in which he used them to compute the growth of rabbit populations. However, Leonardo was not the first to discover them: the Fibonacci numbers appeared in Indian mathematics at least five hundred years prior (they appear quite clearly in the writings of Virahanka), but may well have been known to Pingala, some 1500 years before Leonardo. But since Indian writings were not known in Europe, Fibonacci’s name was attached to the sequence instead, and so it has remained.\n\nThis is part of a larger historical trend of naming mathematical discoveries not after whoever was the first to find them, but after whoever was the first to popularize them in Europe. Another example: the Pell equation was studied in both ancient India and ancient Greece. Who was the first person to discover methods of solving it is probably not a question that we will ever be able to answer with total certainty, but we can say that it was definitely not John Pell.\n\nJohn Pell was an English mathematician who, in 1668, revised a translation of a Swiss book that described William Brouncker’s solution to the Pell equation. (William Brouncker was an Irish mathematician.) Leonard Euler read this book, became interested in the problem, and wrote to other mathematicians about it. Unfortunately, he mistakenly thought that Pell was the one who came up with the solution, and so he referred to it as Pell’s equation. It would have been much more appropriate to name the equation after Brouncker, or Fermat (who posed solving it as a challenge to European mathematicians), or some earlier Indian or Greek mathematician. But, unfortunately, the name stuck, even though Pell really didn’t have anything to do with it at all.\n\nThere are legions of examples like this, and there is a commonality to them: because discoveries were named after those that European mathematicians were familiar with, this meant that the contributions of non-European cultures were not well represented—as mentioned above, even Greek contributions were partially neglected. This was primarily out of ignorance and not malice, but it has contributed to the appearance that other cultures did not aid mathematical development. This is not true: mathematics as it began to flourish in Europe during the Renaissance would not have been possible without the efforts of Greek, Indian, and Arabic mathematicians. Other ancient civilizations were more mathematically sophisticated than we sometimes give them credit for, as well.\n\nIn terms of how we combat this? There have been some efforts to try to rename the Fibonacci numbers and the Pell equation and some others. They have largely been unsuccessful—once something has been named, it is almost impossible to un-name it. The best that we can do, I think, is to teach the full history and acknowledge mathematics as our shared birthright, open for all mankind."", 'aiModelVersion': '1'}",0.68355
David Joyce,1y,How did Pythagoras come up with the Pythagorean theorem?,"Pythagoras didn’t come up with the Pythagorean theorem, and he might not have known any proof of it. It was later called the Pythagorean theorem in honor of him whether or not he came up with it or proved it.

The ancient stories about Pythagoras and his contemporaries include travels to other places including Egypt and the Middle East. The “Pythagorean theorem” was known in Babylonia over a thousand years before Pythagoras and was probably common knowledge throughout that part of the world.

Pythagoras, who was interested in geometry and number theory, learned it as anyone else would have with those interests would have learned it in the Mediterranean region.

He may have known a proof of it, or perhaps he didn’t. There’s no record that he did. Certainly by the time of Euclid, about 250 years later, there were proofs of it. Euclid included two proofs, one that didn’t use the concept of similarity and one that did. The similarity proof was probably known much earlier, but the other one, Proposition I.47, may have been Euclid’s own. Euclid gives no clue where the proof came from as he didn’t give his propositions names. In fact, the Elements included no history and mentioned no one at all. It was a citation-free work.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/aid9xhw4g7myn3z6', 'title': 'How did Pythagoras come up with the Pythagorean theorem?', 'score': {'original': 0.9986, 'ai': 0.0014}, 'blocks': [{'text': 'Pythagoras didn’t come up with the Pythagorean theorem, and he might not have known any proof of it. It was later called the Pythagorean theorem in honor of him whether or not he came up with it or proved it.\n\nThe ancient stories about Pythagoras and his contemporaries include travels to other places including Egypt and the Middle East. The “Pythagorean theorem” was known in Babylonia over a thousand years before Pythagoras and was probably common knowledge throughout that part of the world.\n\nPythagoras, who was interested in geometry and number theory, learned it as anyone else would have with those interests would have learned it in the Mediterranean region.\n\nHe may have known a proof of it, or perhaps he didn’t. There’s no record that he did. Certainly by the time of Euclid, about 250 years later, there were proofs of it. Euclid included two proofs, one that didn’t use the concept of similarity and one that did. The similarity proof was probably known much earlier, but the other one, Proposition I.47, may have been Euclid’s own. Euclid gives no clue where the proof came from as he didn’t give his propositions names. In fact, the Elements included no history and mentioned no one at all. It was a citation-free work.', 'result': {'fake': 0.0014, 'real': 0.9986}, 'status': 'success'}], 'credits_used': 3, 'credits': 1994836, 'subscription': 0, 'content': 'Pythagoras didn’t come up with the Pythagorean theorem, and he might not have known any proof of it. It was later called the Pythagorean theorem in honor of him whether or not he came up with it or proved it.\n\nThe ancient stories about Pythagoras and his contemporaries include travels to other places including Egypt and the Middle East. The “Pythagorean theorem” was known in Babylonia over a thousand years before Pythagoras and was probably common knowledge throughout that part of the world.\n\nPythagoras, who was interested in geometry and number theory, learned it as anyone else would have with those interests would have learned it in the Mediterranean region.\n\nHe may have known a proof of it, or perhaps he didn’t. There’s no record that he did. Certainly by the time of Euclid, about 250 years later, there were proofs of it. Euclid included two proofs, one that didn’t use the concept of similarity and one that did. The similarity proof was probably known much earlier, but the other one, Proposition I.47, may have been Euclid’s own. Euclid gives no clue where the proof came from as he didn’t give his propositions names. In fact, the Elements included no history and mentioned no one at all. It was a citation-free work.', 'aiModelVersion': '1'}",0.9986
David Joyce,1y,"How is it possible that, for example, Leibniz and Newton discovered calculus simultaneously? Does it mean that these concepts have an ontological existence?","Leibniz and Newton were fortunate to have lived in a time when many of the theorems that we now call part of calculus were already proved. In the 1300s the question of changing velocities was studied, and Oresme even showed that if you graph the changing velocities, then the area under the graph was the total change in the quantity. That’s now called the fundamental theorem of calculus. In the 1600s Fermat had a method for finding derivatives. He also integrated 
x
n
xn
 when the exponent 
n
n
 was a rational number other than 
−
1.
−1.
 Others integrated 
x
−
1
.
x−1.

One wonders what Leibniz and Newton did when so much of what we call calculus was known before them. They did find some new things such as the product and chain rule for derivatives. Their important contribution was putting these things together to form a cohesive subject and using that to formulate a way to ask related questions and solve them.

They “discovered” calculus because mathematical analysis was such an active field of research at the time. That was the time for it since Descartes and Fermat in the earlier 1600s developed analytic geometry (i.e., coordinate geometry) which gave a way to use algebra to help solve questions in geometry and mathematical analysis.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/suop81dg7af5im9k', 'title': 'How is it possible that, for example, Leibniz and Newton discovered calculus simultaneously? Does it mean that these concepts have an ontological existence?', 'score': {'original': 0.9803, 'ai': 0.0197}, 'blocks': [{'text': 'Leibniz and Newton were fortunate to have lived in a time when many of the theorems that we now call part of calculus were already proved. In the 1300s the question of changing velocities was studied, and Oresme even showed that if you graph the changing velocities, then the area under the graph was the total change in the quantity. That’s now called the fundamental theorem of calculus. In the 1600s Fermat had a method for finding derivatives. He also integrated \nx\nn\nxn\n when the exponent \nn\nn\n was a rational number other than \n−\n1.\n−1.\n Others integrated \nx\n−\n1\n.\nx−1.\n\nOne wonders what Leibniz and Newton did when so much of what we call calculus was known before them. They did find some new things such as the product and chain rule for derivatives. Their important contribution was putting these things together to form a cohesive subject and using that to formulate a way to ask related questions and solve them.\n\nThey “discovered” calculus because mathematical analysis was such an active field of research at the time. That was the time for it since Descartes and Fermat in the earlier 1600s developed analytic geometry (i.e., coordinate geometry) which gave a way to use algebra to help solve questions in geometry and mathematical analysis.', 'result': {'fake': 0.0197, 'real': 0.9803}, 'status': 'success'}], 'credits_used': 3, 'credits': 1994833, 'subscription': 0, 'content': 'Leibniz and Newton were fortunate to have lived in a time when many of the theorems that we now call part of calculus were already proved. In the 1300s the question of changing velocities was studied, and Oresme even showed that if you graph the changing velocities, then the area under the graph was the total change in the quantity. That’s now called the fundamental theorem of calculus. In the 1600s Fermat had a method for finding derivatives. He also integrated \nx\nn\nxn\n when the exponent \nn\nn\n was a rational number other than \n−\n1.\n−1.\n Others integrated \nx\n−\n1\n.\nx−1.\n\nOne wonders what Leibniz and Newton did when so much of what we call calculus was known before them. They did find some new things such as the product and chain rule for derivatives. Their important contribution was putting these things together to form a cohesive subject and using that to formulate a way to ask related questions and solve them.\n\nThey “discovered” calculus because mathematical analysis was such an active field of research at the time. That was the time for it since Descartes and Fermat in the earlier 1600s developed analytic geometry (i.e., coordinate geometry) which gave a way to use algebra to help solve questions in geometry and mathematical analysis.', 'aiModelVersion': '1'}",0.9803
William Hobba,9mo,Why did David Hilbert think that Albert Einstein was a poor mathematician?,"I dont think anybody thought Einstein a poor mathematician. He was quite competent. It just was not his strong point. HIs strength was as elucidated by Wigner:

“I have known a great many intelligent people in my life. I knew Max Planck, Max von Laue, and Wemer Heisenberg. Paul Dirac was my brother-in-Iaw; Leo Szilard and Edward Teller have been among my closest friends; and Albert Einstein was a good friend, too. And I have known many of the brightest younger scientists. But none of them had a mind as quick and acute as Jancsi von Neumann. I have often remarked this in the presence of those men, and no one ever disputed me. [...] But Einstein's understanding was deeper than even Jancsi von Neumann's. His mind was both more penetrating and more original than von Neumann's. And that is a very remarkable statement. Einstein took an extraordinary pleasure in invention. Two of his greatest inventions are the Special and General Theories of Relativity; and for all of Jancsi's brilliance, he never produced anything so original.”","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/4yr6tnzaudfw1v3q', 'title': 'Why did David Hilbert think that Albert Einstein was a poor mathematician?', 'score': {'original': 0.9994, 'ai': 0.0006}, 'blocks': [{'text': ""I dont think anybody thought Einstein a poor mathematician. He was quite competent. It just was not his strong point. HIs strength was as elucidated by Wigner:\n\n“I have known a great many intelligent people in my life. I knew Max Planck, Max von Laue, and Wemer Heisenberg. Paul Dirac was my brother-in-Iaw; Leo Szilard and Edward Teller have been among my closest friends; and Albert Einstein was a good friend, too. And I have known many of the brightest younger scientists. But none of them had a mind as quick and acute as Jancsi von Neumann. I have often remarked this in the presence of those men, and no one ever disputed me. [...] But Einstein's understanding was deeper than even Jancsi von Neumann's. His mind was both more penetrating and more original than von Neumann's. And that is a very remarkable statement. Einstein took an extraordinary pleasure in invention. Two of his greatest inventions are the Special and General Theories of Relativity; and for all of Jancsi's brilliance, he never produced anything so original.”"", 'result': {'fake': 0.0006, 'real': 0.9994}, 'status': 'success'}], 'credits_used': 2, 'credits': 1994831, 'subscription': 0, 'content': ""I dont think anybody thought Einstein a poor mathematician. He was quite competent. It just was not his strong point. HIs strength was as elucidated by Wigner:\n\n“I have known a great many intelligent people in my life. I knew Max Planck, Max von Laue, and Wemer Heisenberg. Paul Dirac was my brother-in-Iaw; Leo Szilard and Edward Teller have been among my closest friends; and Albert Einstein was a good friend, too. And I have known many of the brightest younger scientists. But none of them had a mind as quick and acute as Jancsi von Neumann. I have often remarked this in the presence of those men, and no one ever disputed me. [...] But Einstein's understanding was deeper than even Jancsi von Neumann's. His mind was both more penetrating and more original than von Neumann's. And that is a very remarkable statement. Einstein took an extraordinary pleasure in invention. Two of his greatest inventions are the Special and General Theories of Relativity; and for all of Jancsi's brilliance, he never produced anything so original.”"", 'aiModelVersion': '1'}",0.9994
Alon Amit,3y,How relevant do you think the contribution of the mathematician John Nash is?,"Relevant…? Relevant to what?

Nash made fundamental discoveries in two areas of mathematics: game theory and geometry. In game theory, he introduced the notion of non-cooperative games and proved the existence of equilibria in such games, now known as Nash equilibria. Later, he addressed other types of games, such as bargaining.

In geometry, Nash solved, in deep and unexpected ways, some of the most basic questions about the relationship between various models of geometry, such as the embeddability of Riemannian manifolds in Euclidean space and the approximation of smooth manifolds by algebraic varieties.

The two categories of his contributions are polar opposites. The game theoretic ones are mathematically relatively simple (his thesis[1] runs all of 28 pages), but have had a dramatic impact on applied disciplines such as economics and decision theory. The results in geometry are deeply sophisticated and intricate, but are quite far removed from applications outside of math.

John Milnor wrote:

Seen in this way, Nash’s prize work is an ingenious but not surprising application of well-known methods, while his subsequent mathematical work is far more rich and important.

(Notices of the AMS, 1998[2] ).

I don’t think it’s possible to imagine modern economic and decision theory without Nash’s fundamental models. Whether they are applied in sound ways or not is a different question, to which the obvious answer is “it depends”. Mathematical models of reality can be useful and they can be abused.

Similarly, his work in geometry far exceeds being “relevant”. It kicked off entire new fields and new perspectives. It brought about “A dramatic alteration of our understanding of the basic logic of analysis and differential geometry” as Misha Gromov, himself a giant of 20th century geometry, had said.

I wouldn’t waste time questioning the “relevance” of Nash’s work. I would spend much time studying his papers.

Footnotes

[1] https://library.princeton.edu/special-collections/sites/default/files/Non-Cooperative_Games_Nash.pdf
[2] http://www.ams.org/notices/199810/milnor.pdf","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/eycqfur0ho5t1jpx', 'title': 'How relevant do you think the contribution of the mathematician John Nash is?', 'score': {'original': 0.9998, 'ai': 0.0002}, 'blocks': [{'text': 'Relevant…? Relevant to what?\n\nNash made fundamental discoveries in two areas of mathematics: game theory and geometry. In game theory, he introduced the notion of non-cooperative games and proved the existence of equilibria in such games, now known as Nash equilibria. Later, he addressed other types of games, such as bargaining.\n\nIn geometry, Nash solved, in deep and unexpected ways, some of the most basic questions about the relationship between various models of geometry, such as the embeddability of Riemannian manifolds in Euclidean space and the approximation of smooth manifolds by algebraic varieties.\n\nThe two categories of his contributions are polar opposites. The game theoretic ones are mathematically relatively simple (his thesis[1] runs all of 28 pages), but have had a dramatic impact on applied disciplines such as economics and decision theory. The results in geometry are deeply sophisticated and intricate, but are quite far removed from applications outside of math.\n\nJohn Milnor wrote:\n\nSeen in this way, Nash’s prize work is an ingenious but not surprising application of well-known methods, while his subsequent mathematical work is far more rich and important.\n\n(Notices of the AMS, 1998[2] ).\n\nI don’t think it’s possible to imagine modern economic and decision theory without Nash’s fundamental models. Whether they are applied in sound ways or not is a different question, to which the obvious answer is “it depends”. Mathematical models of reality can be useful and they can be abused.\n\nSimilarly, his work in geometry far exceeds being “relevant”. It kicked off entire new fields and new perspectives. It brought about “A dramatic alteration of our understanding of the basic logic of analysis and differential geometry” as Misha Gromov, himself a giant of 20th century geometry, had said.\n\nI wouldn’t waste time questioning the “relevance” of Nash’s work. I would spend much time studying his papers.\n\nFootnotes\n\n[1] https://library.princeton.edu/special-collections/sites/default/files/Non-Cooperative_Games_Nash.pdf\n[2] http://www.ams.org/notices/199810/milnor.pdf', 'result': {'fake': 0.0002, 'real': 0.9998}, 'status': 'success'}], 'credits_used': 4, 'credits': 1994827, 'subscription': 0, 'content': 'Relevant…? Relevant to what?\n\nNash made fundamental discoveries in two areas of mathematics: game theory and geometry. In game theory, he introduced the notion of non-cooperative games and proved the existence of equilibria in such games, now known as Nash equilibria. Later, he addressed other types of games, such as bargaining.\n\nIn geometry, Nash solved, in deep and unexpected ways, some of the most basic questions about the relationship between various models of geometry, such as the embeddability of Riemannian manifolds in Euclidean space and the approximation of smooth manifolds by algebraic varieties.\n\nThe two categories of his contributions are polar opposites. The game theoretic ones are mathematically relatively simple (his thesis[1] runs all of 28 pages), but have had a dramatic impact on applied disciplines such as economics and decision theory. The results in geometry are deeply sophisticated and intricate, but are quite far removed from applications outside of math.\n\nJohn Milnor wrote:\n\nSeen in this way, Nash’s prize work is an ingenious but not surprising application of well-known methods, while his subsequent mathematical work is far more rich and important.\n\n(Notices of the AMS, 1998[2] ).\n\nI don’t think it’s possible to imagine modern economic and decision theory without Nash’s fundamental models. Whether they are applied in sound ways or not is a different question, to which the obvious answer is “it depends”. Mathematical models of reality can be useful and they can be abused.\n\nSimilarly, his work in geometry far exceeds being “relevant”. It kicked off entire new fields and new perspectives. It brought about “A dramatic alteration of our understanding of the basic logic of analysis and differential geometry” as Misha Gromov, himself a giant of 20th century geometry, had said.\n\nI wouldn’t waste time questioning the “relevance” of Nash’s work. I would spend much time studying his papers.\n\nFootnotes\n\n[1] https://library.princeton.edu/special-collections/sites/default/files/Non-Cooperative_Games_Nash.pdf\n[2] http://www.ams.org/notices/199810/milnor.pdf', 'aiModelVersion': '1'}",0.9998
Sayan Sarkar,5y,Who is the most mysterious man to have ever lived?,"This person definitely deserves to be on the list:

D.B. Cooper

Cooper was a quiet man who appeared to be in his mid-40s, wearing a business suit with a black tie and white shirt. He ordered a drink — bourbon and soda, while the flight was waiting to take off. A short time after 3:00 p.m., he handed the stewardess a note indicating that he had a bomb in his briefcase and wanted her to sit with him.

The stunned stewardess did as she was told. Opening a cheap attaché case, Cooper showed her a glimpse of a mass of wires and red colored sticks and demanded that she write down what he told her. Soon, she was walking a new note to the captain of the plane that demanded four parachutes and $200,000 in twenty-dollar bills.

When the flight landed in Seattle, the hijacker exchanged the flight’s 36 passengers for the money and parachutes. Cooper kept several crew members, and the plane took off again, ordered to set a course for Mexico City.

Somewhere between Seattle and Reno, a little after 8:00 p.m., the hijacker did the incredible: He jumped out of the back of the plane with a parachute and the ransom money.

The pilots landed safely, but Cooper had disappeared into the night and his ultimate fate remains a mystery to this day.

This is the supposed sketch of him by FBI.

Source:

IndyStar: Indianapolis Star, Indiana news, breaking news and sports

google images","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/fadrvzj85mgtwi4n', 'title': 'Who is the most mysterious man to have ever lived?', 'score': {'original': 0.9992, 'ai': 0.0008}, 'blocks': [{'text': 'This person definitely deserves to be on the list:\n\nD.B. Cooper\n\nCooper was a quiet man who appeared to be in his mid-40s, wearing a business suit with a black tie and white shirt. He ordered a drink — bourbon and soda, while the flight was waiting to take off. A short time after 3:00 p.m., he handed the stewardess a note indicating that he had a bomb in his briefcase and wanted her to sit with him.\n\nThe stunned stewardess did as she was told. Opening a cheap attaché case, Cooper showed her a glimpse of a mass of wires and red colored sticks and demanded that she write down what he told her. Soon, she was walking a new note to the captain of the plane that demanded four parachutes and $200,000 in twenty-dollar bills.\n\nWhen the flight landed in Seattle, the hijacker exchanged the flight’s 36 passengers for the money and parachutes. Cooper kept several crew members, and the plane took off again, ordered to set a course for Mexico City.\n\nSomewhere between Seattle and Reno, a little after 8:00 p.m., the hijacker did the incredible: He jumped out of the back of the plane with a parachute and the ransom money.\n\nThe pilots landed safely, but Cooper had disappeared into the night and his ultimate fate remains a mystery to this day.\n\nThis is the supposed sketch of him by FBI.\n\nSource:\n\nIndyStar: Indianapolis Star, Indiana news, breaking news and sports\n\ngoogle images', 'result': {'fake': 0.0008, 'real': 0.9992}, 'status': 'success'}], 'credits_used': 3, 'credits': 1994824, 'subscription': 0, 'content': 'This person definitely deserves to be on the list:\n\nD.B. Cooper\n\nCooper was a quiet man who appeared to be in his mid-40s, wearing a business suit with a black tie and white shirt. He ordered a drink — bourbon and soda, while the flight was waiting to take off. A short time after 3:00 p.m., he handed the stewardess a note indicating that he had a bomb in his briefcase and wanted her to sit with him.\n\nThe stunned stewardess did as she was told. Opening a cheap attaché case, Cooper showed her a glimpse of a mass of wires and red colored sticks and demanded that she write down what he told her. Soon, she was walking a new note to the captain of the plane that demanded four parachutes and $200,000 in twenty-dollar bills.\n\nWhen the flight landed in Seattle, the hijacker exchanged the flight’s 36 passengers for the money and parachutes. Cooper kept several crew members, and the plane took off again, ordered to set a course for Mexico City.\n\nSomewhere between Seattle and Reno, a little after 8:00 p.m., the hijacker did the incredible: He jumped out of the back of the plane with a parachute and the ransom money.\n\nThe pilots landed safely, but Cooper had disappeared into the night and his ultimate fate remains a mystery to this day.\n\nThis is the supposed sketch of him by FBI.\n\nSource:\n\nIndyStar: Indianapolis Star, Indiana news, breaking news and sports\n\ngoogle images', 'aiModelVersion': '1'}",0.9992
Alon Amit,4y,"When Andrew Wiles proved Fermat's Last Theorem, did you try to read his proof?","Huh? Of course! What warm-blooded creature wouldn’t?

Obviously, “read” is a massive overstatement. “Gawk” would be more appropriate, for me and – I suspect – many other noobs. All I could do is observe some aspects of the high-level structure of the proof, and marvel at just how close to nothing I know. Back then I knew much less than I know now, and what I know now is still minuscule.

Gawking at the two papers did increase my motivation to study elliptic curves and modular representations, which I did. But I still can’t “read” the papers. It’ll take years of additional study for me to able to do so.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/mkociu3naes8xjv7', 'title': ""When Andrew Wiles proved Fermat's Last Theorem, did you try to read his proof?"", 'score': {'original': 0.9993, 'ai': 0.0007}, 'blocks': [{'text': 'Huh? Of course! What warm-blooded creature wouldn’t?\n\nObviously, “read” is a massive overstatement. “Gawk” would be more appropriate, for me and – I suspect – many other noobs. All I could do is observe some aspects of the high-level structure of the proof, and marvel at just how close to nothing I know. Back then I knew much less than I know now, and what I know now is still minuscule.\n\nGawking at the two papers did increase my motivation to study elliptic curves and modular representations, which I did. But I still can’t “read” the papers. It’ll take years of additional study for me to able to do so.', 'result': {'fake': 0.0007, 'real': 0.9993}, 'status': 'success'}], 'credits_used': 2, 'credits': 1994822, 'subscription': 0, 'content': 'Huh? Of course! What warm-blooded creature wouldn’t?\n\nObviously, “read” is a massive overstatement. “Gawk” would be more appropriate, for me and – I suspect – many other noobs. All I could do is observe some aspects of the high-level structure of the proof, and marvel at just how close to nothing I know. Back then I knew much less than I know now, and what I know now is still minuscule.\n\nGawking at the two papers did increase my motivation to study elliptic curves and modular representations, which I did. But I still can’t “read” the papers. It’ll take years of additional study for me to able to do so.', 'aiModelVersion': '1'}",0.9993
Alex Eustis,1y,Who is the most original mathematician of all time and why?,Top 10 most original mathematicians: 10) There 9) is 8) no 7) possible 6) way 5) to 4) rank 3) order 2) mathematicians 1) Srinivasa Ramanujan,"{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/76jki20h4ldbypq3', 'title': 'Who is the most original mathematician of all time and why?', 'score': {'original': 0, 'ai': 1}, 'blocks': [{'text': 'Top 10 most original mathematicians: 10) There 9) is 8) no 7) possible 6) way 5) to 4) rank 3) order 2) mathematicians 1) Srinivasa Ramanujan', 'result': {'fake': 1, 'real': 0}, 'status': 'success'}], 'credits_used': 1, 'credits': 1994821, 'subscription': 0, 'content': 'Top 10 most original mathematicians: 10) There 9) is 8) no 7) possible 6) way 5) to 4) rank 3) order 2) mathematicians 1) Srinivasa Ramanujan', 'aiModelVersion': '1'}",0.0
Alex Eustis,10mo,Why did mathematicians literally invent imaginary numbers instead of admitting that their theories could be wrong?,"Why do people literally interpret the math terms “real” and “imaginary” literally instead of recognizing that they're math terms? You know, like “rational” or “quadratic”?

I mean, why not have a go at irrational numbers while you're at it, based on nothing but the name? Surely you see how risible that would be. “Well, I guess a unit square doesn't have a diagonal, because that would be irrational!” That's not an argument; it’s a silly play on words. A “Dad joke”.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/xkw3ou1e978dfz6t', 'title': 'Why did mathematicians literally invent imaginary numbers instead of admitting that their theories could be wrong?', 'score': {'original': 0.1336, 'ai': 0.8664}, 'blocks': [{'text': ""Why do people literally interpret the math terms “real” and “imaginary” literally instead of recognizing that they're math terms? You know, like “rational” or “quadratic”?\n\nI mean, why not have a go at irrational numbers while you're at it, based on nothing but the name? Surely you see how risible that would be. “Well, I guess a unit square doesn't have a diagonal, because that would be irrational!” That's not an argument; it’s a silly play on words. A “Dad joke”."", 'result': {'fake': 0.8664, 'real': 0.1336}, 'status': 'success'}], 'credits_used': 1, 'credits': 1994820, 'subscription': 0, 'content': ""Why do people literally interpret the math terms “real” and “imaginary” literally instead of recognizing that they're math terms? You know, like “rational” or “quadratic”?\n\nI mean, why not have a go at irrational numbers while you're at it, based on nothing but the name? Surely you see how risible that would be. “Well, I guess a unit square doesn't have a diagonal, because that would be irrational!” That's not an argument; it’s a silly play on words. A “Dad joke”."", 'aiModelVersion': '1'}",0.1336
Tim Dowling,7mo,Why did David Hilbert think that Albert Einstein was a poor mathematician?,"Before asking why ask if.

There is no evidence whatsoever that David Hilbert thought Albert Einstein was a poor mathematician. None.

Let’s start with Dave. David Hilbert was born in 1862. He was a founder of mathematical logic and believed that modern mathematical tools could eventually unify all of mathematics and provide it with a clear base of broad proveability. These tools particularly included set theory and something mainly invented by himself called Peano arithmetic.

He is usually listed as one of about twenty mathematicians who are the greatest ever.

His ambitions for unifying mathematics came crashing down in 1931, when Kurt Gödel published his incompleteness theorem, showing that even in quite simple arithmetical systems there are statements we know to be true that we cannot prove. This is usually regarded as one of the greatest intellectual achievements of last century.

Moving on to Albert. Albert Einstein was a much younger man. He was born in 1879. He was thoroughly exceptional as a student of mathematics from early childhood. He had mastered integral and differential calculus by the age of 15. At the age of 12 he discovered his own proof of the Pythagorean theorem. He had a personal tutor called Max Talmud who introduced him to such matters as geometry and Kantʼs philosophy, both of which he had explored in depth before reaching 14. Talmud had presented Einstein with an advanced geometry textbook and testifies that Einstein by age 13 “had worked through the whole book. He thereupon devoted himself to higher mathematics ... Soon the flight of his mathematical genius was so high I could not follow.”

However, even at such an early moment, it was clear that Einstein’s main inclination was for physics. Aged 12 he declared his conviction that nature could be understood as “a mathematical structure” and, still a teenager, he wrote an essay On the Investigation of the State of the Ether in a Magnetic Field. At the same age (16) he composed in an exercise book a Gedankenexperiment where he imagined riding through the universe alongside a beam of light.

He was allowed early entry to the Eidgenössische Polytechnische Schuler on the strength of exceptional math scores (he scored low at French, chemistry and biology). On leaving the polytechnic, he failed to pick up letters of recommendation from his tutors, owing to the frequency with which he had cut classes. However, his final math scores were exceptional.

Which brings us on to the only sustained run-in between these two guys.

Einstein introduced David Hilbert to general relativity in June/July 1915, when he was still working on it. The occasion was that Hilbert had invited Einstein to the University of Göttingen to lecture on his work, and he stayed at Hilbert’s house. Some of the math Einstein was using had been worked on by Hilbert.

After this, Hilbert’s curiosity was piqued, and he started getting to grips with the mathematics of relativity. Einstein felt somewhat uncomfortable about this and arguably intensified his own efforts.

Hilbert was working on the mathematical problem of combining gravity with electromagnetism. Einstein and Hilbert at that stage seem to have had about equal understanding of the complex math involved. However, Hilbert was hampered by his relative lack of familiarity with the physical facts of the question. For example, Einstein had been working for years on the perihelion advance of Mercury, and knew that a fundamental test would be deriving it systematically from any prospective field equations. Hilbert was constrained by his lesser instinct for this.

Which, of course, is precisely why the problem was Einstein’s idea, not Hilbert’s (Einstein and Grossmann, 1913)¹.

On the 4th of November of the same year, Einstein published non-covariant field equations and on the 11th of November, achieved covariant versions of his field equations from earlier papers by making an equality assumption for the case of the energy-momentum tensor.

There is a manuscript by Hilbert, usually dated to the same week, which shows an identical result. Einstein had sent Hilbert proofs of his papers on the 4th and the 11th and Hilbert later testified that he had altered his own work in response to the proofs (the objective being verification, not plagiarism).

On the 16th of November, Hilbert spoke at the Göttingen Mathematical Society, giving a talk entitled Grundgleichungen der Physik. He immediately sent Einstein a summary of what he had said.

On the 18th of November, Einstein wrote back to Hilbert, cheerfully informing him that they were on the same page and including some details of how he had achieved his final result. In this connection, Einstein referred to the problem of generalizing Newton² and the perihelion advance of Mercury (cancelling out the trace of the energy-momentum tensor solved this last-mentioned issue naturally).

These were both areas in which Einstein’s foregoing experience had been far greater than Hilbert’s.

Hilbert testified to the end of his days that Einstein beat him soundly to the post.

I hope this answer deals with the perfect nonsense implied by the question.

¹M. Grossmann, Entwurf einer verallgemeinerten Relativitatstheroie und einer Theorie der Gravitation: II. Mathematischer Teil (I. Physikalischer Teil von A. Einstein), B. G Teubner, Leipzig and Berlin 1913, p. 36.

²“The difficulty was not to find generally covariant equations for the {symbols}; this is easy with the help of the Riemann tensor. What was difficult instead was to recognize that these equations form a generalization, and that is, a simple and natural generalization of Newtonʼs law”.

Einstein, 18th November, 1915.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/yd794p2xzsev506w', 'title': 'Why did David Hilbert think that Albert Einstein was a poor mathematician?', 'score': {'original': 0.99895, 'ai': 0.00105}, 'blocks': [{'text': 'Before asking why ask if.\n\nThere is no evidence whatsoever that David Hilbert thought Albert Einstein was a poor mathematician. None.\n\nLet’s start with Dave. David Hilbert was born in 1862. He was a founder of mathematical logic and believed that modern mathematical tools could eventually unify all of mathematics and provide it with a clear base of broad proveability. These tools particularly included set theory and something mainly invented by himself called Peano arithmetic.\n\nHe is usually listed as one of about twenty mathematicians who are the greatest ever.\n\nHis ambitions for unifying mathematics came crashing down in 1931, when Kurt Gödel published his incompleteness theorem, showing that even in quite simple arithmetical systems there are statements we know to be true that we cannot prove. This is usually regarded as one of the greatest intellectual achievements of last century.\n\nMoving on to Albert. Albert Einstein was a much younger man. He was born in 1879. He was thoroughly exceptional as a student of mathematics from early childhood. He had mastered integral and differential calculus by the age of 15. At the age of 12 he discovered his own proof of the Pythagorean theorem. He had a personal tutor called Max Talmud who introduced him to such matters as geometry and Kantʼs philosophy, both of which he had explored in depth before reaching 14. Talmud had presented Einstein with an advanced geometry textbook and testifies that Einstein by age 13 “had worked through the whole book. He thereupon devoted himself to higher mathematics ... Soon the flight of his mathematical genius was so high I could not follow.”\n\nHowever, even at such an early moment, it was clear that Einstein’s main inclination was for physics. Aged 12 he declared his conviction that nature could be understood as “a mathematical structure” and, still a teenager, he wrote an essay On the Investigation of the State of the Ether in a Magnetic Field. At the same age (16) he composed in an exercise book a Gedankenexperiment where he imagined riding through the universe alongside a beam of light.\n\nHe was allowed early entry to the Eidgenössische Polytechnische Schuler on the strength of exceptional math scores (he scored low at French, chemistry and biology). On leaving the polytechnic, he failed to pick up letters of recommendation from his tutors, owing to the frequency with which he had cut classes. However, his final math scores were exceptional.\n\nWhich brings us on to the only sustained run-in between these two guys.\n\nEinstein introduced David Hilbert to general relativity in June/July 1915, when he was still working on it. The occasion was that Hilbert had invited Einstein to the University of Göttingen to lecture on his work, and he stayed at Hilbert’s house. Some of the math Einstein was using had been worked on by Hilbert.\n\nAfter this, Hilbert’s curiosity was piqued, and he started getting to grips with the mathematics of relativity. Einstein felt somewhat uncomfortable about this and arguably intensified his own efforts.\n\nHilbert was working on the mathematical problem of combining gravity with electromagnetism. Einstein and Hilbert at that stage seem to have had about', 'result': {'fake': 0.0104, 'real': 0.9896}, 'status': 'success'}, {'text': 'equal understanding of the complex math involved. However, Hilbert was hampered by his relative lack of familiarity with the physical facts of the question. For example, Einstein had been working for years on the perihelion advance of Mercury, and knew that a fundamental test would be deriving it systematically from any prospective field equations. Hilbert was constrained by his lesser instinct for this.\n\nWhich, of course, is precisely why the problem was Einstein’s idea, not Hilbert’s (Einstein and Grossmann, 1913)¹.\n\nOn the 4th of November of the same year, Einstein published non-covariant field equations and on the 11th of November, achieved covariant versions of his field equations from earlier papers by making an equality assumption for the case of the energy-momentum tensor.\n\nThere is a manuscript by Hilbert, usually dated to the same week, which shows an identical result. Einstein had sent Hilbert proofs of his papers on the 4th and the 11th and Hilbert later testified that he had altered his own work in response to the proofs (the objective being verification, not plagiarism).\n\nOn the 16th of November, Hilbert spoke at the Göttingen Mathematical Society, giving a talk entitled Grundgleichungen der Physik. He immediately sent Einstein a summary of what he had said.\n\nOn the 18th of November, Einstein wrote back to Hilbert, cheerfully informing him that they were on the same page and including some details of how he had achieved his final result. In this connection, Einstein referred to the problem of generalizing Newton² and the perihelion advance of Mercury (cancelling out the trace of the energy-momentum tensor solved this last-mentioned issue naturally).\n\nThese were both areas in which Einstein’s foregoing experience had been far greater than Hilbert’s.\n\nHilbert testified to the end of his days that Einstein beat him soundly to the post.\n\nI hope this answer deals with the perfect nonsense implied by the question.\n\n¹M. Grossmann, Entwurf einer verallgemeinerten Relativitatstheroie und einer Theorie der Gravitation: II. Mathematischer Teil (I. Physikalischer Teil von A. Einstein), B. G Teubner, Leipzig and Berlin 1913, p. 36.\n\n²“The difficulty was not to find generally covariant equations for the {symbols}; this is easy with the help of the Riemann tensor. What was difficult instead was to recognize that these equations form a generalization, and that is, a simple and natural generalization of Newtonʼs law”.\n\nEinstein, 18th November, 1915.', 'result': {'fake': 0.1632, 'real': 0.8368}, 'status': 'success'}], 'credits_used': 10, 'credits': 1994810, 'subscription': 0, 'content': 'Before asking why ask if.\n\nThere is no evidence whatsoever that David Hilbert thought Albert Einstein was a poor mathematician. None.\n\nLet’s start with Dave. David Hilbert was born in 1862. He was a founder of mathematical logic and believed that modern mathematical tools could eventually unify all of mathematics and provide it with a clear base of broad proveability. These tools particularly included set theory and something mainly invented by himself called Peano arithmetic.\n\nHe is usually listed as one of about twenty mathematicians who are the greatest ever.\n\nHis ambitions for unifying mathematics came crashing down in 1931, when Kurt Gödel published his incompleteness theorem, showing that even in quite simple arithmetical systems there are statements we know to be true that we cannot prove. This is usually regarded as one of the greatest intellectual achievements of last century.\n\nMoving on to Albert. Albert Einstein was a much younger man. He was born in 1879. He was thoroughly exceptional as a student of mathematics from early childhood. He had mastered integral and differential calculus by the age of 15. At the age of 12 he discovered his own proof of the Pythagorean theorem. He had a personal tutor called Max Talmud who introduced him to such matters as geometry and Kantʼs philosophy, both of which he had explored in depth before reaching 14. Talmud had presented Einstein with an advanced geometry textbook and testifies that Einstein by age 13 “had worked through the whole book. He thereupon devoted himself to higher mathematics ... Soon the flight of his mathematical genius was so high I could not follow.”\n\nHowever, even at such an early moment, it was clear that Einstein’s main inclination was for physics. Aged 12 he declared his conviction that nature could be understood as “a mathematical structure” and, still a teenager, he wrote an essay On the Investigation of the State of the Ether in a Magnetic Field. At the same age (16) he composed in an exercise book a Gedankenexperiment where he imagined riding through the universe alongside a beam of light.\n\nHe was allowed early entry to the Eidgenössische Polytechnische Schuler on the strength of exceptional math scores (he scored low at French, chemistry and biology). On leaving the polytechnic, he failed to pick up letters of recommendation from his tutors, owing to the frequency with which he had cut classes. However, his final math scores were exceptional.\n\nWhich brings us on to the only sustained run-in between these two guys.\n\nEinstein introduced David Hilbert to general relativity in June/July 1915, when he was still working on it. The occasion was that Hilbert had invited Einstein to the University of Göttingen to lecture on his work, and he stayed at Hilbert’s house. Some of the math Einstein was using had been worked on by Hilbert.\n\nAfter this, Hilbert’s curiosity was piqued, and he started getting to grips with the mathematics of relativity. Einstein felt somewhat uncomfortable about this and arguably intensified his own efforts.\n\nHilbert was working on the mathematical problem of combining gravity with electromagnetism. Einstein and Hilbert at that stage seem to have had about equal understanding of the complex math involved. However, Hilbert was hampered by his relative lack of familiarity with the physical facts of the question. For example, Einstein had been working for years on the perihelion advance of Mercury, and knew that a fundamental test would be deriving it systematically from any prospective field equations. Hilbert was constrained by his lesser instinct for this.\n\nWhich, of course, is precisely why the problem was Einstein’s idea, not Hilbert’s (Einstein and Grossmann, 1913)¹.\n\nOn the 4th of November of the same year, Einstein published non-covariant field equations and on the 11th of November, achieved covariant versions of his field equations from earlier papers by making an equality assumption for the case of the energy-momentum tensor.\n\nThere is a manuscript by Hilbert, usually dated to the same week, which shows an identical result. Einstein had sent Hilbert proofs of his papers on the 4th and the 11th and Hilbert later testified that he had altered his own work in response to the proofs (the objective being verification, not plagiarism).\n\nOn the 16th of November, Hilbert spoke at the Göttingen Mathematical Society, giving a talk entitled Grundgleichungen der Physik. He immediately sent Einstein a summary of what he had said.\n\nOn the 18th of November, Einstein wrote back to Hilbert, cheerfully informing him that they were on the same page and including some details of how he had achieved his final result. In this connection, Einstein referred to the problem of generalizing Newton² and the perihelion advance of Mercury (cancelling out the trace of the energy-momentum tensor solved this last-mentioned issue naturally).\n\nThese were both areas in which Einstein’s foregoing experience had been far greater than Hilbert’s.\n\nHilbert testified to the end of his days that Einstein beat him soundly to the post.\n\nI hope this answer deals with the perfect nonsense implied by the question.\n\n¹M. Grossmann, Entwurf einer verallgemeinerten Relativitatstheroie und einer Theorie der Gravitation: II. Mathematischer Teil (I. Physikalischer Teil von A. Einstein), B. G Teubner, Leipzig and Berlin 1913, p. 36.\n\n²“The difficulty was not to find generally covariant equations for the {symbols}; this is easy with the help of the Riemann tensor. What was difficult instead was to recognize that these equations form a generalization, and that is, a simple and natural generalization of Newtonʼs law”.\n\nEinstein, 18th November, 1915.', 'aiModelVersion': '1'}",0.99895
Joshua Gross,3y,Is it true that those who fail calculus do so because of a poor grasp of algebra?,"When I was at UNC Charlotte, the math department (I was in CS) instituted a summer mathematics “bootcamp” for entering students. The focus was entirely on algebraic reasoning (rather than the mechanics of algebra). They brought in entering freshmen at all levels of mathematics, from those who would take developmental (remedial) mathematics, to those who would take calculus. They covered the same material. The program was a success: the students enjoyed it and did well in their subsequent mathematics courses.

Their conclusion was striking: the students consistently had very little understanding of algebraic reasoning, even those who had taken “rigorous” mathematics courses throughout high school. Whether this was a fault with teaching methods, retention, or both, was not clear at all.

I see the same thing in introductory computer science. Students can’t reason their way through a problem that they can solve.

In my particular case, I didn’t fail Calc I, but I probably should have. My issue was not weak algebraic reasoning skills per se; my issue was that I didn’t have anything close to the work habits that I would need to succeed.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/d7ylh1uvf3obcnqg', 'title': 'Is it true that those who fail calculus do so because of a poor grasp of algebra?', 'score': {'original': 0.9994, 'ai': 0.0006}, 'blocks': [{'text': 'When I was at UNC Charlotte, the math department (I was in CS) instituted a summer mathematics “bootcamp” for entering students. The focus was entirely on algebraic reasoning (rather than the mechanics of algebra). They brought in entering freshmen at all levels of mathematics, from those who would take developmental (remedial) mathematics, to those who would take calculus. They covered the same material. The program was a success: the students enjoyed it and did well in their subsequent mathematics courses.\n\nTheir conclusion was striking: the students consistently had very little understanding of algebraic reasoning, even those who had taken “rigorous” mathematics courses throughout high school. Whether this was a fault with teaching methods, retention, or both, was not clear at all.\n\nI see the same thing in introductory computer science. Students can’t reason their way through a problem that they can solve.\n\nIn my particular case, I didn’t fail Calc I, but I probably should have. My issue was not weak algebraic reasoning skills per se; my issue was that I didn’t have anything close to the work habits that I would need to succeed.', 'result': {'fake': 0.0006, 'real': 0.9994}, 'status': 'success'}], 'credits_used': 2, 'credits': 1994808, 'subscription': 0, 'content': 'When I was at UNC Charlotte, the math department (I was in CS) instituted a summer mathematics “bootcamp” for entering students. The focus was entirely on algebraic reasoning (rather than the mechanics of algebra). They brought in entering freshmen at all levels of mathematics, from those who would take developmental (remedial) mathematics, to those who would take calculus. They covered the same material. The program was a success: the students enjoyed it and did well in their subsequent mathematics courses.\n\nTheir conclusion was striking: the students consistently had very little understanding of algebraic reasoning, even those who had taken “rigorous” mathematics courses throughout high school. Whether this was a fault with teaching methods, retention, or both, was not clear at all.\n\nI see the same thing in introductory computer science. Students can’t reason their way through a problem that they can solve.\n\nIn my particular case, I didn’t fail Calc I, but I probably should have. My issue was not weak algebraic reasoning skills per se; my issue was that I didn’t have anything close to the work habits that I would need to succeed.', 'aiModelVersion': '1'}",0.9994
Kip Ingram,1y,"Why were the logarithmic tables created by John Napier considered ""one of the very greatest scientific discoveries that the world has seen""?","Well, the very concept of the logarithm was an interesting mathematical advance. But to be honest, the really significant “payoff” was simply the degree to which use of logarithms reduces computational complexity. It’s easy to lose track of the work that has to be done to do typical calculations in engineering and physics, but back then it all had to be done by hand.

Use of logarithms turns multiplication into addition and division into subtraction. That is a huge reduction in labor. So very suddenly calculations which simply hadn’t been feasible previously became possible.

It’s very similar to the way digital computers have made the application of numerical modeling for the solution of engineering problems much more feasible and widespread. We always could have done all the calculations to solve some complex system of differential equations by hand. But some of the simulations we run these days just wouldn’t be tractable done by hand because of the large number of calculations involved. Computers have made them tractable.

So, tl;dr - logarithms increased the amount of stuff we could do by a huge amount.

Stay safe and well!

Kip","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/0ntzx4vko7lm2bg3', 'title': 'Why were the logarithmic tables created by John Napier considered ""one of the very greatest scientific discoveries that the world has seen""?', 'score': {'original': 0.9993, 'ai': 0.0007}, 'blocks': [{'text': 'Well, the very concept of the logarithm was an interesting mathematical advance. But to be honest, the really significant “payoff” was simply the degree to which use of logarithms reduces computational complexity. It’s easy to lose track of the work that has to be done to do typical calculations in engineering and physics, but back then it all had to be done by hand.\n\nUse of logarithms turns multiplication into addition and division into subtraction. That is a huge reduction in labor. So very suddenly calculations which simply hadn’t been feasible previously became possible.\n\nIt’s very similar to the way digital computers have made the application of numerical modeling for the solution of engineering problems much more feasible and widespread. We always could have done all the calculations to solve some complex system of differential equations by hand. But some of the simulations we run these days just wouldn’t be tractable done by hand because of the large number of calculations involved. Computers have made them tractable.\n\nSo, tl;dr - logarithms increased the amount of stuff we could do by a huge amount.\n\nStay safe and well!\n\nKip', 'result': {'fake': 0.0007, 'real': 0.9993}, 'status': 'success'}], 'credits_used': 2, 'credits': 1994806, 'subscription': 0, 'content': 'Well, the very concept of the logarithm was an interesting mathematical advance. But to be honest, the really significant “payoff” was simply the degree to which use of logarithms reduces computational complexity. It’s easy to lose track of the work that has to be done to do typical calculations in engineering and physics, but back then it all had to be done by hand.\n\nUse of logarithms turns multiplication into addition and division into subtraction. That is a huge reduction in labor. So very suddenly calculations which simply hadn’t been feasible previously became possible.\n\nIt’s very similar to the way digital computers have made the application of numerical modeling for the solution of engineering problems much more feasible and widespread. We always could have done all the calculations to solve some complex system of differential equations by hand. But some of the simulations we run these days just wouldn’t be tractable done by hand because of the large number of calculations involved. Computers have made them tractable.\n\nSo, tl;dr - logarithms increased the amount of stuff we could do by a huge amount.\n\nStay safe and well!\n\nKip', 'aiModelVersion': '1'}",0.9993
David Joyce,4y,"When and why did vector quantities start to be written as bold letters, rather than the letter with an arrow overhead?","The concept of vectors was developed in the 1800s, but one of the most influential textbooks on vectors was this one published in 1901: Vector analysis; a text-book for the use of students of mathematics and physics : Gibbs, J. Willard (Josiah Willard), 1839-1903 : Free Download, Borrow, and Streaming : Internet Archive. Here is the explanation for using a different notation for vectors than for ordinary variables, from page 4:Here’s a diagram that illustrates negation, addition and subtraction of vectors, from page 12:It’s interesting in this book that coordinate notation isn’t used. The notation A=(2,1,5)A=(2,1,5)\mathbf A=(2,1,5) doesn’t appear, but A=2i+j+5kA=2i+j+5k\mathbf A=2\mathbf i+\mathbf j+5\mathbf k does. Now, when writing by hand on paper or a blackboard, you really can’t write boldface, so some other way to indicated vectors is needed. There are a few ways to indicate a vector in writing. One is to underline it, a––=(2,1,5),a_=(2,1,5),\underline a=(2,1,5), another is to put a bar over it, ¯¯¯a=(2,1,5),a¯=(2,1,5),\overline a=(2,1,5), and a third is to put an arrow over the top of it, →a=(2,1,5).a→=(2,1,5).\vec a=(2,1,5). Often, however, no special emphasis is made, and the context indicates that it’s a vector, a=(2,1,5).a=(2,1,5).a=(2,1,5).By the way, to underline a symbol in LaTeX, use \underline, to put a bar over it, use \overline. To place an arrow over a symbol, use \vec. If you want the arrow to go all the way over several symbols, use \overrightarrow as in \overrightarrow{CD} which gives −−→CD.CD→.\overrightarrow{CD}. If you use \vec{CD} you’ll get →CD.CD→.\vec{CD}.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/y3498shpvbierf1q', 'title': 'When and why did vector quantities start to be written as bold letters, rather than the letter with an arrow overhead?', 'score': {'original': 0.9997, 'ai': 0.0003}, 'blocks': [{'text': 'The concept of vectors was developed in the 1800s, but one of the most influential textbooks on vectors was this one published in 1901: Vector analysis; a text-book for the use of students of mathematics and physics : Gibbs, J. Willard (Josiah Willard), 1839-1903 : Free Download, Borrow, and Streaming : Internet Archive. Here is the explanation for using a different notation for vectors than for ordinary variables, from page 4:Here’s a diagram that illustrates negation, addition and subtraction of vectors, from page 12:It’s interesting in this book that coordinate notation isn’t used. The notation A=(2,1,5)A=(2,1,5)\\mathbf A=(2,1,5) doesn’t appear, but A=2i+j+5kA=2i+j+5k\\mathbf A=2\\mathbf i+\\mathbf j+5\\mathbf k does. Now, when writing by hand on paper or a blackboard, you really can’t write boldface, so some other way to indicated vectors is needed. There are a few ways to indicate a vector in writing. One is to underline it, a––=(2,1,5),a_=(2,1,5),\\underline a=(2,1,5), another is to put a bar over it, ¯¯¯a=(2,1,5),a¯=(2,1,5),\\overline a=(2,1,5), and a third is to put an arrow over the top of it, →a=(2,1,5).a→=(2,1,5).\\vec a=(2,1,5). Often, however, no special emphasis is made, and the context indicates that it’s a vector, a=(2,1,5).a=(2,1,5).a=(2,1,5).By the way, to underline a symbol in LaTeX, use \\underline, to put a bar over it, use \\overline. To place an arrow over a symbol, use \\vec. If you want the arrow to go all the way over several symbols, use \\overrightarrow as in \\overrightarrow{CD} which gives −−→CD.CD→.\\overrightarrow{CD}. If you use \\vec{CD} you’ll get →CD.CD→.\\vec{CD}.', 'result': {'fake': 0.0003, 'real': 0.9997}, 'status': 'success'}], 'credits_used': 3, 'credits': 1994803, 'subscription': 0, 'content': 'The concept of vectors was developed in the 1800s, but one of the most influential textbooks on vectors was this one published in 1901: Vector analysis; a text-book for the use of students of mathematics and physics : Gibbs, J. Willard (Josiah Willard), 1839-1903 : Free Download, Borrow, and Streaming : Internet Archive. Here is the explanation for using a different notation for vectors than for ordinary variables, from page 4:Here’s a diagram that illustrates negation, addition and subtraction of vectors, from page 12:It’s interesting in this book that coordinate notation isn’t used. The notation A=(2,1,5)A=(2,1,5)\\mathbf A=(2,1,5) doesn’t appear, but A=2i+j+5kA=2i+j+5k\\mathbf A=2\\mathbf i+\\mathbf j+5\\mathbf k does. Now, when writing by hand on paper or a blackboard, you really can’t write boldface, so some other way to indicated vectors is needed. There are a few ways to indicate a vector in writing. One is to underline it, a––=(2,1,5),a_=(2,1,5),\\underline a=(2,1,5), another is to put a bar over it, ¯¯¯a=(2,1,5),a¯=(2,1,5),\\overline a=(2,1,5), and a third is to put an arrow over the top of it, →a=(2,1,5).a→=(2,1,5).\\vec a=(2,1,5). Often, however, no special emphasis is made, and the context indicates that it’s a vector, a=(2,1,5).a=(2,1,5).a=(2,1,5).By the way, to underline a symbol in LaTeX, use \\underline, to put a bar over it, use \\overline. To place an arrow over a symbol, use \\vec. If you want the arrow to go all the way over several symbols, use \\overrightarrow as in \\overrightarrow{CD} which gives −−→CD.CD→.\\overrightarrow{CD}. If you use \\vec{CD} you’ll get →CD.CD→.\\vec{CD}.', 'aiModelVersion': '1'}",0.9997
Ian Lang,2y,Which country invented mathematics?,"No particular country invented mathematics. There is a compelling argument, though it can never be known for sure, that our distant ancestors could do arithmetic, marking off on animal bones. Arithmetic (addition,subtraction, division and multiplication) has been with us a long time. Every time anthropologists discover a new tribe, they can all count in some way or another; most can count as high as they need and may not have a word for million because they’ve never had a million of anything, but one,two, three is pretty common and some base their systems not on tens but on other numbers that are more useful to them. One, two, three, four, four and one, four and two, four and three, twofours, that sort of thing.

Arithmetic is the keystone of maths and if you can add and subtract then it doesn’t take long to realise that multiplication is just repeated addition and division just repeated subtraction. Certainly by the Neolithic age everybody had got the hang of this. Once you’ve got arithmetic down pat you can start on geometry. It’s plain that the circle’s circumference must have a relationship to its radius, but now you’ve just got to work out what it is. The peoples of China, Babylon, the Indian sub-continent, and Ancient Greece busied thenselves with this, and with triangles, squares, and all sorts of other planes and solids as well. Euclid formalised a lot of it some time round 400 BC.

That’s arithmetic, trig and geometry got down. Once you start looking into geometry you realise that it all follows rules like clockwork and instead of formalising in words you can get it down to simple formulae which are understood universally. That was the work largely of the Ottomans and from that we get Algebra.

Algebra is good because you can use variables and just plug in known numbers. If you wanted to, you could make a lot of calculations and write down the results. Then it was realised that if you have two variables, you could graph them one against the other. But what if you want to look at really tiny instances on a curve? Hmm. Now you’d need to be setting limits and letting them tend towards zero………oh. Here comes calculus. From then on you can piss about with anything and reduce it all to numbers. The Europeans, Americans, Chinese, Indians, and everybody else are having a whale of a time pissing about with numbers and this filters off into the physics and chemistry world.

So no one country invented maths. Everybody put something in, even the French, and we end up with the field of maths so big today that no one mathematician is competent in it all. Which serves ’em right, Karma likes to slap every now and then.

I blame the EU. Acuter von der Liketerms.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/0j64n7qpalbuzcf8', 'title': 'Which country invented mathematics?', 'score': {'original': 0.9998, 'ai': 0.0002}, 'blocks': [{'text': 'No particular country invented mathematics. There is a compelling argument, though it can never be known for sure, that our distant ancestors could do arithmetic, marking off on animal bones. Arithmetic (addition,subtraction, division and multiplication) has been with us a long time. Every time anthropologists discover a new tribe, they can all count in some way or another; most can count as high as they need and may not have a word for million because they’ve never had a million of anything, but one,two, three is pretty common and some base their systems not on tens but on other numbers that are more useful to them. One, two, three, four, four and one, four and two, four and three, twofours, that sort of thing.\n\nArithmetic is the keystone of maths and if you can add and subtract then it doesn’t take long to realise that multiplication is just repeated addition and division just repeated subtraction. Certainly by the Neolithic age everybody had got the hang of this. Once you’ve got arithmetic down pat you can start on geometry. It’s plain that the circle’s circumference must have a relationship to its radius, but now you’ve just got to work out what it is. The peoples of China, Babylon, the Indian sub-continent, and Ancient Greece busied thenselves with this, and with triangles, squares, and all sorts of other planes and solids as well. Euclid formalised a lot of it some time round 400 BC.\n\nThat’s arithmetic, trig and geometry got down. Once you start looking into geometry you realise that it all follows rules like clockwork and instead of formalising in words you can get it down to simple formulae which are understood universally. That was the work largely of the Ottomans and from that we get Algebra.\n\nAlgebra is good because you can use variables and just plug in known numbers. If you wanted to, you could make a lot of calculations and write down the results. Then it was realised that if you have two variables, you could graph them one against the other. But what if you want to look at really tiny instances on a curve? Hmm. Now you’d need to be setting limits and letting them tend towards zero………oh. Here comes calculus. From then on you can piss about with anything and reduce it all to numbers. The Europeans, Americans, Chinese, Indians, and everybody else are having a whale of a time pissing about with numbers and this filters off into the physics and chemistry world.\n\nSo no one country invented maths. Everybody put something in, even the French, and we end up with the field of maths so big today that no one mathematician is competent in it all. Which serves ’em right, Karma likes to slap every now and then.\n\nI blame the EU. Acuter von der Liketerms.', 'result': {'fake': 0.0002, 'real': 0.9998}, 'status': 'success'}], 'credits_used': 5, 'credits': 1994798, 'subscription': 0, 'content': 'No particular country invented mathematics. There is a compelling argument, though it can never be known for sure, that our distant ancestors could do arithmetic, marking off on animal bones. Arithmetic (addition,subtraction, division and multiplication) has been with us a long time. Every time anthropologists discover a new tribe, they can all count in some way or another; most can count as high as they need and may not have a word for million because they’ve never had a million of anything, but one,two, three is pretty common and some base their systems not on tens but on other numbers that are more useful to them. One, two, three, four, four and one, four and two, four and three, twofours, that sort of thing.\n\nArithmetic is the keystone of maths and if you can add and subtract then it doesn’t take long to realise that multiplication is just repeated addition and division just repeated subtraction. Certainly by the Neolithic age everybody had got the hang of this. Once you’ve got arithmetic down pat you can start on geometry. It’s plain that the circle’s circumference must have a relationship to its radius, but now you’ve just got to work out what it is. The peoples of China, Babylon, the Indian sub-continent, and Ancient Greece busied thenselves with this, and with triangles, squares, and all sorts of other planes and solids as well. Euclid formalised a lot of it some time round 400 BC.\n\nThat’s arithmetic, trig and geometry got down. Once you start looking into geometry you realise that it all follows rules like clockwork and instead of formalising in words you can get it down to simple formulae which are understood universally. That was the work largely of the Ottomans and from that we get Algebra.\n\nAlgebra is good because you can use variables and just plug in known numbers. If you wanted to, you could make a lot of calculations and write down the results. Then it was realised that if you have two variables, you could graph them one against the other. But what if you want to look at really tiny instances on a curve? Hmm. Now you’d need to be setting limits and letting them tend towards zero………oh. Here comes calculus. From then on you can piss about with anything and reduce it all to numbers. The Europeans, Americans, Chinese, Indians, and everybody else are having a whale of a time pissing about with numbers and this filters off into the physics and chemistry world.\n\nSo no one country invented maths. Everybody put something in, even the French, and we end up with the field of maths so big today that no one mathematician is competent in it all. Which serves ’em right, Karma likes to slap every now and then.\n\nI blame the EU. Acuter von der Liketerms.', 'aiModelVersion': '1'}",0.9998
Senia Sheydvasser,Updated Oct 12,Is it true that around 90% of mathematics has been invented in the last 100 years?,"It depends on how you count, obviously, but I would say that, yes, at least 90% of mathematics has been invented in the last 100 years. It might well be more.

Consider that, prior to 1920, you had:

Virtually no logic, set theory, or computability theory. There was classical work on first-order logic at that point, of course, and the naive set theory of Cantor. Some of the foundations were being put down, with the important early paradoxes discovered. But there was not yet an understanding of the limitations of any of these structures, nor of what the alternatives are, nor how you can exploit the seeming limitations, etc., etc.
Virtually no graph theory. Yes, Euler was proving some basic theorems in the 18th century, but it didn’t become a field in its own right until the 20th century.
No category theory, almost no homological algebra, which is the modern approach to all of algebraic topology. There was no Hodge theory.
No modern algebraic geometry—no Zariski topology, no precise notion of generic points, no localizations via ideals, and certainly not any schemes as due to Grothendieck.
Little representation theory—the field was started by Frobenius, but the connections to Hilbert spaces, to the Langlands program, and so on, would only show up post 1920.
Very rudimentary knowledge of the circle method and sieves in analytic number theory. Basic versions of both were invented just a few years before 1920, but the more sophisticated techniques and most of the important results came later.

And so on, and so on. The growth of knowledge is roughly exponential, so you always expect that most progress has been quite recent.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/gfnkipdxhjz0l7rs', 'title': 'Is it true that around 90% of mathematics has been invented in the last 100 years?', 'score': {'original': 0.9997, 'ai': 0.0003}, 'blocks': [{'text': 'It depends on how you count, obviously, but I would say that, yes, at least 90% of mathematics has been invented in the last 100 years. It might well be more.\n\nConsider that, prior to 1920, you had:\n\nVirtually no logic, set theory, or computability theory. There was classical work on first-order logic at that point, of course, and the naive set theory of Cantor. Some of the foundations were being put down, with the important early paradoxes discovered. But there was not yet an understanding of the limitations of any of these structures, nor of what the alternatives are, nor how you can exploit the seeming limitations, etc., etc.\nVirtually no graph theory. Yes, Euler was proving some basic theorems in the 18th century, but it didn’t become a field in its own right until the 20th century.\nNo category theory, almost no homological algebra, which is the modern approach to all of algebraic topology. There was no Hodge theory.\nNo modern algebraic geometry—no Zariski topology, no precise notion of generic points, no localizations via ideals, and certainly not any schemes as due to Grothendieck.\nLittle representation theory—the field was started by Frobenius, but the connections to Hilbert spaces, to the Langlands program, and so on, would only show up post 1920.\nVery rudimentary knowledge of the circle method and sieves in analytic number theory. Basic versions of both were invented just a few years before 1920, but the more sophisticated techniques and most of the important results came later.\n\nAnd so on, and so on. The growth of knowledge is roughly exponential, so you always expect that most progress has been quite recent.', 'result': {'fake': 0.0003, 'real': 0.9997}, 'status': 'success'}], 'credits_used': 3, 'credits': 1994795, 'subscription': 0, 'content': 'It depends on how you count, obviously, but I would say that, yes, at least 90% of mathematics has been invented in the last 100 years. It might well be more.\n\nConsider that, prior to 1920, you had:\n\nVirtually no logic, set theory, or computability theory. There was classical work on first-order logic at that point, of course, and the naive set theory of Cantor. Some of the foundations were being put down, with the important early paradoxes discovered. But there was not yet an understanding of the limitations of any of these structures, nor of what the alternatives are, nor how you can exploit the seeming limitations, etc., etc.\nVirtually no graph theory. Yes, Euler was proving some basic theorems in the 18th century, but it didn’t become a field in its own right until the 20th century.\nNo category theory, almost no homological algebra, which is the modern approach to all of algebraic topology. There was no Hodge theory.\nNo modern algebraic geometry—no Zariski topology, no precise notion of generic points, no localizations via ideals, and certainly not any schemes as due to Grothendieck.\nLittle representation theory—the field was started by Frobenius, but the connections to Hilbert spaces, to the Langlands program, and so on, would only show up post 1920.\nVery rudimentary knowledge of the circle method and sieves in analytic number theory. Basic versions of both were invented just a few years before 1920, but the more sophisticated techniques and most of the important results came later.\n\nAnd so on, and so on. The growth of knowledge is roughly exponential, so you always expect that most progress has been quite recent.', 'aiModelVersion': '1'}",0.9997
Alon Amit,2y,"Since Andrew Wiles’ proof of Fermat's Last Theorem, have any mathematicians been working on simpler proofs of the same theorem?","Mathematicians think about all kinds of things, and they don’t register their thoughts with any central authority. It’s entirely possible that some people spend some amount of time thinking about alternative approaches to FLT.

However, it’s very unlikely that much time is spent thinking specifically about FLT. It is not, in and of itself, an important result. It is much more likely that people spend time thinking about novel ways of proving the Modularity Theorem
, for example, which is the theorem that Andrew Wiles actually (partially) proved. This is a central and profound result of Number Theory, and it is rewarding and useful to try and understand it in new ways.

A simpler proof of the Modularity Theorem would, among many other things, also furnish a new and simpler proof of FLT, which is a little like saying that a new and improved microprocessor technology would also make the AvaWeigh PC10 Kitchen Digital Scale slightly cheaper. It would, but it would first and foremost transform an entire industry of consumer electronics.

Similarly, a lot of people are thinking about the ABC Conjecture
. This, too, is a profoundly important result in Number Theory, and as opposed to the Modularity Theorem, it is not yet resolved. A proof of (a sufficiently strong version of) the ABC Conjecture would provide a totally new proof of FLT, among a million other things. Such a proof may or may not be simpler, but it would almost certainly be very different.

People are definitely working on the ABC Conjecture, and maybe they’re slightly motivated by the prospect of providing an alternative path to FLT, but this is not at all the main issue. The ABC Conjecture is immensely more important than merely a new FLT proof.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/2tu3c5rwnh9xqbkz', 'title': ""Since Andrew Wiles’ proof of Fermat's Last Theorem, have any mathematicians been working on simpler proofs of the same theorem?"", 'score': {'original': 0.9989, 'ai': 0.0011}, 'blocks': [{'text': 'Mathematicians think about all kinds of things, and they don’t register their thoughts with any central authority. It’s entirely possible that some people spend some amount of time thinking about alternative approaches to FLT.\n\nHowever, it’s very unlikely that much time is spent thinking specifically about FLT. It is not, in and of itself, an important result. It is much more likely that people spend time thinking about novel ways of proving the Modularity Theorem\n, for example, which is the theorem that Andrew Wiles actually (partially) proved. This is a central and profound result of Number Theory, and it is rewarding and useful to try and understand it in new ways.\n\nA simpler proof of the Modularity Theorem would, among many other things, also furnish a new and simpler proof of FLT, which is a little like saying that a new and improved microprocessor technology would also make the AvaWeigh PC10 Kitchen Digital Scale slightly cheaper. It would, but it would first and foremost transform an entire industry of consumer electronics.\n\nSimilarly, a lot of people are thinking about the ABC Conjecture\n. This, too, is a profoundly important result in Number Theory, and as opposed to the Modularity Theorem, it is not yet resolved. A proof of (a sufficiently strong version of) the ABC Conjecture would provide a totally new proof of FLT, among a million other things. Such a proof may or may not be simpler, but it would almost certainly be very different.\n\nPeople are definitely working on the ABC Conjecture, and maybe they’re slightly motivated by the prospect of providing an alternative path to FLT, but this is not at all the main issue. The ABC Conjecture is immensely more important than merely a new FLT proof.', 'result': {'fake': 0.0011, 'real': 0.9989}, 'status': 'success'}], 'credits_used': 3, 'credits': 1994792, 'subscription': 0, 'content': 'Mathematicians think about all kinds of things, and they don’t register their thoughts with any central authority. It’s entirely possible that some people spend some amount of time thinking about alternative approaches to FLT.\n\nHowever, it’s very unlikely that much time is spent thinking specifically about FLT. It is not, in and of itself, an important result. It is much more likely that people spend time thinking about novel ways of proving the Modularity Theorem\n, for example, which is the theorem that Andrew Wiles actually (partially) proved. This is a central and profound result of Number Theory, and it is rewarding and useful to try and understand it in new ways.\n\nA simpler proof of the Modularity Theorem would, among many other things, also furnish a new and simpler proof of FLT, which is a little like saying that a new and improved microprocessor technology would also make the AvaWeigh PC10 Kitchen Digital Scale slightly cheaper. It would, but it would first and foremost transform an entire industry of consumer electronics.\n\nSimilarly, a lot of people are thinking about the ABC Conjecture\n. This, too, is a profoundly important result in Number Theory, and as opposed to the Modularity Theorem, it is not yet resolved. A proof of (a sufficiently strong version of) the ABC Conjecture would provide a totally new proof of FLT, among a million other things. Such a proof may or may not be simpler, but it would almost certainly be very different.\n\nPeople are definitely working on the ABC Conjecture, and maybe they’re slightly motivated by the prospect of providing an alternative path to FLT, but this is not at all the main issue. The ABC Conjecture is immensely more important than merely a new FLT proof.', 'aiModelVersion': '1'}",0.9989
Huyen Nguyen,Updated 4y,What are some of the most audacious calculations in the history of mathematics?,"By the mid-nineteenth century it had become generally accepted that much of Europe had once been covered by glacier. The cause for such dramatic shifts in the Earth’s climate was unknown until James Croll, a janitor, at Anderson’s University in Glasgow proposed the idea that variations in the Earth’s orbit might have precipitated ice ages. James Croll was a real-life Good Will Hunting who grew up poor, had limited education and worked as a janitor at the university. He spent much of his free time in the university library teaching himself physics, mechanics, astronomy and many other subjects. He was the first to suggest that cyclical changes in the shape of the Earth’s orbit might explain the onset and retreat of ice ages.

While Croll’s theory had some truth to it and gained acceptance and Croll himself later got elected Fellow of the Royal Society, a Serbian mathematician and engineer named Milutin Milankovitch realized that it was too simple. He set out to build a full mathematical model of the climate of the Earth in the past.

For twenty years, even while on holiday, he worked tirelessly with pencil and slide rule computing the tables of his cycles. In 1914 when the First World War broke out, Milankovitch was arrested by the Austro-Hungarian army owing to his position as a reservist in the Serbian army. He described his first day in prison in a calm, blasé manner:

""The heavy iron door closed behind me....I sat on my bed, looked around the room and started to take in my new social circumstances… In my hand luggage which I brought with me were my already printed or only started works on my cosmic problem; there was even some blank paper. I looked over my works, took my faithful ink pen and started to write and calculate.”

Through social connections, his wife managed to get him released from prison and permission to spend his captivity in Budapest with the right to work. He spent most of the next four years under loose house arrest in Budapest, required only to report to the police once a week. The rest of his time was spent working in the library of the Hungarian Academy of Sciences. He was possibly the happiest prisoner of war in history.

He used mathematical methods to study the current climate of inner planets of the solar system. Based on the calculations of solar radiation, he was able to approximate the temperatures on the Moon, Venus, Mercury and Mars.

He spent many painstaking years measuring the slow changes in Earth’s orbit around the Sun, by calculating gravitational effects and the positions of stars and planets in relation to the Earth. He concluded that Earth’s orbit changes in three cycles of different lengths. The eccentricity of the Earth (changing from elliptical to nearly circular) has a period of 96,000 years. The Earth’s tilt changes every 41,000 years. The Earth’s axis of spin wobbles with a period of 23,000 years.

Milankovitch prepared a graph of solar radiation changes and the corresponding surface temperature at geographical latitudes of 55°, 60° and 65°
 north for the past 650,000 years. He then attempted to correlate these changes with the growth and retreat of the Ice Ages. To do this, Milankovitch assumed that radiation changes in some latitudes and seasons are more important to ice sheet growth and decay than those in others. Then, at the suggestion of German Climatologist Vladimir Koppen, he chose summer insolation at 65° North as the most important latitude and season to model, reasoning that great ice sheets grew near this latitude and that cooler summers might reduce summer snowmelt, leading to ice sheet growth. His calculations culminated in the 1930 book Mathematical Climatology and the Astronomical Theory of Climatic Changes and are still in use today.

Unfortunately, his work was initially greeted with much excitement but was then forgotten due to the lack of data. Ice ages are difficult to date and scientists were unable to correlate his results with the supposed dates of ice ages. He died in 1958, unable to prove that his cycles were correct.

Not until the 1970s and the refinement of a potassium-argon method for dating ancient sea-floor sediments were his theories finally vindicated. Project CLIMAP
 (Climate: Long Range Investigation, Mapping and Production) finally resolved the dispute and proved the theory of Milankovitch cycles. In 1972, scientists compiled a time scale of climatic events in the past 700,000 years from deep-sea cores. They performed the analysis of the cores and four years later, came to the conclusion that in the past 500,000 years, climate has changed depending on the inclination of the Earth’s axis of rotation and its precession
, just as Milankovitch predicted. Indeed, ice ages had occurred when the Earth was going through different stages of orbital variation. Since this study, the National Research Council of the U.S. National Academy of Sciences has embraced the Milankovitch Cycle model.

However, it also became clear that astronomical factors alone are not sufficient to cause the large climate changes. Other factors must be at play and scientists are still looking for them. Still, that doesn’t undermine Milankovitch’s incredibly painstaking efforts and monumental achievement to unveil one of the greatest mysteries of the Earth.

James Croll - Wikipedia

Milankovitch Cycles

Milutin Milanković - Wikipedia

Milankovitch cycles - Wikipedia

Milankovitch Cycle - Universe Today

Variations in the Earth's Orbit: Pacemaker of the Ice Ages

P/S: Quite interestingly, I learned that one of the famous Quorans, Professor Richard Muller actually published a paper Glacial Cycles and Astronomical Forcing
 in 1997 in Science which supports the Croll/Milankovitch theory mentioned in this answer Richard Muller's answer to I am triple majoring in math, computer science, and physics because these are my passions. Is this a bad idea? The paper is unfortunately behind a paywall.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/h5l2rcgaj38vbkwy', 'title': 'What are some of the most audacious calculations in the history of mathematics?', 'score': {'original': 0.56415, 'ai': 0.43585}, 'blocks': [{'text': 'By the mid-nineteenth century it had become generally accepted that much of Europe had once been covered by glacier. The cause for such dramatic shifts in the Earth’s climate was unknown until James Croll, a janitor, at Anderson’s University in Glasgow proposed the idea that variations in the Earth’s orbit might have precipitated ice ages. James Croll was a real-life Good Will Hunting who grew up poor, had limited education and worked as a janitor at the university. He spent much of his free time in the university library teaching himself physics, mechanics, astronomy and many other subjects. He was the first to suggest that cyclical changes in the shape of the Earth’s orbit might explain the onset and retreat of ice ages.\n\nWhile Croll’s theory had some truth to it and gained acceptance and Croll himself later got elected Fellow of the Royal Society, a Serbian mathematician and engineer named Milutin Milankovitch realized that it was too simple. He set out to build a full mathematical model of the climate of the Earth in the past.\n\nFor twenty years, even while on holiday, he worked tirelessly with pencil and slide rule computing the tables of his cycles. In 1914 when the First World War broke out, Milankovitch was arrested by the Austro-Hungarian army owing to his position as a reservist in the Serbian army. He described his first day in prison in a calm, blasé manner:\n\n""The heavy iron door closed behind me....I sat on my bed, looked around the room and started to take in my new social circumstances… In my hand luggage which I brought with me were my already printed or only started works on my cosmic problem; there was even some blank paper. I looked over my works, took my faithful ink pen and started to write and calculate.”\n\nThrough social connections, his wife managed to get him released from prison and permission to spend his captivity in Budapest with the right to work. He spent most of the next four years under loose house arrest in Budapest, required only to report to the police once a week. The rest of his time was spent working in the library of the Hungarian Academy of Sciences. He was possibly the happiest prisoner of war in history.\n\nHe used mathematical methods to study the current climate of inner planets of the solar system. Based on the calculations of solar radiation, he was able to approximate the temperatures on the Moon, Venus, Mercury and Mars.\n\nHe spent many painstaking years measuring the slow changes in Earth’s orbit around the Sun, by calculating gravitational effects and the positions of stars and planets in relation to the Earth. He concluded that Earth’s orbit changes in three cycles of different lengths. The eccentricity of the Earth (changing from elliptical to nearly circular) has a period of 96,000 years. The Earth’s tilt changes every 41,000 years. The Earth’s axis of spin wobbles with a period of 23,000 years.\n\nMilankovitch prepared a graph of solar radiation changes and the corresponding surface temperature at geographical latitudes of 55°, 60° and 65°\n north for', 'result': {'fake': 0.57, 'real': 0.43}, 'status': 'success'}, {'text': ""the past 650,000 years. He then attempted to correlate these changes with the growth and retreat of the Ice Ages. To do this, Milankovitch assumed that radiation changes in some latitudes and seasons are more important to ice sheet growth and decay than those in others. Then, at the suggestion of German Climatologist Vladimir Koppen, he chose summer insolation at 65° North as the most important latitude and season to model, reasoning that great ice sheets grew near this latitude and that cooler summers might reduce summer snowmelt, leading to ice sheet growth. His calculations culminated in the 1930 book Mathematical Climatology and the Astronomical Theory of Climatic Changes and are still in use today.\n\nUnfortunately, his work was initially greeted with much excitement but was then forgotten due to the lack of data. Ice ages are difficult to date and scientists were unable to correlate his results with the supposed dates of ice ages. He died in 1958, unable to prove that his cycles were correct.\n\nNot until the 1970s and the refinement of a potassium-argon method for dating ancient sea-floor sediments were his theories finally vindicated. Project CLIMAP\n (Climate: Long Range Investigation, Mapping and Production) finally resolved the dispute and proved the theory of Milankovitch cycles. In 1972, scientists compiled a time scale of climatic events in the past 700,000 years from deep-sea cores. They performed the analysis of the cores and four years later, came to the conclusion that in the past 500,000 years, climate has changed depending on the inclination of the Earth’s axis of rotation and its precession\n, just as Milankovitch predicted. Indeed, ice ages had occurred when the Earth was going through different stages of orbital variation. Since this study, the National Research Council of the U.S. National Academy of Sciences has embraced the Milankovitch Cycle model.\n\nHowever, it also became clear that astronomical factors alone are not sufficient to cause the large climate changes. Other factors must be at play and scientists are still looking for them. Still, that doesn’t undermine Milankovitch’s incredibly painstaking efforts and monumental achievement to unveil one of the greatest mysteries of the Earth.\n\nJames Croll - Wikipedia\n\nMilankovitch Cycles\n\nMilutin Milanković - Wikipedia\n\nMilankovitch cycles - Wikipedia\n\nMilankovitch Cycle - Universe Today\n\nVariations in the Earth's Orbit: Pacemaker of the Ice Ages\n\nP/S: Quite interestingly, I learned that one of the famous Quorans, Professor Richard Muller actually published a paper Glacial Cycles and Astronomical Forcing\n in 1997 in Science which supports the Croll/Milankovitch theory mentioned in this answer Richard Muller's answer to I am triple majoring in math, computer science, and physics because these are my passions. Is this a bad idea? The paper is unfortunately behind a paywall."", 'result': {'fake': 0.8897, 'real': 0.1103}, 'status': 'success'}], 'credits_used': 10, 'credits': 1994782, 'subscription': 0, 'content': 'By the mid-nineteenth century it had become generally accepted that much of Europe had once been covered by glacier. The cause for such dramatic shifts in the Earth’s climate was unknown until James Croll, a janitor, at Anderson’s University in Glasgow proposed the idea that variations in the Earth’s orbit might have precipitated ice ages. James Croll was a real-life Good Will Hunting who grew up poor, had limited education and worked as a janitor at the university. He spent much of his free time in the university library teaching himself physics, mechanics, astronomy and many other subjects. He was the first to suggest that cyclical changes in the shape of the Earth’s orbit might explain the onset and retreat of ice ages.\n\nWhile Croll’s theory had some truth to it and gained acceptance and Croll himself later got elected Fellow of the Royal Society, a Serbian mathematician and engineer named Milutin Milankovitch realized that it was too simple. He set out to build a full mathematical model of the climate of the Earth in the past.\n\nFor twenty years, even while on holiday, he worked tirelessly with pencil and slide rule computing the tables of his cycles. In 1914 when the First World War broke out, Milankovitch was arrested by the Austro-Hungarian army owing to his position as a reservist in the Serbian army. He described his first day in prison in a calm, blasé manner:\n\n""The heavy iron door closed behind me....I sat on my bed, looked around the room and started to take in my new social circumstances… In my hand luggage which I brought with me were my already printed or only started works on my cosmic problem; there was even some blank paper. I looked over my works, took my faithful ink pen and started to write and calculate.”\n\nThrough social connections, his wife managed to get him released from prison and permission to spend his captivity in Budapest with the right to work. He spent most of the next four years under loose house arrest in Budapest, required only to report to the police once a week. The rest of his time was spent working in the library of the Hungarian Academy of Sciences. He was possibly the happiest prisoner of war in history.\n\nHe used mathematical methods to study the current climate of inner planets of the solar system. Based on the calculations of solar radiation, he was able to approximate the temperatures on the Moon, Venus, Mercury and Mars.\n\nHe spent many painstaking years measuring the slow changes in Earth’s orbit around the Sun, by calculating gravitational effects and the positions of stars and planets in relation to the Earth. He concluded that Earth’s orbit changes in three cycles of different lengths. The eccentricity of the Earth (changing from elliptical to nearly circular) has a period of 96,000 years. The Earth’s tilt changes every 41,000 years. The Earth’s axis of spin wobbles with a period of 23,000 years.\n\nMilankovitch prepared a graph of solar radiation changes and the corresponding surface temperature at geographical latitudes of 55°, 60° and 65°\n north for the past 650,000 years. He then attempted to correlate these changes with the growth and retreat of the Ice Ages. To do this, Milankovitch assumed that radiation changes in some latitudes and seasons are more important to ice sheet growth and decay than those in others. Then, at the suggestion of German Climatologist Vladimir Koppen, he chose summer insolation at 65° North as the most important latitude and season to model, reasoning that great ice sheets grew near this latitude and that cooler summers might reduce summer snowmelt, leading to ice sheet growth. His calculations culminated in the 1930 book Mathematical Climatology and the Astronomical Theory of Climatic Changes and are still in use today.\n\nUnfortunately, his work was initially greeted with much excitement but was then forgotten due to the lack of data. Ice ages are difficult to date and scientists were unable to correlate his results with the supposed dates of ice ages. He died in 1958, unable to prove that his cycles were correct.\n\nNot until the 1970s and the refinement of a potassium-argon method for dating ancient sea-floor sediments were his theories finally vindicated. Project CLIMAP\n (Climate: Long Range Investigation, Mapping and Production) finally resolved the dispute and proved the theory of Milankovitch cycles. In 1972, scientists compiled a time scale of climatic events in the past 700,000 years from deep-sea cores. They performed the analysis of the cores and four years later, came to the conclusion that in the past 500,000 years, climate has changed depending on the inclination of the Earth’s axis of rotation and its precession\n, just as Milankovitch predicted. Indeed, ice ages had occurred when the Earth was going through different stages of orbital variation. Since this study, the National Research Council of the U.S. National Academy of Sciences has embraced the Milankovitch Cycle model.\n\nHowever, it also became clear that astronomical factors alone are not sufficient to cause the large climate changes. Other factors must be at play and scientists are still looking for them. Still, that doesn’t undermine Milankovitch’s incredibly painstaking efforts and monumental achievement to unveil one of the greatest mysteries of the Earth.\n\nJames Croll - Wikipedia\n\nMilankovitch Cycles\n\nMilutin Milanković - Wikipedia\n\nMilankovitch cycles - Wikipedia\n\nMilankovitch Cycle - Universe Today\n\nVariations in the Earth\'s Orbit: Pacemaker of the Ice Ages\n\nP/S: Quite interestingly, I learned that one of the famous Quorans, Professor Richard Muller actually published a paper Glacial Cycles and Astronomical Forcing\n in 1997 in Science which supports the Croll/Milankovitch theory mentioned in this answer Richard Muller\'s answer to I am triple majoring in math, computer science, and physics because these are my passions. Is this a bad idea? The paper is unfortunately behind a paywall.', 'aiModelVersion': '1'}",0.56415
Senia Sheydvasser,4y,"Who was the mathematician Paul Erdős, and what did he discover?","Paul Erdős
 was a Hungarian mathematician who was born in 1913 and died in 1996. He was also unique. I strongly recommend reading at least the Wikipedia article on him, because he was such an unusual and colorful character.

(This screenshot is taken from N is a Number: A Portrait of Paul Erdös. I don’t know of another modern mathematician who has as many books and movies about him as Erdős.)

If you want to know what Erdős was like as a mathematician, there are a few key things you need to understand.

Erdős viewed mathematics as quintessentially a collaborative, social process. He co-authored papers with over 500 different people, and traveled from math department to math department, country to country, without any permanent place of dwelling. He donated most of the money that he made to students and to set up prize money for problems that he proposed. Usually these were small prizes ($25-$100), but he set them up for literally hundreds of different problems.
Erdős was prolific in the extreme: he wrote over 1500 papers over his lifetime, an unmatched record. (Although, it should perhaps be mentioned that Euler wrote a larger total number of pages.)
Erdős had a marvelous ability to tweak a problem so that it was solvable but only just, and he would know exactly who to talk to in order to get a solution. That is, you would talk to him and ask whether he thought that such-and-such a problem could be solved, and he would either reply that yes, it could, and moreover he thought a little bit more could be said, or alternatively he would say that no, this was probably too ambitious, but if you changed it just so, and talked to a particular graph theorist in Israel, then you would be able to prove something interesting.
Erdős was quintessentially a problem solver. Some mathematicians are theory-builders—they will spend years working on just one area, slowly building up what is known about it, until eventually they produce an edifice of machinery of breath-taking generality capable of resolving wide swathes of mathematics. This was not how Erdős operated; he would flit between areas, doing a little bit of work here, and a bit there. As mentioned before, he was very good at zeroing in on problems that were solvable, but not trivial. While most of his work involved discrete mathematics, he wrote papers in number theory, graph theory, analysis, probability theory, and much more.

It is therefore difficult to summarize everything that Erdős discovered. There are quite a few theorems that carry his name, including (but probably not limited to) the following.

de Bruijn–Erdős theorem
de Bruijn–Erdős theorem
Davenport–Erdős theorem
Erdős–Anning theorem
Erdős–Beck theorem
Erdős–Dushnik–Miller theorem
Erdős–Gallai theorem
Erdős–Kac theorem
Erdős–Ko–Rado theorem
Erdős–Nagy theorem
Erdős–Rado theorem
Erdős–Stone theorem
Erdős–Szekeres theorem
Erdős–Szemerédi theorem
Hsu–Robbins–Erdős theorem

They are all quite different, although all of them have a certain Erdős je ne sais quoi that is difficult to pin down. (The term “Erdős type problem” has entered the mathematical lexicon, but I don’t think that I have ever seen it defined.)

Erdős lived for mathematics—it was one of the only things that he ever cared about. He was asked at one point how he wanted to die, and he replied thus.

I want to be giving a lecture, finishing up an important proof on the blackboard, when someone in the audience shouts out, 'What about the general case?'. I'll turn to the audience and smile, 'I'll leave that to the next generation,' and then I'll keel over.

I find it satisfying that this is quite similar to how he actually passed away—in 1996 he was at a mathematics conference in Warsaw, when he had a heart attack. He continued happily chatting with people about his beloved occupation up until the moment that he died: or, in his own peculiar manner of expressing himself, when he left.

May we remember Paul Erdős P.G.O.M. (Poor Great Old Man) L.D. (Living Dead) A.D. (Archaelogical Discovery) L.D. (Legally Dead) C.D. (Counts Dead).","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/7zs2yjqld63xircp', 'title': 'Who was the mathematician Paul Erdős, and what did he discover?', 'score': {'original': 0.66835, 'ai': 0.33165}, 'blocks': [{'text': 'Paul Erdős\n was a Hungarian mathematician who was born in 1913 and died in 1996. He was also unique. I strongly recommend reading at least the Wikipedia article on him, because he was such an unusual and colorful character.\n\n(This screenshot is taken from N is a Number: A Portrait of Paul Erdös. I don’t know of another modern mathematician who has as many books and movies about him as Erdős.)\n\nIf you want to know what Erdős was like as a mathematician, there are a few key things you need to understand.\n\nErdős viewed mathematics as quintessentially a collaborative, social process. He co-authored papers with over 500 different people, and traveled from math department to math department, country to country, without any permanent place of dwelling. He donated most of the money that he made to students and to set up prize money for problems that he proposed. Usually these were small prizes ($25-$100), but he set them up for literally hundreds of different problems.\nErdős was prolific in the extreme: he wrote over 1500 papers over his lifetime, an unmatched record. (Although, it should perhaps be mentioned that Euler wrote a larger total number of pages.)\nErdős had a marvelous ability to tweak a problem so that it was solvable but only just, and he would know exactly who to talk to in order to get a solution. That is, you would talk to him and ask whether he thought that such-and-such a problem could be solved, and he would either reply that yes, it could, and moreover he thought a little bit more could be said, or alternatively he would say that no, this was probably too ambitious, but if you changed it just so, and talked to a particular graph theorist in Israel, then you would be able to prove something interesting.\nErdős was quintessentially a problem solver. Some mathematicians are theory-builders—they will spend years working on just one area, slowly building up what is known about it, until eventually they produce an edifice of machinery of breath-taking generality capable of resolving wide swathes of mathematics. This was not how Erdős operated; he would flit between areas, doing a little bit of work here, and a bit there. As mentioned before, he was very good at zeroing in on problems that were solvable, but not trivial. While most of his work involved discrete mathematics, he wrote papers in number theory, graph theory, analysis, probability theory, and much more.\n\nIt is therefore difficult to summarize everything that Erdős discovered. There are quite a few theorems that carry his name, including (but probably not limited to) the following.\n\nde Bruijn–Erdős theorem\nde Bruijn–Erdős theorem\nDavenport–Erdős theorem\nErdős–Anning theorem\nErdős–Beck theorem\nErdős–Dushnik–Miller theorem\nErdős–Gallai theorem\nErdős–Kac theorem\nErdős–Ko–Rado theorem\nErdős–Nagy theorem\nErdős–Rado theorem\nErdős–Stone theorem\nErdős–Szekeres theorem\nErdős–Szemerédi theorem\nHsu–Robbins–Erdős theorem\n\nThey are all quite different, although all of them have a certain Erdős je ne sais quoi that is difficult to pin down. (The term “Erdős type problem” has entered the mathematical lexicon, but I don’t think that I have ever seen it defined.)\n\nErdős lived for mathematics—it was one of the only things that he ever cared about. He was asked at one', 'result': {'fake': 0.0017, 'real': 0.9983}, 'status': 'success'}, {'text': ""point how he wanted to die, and he replied thus.\n\nI want to be giving a lecture, finishing up an important proof on the blackboard, when someone in the audience shouts out, 'What about the general case?'. I'll turn to the audience and smile, 'I'll leave that to the next generation,' and then I'll keel over.\n\nI find it satisfying that this is quite similar to how he actually passed away—in 1996 he was at a mathematics conference in Warsaw, when he had a heart attack. He continued happily chatting with people about his beloved occupation up until the moment that he died: or, in his own peculiar manner of expressing himself, when he left.\n\nMay we remember Paul Erdős P.G.O.M. (Poor Great Old Man) L.D. (Living Dead) A.D. (Archaelogical Discovery) L.D. (Legally Dead) C.D. (Counts Dead)."", 'result': {'fake': 0.4632, 'real': 0.5368}, 'status': 'success'}], 'credits_used': 8, 'credits': 1994774, 'subscription': 0, 'content': ""Paul Erdős\n was a Hungarian mathematician who was born in 1913 and died in 1996. He was also unique. I strongly recommend reading at least the Wikipedia article on him, because he was such an unusual and colorful character.\n\n(This screenshot is taken from N is a Number: A Portrait of Paul Erdös. I don’t know of another modern mathematician who has as many books and movies about him as Erdős.)\n\nIf you want to know what Erdős was like as a mathematician, there are a few key things you need to understand.\n\nErdős viewed mathematics as quintessentially a collaborative, social process. He co-authored papers with over 500 different people, and traveled from math department to math department, country to country, without any permanent place of dwelling. He donated most of the money that he made to students and to set up prize money for problems that he proposed. Usually these were small prizes ($25-$100), but he set them up for literally hundreds of different problems.\nErdős was prolific in the extreme: he wrote over 1500 papers over his lifetime, an unmatched record. (Although, it should perhaps be mentioned that Euler wrote a larger total number of pages.)\nErdős had a marvelous ability to tweak a problem so that it was solvable but only just, and he would know exactly who to talk to in order to get a solution. That is, you would talk to him and ask whether he thought that such-and-such a problem could be solved, and he would either reply that yes, it could, and moreover he thought a little bit more could be said, or alternatively he would say that no, this was probably too ambitious, but if you changed it just so, and talked to a particular graph theorist in Israel, then you would be able to prove something interesting.\nErdős was quintessentially a problem solver. Some mathematicians are theory-builders—they will spend years working on just one area, slowly building up what is known about it, until eventually they produce an edifice of machinery of breath-taking generality capable of resolving wide swathes of mathematics. This was not how Erdős operated; he would flit between areas, doing a little bit of work here, and a bit there. As mentioned before, he was very good at zeroing in on problems that were solvable, but not trivial. While most of his work involved discrete mathematics, he wrote papers in number theory, graph theory, analysis, probability theory, and much more.\n\nIt is therefore difficult to summarize everything that Erdős discovered. There are quite a few theorems that carry his name, including (but probably not limited to) the following.\n\nde Bruijn–Erdős theorem\nde Bruijn–Erdős theorem\nDavenport–Erdős theorem\nErdős–Anning theorem\nErdős–Beck theorem\nErdős–Dushnik–Miller theorem\nErdős–Gallai theorem\nErdős–Kac theorem\nErdős–Ko–Rado theorem\nErdős–Nagy theorem\nErdős–Rado theorem\nErdős–Stone theorem\nErdős–Szekeres theorem\nErdős–Szemerédi theorem\nHsu–Robbins–Erdős theorem\n\nThey are all quite different, although all of them have a certain Erdős je ne sais quoi that is difficult to pin down. (The term “Erdős type problem” has entered the mathematical lexicon, but I don’t think that I have ever seen it defined.)\n\nErdős lived for mathematics—it was one of the only things that he ever cared about. He was asked at one point how he wanted to die, and he replied thus.\n\nI want to be giving a lecture, finishing up an important proof on the blackboard, when someone in the audience shouts out, 'What about the general case?'. I'll turn to the audience and smile, 'I'll leave that to the next generation,' and then I'll keel over.\n\nI find it satisfying that this is quite similar to how he actually passed away—in 1996 he was at a mathematics conference in Warsaw, when he had a heart attack. He continued happily chatting with people about his beloved occupation up until the moment that he died: or, in his own peculiar manner of expressing himself, when he left.\n\nMay we remember Paul Erdős P.G.O.M. (Poor Great Old Man) L.D. (Living Dead) A.D. (Archaelogical Discovery) L.D. (Legally Dead) C.D. (Counts Dead)."", 'aiModelVersion': '1'}",0.66835
Alon Amit,3y,"Were all great mathematicians such as Hilbert, Euler, and Newton great with mental calculations? Were they all able to calculate, for example, 737483*83847 within seconds?","No. The vast majority of mathematicians pay very little attention to “mental arithmetic” feats. Multiplying 5 or 6 digit numbers “within seconds” is a chore that takes practice and dedication which no serious mathematician would care to spend time on.

As children, many people who are drawn to mathematics start their journey by playing with numbers, which often takes the form of a good facility with mental calculations. But as soon as they move on to the deeper study of math, multiplying six-digit numbers is quickly seen as a silly waste of time.

Gauss was famously able to carry out highly intricate calculations by hand (computers were not quite around during his lifetime), but I’m not aware that he indulged in elaborate mental arithmetic tricks.

Euler was a phenomenal mental calculator, particularly after losing most of his eyesight. A few other mathematicians (like von Neumann) were shockingly good at mental calculation. But this isn’t the norm, even among the greatest mathematicians. I don’t know that Riemann, or Poincaré, or Hilbert, were able to multiply anything by anything within seconds, or extract cube roots to ten digits of precision in their head. This isn’t even remotely what they cared about.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/fa08vn23xtm6lcsp', 'title': 'Were all great mathematicians such as Hilbert, Euler, and Newton great with mental calculations? Were they all able to calculate, for example, 737483*83847 within seconds?', 'score': {'original': 0.9991, 'ai': 0.0009}, 'blocks': [{'text': 'No. The vast majority of mathematicians pay very little attention to “mental arithmetic” feats. Multiplying 5 or 6 digit numbers “within seconds” is a chore that takes practice and dedication which no serious mathematician would care to spend time on.\n\nAs children, many people who are drawn to mathematics start their journey by playing with numbers, which often takes the form of a good facility with mental calculations. But as soon as they move on to the deeper study of math, multiplying six-digit numbers is quickly seen as a silly waste of time.\n\nGauss was famously able to carry out highly intricate calculations by hand (computers were not quite around during his lifetime), but I’m not aware that he indulged in elaborate mental arithmetic tricks.\n\nEuler was a phenomenal mental calculator, particularly after losing most of his eyesight. A few other mathematicians (like von Neumann) were shockingly good at mental calculation. But this isn’t the norm, even among the greatest mathematicians. I don’t know that Riemann, or Poincaré, or Hilbert, were able to multiply anything by anything within seconds, or extract cube roots to ten digits of precision in their head. This isn’t even remotely what they cared about.', 'result': {'fake': 0.0009, 'real': 0.9991}, 'status': 'success'}], 'credits_used': 3, 'credits': 1994771, 'subscription': 0, 'content': 'No. The vast majority of mathematicians pay very little attention to “mental arithmetic” feats. Multiplying 5 or 6 digit numbers “within seconds” is a chore that takes practice and dedication which no serious mathematician would care to spend time on.\n\nAs children, many people who are drawn to mathematics start their journey by playing with numbers, which often takes the form of a good facility with mental calculations. But as soon as they move on to the deeper study of math, multiplying six-digit numbers is quickly seen as a silly waste of time.\n\nGauss was famously able to carry out highly intricate calculations by hand (computers were not quite around during his lifetime), but I’m not aware that he indulged in elaborate mental arithmetic tricks.\n\nEuler was a phenomenal mental calculator, particularly after losing most of his eyesight. A few other mathematicians (like von Neumann) were shockingly good at mental calculation. But this isn’t the norm, even among the greatest mathematicians. I don’t know that Riemann, or Poincaré, or Hilbert, were able to multiply anything by anything within seconds, or extract cube roots to ten digits of precision in their head. This isn’t even remotely what they cared about.', 'aiModelVersion': '1'}",0.9991
Alon Amit,3y,Is it a consensus among mathematicians that 1 is not a prime number?,"Yes. Unequivocally, totally and completely.

Just to be clear, this isn’t a consensus about the way things are, it’s consensus about terminology. The definition of prime numbers among the natural numbers, or among elements of other rings, is just that: a definition.

There do exist terms in math that don’t have a single, agreed-upon definition, and writers must clarify what they mean when they use such terms. This isn’t one of them. Literally nobody nowadays considers 1 to be a prime number. The last serious mathematician I’m aware of who did was D. N. Lehmer
, who passed away in 1938.

I’m aware that I can’t speak for all mathematicians, and I didn’t survey every single living one. But I can assert that if anyone used the opposite convention, it would be regarded as a strange and peculiar deviation from the norm, and they would be expected to explicitly and clearly clarify that they do (and why). Nobody who uses the ordinary definition needs to clarify that they do.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/pc4r59f6yhqvib0l', 'title': 'Is it a consensus among mathematicians that 1 is not a prime number?', 'score': {'original': 0.998, 'ai': 0.002}, 'blocks': [{'text': 'Yes. Unequivocally, totally and completely.\n\nJust to be clear, this isn’t a consensus about the way things are, it’s consensus about terminology. The definition of prime numbers among the natural numbers, or among elements of other rings, is just that: a definition.\n\nThere do exist terms in math that don’t have a single, agreed-upon definition, and writers must clarify what they mean when they use such terms. This isn’t one of them. Literally nobody nowadays considers 1 to be a prime number. The last serious mathematician I’m aware of who did was D. N. Lehmer\n, who passed away in 1938.\n\nI’m aware that I can’t speak for all mathematicians, and I didn’t survey every single living one. But I can assert that if anyone used the opposite convention, it would be regarded as a strange and peculiar deviation from the norm, and they would be expected to explicitly and clearly clarify that they do (and why). Nobody who uses the ordinary definition needs to clarify that they do.', 'result': {'fake': 0.002, 'real': 0.998}, 'status': 'success'}], 'credits_used': 2, 'credits': 1994769, 'subscription': 0, 'content': 'Yes. Unequivocally, totally and completely.\n\nJust to be clear, this isn’t a consensus about the way things are, it’s consensus about terminology. The definition of prime numbers among the natural numbers, or among elements of other rings, is just that: a definition.\n\nThere do exist terms in math that don’t have a single, agreed-upon definition, and writers must clarify what they mean when they use such terms. This isn’t one of them. Literally nobody nowadays considers 1 to be a prime number. The last serious mathematician I’m aware of who did was D. N. Lehmer\n, who passed away in 1938.\n\nI’m aware that I can’t speak for all mathematicians, and I didn’t survey every single living one. But I can assert that if anyone used the opposite convention, it would be regarded as a strange and peculiar deviation from the norm, and they would be expected to explicitly and clearly clarify that they do (and why). Nobody who uses the ordinary definition needs to clarify that they do.', 'aiModelVersion': '1'}",0.998
Susanna Viljanen,6mo,Who discovered zero (0)?,"Zero is a discovery which has been made independently in several places around the world.

Ancient Egyptian numerals were of base 10. They used hieroglyphs for the digits and were not positional. By 1770 BC, the Egyptians had a symbol for zero in accounting texts. This is the oldest referral on nought.

By 1500 BC, the Babylonian mathematics had a sophisticated base 60 positional numeral system. The lack of a positional value (or zero) was indicated by a space between sexagesimal numerals. By 300 BC, a punctuation symbol (two slanted wedges) was co-opted to serve as this placeholder. The Babylonian placeholder was not a true zero because it was not used alone, nor was it used at the end of a number. Thus numbers like 2 and 120 (2×60), 3 and 180 (3×60), 4 and 240 (4×60) looked the same, because the larger numbers lacked a final sexagesimal placeholder.

The ancient Greeks had no symbol for zero, and did not use a digit placeholder for it. 
They used letters to denote numbers. The Classical Greeks did begin to adopt the Babylonian placeholder zero for their work in astronomy after 500 BC, representing it with the lowercase Greek letter ό (όμικρον) or omicron. However, after using the Babylonian placeholder zero for astronomical calculations they would typically convert the numbers back into Greek letter numerals. Greeks seemed to have a philosophical opposition to using zero as a number. Some of them asked themselves, ""How can not being be?"", leading to philosophical arguments about the nature and existence of zero and the vacuum. The paradoxes of Zeno depend in large part on the uncertain interpretation of zero.

In India, Pingala (c. 3rd/2nd century BC), used the Sanskrit word śūnya explicitly to refer to zero. He also realized that non-existence exists and came up with a symbol for zero, a large dot. It is likely to be the precursor of the still-current hollow symbol, and is used throughout the Bakhshali manuscript, a practical manual on arithmetic for merchants. In 2017, three samples from the manuscript were shown by radiocarbon dating to come from three different centuries: from AD 224–383, AD 680–779, and AD 885–993, making it South Asia's oldest recorded use of the zero symbol.

India can be considered as the true birthplace of zero as a placeholder.

Meanwhile in China, the 4th century BC Chinese counting rods system enabled one to perform decimal calculations, and like the Babylonians, they represented zero as an empty space. According to A History of Mathematics, the rods ""gave the decimal representation of a number, with an empty space denoting zero"". The counting rod system is considered a positional notation system. In AD 690, Empress Wǔ promulgated Zetian characters, one of which was ""〇""; originally meaning 'star', it subsequently came to represent zero. It was not treated as a number at that time, but as a ""vacant position"". Later, the character 零 came to mean “zero”.

The Roman numbers did not originally have a cipher for zero, but the Latin language knows the concepts nullus (“none”), sine (“without”) and nihil (“not anything”). Zero was known as a legal concept as nullus rather than as a mathematical concept. But in the Dark Ages, mathematician Dionysius Exiguus was the first Westerner to use a mathematical cipher for “nothing”. He used the letter N to denote zero on the Easter computus formula from 536 AD for Roman numerals. Also Bede Venerabilis uses N to denote zero in 725 AD.

The Indians were first to discover the sum, multiplication and subtraction with zero, and also that zero divided by anything is zero.

The Arabs conquered much of India in the 8th century, and also they assumed the positional system and the concept of zero. They invented the Arabic numbers, and Muḥammad ibn Mūsā al-Khwārizmī, using Hindu numerals; and about 825, he published a book synthesizing Greek and Hindu knowledge and also contained his own contribution to mathematics including an explanation of the use of zero. This book was later translated into Latin in the 12th century under the title Algoritmi de numero Indorum. This title means ""al-Khwarizmi on the Numerals of the Indians"". The word ""Algoritmi"" was the translator's Latinization of Al-Khwarizmi's name, and the word ""Algorithm"" or ""Algorism"" started to acquire a meaning of any arithmetic based on decimals.

Muhammad ibn Ahmad al-Khwarizmi, in 976, stated that if no number appears in the place of tens in a calculation, a little circle should be used ""to keep the rows"". This circle was called ṣifr. This word is the stem for “cipher” and “zero”, and it is a convergent evolution to the Chinese little circle for “nothing”.

The Arabic numerals spred to Europe by 1150, and they superseded exceedingly fast the Roman numerals. They were in almost universal use by 1200, with the Roman numerals being used only on specific purposes, such as ordinal numbers. The Europeans also adopted the positional system, and the small circle which the Arabs had used, now grew into a full sized ‘0’. It got the Latin name nullus (from which English and German ‘null’, Italian “nullo”, Swedish ‘noll’, Finnish ‘nolla’ etc), but also the Arabic name ṣifr was adopted as “zero” or “cero” in various languages.

Meanwhile in the Americas, the Maya discovered the concept of zero independently. The Mesoamerican Long Count calendar developed in south-central Mexico and Central America required the use of zero as a placeholder within its base-20 positional numeral system. Many different glyphs, including the partial quatrefoil were used as a zero symbol for these Long Count dates, the earliest has a date of 36 BC. It is generally believed that the use of zero in the Americas predated the Maya and was possibly the invention of the Olmecs.

Although zero became an integral part of Maya numerals, with a different, empty shell shape used for many depictions of the ""zero"" numeral, it is assumed not to have influenced Old World numeral systems nor been adopted from them.

0 - Wikipedia
Number This article is about the number. Natural number Cardinal 0, zero, ""oh"" ( / oʊ / ) , nought, naught, nil Ordinal Zeroth, noughth, 0th Latin prefix nulli- Binary 0 2 Ternary 0 3 Senary 0 6 Octal 0 8 Duodecimal 0 12 Hexadecimal 0 16 Arabic , Kurdish , Persian , Sindhi , Urdu ٠ Hindu numerals ० Chinese 零, 〇 Burmese ၀ Khmer ០ Thai ๐ Assamese, Bengali ০ 0 ( zero ) is a number representing an empty quantity . Adding 0 to any number leaves that number unchanged. In mathematical terminology, 0 is the additive identity of the integers , rational numbers , real numbers , and complex numbers , as well as other algebraic structures . Multiplying any number by 0 has the result 0, and consequently, division by zero has no meaning in arithmetic . As a numerical digit , 0 plays a crucial role in decimal notation: it indicates that the power of ten corresponding to the place containing a 0 does not contribute to the total. For example, "" 205 "" in decimal means two hundreds, no tens, and five ones. The same principle applies in place-value notations that uses a base other than ten, such as binary and hexadecimal . The modern use of 0 in this manner derives from Indian mathematics that was transmitted to Europe via medieval Islamic mathematicians and popularized by Fibonacci . It was independently used by the Maya . Common names for the number 0 in English include zero , nought , naught ( / n ɔː t / ), and nil . In contexts where at least one adjacent digit distinguishes it from the letter O , the number is sometimes pronounced as oh or o ( / oʊ / ). Informal or slang terms for 0 include zilch and zip . Historically, ought , aught ( / ɔː t / ), and cipher have also been used. Etymology The word zero came into the English language via French zéro from the Italian zero , a contraction of the Venetian zevero form of Italian zefiro via ṣafira or ṣifr . [1] In pre-Islamic time the word ṣifr (Arabic صفر ) had the meaning ""empty"". [2] Sifr evolved to mean zero when it was used to translate śūnya ( Sanskrit : शून्य ) from India. [2] The first known English use of zero was in 1598. [3] The Italian mathematician Fibonacci ( c. 1170 – c. 1250 ), who grew up in North Africa and is credited with introducing the decimal system to Europe, used the term zephyrum . This became zefiro in Italian, and was then contracted to zero in Venetian. The Italian word zefiro was already in existence (meaning ""west wind"" from Latin and Greek Zephyrus ) and may have influenced the spelling when transcribing Arabic ṣifr . [4] Modern usage Depending on the context, there may be different words used for the number zero, or the concept of zero. For the simple notion of lacking, the words ""nothing"" and ""none"" are often used. The British English words ""nought"" or ""naught"" , and "" nil "" are also synonymous. [5] [6] It is often called ""oh"" in the context of reading out a string of digits, such as telephone numbers , street addresses , credit card numbers , military time , or years. For example, t
https://en.wikipedia.org/wiki/0","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/isdcvkw4z0aerng3', 'title': 'Who discovered zero (0)?', 'score': {'original': 0.85245, 'ai': 0.14755}, 'blocks': [{'text': 'Zero is a discovery which has been made independently in several places around the world.\n\nAncient Egyptian numerals were of base 10. They used hieroglyphs for the digits and were not positional. By 1770 BC, the Egyptians had a symbol for zero in accounting texts. This is the oldest referral on nought.\n\nBy 1500 BC, the Babylonian mathematics had a sophisticated base 60 positional numeral system. The lack of a positional value (or zero) was indicated by a space between sexagesimal numerals. By 300 BC, a punctuation symbol (two slanted wedges) was co-opted to serve as this placeholder. The Babylonian placeholder was not a true zero because it was not used alone, nor was it used at the end of a number. Thus numbers like 2 and 120 (2×60), 3 and 180 (3×60), 4 and 240 (4×60) looked the same, because the larger numbers lacked a final sexagesimal placeholder.\n\nThe ancient Greeks had no symbol for zero, and did not use a digit placeholder for it. \nThey used letters to denote numbers. The Classical Greeks did begin to adopt the Babylonian placeholder zero for their work in astronomy after 500 BC, representing it with the lowercase Greek letter ό (όμικρον) or omicron. However, after using the Babylonian placeholder zero for astronomical calculations they would typically convert the numbers back into Greek letter numerals. Greeks seemed to have a philosophical opposition to using zero as a number. Some of them asked themselves, ""How can not being be?"", leading to philosophical arguments about the nature and existence of zero and the vacuum. The paradoxes of Zeno depend in large part on the uncertain interpretation of zero.\n\nIn India, Pingala (c. 3rd/2nd century BC), used the Sanskrit word śūnya explicitly to refer to zero. He also realized that non-existence exists and came up with a symbol for zero, a large dot. It is likely to be the precursor of the still-current hollow symbol, and is used throughout the Bakhshali manuscript, a practical manual on arithmetic for merchants. In 2017, three samples from the manuscript were shown by radiocarbon dating to come from three different centuries: from AD 224–383, AD 680–779, and AD 885–993, making it South Asia\'s oldest recorded use of the zero symbol.\n\nIndia can be considered as the true birthplace of zero as a placeholder.\n\nMeanwhile in China, the 4th century BC Chinese counting rods system enabled one to perform decimal calculations, and like the Babylonians, they represented zero as an empty space. According to A History of Mathematics, the rods ""gave the decimal representation of a number, with an empty space denoting zero"". The counting rod system is considered a positional notation system. In AD 690, Empress Wǔ promulgated Zetian characters, one of which was ""〇""; originally meaning \'star\', it subsequently came to represent zero. It was not treated as a number at that time, but as a ""vacant position"". Later, the character 零 came to mean “zero”.\n\nThe Roman numbers did not originally have a cipher for zero, but the Latin language knows the concepts nullus (“none”), sine (“without”) and nihil (“not anything”). Zero was known as a', 'result': {'fake': 0.5399, 'real': 0.4601}, 'status': 'success'}, {'text': 'legal concept as nullus rather than as a mathematical concept. But in the Dark Ages, mathematician Dionysius Exiguus was the first Westerner to use a mathematical cipher for “nothing”. He used the letter N to denote zero on the Easter computus formula from 536 AD for Roman numerals. Also Bede Venerabilis uses N to denote zero in 725 AD.\n\nThe Indians were first to discover the sum, multiplication and subtraction with zero, and also that zero divided by anything is zero.\n\nThe Arabs conquered much of India in the 8th century, and also they assumed the positional system and the concept of zero. They invented the Arabic numbers, and Muḥammad ibn Mūsā al-Khwārizmī, using Hindu numerals; and about 825, he published a book synthesizing Greek and Hindu knowledge and also contained his own contribution to mathematics including an explanation of the use of zero. This book was later translated into Latin in the 12th century under the title Algoritmi de numero Indorum. This title means ""al-Khwarizmi on the Numerals of the Indians"". The word ""Algoritmi"" was the translator\'s Latinization of Al-Khwarizmi\'s name, and the word ""Algorithm"" or ""Algorism"" started to acquire a meaning of any arithmetic based on decimals.\n\nMuhammad ibn Ahmad al-Khwarizmi, in 976, stated that if no number appears in the place of tens in a calculation, a little circle should be used ""to keep the rows"". This circle was called ṣifr. This word is the stem for “cipher” and “zero”, and it is a convergent evolution to the Chinese little circle for “nothing”.\n\nThe Arabic numerals spred to Europe by 1150, and they superseded exceedingly fast the Roman numerals. They were in almost universal use by 1200, with the Roman numerals being used only on specific purposes, such as ordinal numbers. The Europeans also adopted the positional system, and the small circle which the Arabs had used, now grew into a full sized ‘0’. It got the Latin name nullus (from which English and German ‘null’, Italian “nullo”, Swedish ‘noll’, Finnish ‘nolla’ etc), but also the Arabic name ṣifr was adopted as “zero” or “cero” in various languages.\n\nMeanwhile in the Americas, the Maya discovered the concept of zero independently. The Mesoamerican Long Count calendar developed in south-central Mexico and Central America required the use of zero as a placeholder within its base-20 positional numeral system. Many different glyphs, including the partial quatrefoil were used as a zero symbol for these Long Count dates, the earliest has a date of 36 BC. It is generally believed that the use of zero in the Americas predated the Maya and was possibly the invention of the Olmecs.\n\nAlthough zero became an integral part of Maya numerals, with a different, empty shell shape used for many depictions of the ""zero"" numeral, it is assumed not to have influenced Old World numeral systems nor been adopted from them.\n\n0 - Wikipedia\nNumber This article is about the number. Natural number Cardinal 0, zero, ""oh"" ( / oʊ / ) , nought, naught, nil Ordinal Zeroth, noughth, 0th Latin prefix nulli- Binary 0 2 Ternary 0 3 Senary 0 6 Octal 0', 'result': {'fake': 0.3895, 'real': 0.6105}, 'status': 'success'}, {'text': '8 Duodecimal 0 12 Hexadecimal 0 16 Arabic , Kurdish , Persian , Sindhi , Urdu ٠ Hindu numerals ० Chinese 零, 〇 Burmese ၀ Khmer ០ Thai ๐ Assamese, Bengali ০ 0 ( zero ) is a number representing an empty quantity . Adding 0 to any number leaves that number unchanged. In mathematical terminology, 0 is the additive identity of the integers , rational numbers , real numbers , and complex numbers , as well as other algebraic structures . Multiplying any number by 0 has the result 0, and consequently, division by zero has no meaning in arithmetic . As a numerical digit , 0 plays a crucial role in decimal notation: it indicates that the power of ten corresponding to the place containing a 0 does not contribute to the total. For example, "" 205 "" in decimal means two hundreds, no tens, and five ones. The same principle applies in place-value notations that uses a base other than ten, such as binary and hexadecimal . The modern use of 0 in this manner derives from Indian mathematics that was transmitted to Europe via medieval Islamic mathematicians and popularized by Fibonacci . It was independently used by the Maya . Common names for the number 0 in English include zero , nought , naught ( / n ɔː t / ), and nil . In contexts where at least one adjacent digit distinguishes it from the letter O , the number is sometimes pronounced as oh or o ( / oʊ / ). Informal or slang terms for 0 include zilch and zip . Historically, ought , aught ( / ɔː t / ), and cipher have also been used. Etymology The word zero came into the English language via French zéro from the Italian zero , a contraction of the Venetian zevero form of Italian zefiro via ṣafira or ṣifr . [1] In pre-Islamic time the word ṣifr (Arabic صفر ) had the meaning ""empty"". [2] Sifr evolved to mean zero when it was used to translate śūnya ( Sanskrit : शून्य ) from India. [2] The first known English use of zero was in 1598. [3] The Italian mathematician Fibonacci ( c. 1170 – c. 1250 ), who grew up in North Africa and is credited with introducing the decimal system to Europe, used the term zephyrum . This became zefiro in Italian, and was then contracted to zero in Venetian. The Italian word zefiro was already in existence (meaning ""west wind"" from Latin and Greek Zephyrus ) and may have influenced the spelling when transcribing Arabic ṣifr . [4] Modern usage Depending on the context, there may be different words used for the number zero, or the concept of zero. For the simple notion of lacking, the words ""nothing"" and ""none"" are often used. The British English words ""nought"" or ""naught"" , and "" nil "" are also synonymous. [5] [6] It is often called ""oh"" in the context of reading out a string of digits, such as telephone numbers , street addresses , credit', 'result': {'fake': 0.2897, 'real': 0.7103}, 'status': 'success'}, {'text': 'card numbers , military time , or years. For example, t\nhttps://en.wikipedia.org/wiki/0', 'result': {'fake': 0.5229, 'real': 0.4771}, 'status': 'success'}], 'credits_used': 15, 'credits': 1994754, 'subscription': 0, 'content': 'Zero is a discovery which has been made independently in several places around the world.\n\nAncient Egyptian numerals were of base 10. They used hieroglyphs for the digits and were not positional. By 1770 BC, the Egyptians had a symbol for zero in accounting texts. This is the oldest referral on nought.\n\nBy 1500 BC, the Babylonian mathematics had a sophisticated base 60 positional numeral system. The lack of a positional value (or zero) was indicated by a space between sexagesimal numerals. By 300 BC, a punctuation symbol (two slanted wedges) was co-opted to serve as this placeholder. The Babylonian placeholder was not a true zero because it was not used alone, nor was it used at the end of a number. Thus numbers like 2 and 120 (2×60), 3 and 180 (3×60), 4 and 240 (4×60) looked the same, because the larger numbers lacked a final sexagesimal placeholder.\n\nThe ancient Greeks had no symbol for zero, and did not use a digit placeholder for it. \nThey used letters to denote numbers. The Classical Greeks did begin to adopt the Babylonian placeholder zero for their work in astronomy after 500 BC, representing it with the lowercase Greek letter ό (όμικρον) or omicron. However, after using the Babylonian placeholder zero for astronomical calculations they would typically convert the numbers back into Greek letter numerals. Greeks seemed to have a philosophical opposition to using zero as a number. Some of them asked themselves, ""How can not being be?"", leading to philosophical arguments about the nature and existence of zero and the vacuum. The paradoxes of Zeno depend in large part on the uncertain interpretation of zero.\n\nIn India, Pingala (c. 3rd/2nd century BC), used the Sanskrit word śūnya explicitly to refer to zero. He also realized that non-existence exists and came up with a symbol for zero, a large dot. It is likely to be the precursor of the still-current hollow symbol, and is used throughout the Bakhshali manuscript, a practical manual on arithmetic for merchants. In 2017, three samples from the manuscript were shown by radiocarbon dating to come from three different centuries: from AD 224–383, AD 680–779, and AD 885–993, making it South Asia\'s oldest recorded use of the zero symbol.\n\nIndia can be considered as the true birthplace of zero as a placeholder.\n\nMeanwhile in China, the 4th century BC Chinese counting rods system enabled one to perform decimal calculations, and like the Babylonians, they represented zero as an empty space. According to A History of Mathematics, the rods ""gave the decimal representation of a number, with an empty space denoting zero"". The counting rod system is considered a positional notation system. In AD 690, Empress Wǔ promulgated Zetian characters, one of which was ""〇""; originally meaning \'star\', it subsequently came to represent zero. It was not treated as a number at that time, but as a ""vacant position"". Later, the character 零 came to mean “zero”.\n\nThe Roman numbers did not originally have a cipher for zero, but the Latin language knows the concepts nullus (“none”), sine (“without”) and nihil (“not anything”). Zero was known as a legal concept as nullus rather than as a mathematical concept. But in the Dark Ages, mathematician Dionysius Exiguus was the first Westerner to use a mathematical cipher for “nothing”. He used the letter N to denote zero on the Easter computus formula from 536 AD for Roman numerals. Also Bede Venerabilis uses N to denote zero in 725 AD.\n\nThe Indians were first to discover the sum, multiplication and subtraction with zero, and also that zero divided by anything is zero.\n\nThe Arabs conquered much of India in the 8th century, and also they assumed the positional system and the concept of zero. They invented the Arabic numbers, and Muḥammad ibn Mūsā al-Khwārizmī, using Hindu numerals; and about 825, he published a book synthesizing Greek and Hindu knowledge and also contained his own contribution to mathematics including an explanation of the use of zero. This book was later translated into Latin in the 12th century under the title Algoritmi de numero Indorum. This title means ""al-Khwarizmi on the Numerals of the Indians"". The word ""Algoritmi"" was the translator\'s Latinization of Al-Khwarizmi\'s name, and the word ""Algorithm"" or ""Algorism"" started to acquire a meaning of any arithmetic based on decimals.\n\nMuhammad ibn Ahmad al-Khwarizmi, in 976, stated that if no number appears in the place of tens in a calculation, a little circle should be used ""to keep the rows"". This circle was called ṣifr. This word is the stem for “cipher” and “zero”, and it is a convergent evolution to the Chinese little circle for “nothing”.\n\nThe Arabic numerals spred to Europe by 1150, and they superseded exceedingly fast the Roman numerals. They were in almost universal use by 1200, with the Roman numerals being used only on specific purposes, such as ordinal numbers. The Europeans also adopted the positional system, and the small circle which the Arabs had used, now grew into a full sized ‘0’. It got the Latin name nullus (from which English and German ‘null’, Italian “nullo”, Swedish ‘noll’, Finnish ‘nolla’ etc), but also the Arabic name ṣifr was adopted as “zero” or “cero” in various languages.\n\nMeanwhile in the Americas, the Maya discovered the concept of zero independently. The Mesoamerican Long Count calendar developed in south-central Mexico and Central America required the use of zero as a placeholder within its base-20 positional numeral system. Many different glyphs, including the partial quatrefoil were used as a zero symbol for these Long Count dates, the earliest has a date of 36 BC. It is generally believed that the use of zero in the Americas predated the Maya and was possibly the invention of the Olmecs.\n\nAlthough zero became an integral part of Maya numerals, with a different, empty shell shape used for many depictions of the ""zero"" numeral, it is assumed not to have influenced Old World numeral systems nor been adopted from them.\n\n0 - Wikipedia\nNumber This article is about the number. Natural number Cardinal 0, zero, ""oh"" ( / oʊ / ) , nought, naught, nil Ordinal Zeroth, noughth, 0th Latin prefix nulli- Binary 0 2 Ternary 0 3 Senary 0 6 Octal 0 8 Duodecimal 0 12 Hexadecimal 0 16 Arabic , Kurdish , Persian , Sindhi , Urdu ٠ Hindu numerals ० Chinese 零, 〇 Burmese ၀ Khmer ០ Thai ๐ Assamese, Bengali ০ 0 ( zero ) is a number representing an empty quantity . Adding 0 to any number leaves that number unchanged. In mathematical terminology, 0 is the additive identity of the integers , rational numbers , real numbers , and complex numbers , as well as other algebraic structures . Multiplying any number by 0 has the result 0, and consequently, division by zero has no meaning in arithmetic . As a numerical digit , 0 plays a crucial role in decimal notation: it indicates that the power of ten corresponding to the place containing a 0 does not contribute to the total. For example, "" 205 "" in decimal means two hundreds, no tens, and five ones. The same principle applies in place-value notations that uses a base other than ten, such as binary and hexadecimal . The modern use of 0 in this manner derives from Indian mathematics that was transmitted to Europe via medieval Islamic mathematicians and popularized by Fibonacci . It was independently used by the Maya . Common names for the number 0 in English include zero , nought , naught ( / n ɔː t / ), and nil . In contexts where at least one adjacent digit distinguishes it from the letter O , the number is sometimes pronounced as oh or o ( / oʊ / ). Informal or slang terms for 0 include zilch and zip . Historically, ought , aught ( / ɔː t / ), and cipher have also been used. Etymology The word zero came into the English language via French zéro from the Italian zero , a contraction of the Venetian zevero form of Italian zefiro via ṣafira or ṣifr . [1] In pre-Islamic time the word ṣifr (Arabic صفر ) had the meaning ""empty"". [2] Sifr evolved to mean zero when it was used to translate śūnya ( Sanskrit : शून्य ) from India. [2] The first known English use of zero was in 1598. [3] The Italian mathematician Fibonacci ( c. 1170 – c. 1250 ), who grew up in North Africa and is credited with introducing the decimal system to Europe, used the term zephyrum . This became zefiro in Italian, and was then contracted to zero in Venetian. The Italian word zefiro was already in existence (meaning ""west wind"" from Latin and Greek Zephyrus ) and may have influenced the spelling when transcribing Arabic ṣifr . [4] Modern usage Depending on the context, there may be different words used for the number zero, or the concept of zero. For the simple notion of lacking, the words ""nothing"" and ""none"" are often used. The British English words ""nought"" or ""naught"" , and "" nil "" are also synonymous. [5] [6] It is often called ""oh"" in the context of reading out a string of digits, such as telephone numbers , street addresses , credit card numbers , military time , or years. For example, t\nhttps://en.wikipedia.org/wiki/0', 'aiModelVersion': '1'}",0.85245
Alon Amit,4y,What is the first discovered math formula that is still in use today?,"Nobody knows which math formula was discovered when, but the Pythagorean theorem asserting that 
a
2
+
b
2
=
c
2
a2+b2=c2
 whenever 
a
,
b
a,b
 are the sides of a right triangle and 
c
c
 its hypotenuse is a strong contender, and it’s still in use today – for example, every time a graphic or industrial designer uses a graphic editor to draw a circle on the screen, marking off the center and some point for the circle to pass through.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/d40hbepmfu5j8n6l', 'title': 'What is the first discovered math formula that is still in use today?', 'score': {'original': 0.9743, 'ai': 0.0257}, 'blocks': [{'text': 'Nobody knows which math formula was discovered when, but the Pythagorean theorem asserting that \na\n2\n+\nb\n2\n=\nc\n2\na2+b2=c2\n whenever \na\n,\nb\na,b\n are the sides of a right triangle and \nc\nc\n its hypotenuse is a strong contender, and it’s still in use today – for example, every time a graphic or industrial designer uses a graphic editor to draw a circle on the screen, marking off the center and some point for the circle to pass through.', 'result': {'fake': 0.0257, 'real': 0.9743}, 'status': 'success'}], 'credits_used': 1, 'credits': 1994753, 'subscription': 0, 'content': 'Nobody knows which math formula was discovered when, but the Pythagorean theorem asserting that \na\n2\n+\nb\n2\n=\nc\n2\na2+b2=c2\n whenever \na\n,\nb\na,b\n are the sides of a right triangle and \nc\nc\n its hypotenuse is a strong contender, and it’s still in use today – for example, every time a graphic or industrial designer uses a graphic editor to draw a circle on the screen, marking off the center and some point for the circle to pass through.', 'aiModelVersion': '1'}",0.9743
Alon Amit,5y,What’s a math problem we thought was unsolvable which was then solved?,"The “we thought was unsolvable” part is quite vague. There were many problems which some people thought were unsolvable in some sense, and were later solved. People may have lost hope, considered the problems too hard, or (more recently) entertained the possibility that certain problems are undecidable in ZFC.

So it’s hard to answer the question definitively, but anyway, here are a couple of possible examples:

For millennia, it was believed by many that higher-order polynomial equations (cubic ones, and above) cannot be solved using radical expressions. Eventually, suitable formulas for cubic and quartic equations were found in the 16th century (del Ferro
, Tartaglia
)
Explicit formulas for the sums 
ζ
(
k
)
=
∑
n
1
/
n
k
ζ(k)=∑n1/nk
 were known for even values of the integer 
k
k
 since Euler in the early 18th century. For odd values, nothing was known, and I believe by the late 20th century many people lost hope that we could say anything meaningful about these numbers. When Roger Apéry proved, in 1979, that 
ζ
(
3
)
ζ(3)
 is irrational, this was a complete sensation.
In 1922, L. J. Mordell
 conjectured that curves of genus greater than 1 over the rational numbers can only have finitely many rational points. The story I’ve heard was that he never officially “conjectured” this: he mentioned it as a possibility in a paper, and later clarified that he had no reason to believe it’s true or that it’s amenable to any known method (it’s a hard problem). In fact, until the moment the conjecture was resolved, there wasn’t a single curve for which it was known to be true. But in 1983 Gerd Faltings
 proved the conjecture in full.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/kti7cud6hfj9aw43', 'title': 'What’s a math problem we thought was unsolvable which was then solved?', 'score': {'original': 0.9996, 'ai': 0.0004}, 'blocks': [{'text': 'The “we thought was unsolvable” part is quite vague. There were many problems which some people thought were unsolvable in some sense, and were later solved. People may have lost hope, considered the problems too hard, or (more recently) entertained the possibility that certain problems are undecidable in ZFC.\n\nSo it’s hard to answer the question definitively, but anyway, here are a couple of possible examples:\n\nFor millennia, it was believed by many that higher-order polynomial equations (cubic ones, and above) cannot be solved using radical expressions. Eventually, suitable formulas for cubic and quartic equations were found in the 16th century (del Ferro\n, Tartaglia\n)\nExplicit formulas for the sums \nζ\n(\nk\n)\n=\n∑\nn\n1\n/\nn\nk\nζ(k)=∑n1/nk\n were known for even values of the integer \nk\nk\n since Euler in the early 18th century. For odd values, nothing was known, and I believe by the late 20th century many people lost hope that we could say anything meaningful about these numbers. When Roger Apéry proved, in 1979, that \nζ\n(\n3\n)\nζ(3)\n is irrational, this was a complete sensation.\nIn 1922, L. J. Mordell\n conjectured that curves of genus greater than 1 over the rational numbers can only have finitely many rational points. The story I’ve heard was that he never officially “conjectured” this: he mentioned it as a possibility in a paper, and later clarified that he had no reason to believe it’s true or that it’s amenable to any known method (it’s a hard problem). In fact, until the moment the conjecture was resolved, there wasn’t a single curve for which it was known to be true. But in 1983 Gerd Faltings\n proved the conjecture in full.', 'result': {'fake': 0.0004, 'real': 0.9996}, 'status': 'success'}], 'credits_used': 3, 'credits': 1994750, 'subscription': 0, 'content': 'The “we thought was unsolvable” part is quite vague. There were many problems which some people thought were unsolvable in some sense, and were later solved. People may have lost hope, considered the problems too hard, or (more recently) entertained the possibility that certain problems are undecidable in ZFC.\n\nSo it’s hard to answer the question definitively, but anyway, here are a couple of possible examples:\n\nFor millennia, it was believed by many that higher-order polynomial equations (cubic ones, and above) cannot be solved using radical expressions. Eventually, suitable formulas for cubic and quartic equations were found in the 16th century (del Ferro\n, Tartaglia\n)\nExplicit formulas for the sums \nζ\n(\nk\n)\n=\n∑\nn\n1\n/\nn\nk\nζ(k)=∑n1/nk\n were known for even values of the integer \nk\nk\n since Euler in the early 18th century. For odd values, nothing was known, and I believe by the late 20th century many people lost hope that we could say anything meaningful about these numbers. When Roger Apéry proved, in 1979, that \nζ\n(\n3\n)\nζ(3)\n is irrational, this was a complete sensation.\nIn 1922, L. J. Mordell\n conjectured that curves of genus greater than 1 over the rational numbers can only have finitely many rational points. The story I’ve heard was that he never officially “conjectured” this: he mentioned it as a possibility in a paper, and later clarified that he had no reason to believe it’s true or that it’s amenable to any known method (it’s a hard problem). In fact, until the moment the conjecture was resolved, there wasn’t a single curve for which it was known to be true. But in 1983 Gerd Faltings\n proved the conjecture in full.', 'aiModelVersion': '1'}",0.9996
James Fullwood,Updated 4y,Is it true that Calculus is child’s play to a mathematician?,"Calculus is math that is often taught in high-school.

Moreover, mathematicians have taken a full undergraduate curriculum of math courses more advanced than calculus, a graduate curriculum of even more advanced math courses, and then have since moved on to doing research at the forefront of modern day mathematics.

Now this is not to say that a mathematician could do any calculus problem with ease. In any field of mathematics you can formulate problems of arbitrary levels of difficulty. Fermat’s Last Theorem after all, which was a statement in arithmetic, took mathematicians over 300 years to solve.

In any case, the answer is yes, the mathematical concepts at the basis of calculus are like “child's play” for a mathematician. We don't view it much different than highschool algebra.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/fwldgsut9m4joixa', 'title': 'Is it true that Calculus is child’s play to a mathematician?', 'score': {'original': 0.9968, 'ai': 0.0032}, 'blocks': [{'text': ""Calculus is math that is often taught in high-school.\n\nMoreover, mathematicians have taken a full undergraduate curriculum of math courses more advanced than calculus, a graduate curriculum of even more advanced math courses, and then have since moved on to doing research at the forefront of modern day mathematics.\n\nNow this is not to say that a mathematician could do any calculus problem with ease. In any field of mathematics you can formulate problems of arbitrary levels of difficulty. Fermat’s Last Theorem after all, which was a statement in arithmetic, took mathematicians over 300 years to solve.\n\nIn any case, the answer is yes, the mathematical concepts at the basis of calculus are like “child's play” for a mathematician. We don't view it much different than highschool algebra."", 'result': {'fake': 0.0032, 'real': 0.9968}, 'status': 'success'}], 'credits_used': 2, 'credits': 1994748, 'subscription': 0, 'content': ""Calculus is math that is often taught in high-school.\n\nMoreover, mathematicians have taken a full undergraduate curriculum of math courses more advanced than calculus, a graduate curriculum of even more advanced math courses, and then have since moved on to doing research at the forefront of modern day mathematics.\n\nNow this is not to say that a mathematician could do any calculus problem with ease. In any field of mathematics you can formulate problems of arbitrary levels of difficulty. Fermat’s Last Theorem after all, which was a statement in arithmetic, took mathematicians over 300 years to solve.\n\nIn any case, the answer is yes, the mathematical concepts at the basis of calculus are like “child's play” for a mathematician. We don't view it much different than highschool algebra."", 'aiModelVersion': '1'}",0.9968
Senia Sheydvasser,5y,"Did mathematicians consider non-positive definite quadratic forms for the distance squared before Minkowski proposed his metric for Special Relativity? The Minkowski distance squared can be positive, negative or zero.","Overall, I agree with Viktor T. Toth's answer, but I think that the mathematical roots can be traced further back still. In particular, I would at the very least place it in 1848, with James Cockle’s introduction of what he called the real tessarines, nowadays known as the split-complex numbers. These were analogous to complex numbers, consisting of elements a+bia+bia + bi, where a,ba,ba,b were real, but the rules for multiplication were ever so slightly different in that i2=1i2=1i^2 = 1, rather than i2=−1i2=−1i^2 = -1. This slight tweak was important, because while the norm on the complex numbers is the positive definite quadratic form a+bi↦a2+b2a+bi↦a2+b2a + bi \mapsto a^2 + b^2, on the split complex numbers it is instead a+bi↦a2−b2a+bi↦a2−b2a + bi \mapsto a^2 - b^2. Today, we would recognize this as being nothing more than (1,1)(1,1)(1,1)-Minkowski space, but as you can see the basic idea is a fair bit older.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/5wysfrh7iplkex6u', 'title': 'Did mathematicians consider non-positive definite quadratic forms for the distance squared before Minkowski proposed his metric for Special Relativity? The Minkowski distance squared can be positive, negative or zero.', 'score': {'original': 0.7576, 'ai': 0.2424}, 'blocks': [{'text': ""Overall, I agree with Viktor T. Toth's answer, but I think that the mathematical roots can be traced further back still. In particular, I would at the very least place it in 1848, with James Cockle’s introduction of what he called the real tessarines, nowadays known as the split-complex numbers. These were analogous to complex numbers, consisting of elements a+bia+bia + bi, where a,ba,ba,b were real, but the rules for multiplication were ever so slightly different in that i2=1i2=1i^2 = 1, rather than i2=−1i2=−1i^2 = -1. This slight tweak was important, because while the norm on the complex numbers is the positive definite quadratic form a+bi↦a2+b2a+bi↦a2+b2a + bi \\mapsto a^2 + b^2, on the split complex numbers it is instead a+bi↦a2−b2a+bi↦a2−b2a + bi \\mapsto a^2 - b^2. Today, we would recognize this as being nothing more than (1,1)(1,1)(1,1)-Minkowski space, but as you can see the basic idea is a fair bit older."", 'result': {'fake': 0.2424, 'real': 0.7576}, 'status': 'success'}], 'credits_used': 2, 'credits': 1994746, 'subscription': 0, 'content': ""Overall, I agree with Viktor T. Toth's answer, but I think that the mathematical roots can be traced further back still. In particular, I would at the very least place it in 1848, with James Cockle’s introduction of what he called the real tessarines, nowadays known as the split-complex numbers. These were analogous to complex numbers, consisting of elements a+bia+bia + bi, where a,ba,ba,b were real, but the rules for multiplication were ever so slightly different in that i2=1i2=1i^2 = 1, rather than i2=−1i2=−1i^2 = -1. This slight tweak was important, because while the norm on the complex numbers is the positive definite quadratic form a+bi↦a2+b2a+bi↦a2+b2a + bi \\mapsto a^2 + b^2, on the split complex numbers it is instead a+bi↦a2−b2a+bi↦a2−b2a + bi \\mapsto a^2 - b^2. Today, we would recognize this as being nothing more than (1,1)(1,1)(1,1)-Minkowski space, but as you can see the basic idea is a fair bit older."", 'aiModelVersion': '1'}",0.7576
Alon Amit,Updated 4y,What are some famous mathematical inventions by more than one mathematician working together?,"Prior to the 20th century, collaboration in mathematics was rare. Things we know as carrying two names, like the Cayley-Hamilton theorem, are usually one person completing or extending the work of another, independently. (As is typical, the Cayley-Hamilton theorem as we know it today was proved by neither Cayley nor Hamilton, but by Frobenius.)

But in the last 100 years things changed dramatically. Tons of modern math were developed by pairs of people working together, and sometimes even larger groups.

A random sample of the large and small:

The fantastically fruitful theory of random graphs was initiated by Erdős and Renyi.
Bass-Serre theory[1] of groups acting on graphs was developed by Hyman Bass and J.-P. Serre.
Emil Artin and John Tate (advisor and student) developed together many things called Artin-Tate <something>.
The Baumslag-Solitar group was discovered (or invented, if you prefer) by, well, Baumslag and Solitar.
The Goldston-Pintz-Yıldırım breakthrough[2] in analytic number theory resulted from a close collaboration of geographically remote people. I recently had the honor of asking Dan Goldston himself about the history of the collaboration; in short, Goldston (California) and Yıldırım (Turkey) worked together since they met in Canada (Yıldırım was a student of Friedlander) and, after several years of collaboration, János Pintz heard about their progress through a lecture in Budapest (delivered by someone else!) and had ideas to help. History was made.
The proof of Fermat’s Last Theorem was actually split into two papers, one of which was the result of a close collaboration between Andrew Wiles and Richard Taylor.

There are many, many other examples of concepts, discoveries, theories and ideas developed by collaborative teams.

Footnotes

[1] Bass–Serre theory - Wikipedia
[2] http://www.ams.org/bull/2007-44-01/S0273-0979-06-01142-6/S0273-0979-06-01142-6.pdf","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/905x4c63m2ayjbqs', 'title': 'What are some famous mathematical inventions by more than one mathematician working together?', 'score': {'original': 0.9998, 'ai': 0.0002}, 'blocks': [{'text': 'Prior to the 20th century, collaboration in mathematics was rare. Things we know as carrying two names, like the Cayley-Hamilton theorem, are usually one person completing or extending the work of another, independently. (As is typical, the Cayley-Hamilton theorem as we know it today was proved by neither Cayley nor Hamilton, but by Frobenius.)\n\nBut in the last 100 years things changed dramatically. Tons of modern math were developed by pairs of people working together, and sometimes even larger groups.\n\nA random sample of the large and small:\n\nThe fantastically fruitful theory of random graphs was initiated by Erdős and Renyi.\nBass-Serre theory[1] of groups acting on graphs was developed by Hyman Bass and J.-P. Serre.\nEmil Artin and John Tate (advisor and student) developed together many things called Artin-Tate <something>.\nThe Baumslag-Solitar group was discovered (or invented, if you prefer) by, well, Baumslag and Solitar.\nThe Goldston-Pintz-Yıldırım breakthrough[2] in analytic number theory resulted from a close collaboration of geographically remote people. I recently had the honor of asking Dan Goldston himself about the history of the collaboration; in short, Goldston (California) and Yıldırım (Turkey) worked together since they met in Canada (Yıldırım was a student of Friedlander) and, after several years of collaboration, János Pintz heard about their progress through a lecture in Budapest (delivered by someone else!) and had ideas to help. History was made.\nThe proof of Fermat’s Last Theorem was actually split into two papers, one of which was the result of a close collaboration between Andrew Wiles and Richard Taylor.\n\nThere are many, many other examples of concepts, discoveries, theories and ideas developed by collaborative teams.\n\nFootnotes\n\n[1] Bass–Serre theory - Wikipedia\n[2] http://www.ams.org/bull/2007-44-01/S0273-0979-06-01142-6/S0273-0979-06-01142-6.pdf', 'result': {'fake': 0.0002, 'real': 0.9998}, 'status': 'success'}], 'credits_used': 4, 'credits': 1994742, 'subscription': 0, 'content': 'Prior to the 20th century, collaboration in mathematics was rare. Things we know as carrying two names, like the Cayley-Hamilton theorem, are usually one person completing or extending the work of another, independently. (As is typical, the Cayley-Hamilton theorem as we know it today was proved by neither Cayley nor Hamilton, but by Frobenius.)\n\nBut in the last 100 years things changed dramatically. Tons of modern math were developed by pairs of people working together, and sometimes even larger groups.\n\nA random sample of the large and small:\n\nThe fantastically fruitful theory of random graphs was initiated by Erdős and Renyi.\nBass-Serre theory[1] of groups acting on graphs was developed by Hyman Bass and J.-P. Serre.\nEmil Artin and John Tate (advisor and student) developed together many things called Artin-Tate <something>.\nThe Baumslag-Solitar group was discovered (or invented, if you prefer) by, well, Baumslag and Solitar.\nThe Goldston-Pintz-Yıldırım breakthrough[2] in analytic number theory resulted from a close collaboration of geographically remote people. I recently had the honor of asking Dan Goldston himself about the history of the collaboration; in short, Goldston (California) and Yıldırım (Turkey) worked together since they met in Canada (Yıldırım was a student of Friedlander) and, after several years of collaboration, János Pintz heard about their progress through a lecture in Budapest (delivered by someone else!) and had ideas to help. History was made.\nThe proof of Fermat’s Last Theorem was actually split into two papers, one of which was the result of a close collaboration between Andrew Wiles and Richard Taylor.\n\nThere are many, many other examples of concepts, discoveries, theories and ideas developed by collaborative teams.\n\nFootnotes\n\n[1] Bass–Serre theory - Wikipedia\n[2] http://www.ams.org/bull/2007-44-01/S0273-0979-06-01142-6/S0273-0979-06-01142-6.pdf', 'aiModelVersion': '1'}",0.9998
Alon Amit,2y,What is the name of the 19th century German mathematician?,"“The”…?

Gauss, Riemann, Hilbert, Dedekind, Dirichlet, Jacobi, Frobenius, Minkowski, Eisenstein, Kronecker, Weierstrass, Cantor, Fuchs, Kummer, Hurwitz, Klein, Stern, Gordan, Plücker, Clebsch, Roch, Grassmann, Weber or Schwarz fit the bill quite well.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/3518ao2cxdhfbk4u', 'title': 'What is the name of the 19th century German mathematician?', 'score': {'original': 0.7315, 'ai': 0.2685}, 'blocks': [{'text': '“The”…?\n\nGauss, Riemann, Hilbert, Dedekind, Dirichlet, Jacobi, Frobenius, Minkowski, Eisenstein, Kronecker, Weierstrass, Cantor, Fuchs, Kummer, Hurwitz, Klein, Stern, Gordan, Plücker, Clebsch, Roch, Grassmann, Weber or Schwarz fit the bill quite well.', 'result': {'fake': 0.2685, 'real': 0.7315}, 'status': 'success'}], 'credits_used': 1, 'credits': 1994741, 'subscription': 0, 'content': '“The”…?\n\nGauss, Riemann, Hilbert, Dedekind, Dirichlet, Jacobi, Frobenius, Minkowski, Eisenstein, Kronecker, Weierstrass, Cantor, Fuchs, Kummer, Hurwitz, Klein, Stern, Gordan, Plücker, Clebsch, Roch, Grassmann, Weber or Schwarz fit the bill quite well.', 'aiModelVersion': '1'}",0.7315
Scott Brickner,1y,"Why is the obelus ""÷"" symbol seldom used to denote the division operation in higher math?","Because it’s ambiguous. In some parts of Northern Europe, the same symbol occasionally denoted subtraction.

Its use was never particularly widespread in mathematics. It somehow caught on as notation used in teaching arithmetic in English-speaking countries. Elsewhere, it never caught on.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/9v6jbq5aeoyfixcl', 'title': 'Why is the obelus ""÷"" symbol seldom used to denote the division operation in higher math?', 'score': {'original': 0.9877, 'ai': 0.0123}, 'blocks': [{'text': 'Because it’s ambiguous. In some parts of Northern Europe, the same symbol occasionally denoted subtraction.\n\nIts use was never particularly widespread in mathematics. It somehow caught on as notation used in teaching arithmetic in English-speaking countries. Elsewhere, it never caught on.', 'result': {'fake': 0.0123, 'real': 0.9877}, 'status': 'success'}], 'credits_used': 1, 'credits': 1994740, 'subscription': 0, 'content': 'Because it’s ambiguous. In some parts of Northern Europe, the same symbol occasionally denoted subtraction.\n\nIts use was never particularly widespread in mathematics. It somehow caught on as notation used in teaching arithmetic in English-speaking countries. Elsewhere, it never caught on.', 'aiModelVersion': '1'}",0.9877
Alon Amit,7y,Does Alon Amit fully understand the Wiles - Taylor proof of Fermat's Last Theorem?,"Oh goodness. I wish. When I was a graduate student I took every Number Theory, Algebraic Geometry and Representation Theory course I could find, specifically trying to learn everything Ehud de Shalit was teaching. He's one of very few people mentioned by Wiles in the Annals paper containing the proof, but this wasn't even the main reason: de Shalit is a phenomenal teacher, an outstanding researcher, and this domain of mathematics attracts me like no other.  I took the basic graduate-level courses in commutative algebra and number theory. I took Algebraic Number Theory, two courses on Elliptic Curves, and a course on ppp-adic analysis – all of these with de Shalit. I took reading seminars on these topics. And I believe I'm still years of concentrated study away from being able to comprehend the proof, end to end. I'm not yet capable of reading Ribet's proof of Serre's εε\varepsilon-conjecture, nor Wiles' earlier papers with Coates, nor the basic papers of Shimura and Eichler on modular forms.  My next project, if and when my life allows me the luxury of being a student again, is to master Diamond and Shurman's ""A First Course in Modular Forms"". I'm not completely ignorant of the contents of this book; I ostensibly already know much of it. But ""knowing"" isn't the same as ""having it in the palm of your hand"", and that's what I think I need to do first.  I want, one day, to do more traveling and be in places I haven't been to yet: New Zealand, Norway, China, South America. In the same spirit, I hope I get to visit this wonderful place called Wiles' proof. It's a selfish goal. I will likely not have an opportunity to meaningfully teach this proof to others, given the enormous amount of prerequisites. Like climbing Mt. Everest, it's something one wants for oneself.  And I really, really want to. ","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/sklgn3i75xya0eq9', 'title': ""Does Alon Amit fully understand the Wiles - Taylor proof of Fermat's Last Theorem?"", 'score': {'original': 0.9996, 'ai': 0.0004}, 'blocks': [{'text': 'Oh goodness. I wish. When I was a graduate student I took every Number Theory, Algebraic Geometry and Representation Theory course I could find, specifically trying to learn everything Ehud de Shalit was teaching. He\'s one of very few people mentioned by Wiles in the Annals paper containing the proof, but this wasn\'t even the main reason: de Shalit is a phenomenal teacher, an outstanding researcher, and this domain of mathematics attracts me like no other.  I took the basic graduate-level courses in commutative algebra and number theory. I took Algebraic Number Theory, two courses on Elliptic Curves, and a course on ppp-adic analysis – all of these with de Shalit. I took reading seminars on these topics. And I believe I\'m still years of concentrated study away from being able to comprehend the proof, end to end. I\'m not yet capable of reading Ribet\'s proof of Serre\'s εε\\varepsilon-conjecture, nor Wiles\' earlier papers with Coates, nor the basic papers of Shimura and Eichler on modular forms.  My next project, if and when my life allows me the luxury of being a student again, is to master Diamond and Shurman\'s ""A First Course in Modular Forms"". I\'m not completely ignorant of the contents of this book; I ostensibly already know much of it. But ""knowing"" isn\'t the same as ""having it in the palm of your hand"", and that\'s what I think I need to do first.  I want, one day, to do more traveling and be in places I haven\'t been to yet: New Zealand, Norway, China, South America. In the same spirit, I hope I get to visit this wonderful place called Wiles\' proof. It\'s a selfish goal. I will likely not have an opportunity to meaningfully teach this proof to others, given the enormous amount of prerequisites. Like climbing Mt. Everest, it\'s something one wants for oneself.  And I really, really want to.', 'result': {'fake': 0.0004, 'real': 0.9996}, 'status': 'success'}], 'credits_used': 4, 'credits': 1994736, 'subscription': 0, 'content': 'Oh goodness. I wish. When I was a graduate student I took every Number Theory, Algebraic Geometry and Representation Theory course I could find, specifically trying to learn everything Ehud de Shalit was teaching. He\'s one of very few people mentioned by Wiles in the Annals paper containing the proof, but this wasn\'t even the main reason: de Shalit is a phenomenal teacher, an outstanding researcher, and this domain of mathematics attracts me like no other.  I took the basic graduate-level courses in commutative algebra and number theory. I took Algebraic Number Theory, two courses on Elliptic Curves, and a course on ppp-adic analysis – all of these with de Shalit. I took reading seminars on these topics. And I believe I\'m still years of concentrated study away from being able to comprehend the proof, end to end. I\'m not yet capable of reading Ribet\'s proof of Serre\'s εε\\varepsilon-conjecture, nor Wiles\' earlier papers with Coates, nor the basic papers of Shimura and Eichler on modular forms.  My next project, if and when my life allows me the luxury of being a student again, is to master Diamond and Shurman\'s ""A First Course in Modular Forms"". I\'m not completely ignorant of the contents of this book; I ostensibly already know much of it. But ""knowing"" isn\'t the same as ""having it in the palm of your hand"", and that\'s what I think I need to do first.  I want, one day, to do more traveling and be in places I haven\'t been to yet: New Zealand, Norway, China, South America. In the same spirit, I hope I get to visit this wonderful place called Wiles\' proof. It\'s a selfish goal. I will likely not have an opportunity to meaningfully teach this proof to others, given the enormous amount of prerequisites. Like climbing Mt. Everest, it\'s something one wants for oneself.  And I really, really want to.', 'aiModelVersion': '1'}",0.9996
Alon Amit,4y,What would Euclid think of non-Euclidean mathematics?,"Glorious. Beautifully, wonderfully exhilarating. He would be stunned, and overjoyed. He’d love it. My, what I would pay to see him process this. Where do I sign up?

It would take some time for someone competent in modern math and ancient Greek to sit him down and walk him through several millennia of progress – though, honestly, very little has happened in the time separating Euclid himself and the Renaissance or thereabouts. Still, there’s a great deal to cover.

Once basic language and terminology were established, once the teacher earned Euclid’s trust and attention, she would be able to get her student past the barrier of truly believing his own axioms, working with them for what they say without prejudice or bias or preconceived notions. It is then easy to see that a different interpretation of “point”, “line” and “circle” leads to a perfectly consistent model which satisfies all of the axioms except the parallel postulate.

There’s lots to clear up on the way. Euclid’s own axioms were confusingly insufficient, and it may be worthwhile to explain why. But excessive pedantry might not even be necessary. Appreciating spherical and hyperbolic geometry can be done almost immediately following the groundwork of the axiomatic method, and portraying the Poincaré model of the hyperbolic plane is a joyous journey with a student as brilliantly capable as Euclid.

He would absolutely revel in seeing how far his ideas were taken, how theoretically beautiful and practically relevant they have become. He’d be the happiest man in history.

(There’s no “non-Euclidean mathematics”. It’s called non-Euclidean geometry.)","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/oyjv01het4zqlsrc', 'title': 'What would Euclid think of non-Euclidean mathematics?', 'score': {'original': 0.9991, 'ai': 0.0009}, 'blocks': [{'text': 'Glorious. Beautifully, wonderfully exhilarating. He would be stunned, and overjoyed. He’d love it. My, what I would pay to see him process this. Where do I sign up?\n\nIt would take some time for someone competent in modern math and ancient Greek to sit him down and walk him through several millennia of progress – though, honestly, very little has happened in the time separating Euclid himself and the Renaissance or thereabouts. Still, there’s a great deal to cover.\n\nOnce basic language and terminology were established, once the teacher earned Euclid’s trust and attention, she would be able to get her student past the barrier of truly believing his own axioms, working with them for what they say without prejudice or bias or preconceived notions. It is then easy to see that a different interpretation of “point”, “line” and “circle” leads to a perfectly consistent model which satisfies all of the axioms except the parallel postulate.\n\nThere’s lots to clear up on the way. Euclid’s own axioms were confusingly insufficient, and it may be worthwhile to explain why. But excessive pedantry might not even be necessary. Appreciating spherical and hyperbolic geometry can be done almost immediately following the groundwork of the axiomatic method, and portraying the Poincaré model of the hyperbolic plane is a joyous journey with a student as brilliantly capable as Euclid.\n\nHe would absolutely revel in seeing how far his ideas were taken, how theoretically beautiful and practically relevant they have become. He’d be the happiest man in history.\n\n(There’s no “non-Euclidean mathematics”. It’s called non-Euclidean geometry.)', 'result': {'fake': 0.0009, 'real': 0.9991}, 'status': 'success'}], 'credits_used': 3, 'credits': 1994733, 'subscription': 0, 'content': 'Glorious. Beautifully, wonderfully exhilarating. He would be stunned, and overjoyed. He’d love it. My, what I would pay to see him process this. Where do I sign up?\n\nIt would take some time for someone competent in modern math and ancient Greek to sit him down and walk him through several millennia of progress – though, honestly, very little has happened in the time separating Euclid himself and the Renaissance or thereabouts. Still, there’s a great deal to cover.\n\nOnce basic language and terminology were established, once the teacher earned Euclid’s trust and attention, she would be able to get her student past the barrier of truly believing his own axioms, working with them for what they say without prejudice or bias or preconceived notions. It is then easy to see that a different interpretation of “point”, “line” and “circle” leads to a perfectly consistent model which satisfies all of the axioms except the parallel postulate.\n\nThere’s lots to clear up on the way. Euclid’s own axioms were confusingly insufficient, and it may be worthwhile to explain why. But excessive pedantry might not even be necessary. Appreciating spherical and hyperbolic geometry can be done almost immediately following the groundwork of the axiomatic method, and portraying the Poincaré model of the hyperbolic plane is a joyous journey with a student as brilliantly capable as Euclid.\n\nHe would absolutely revel in seeing how far his ideas were taken, how theoretically beautiful and practically relevant they have become. He’d be the happiest man in history.\n\n(There’s no “non-Euclidean mathematics”. It’s called non-Euclidean geometry.)', 'aiModelVersion': '1'}",0.9991
Senia Sheydvasser,4y,Is there a math problem that no mathematician has been able to solve?,"There are hundreds, if not thousands of such questions. It is, in fact, almost comically easy to produce a question that no mathematician will know how to answer. For example: choose a random polynomial 
p
(
X
)
p(X)
 with integer coefficients. It is almost guaranteed that if you then ask whether there are infinitely many integers 
X
X
 such that 
p
(
X
)
p(X)
 is a prime number, this will be unknown. (If the polynomial factors, the answer is obviously “no.” However, this will almost never happen. The only other case where the answer is known are linear polynomials, where the answer is known to be “yes” by a classical theorem of Dirichlet
. Literally all other cases are totally open.) Heck, even if you ask about polynomials 
p
(
X
,
Y
)
p(X,Y)
 with two variables, the answer is totally unknown most of the time. For instance, 
p
(
X
,
Y
)
=
X
2
+
Y
4
p(X,Y)=X2+Y4
 was only proven to produce infinitely many primes in 1998, thanks to a nearly 100 page paper by Friedlander and Iwaniec
.

A relatively unknown consequence of the Gödel's incompleteness theorems is that the length of the shortest proof of a theorem about arithmetic must grow faster than any computable function as a function of the length of the statement of the theorem. What this tells you is that even comparatively short, comparatively simple statements can have extremely long proofs. This is simple to miss when you are in the beginning of your mathematical education, and are only seeing problems that have been solved. When you get to actually doing mathematical research, this becomes self-evident.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/8nthiaj59ydpbvl1', 'title': 'Is there a math problem that no mathematician has been able to solve?', 'score': {'original': 0.9989, 'ai': 0.0011}, 'blocks': [{'text': ""There are hundreds, if not thousands of such questions. It is, in fact, almost comically easy to produce a question that no mathematician will know how to answer. For example: choose a random polynomial \np\n(\nX\n)\np(X)\n with integer coefficients. It is almost guaranteed that if you then ask whether there are infinitely many integers \nX\nX\n such that \np\n(\nX\n)\np(X)\n is a prime number, this will be unknown. (If the polynomial factors, the answer is obviously “no.” However, this will almost never happen. The only other case where the answer is known are linear polynomials, where the answer is known to be “yes” by a classical theorem of Dirichlet\n. Literally all other cases are totally open.) Heck, even if you ask about polynomials \np\n(\nX\n,\nY\n)\np(X,Y)\n with two variables, the answer is totally unknown most of the time. For instance, \np\n(\nX\n,\nY\n)\n=\nX\n2\n+\nY\n4\np(X,Y)=X2+Y4\n was only proven to produce infinitely many primes in 1998, thanks to a nearly 100 page paper by Friedlander and Iwaniec\n.\n\nA relatively unknown consequence of the Gödel's incompleteness theorems is that the length of the shortest proof of a theorem about arithmetic must grow faster than any computable function as a function of the length of the statement of the theorem. What this tells you is that even comparatively short, comparatively simple statements can have extremely long proofs. This is simple to miss when you are in the beginning of your mathematical education, and are only seeing problems that have been solved. When you get to actually doing mathematical research, this becomes self-evident."", 'result': {'fake': 0.0011, 'real': 0.9989}, 'status': 'success'}], 'credits_used': 3, 'credits': 1994730, 'subscription': 0, 'content': ""There are hundreds, if not thousands of such questions. It is, in fact, almost comically easy to produce a question that no mathematician will know how to answer. For example: choose a random polynomial \np\n(\nX\n)\np(X)\n with integer coefficients. It is almost guaranteed that if you then ask whether there are infinitely many integers \nX\nX\n such that \np\n(\nX\n)\np(X)\n is a prime number, this will be unknown. (If the polynomial factors, the answer is obviously “no.” However, this will almost never happen. The only other case where the answer is known are linear polynomials, where the answer is known to be “yes” by a classical theorem of Dirichlet\n. Literally all other cases are totally open.) Heck, even if you ask about polynomials \np\n(\nX\n,\nY\n)\np(X,Y)\n with two variables, the answer is totally unknown most of the time. For instance, \np\n(\nX\n,\nY\n)\n=\nX\n2\n+\nY\n4\np(X,Y)=X2+Y4\n was only proven to produce infinitely many primes in 1998, thanks to a nearly 100 page paper by Friedlander and Iwaniec\n.\n\nA relatively unknown consequence of the Gödel's incompleteness theorems is that the length of the shortest proof of a theorem about arithmetic must grow faster than any computable function as a function of the length of the statement of the theorem. What this tells you is that even comparatively short, comparatively simple statements can have extremely long proofs. This is simple to miss when you are in the beginning of your mathematical education, and are only seeing problems that have been solved. When you get to actually doing mathematical research, this becomes self-evident."", 'aiModelVersion': '1'}",0.9989
Dave Smith,1y,"Why is the obelus ""÷"" symbol seldom used to denote the division operation in higher math?","The obelus division symbol is basically just for children and Facebook posts. The great thing about using a vinculum (line) for dividing is that it effectively puts brackets around the numerator and denominator but it is so intuitively obvious that no one even realises it has happened. That is why the Facebook “what is the value of 1 + 2 ÷ 3 + 4” type questions are so stupid, ie because if you actually wrote it out like an adult there would be no doubt what you meant. The only real problem is that properly written mathematical division doesn’t work for inline text, so you need to actually put the brackets in. But again, if you write like an adult everything is still clear and you have 1 + (2/3) + 4 or (1 + 2)/(3 + 4) or whatever, as required.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/d57ep6uatq2c40ho', 'title': 'Why is the obelus ""÷"" symbol seldom used to denote the division operation in higher math?', 'score': {'original': 0.9986, 'ai': 0.0014}, 'blocks': [{'text': 'The obelus division symbol is basically just for children and Facebook posts. The great thing about using a vinculum (line) for dividing is that it effectively puts brackets around the numerator and denominator but it is so intuitively obvious that no one even realises it has happened. That is why the Facebook “what is the value of 1 + 2 ÷ 3 + 4” type questions are so stupid, ie because if you actually wrote it out like an adult there would be no doubt what you meant. The only real problem is that properly written mathematical division doesn’t work for inline text, so you need to actually put the brackets in. But again, if you write like an adult everything is still clear and you have 1 + (2/3) + 4 or (1 + 2)/(3 + 4) or whatever, as required.', 'result': {'fake': 0.0014, 'real': 0.9986}, 'status': 'success'}], 'credits_used': 2, 'credits': 1994728, 'subscription': 0, 'content': 'The obelus division symbol is basically just for children and Facebook posts. The great thing about using a vinculum (line) for dividing is that it effectively puts brackets around the numerator and denominator but it is so intuitively obvious that no one even realises it has happened. That is why the Facebook “what is the value of 1 + 2 ÷ 3 + 4” type questions are so stupid, ie because if you actually wrote it out like an adult there would be no doubt what you meant. The only real problem is that properly written mathematical division doesn’t work for inline text, so you need to actually put the brackets in. But again, if you write like an adult everything is still clear and you have 1 + (2/3) + 4 or (1 + 2)/(3 + 4) or whatever, as required.', 'aiModelVersion': '1'}",0.9986
Sridhar Ramesh,4y,Suppose I'm an early mathematician looking for the function ,"Roughly, the meaning of f′(x)f′(x)f'(x) is that f(x+ϵ)=f(x)+f′(x)ϵf(x+ϵ)=f(x)+f′(x)ϵf(x + \epsilon) = f(x) + f'(x)\epsilon, for infinitesimally small ϵϵ\epsilon. [If we’re being more formal, we might say that f(x+ϵ)=f(x)+f′(x)ϵ+o(ϵ)f(x+ϵ)=f(x)+f′(x)ϵ+o(ϵ)f(x + \epsilon) = f(x) + f'(x)\epsilon + o(\epsilon) in the limit as ϵϵ\epsilon approaches 000, but whatever. The early exploration is rarely formal. Formalization can come later, choosing to define clear hard boundaries into what was previously more informally defined game-playing.] So if f′(x)=f(x)f′(x)=f(x)f'(x) = f(x), then we have that f(x+ϵ)=f(x)+f(x)ϵ=(1+ϵ)f(x)f(x+ϵ)=f(x)+f(x)ϵ=(1+ϵ)f(x)f(x + \epsilon) = f(x) + f(x) \epsilon = (1 + \epsilon)f(x). In other words, we have that fff multiplies by a particular amount whenever its input is increased by a particular amount. In particular, it takes x/ϵx/ϵx/\epsilon many hops of size ϵϵ\epsilon to get up to xxx from 000, so we should expect f(x)=(1+ϵ)x/ϵf(0)=exf(0)f(x)=(1+ϵ)x/ϵf(0)=exf(0)f(x) = (1 + \epsilon)^{x/\epsilon} f(0) = e^x f(0), where eee is simply the name we give to (1+ϵ)1/ϵ(1+ϵ)1/ϵ(1 + \epsilon)^{1/\epsilon} in the limit of infinitesimal ϵϵ\epsilon. And there we have it. [If you want to be more formal about it, now you can go ahead and codify the above reasoning into whatever formal system of your choice. But the early mathematicians who figured all this stuff out certainly weren’t being so formal.]","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/f3o7qacg89nvk15e', 'title': ""Suppose I'm an early mathematician looking for the function"", 'score': {'original': 0.9962, 'ai': 0.0038}, 'blocks': [{'text': ""Roughly, the meaning of f′(x)f′(x)f'(x) is that f(x+ϵ)=f(x)+f′(x)ϵf(x+ϵ)=f(x)+f′(x)ϵf(x + \\epsilon) = f(x) + f'(x)\\epsilon, for infinitesimally small ϵϵ\\epsilon. [If we’re being more formal, we might say that f(x+ϵ)=f(x)+f′(x)ϵ+o(ϵ)f(x+ϵ)=f(x)+f′(x)ϵ+o(ϵ)f(x + \\epsilon) = f(x) + f'(x)\\epsilon + o(\\epsilon) in the limit as ϵϵ\\epsilon approaches 000, but whatever. The early exploration is rarely formal. Formalization can come later, choosing to define clear hard boundaries into what was previously more informally defined game-playing.] So if f′(x)=f(x)f′(x)=f(x)f'(x) = f(x), then we have that f(x+ϵ)=f(x)+f(x)ϵ=(1+ϵ)f(x)f(x+ϵ)=f(x)+f(x)ϵ=(1+ϵ)f(x)f(x + \\epsilon) = f(x) + f(x) \\epsilon = (1 + \\epsilon)f(x). In other words, we have that fff multiplies by a particular amount whenever its input is increased by a particular amount. In particular, it takes x/ϵx/ϵx/\\epsilon many hops of size ϵϵ\\epsilon to get up to xxx from 000, so we should expect f(x)=(1+ϵ)x/ϵf(0)=exf(0)f(x)=(1+ϵ)x/ϵf(0)=exf(0)f(x) = (1 + \\epsilon)^{x/\\epsilon} f(0) = e^x f(0), where eee is simply the name we give to (1+ϵ)1/ϵ(1+ϵ)1/ϵ(1 + \\epsilon)^{1/\\epsilon} in the limit of infinitesimal ϵϵ\\epsilon. And there we have it. [If you want to be more formal about it, now you can go ahead and codify the above reasoning into whatever formal system of your choice. But the early mathematicians who figured all this stuff out certainly weren’t being so formal.]"", 'result': {'fake': 0.0038, 'real': 0.9962}, 'status': 'success'}], 'credits_used': 3, 'credits': 1994725, 'subscription': 0, 'content': ""Roughly, the meaning of f′(x)f′(x)f'(x) is that f(x+ϵ)=f(x)+f′(x)ϵf(x+ϵ)=f(x)+f′(x)ϵf(x + \\epsilon) = f(x) + f'(x)\\epsilon, for infinitesimally small ϵϵ\\epsilon. [If we’re being more formal, we might say that f(x+ϵ)=f(x)+f′(x)ϵ+o(ϵ)f(x+ϵ)=f(x)+f′(x)ϵ+o(ϵ)f(x + \\epsilon) = f(x) + f'(x)\\epsilon + o(\\epsilon) in the limit as ϵϵ\\epsilon approaches 000, but whatever. The early exploration is rarely formal. Formalization can come later, choosing to define clear hard boundaries into what was previously more informally defined game-playing.] So if f′(x)=f(x)f′(x)=f(x)f'(x) = f(x), then we have that f(x+ϵ)=f(x)+f(x)ϵ=(1+ϵ)f(x)f(x+ϵ)=f(x)+f(x)ϵ=(1+ϵ)f(x)f(x + \\epsilon) = f(x) + f(x) \\epsilon = (1 + \\epsilon)f(x). In other words, we have that fff multiplies by a particular amount whenever its input is increased by a particular amount. In particular, it takes x/ϵx/ϵx/\\epsilon many hops of size ϵϵ\\epsilon to get up to xxx from 000, so we should expect f(x)=(1+ϵ)x/ϵf(0)=exf(0)f(x)=(1+ϵ)x/ϵf(0)=exf(0)f(x) = (1 + \\epsilon)^{x/\\epsilon} f(0) = e^x f(0), where eee is simply the name we give to (1+ϵ)1/ϵ(1+ϵ)1/ϵ(1 + \\epsilon)^{1/\\epsilon} in the limit of infinitesimal ϵϵ\\epsilon. And there we have it. [If you want to be more formal about it, now you can go ahead and codify the above reasoning into whatever formal system of your choice. But the early mathematicians who figured all this stuff out certainly weren’t being so formal.]"", 'aiModelVersion': '1'}",0.9962
Wes Browning,Updated 1y,How did mathematicians find out that Euclid's parallel postulate was incorrect? How long did it take them to discover this?,"It was never found to be incorrect. That is a complete misunderstanding of what the whole deal was. What they found out was that it is necessary to include the parallel postulate in Eclidean geometry in order for it to be Euclidean Geometry. Rather than prove the postulate false the discovery of valid non-Euclidean gemetries vindicated Euclid’s choice to include the parallel postulate in his system.

What happened was that for around 2000 years many mathematicians tried to prove the parallel postulate from the other axioms and postulates. Then hyperbolic geometry was discovered, and proofs were found to show that if you accept that Euclidean geometry, with the parallel postulate is valid and consistent, then so is hyperbolic geometry even though the parallel postulate doesn’t hold in it.

That didn’t prove the parallel postulate was wrong, it proved that the parallel postulate is independent of the rest of Euclid’s axioms and postulates, and it meant that you have a choice. You can adopt the parallel potulate and work within Euclidean geometry, or you can work within hyperbolic geometry withi=out the parallel postulate","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/zr07n3gjl18yciea', 'title': ""How did mathematicians find out that Euclid's parallel postulate was incorrect? How long did it take them to discover this?"", 'score': {'original': 0.9992, 'ai': 0.0008}, 'blocks': [{'text': 'It was never found to be incorrect. That is a complete misunderstanding of what the whole deal was. What they found out was that it is necessary to include the parallel postulate in Eclidean geometry in order for it to be Euclidean Geometry. Rather than prove the postulate false the discovery of valid non-Euclidean gemetries vindicated Euclid’s choice to include the parallel postulate in his system.\n\nWhat happened was that for around 2000 years many mathematicians tried to prove the parallel postulate from the other axioms and postulates. Then hyperbolic geometry was discovered, and proofs were found to show that if you accept that Euclidean geometry, with the parallel postulate is valid and consistent, then so is hyperbolic geometry even though the parallel postulate doesn’t hold in it.\n\nThat didn’t prove the parallel postulate was wrong, it proved that the parallel postulate is independent of the rest of Euclid’s axioms and postulates, and it meant that you have a choice. You can adopt the parallel potulate and work within Euclidean geometry, or you can work within hyperbolic geometry withi=out the parallel postulate', 'result': {'fake': 0.0008, 'real': 0.9992}, 'status': 'success'}], 'credits_used': 2, 'credits': 1994723, 'subscription': 0, 'content': 'It was never found to be incorrect. That is a complete misunderstanding of what the whole deal was. What they found out was that it is necessary to include the parallel postulate in Eclidean geometry in order for it to be Euclidean Geometry. Rather than prove the postulate false the discovery of valid non-Euclidean gemetries vindicated Euclid’s choice to include the parallel postulate in his system.\n\nWhat happened was that for around 2000 years many mathematicians tried to prove the parallel postulate from the other axioms and postulates. Then hyperbolic geometry was discovered, and proofs were found to show that if you accept that Euclidean geometry, with the parallel postulate is valid and consistent, then so is hyperbolic geometry even though the parallel postulate doesn’t hold in it.\n\nThat didn’t prove the parallel postulate was wrong, it proved that the parallel postulate is independent of the rest of Euclid’s axioms and postulates, and it meant that you have a choice. You can adopt the parallel potulate and work within Euclidean geometry, or you can work within hyperbolic geometry withi=out the parallel postulate', 'aiModelVersion': '1'}",0.9992
Colin Reid,4y,Mathematicians spend massive amounts of time (even entire lifetimes) to develop a single theorem or proof. Where do they get their funds?,"They typically get paid a salary by a university and/or research grants. Mathematicians don’t generally incur especially large research expenses: outside of salary, the main things would be travel (to go visit other mathematicians and/or meet at conferences) and possibly computer resources (but less than you might imagine: a lot of maths is still done entirely ‘by hand’, and even if a computer is required, an ordinary PC can do an awful lot of calculations these days). So for the most part, the role of funding in mathematics is to ensure mathematicians don’t have to go out and do some other kind of job that would take away their time to think.

It’s true that publication rates are lower in pure maths than in most STEM subjects. Even so, it’s very rare for a mathematician to deliberately go into seclusion for years at a time without producing any results. Partly it’s because yes, whoever is paying them expects them to keep publishing to show they are productive. But it’s also a reflection of the nature of mathematical research:

Purely from an intellectual standpoint, it’s not a good approach to focus all your efforts on proving one theorem. For one thing, the purported statement is often false, or technically true but ‘misses the point’, in that a stronger statement is both true and conceptually clearer than your initial guess. The central premise of the Hitchhikers’ Guide to the Galaxy, about how it can be much harder to ask the right question than to give the right answer, definitely applies to pure mathematics. But even if you have asked exactly ‘the right question’, you’ll often get a lot further by trying to prove related results first. These will often be of independent interest even if they don’t ultimately contribute to the solution of the famous problem.
Even if everything is leading up to one big theorem, such results are rarely proved all in one go, but rather there is a long lead-up of partial results, which are sometimes by different authors. These are often publishable in their own right, even if they will ultimately be superseded by the big theorem. If you’ve written dozens of pages of ‘lemmas’ in the hope that they will eventually add up to a proof of the big theorem, it’s a good sign if they can immediately be used or adapted to prove something else people are interested in, and a bad sign if they are purely technical and bespoke.
For all the ‘lone genius’ stereotypes, over the long term, mathematics is a hugely collaborative exercise. You’re not writing a novel, you’re contributing to a form of objective knowledge that belongs to humanity as a whole. Maybe no one person knows enough to prove the theorem, but the mathematical community collectively does. This is why mathematicians are constantly telling each other what they are doing, what ideas they have and so on, or at least they should be. Maybe somebody else will take your idea and prove the theorem, getting most of the fame when you could have done it yourself given enough time. But so what? How can you know you that you would have figured it out? The important thing for most mathematicians is not ‘who’ but ‘what’ and ‘why’: in the words of David Hilbert, “we must know, we will know”.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/cu4kyzbiqrmanhe0', 'title': 'Mathematicians spend massive amounts of time (even entire lifetimes) to develop a single theorem or proof. Where do they get their funds?', 'score': {'original': 0.45685, 'ai': 0.54315}, 'blocks': [{'text': 'They typically get paid a salary by a university and/or research grants. Mathematicians don’t generally incur especially large research expenses: outside of salary, the main things would be travel (to go visit other mathematicians and/or meet at conferences) and possibly computer resources (but less than you might imagine: a lot of maths is still done entirely ‘by hand’, and even if a computer is required, an ordinary PC can do an awful lot of calculations these days). So for the most part, the role of funding in mathematics is to ensure mathematicians don’t have to go out and do some other kind of job that would take away their time to think.\n\nIt’s true that publication rates are lower in pure maths than in most STEM subjects. Even so, it’s very rare for a mathematician to deliberately go into seclusion for years at a time without producing any results. Partly it’s because yes, whoever is paying them expects them to keep publishing to show they are productive. But it’s also a reflection of the nature of mathematical research:\n\nPurely from an intellectual standpoint, it’s not a good approach to focus all your efforts on proving one theorem. For one thing, the purported statement is often false, or technically true but ‘misses the point’, in that a stronger statement is both true and conceptually clearer than your initial guess. The central premise of the Hitchhikers’ Guide to the Galaxy, about how it can be much harder to ask the right question than to give the right answer, definitely applies to pure mathematics. But even if you have asked exactly ‘the right question’, you’ll often get a lot further by trying to prove related results first. These will often be of independent interest even if they don’t ultimately contribute to the solution of the famous problem.\nEven if everything is leading up to one big theorem, such results are rarely proved all in one go, but rather there is a long lead-up of partial results, which are sometimes by different authors. These are often publishable in their own right, even if they will ultimately be superseded by the big theorem. If you’ve written dozens of pages of ‘lemmas’ in the hope that they will eventually add up to a proof of the big theorem, it’s a good sign if they can immediately be used or adapted to prove something else people are interested in, and a bad sign if they are purely technical and bespoke.\nFor all the ‘lone genius’ stereotypes, over the long term, mathematics is a hugely collaborative exercise. You’re not writing a novel, you’re contributing to a form of objective knowledge that belongs to humanity as a whole. Maybe no one person knows enough to prove the theorem, but the mathematical community collectively does. This is why mathematicians are constantly telling each other what they are doing, what ideas they have and so on, or at least they should be. Maybe somebody else will take your idea and prove the theorem, getting most of the fame when you could have done it yourself given enough', 'result': {'fake': 0.397, 'real': 0.603}, 'status': 'success'}, {'text': 'time. But so what? How can you know you that you would have figured it out? The important thing for most mathematicians is not ‘who’ but ‘what’ and ‘why’: in the words of David Hilbert, “we must know, we will know”.', 'result': {'fake': 0.9996, 'real': 0.0004}, 'status': 'success'}], 'credits_used': 6, 'credits': 1994717, 'subscription': 0, 'content': 'They typically get paid a salary by a university and/or research grants. Mathematicians don’t generally incur especially large research expenses: outside of salary, the main things would be travel (to go visit other mathematicians and/or meet at conferences) and possibly computer resources (but less than you might imagine: a lot of maths is still done entirely ‘by hand’, and even if a computer is required, an ordinary PC can do an awful lot of calculations these days). So for the most part, the role of funding in mathematics is to ensure mathematicians don’t have to go out and do some other kind of job that would take away their time to think.\n\nIt’s true that publication rates are lower in pure maths than in most STEM subjects. Even so, it’s very rare for a mathematician to deliberately go into seclusion for years at a time without producing any results. Partly it’s because yes, whoever is paying them expects them to keep publishing to show they are productive. But it’s also a reflection of the nature of mathematical research:\n\nPurely from an intellectual standpoint, it’s not a good approach to focus all your efforts on proving one theorem. For one thing, the purported statement is often false, or technically true but ‘misses the point’, in that a stronger statement is both true and conceptually clearer than your initial guess. The central premise of the Hitchhikers’ Guide to the Galaxy, about how it can be much harder to ask the right question than to give the right answer, definitely applies to pure mathematics. But even if you have asked exactly ‘the right question’, you’ll often get a lot further by trying to prove related results first. These will often be of independent interest even if they don’t ultimately contribute to the solution of the famous problem.\nEven if everything is leading up to one big theorem, such results are rarely proved all in one go, but rather there is a long lead-up of partial results, which are sometimes by different authors. These are often publishable in their own right, even if they will ultimately be superseded by the big theorem. If you’ve written dozens of pages of ‘lemmas’ in the hope that they will eventually add up to a proof of the big theorem, it’s a good sign if they can immediately be used or adapted to prove something else people are interested in, and a bad sign if they are purely technical and bespoke.\nFor all the ‘lone genius’ stereotypes, over the long term, mathematics is a hugely collaborative exercise. You’re not writing a novel, you’re contributing to a form of objective knowledge that belongs to humanity as a whole. Maybe no one person knows enough to prove the theorem, but the mathematical community collectively does. This is why mathematicians are constantly telling each other what they are doing, what ideas they have and so on, or at least they should be. Maybe somebody else will take your idea and prove the theorem, getting most of the fame when you could have done it yourself given enough time. But so what? How can you know you that you would have figured it out? The important thing for most mathematicians is not ‘who’ but ‘what’ and ‘why’: in the words of David Hilbert, “we must know, we will know”.', 'aiModelVersion': '1'}",0.45685
Viktor T. Toth,7y,How was the form of the Lagrangian discovered?,"The development of the action principle and the modern formulation of Lagrangians is the result of the work of many people over a time period spanning centuries. (Wikipedia actually offers a good, albeit concise, overview: Principle of least action
). There was no big “aha!” moment; rather, there were several small ones, each an essential step towards the modern formulation.

At the conceptual roots, we find Fermat’s principle from the mid-1600s: that a ray of light, as it travels through various mediums, finds the path between two points that takes the least amount of time.

In the mid-1700s, Maupertius applied the same principle more broadly, as the foundation of all the “laws of movement and rest”.

Around the same time, in 1744, Euler presented a formulation of the action principle that we now recognize as the reduced action: 
δ
∫
p
 
d
q
=
0
δ∫p dq=0
.

In 1760, Lagrange developed what is nowadays known as the calculus of variations, which is the formal mathematics behind the action principle.

Finally, in 1834–35, Hamilton applied Lagrange’s mathematics to the classical Lagrangian in the form 
L
=
T
−
V
L=T−V
 (
T
T
 being the kinetic, 
V
V
 the potential energy) and modern Lagrange-Hamiltonian mechanics was born.

As the question details suggest, it would have been indeed baffling if a single individual came up with this spectacularly beautiful but by no means trivial concept. But that was not the case. Rather, it required the contribution of many exceptional individuals over the course of roughly two hundred years… so it was by no means an easy birth.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/p4rhgcfqiyo1dbz0', 'title': 'How was the form of the Lagrangian discovered?', 'score': {'original': 0.9942, 'ai': 0.0058}, 'blocks': [{'text': 'The development of the action principle and the modern formulation of Lagrangians is the result of the work of many people over a time period spanning centuries. (Wikipedia actually offers a good, albeit concise, overview: Principle of least action\n). There was no big “aha!” moment; rather, there were several small ones, each an essential step towards the modern formulation.\n\nAt the conceptual roots, we find Fermat’s principle from the mid-1600s: that a ray of light, as it travels through various mediums, finds the path between two points that takes the least amount of time.\n\nIn the mid-1700s, Maupertius applied the same principle more broadly, as the foundation of all the “laws of movement and rest”.\n\nAround the same time, in 1744, Euler presented a formulation of the action principle that we now recognize as the reduced action: \nδ\n∫\np\n\xa0\nd\nq\n=\n0\nδ∫p\xa0dq=0\n.\n\nIn 1760, Lagrange developed what is nowadays known as the calculus of variations, which is the formal mathematics behind the action principle.\n\nFinally, in 1834–35, Hamilton applied Lagrange’s mathematics to the classical Lagrangian in the form \nL\n=\nT\n−\nV\nL=T−V\n (\nT\nT\n being the kinetic, \nV\nV\n the potential energy) and modern Lagrange-Hamiltonian mechanics was born.\n\nAs the question details suggest, it would have been indeed baffling if a single individual came up with this spectacularly beautiful but by no means trivial concept. But that was not the case. Rather, it required the contribution of many exceptional individuals over the course of roughly two hundred years… so it was by no means an easy birth.', 'result': {'fake': 0.0087, 'real': 0.9913}, 'status': 'success'}], 'credits_used': 3, 'credits': 1994714, 'subscription': 0, 'content': 'The development of the action principle and the modern formulation of Lagrangians is the result of the work of many people over a time period spanning centuries. (Wikipedia actually offers a good, albeit concise, overview: Principle of least action\n). There was no big “aha!” moment; rather, there were several small ones, each an essential step towards the modern formulation.\n\nAt the conceptual roots, we find Fermat’s principle from the mid-1600s: that a ray of light, as it travels through various mediums, finds the path between two points that takes the least amount of time.\n\nIn the mid-1700s, Maupertius applied the same principle more broadly, as the foundation of all the “laws of movement and rest”.\n\nAround the same time, in 1744, Euler presented a formulation of the action principle that we now recognize as the reduced action: \nδ\n∫\np\n\xa0\nd\nq\n=\n0\nδ∫p\xa0dq=0\n.\n\nIn 1760, Lagrange developed what is nowadays known as the calculus of variations, which is the formal mathematics behind the action principle.\n\nFinally, in 1834–35, Hamilton applied Lagrange’s mathematics to the classical Lagrangian in the form \nL\n=\nT\n−\nV\nL=T−V\n (\nT\nT\n being the kinetic, \nV\nV\n the potential energy) and modern Lagrange-Hamiltonian mechanics was born.\n\nAs the question details suggest, it would have been indeed baffling if a single individual came up with this spectacularly beautiful but by no means trivial concept. But that was not the case. Rather, it required the contribution of many exceptional individuals over the course of roughly two hundred years… so it was by no means an easy birth.', 'aiModelVersion': '1'}",0.9942
Senia Sheydvasser,1y,Why were the axioms of arithmetic developed so many centuries after the axioms of geometry? What role might class and status have had to do with the disparity?,"The assertion in the question is false. A full axiomatization of arithmetic was done by Peirce in 1881. A full axiomatization of geometry was done by Hilbert in 1899, almost two decades later.

Now, it is arguable that humanity started work on axiomatizing geometry before the same was done for arithmetic—specifically, the first attempted axiomatization that we have a record of is Euclid’s, which he wrote around 300 BCE. (It was very incomplete: it’s well known that the very first proposition that Euclid proves in the Elements doesn’t quite follow from his stated axioms.)

However, even this argument is a little shaky, considering that Euclid started the Elements with five common notions:

Things which equal the same thing also equal one another.
If equals are added to equals, then the wholes are equal.
If equals are subtracted from equals, then the remainders are equal.
Things which coincide with one another equal one another.
The whole is greater than the part.

That certainly looks like an attempt to axiomatize some piece of arithmetic. (Although given what Euclid was using this for, it would probably be more correct to say that this is an attempt of axiomatizing the arithmetic of real numbers, rather than the integers.) It’s incredibly incomplete, of course, but that can at least partially be blamed on the fact that Euclid lacked algebra and algebraic thinking, and otherwise blamed on the fact that nobody thought that a rigorous axiomatization was important.

Modern notions of rigor are, well, modern—i.e. they do not go back farther than the late 19th century at the most.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/495s2eyphgt6bixm', 'title': 'Why were the axioms of arithmetic developed so many centuries after the axioms of geometry? What role might class and status have had to do with the disparity?', 'score': {'original': 0.9996, 'ai': 0.0004}, 'blocks': [{'text': 'The assertion in the question is false. A full axiomatization of arithmetic was done by Peirce in 1881. A full axiomatization of geometry was done by Hilbert in 1899, almost two decades later.\n\nNow, it is arguable that humanity started work on axiomatizing geometry before the same was done for arithmetic—specifically, the first attempted axiomatization that we have a record of is Euclid’s, which he wrote around 300 BCE. (It was very incomplete: it’s well known that the very first proposition that Euclid proves in the Elements doesn’t quite follow from his stated axioms.)\n\nHowever, even this argument is a little shaky, considering that Euclid started the Elements with five common notions:\n\nThings which equal the same thing also equal one another.\nIf equals are added to equals, then the wholes are equal.\nIf equals are subtracted from equals, then the remainders are equal.\nThings which coincide with one another equal one another.\nThe whole is greater than the part.\n\nThat certainly looks like an attempt to axiomatize some piece of arithmetic. (Although given what Euclid was using this for, it would probably be more correct to say that this is an attempt of axiomatizing the arithmetic of real numbers, rather than the integers.) It’s incredibly incomplete, of course, but that can at least partially be blamed on the fact that Euclid lacked algebra and algebraic thinking, and otherwise blamed on the fact that nobody thought that a rigorous axiomatization was important.\n\nModern notions of rigor are, well, modern—i.e. they do not go back farther than the late 19th century at the most.', 'result': {'fake': 0.0004, 'real': 0.9996}, 'status': 'success'}], 'credits_used': 3, 'credits': 1994711, 'subscription': 0, 'content': 'The assertion in the question is false. A full axiomatization of arithmetic was done by Peirce in 1881. A full axiomatization of geometry was done by Hilbert in 1899, almost two decades later.\n\nNow, it is arguable that humanity started work on axiomatizing geometry before the same was done for arithmetic—specifically, the first attempted axiomatization that we have a record of is Euclid’s, which he wrote around 300 BCE. (It was very incomplete: it’s well known that the very first proposition that Euclid proves in the Elements doesn’t quite follow from his stated axioms.)\n\nHowever, even this argument is a little shaky, considering that Euclid started the Elements with five common notions:\n\nThings which equal the same thing also equal one another.\nIf equals are added to equals, then the wholes are equal.\nIf equals are subtracted from equals, then the remainders are equal.\nThings which coincide with one another equal one another.\nThe whole is greater than the part.\n\nThat certainly looks like an attempt to axiomatize some piece of arithmetic. (Although given what Euclid was using this for, it would probably be more correct to say that this is an attempt of axiomatizing the arithmetic of real numbers, rather than the integers.) It’s incredibly incomplete, of course, but that can at least partially be blamed on the fact that Euclid lacked algebra and algebraic thinking, and otherwise blamed on the fact that nobody thought that a rigorous axiomatization was important.\n\nModern notions of rigor are, well, modern—i.e. they do not go back farther than the late 19th century at the most.', 'aiModelVersion': '1'}",0.9996
Ben Brink,1y,"Why is the obelus ""÷"" symbol seldom used to denote the division operation in higher math?",“/” says the same thing and is easier to write. The old-fashioned symbol is fine until you teach fractions. But top end mathematicians are “simplification” freaks; in many cases you have to “recomplicate” their notation. Great question!,"{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/iwdgb5v34ux1er6m', 'title': 'Why is the obelus ""÷"" symbol seldom used to denote the division operation in higher math?', 'score': {'original': 0.9548, 'ai': 0.0452}, 'blocks': [{'text': '“/” says the same thing and is easier to write. The old-fashioned symbol is fine until you teach fractions. But top end mathematicians are “simplification” freaks; in many cases you have to “recomplicate” their notation. Great question!', 'result': {'fake': 0.0452, 'real': 0.9548}, 'status': 'success'}], 'credits_used': 1, 'credits': 1994710, 'subscription': 0, 'content': '“/” says the same thing and is easier to write. The old-fashioned symbol is fine until you teach fractions. But top end mathematicians are “simplification” freaks; in many cases you have to “recomplicate” their notation. Great question!', 'aiModelVersion': '1'}",0.9548
Alon Amit,2y,Are there advanced forms of math created by civilizations that differ from modern Western math?,"Modern math isn’t “modern Western math”. Over the past 120 years, at least, math was vigorously developed in many regions and countries which aren’t “The West”, including Eastern Europe, Asia and elsewhere.

Present-day Mathematicians in (or from) India, China, Japan, Vietnam, Thailand, Iran, Russia, Turkey, Hungary, Romania, Poland, Bulgaria, Egypt, Nigeria, Brazil, Argentina or Cuba don’t consider themselves “Western mathematicians” working on “Western mathematics”. They are mathematicians, working on mathematics.

In the past, things were obviously a lot less connected and uniform. Various mathematical ideas evolved in different places, possibly without communication, and there are interesting questions about how and where those developments took place.

But as far as we know, or expect, there isn’t some kind of “other” math we would call advanced and differs from what people study or research worldwide today.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/anqm4v9ckdlsi1gw', 'title': 'Are there advanced forms of math created by civilizations that differ from modern Western math?', 'score': {'original': 0.9997, 'ai': 0.0003}, 'blocks': [{'text': 'Modern math isn’t “modern Western math”. Over the past 120 years, at least, math was vigorously developed in many regions and countries which aren’t “The West”, including Eastern Europe, Asia and elsewhere.\n\nPresent-day Mathematicians in (or from) India, China, Japan, Vietnam, Thailand, Iran, Russia, Turkey, Hungary, Romania, Poland, Bulgaria, Egypt, Nigeria, Brazil, Argentina or Cuba don’t consider themselves “Western mathematicians” working on “Western mathematics”. They are mathematicians, working on mathematics.\n\nIn the past, things were obviously a lot less connected and uniform. Various mathematical ideas evolved in different places, possibly without communication, and there are interesting questions about how and where those developments took place.\n\nBut as far as we know, or expect, there isn’t some kind of “other” math we would call advanced and differs from what people study or research worldwide today.', 'result': {'fake': 0.0003, 'real': 0.9997}, 'status': 'success'}], 'credits_used': 2, 'credits': 1994708, 'subscription': 0, 'content': 'Modern math isn’t “modern Western math”. Over the past 120 years, at least, math was vigorously developed in many regions and countries which aren’t “The West”, including Eastern Europe, Asia and elsewhere.\n\nPresent-day Mathematicians in (or from) India, China, Japan, Vietnam, Thailand, Iran, Russia, Turkey, Hungary, Romania, Poland, Bulgaria, Egypt, Nigeria, Brazil, Argentina or Cuba don’t consider themselves “Western mathematicians” working on “Western mathematics”. They are mathematicians, working on mathematics.\n\nIn the past, things were obviously a lot less connected and uniform. Various mathematical ideas evolved in different places, possibly without communication, and there are interesting questions about how and where those developments took place.\n\nBut as far as we know, or expect, there isn’t some kind of “other” math we would call advanced and differs from what people study or research worldwide today.', 'aiModelVersion': '1'}",0.9997
Alon Amit,Updated 3y,"On Wikipedia, under the definition of mathematics, it reads “There is not even consensus on whether mathematics is an art or a science.” How accurate is this statement? What do mathematicians classify mathematics as?","The phrasing of the statement “There is not even consensus on whether mathematics is an art or a science” seems to suggest that it is supposed to be one or the other. This is not the case. Math is not in need of being classified as either an art or a science and, indeed, there’s no consensus that it’s either, because there’s a fairly broad consensus that it is neither.

Math shares some aspects with the sciences, it shares some aspects with art, and it shares some aspects with nothing else. Sometimes mathematicians empirically study phenomena, discern patterns and form hypotheses, as one does in science. Sometimes they dream up structures and methods that elicit a deep sense of aesthetic satisfaction, as one does in the arts. And often times, mathematicians seek to prove things in a way that is quite unlike anything else (even unlike Sherlock Holmes’ fanciful deductions).

Mathematicians, as a whole, are far more interested in doing mathematics than in classifying it as this or that.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/2m8ngwfz01a7iypx', 'title': 'On Wikipedia, under the definition of mathematics, it reads “There is not even consensus on whether mathematics is an art or a science.” How accurate is this statement? What do mathematicians classify mathematics as?', 'score': {'original': 0.9543, 'ai': 0.0457}, 'blocks': [{'text': 'The phrasing of the statement “There is not even consensus on whether mathematics is an art or a science” seems to suggest that it is supposed to be one or the other. This is not the case. Math is not in need of being classified as either an art or a science and, indeed, there’s no consensus that it’s either, because there’s a fairly broad consensus that it is neither.\n\nMath shares some aspects with the sciences, it shares some aspects with art, and it shares some aspects with nothing else. Sometimes mathematicians empirically study phenomena, discern patterns and form hypotheses, as one does in science. Sometimes they dream up structures and methods that elicit a deep sense of aesthetic satisfaction, as one does in the arts. And often times, mathematicians seek to prove things in a way that is quite unlike anything else (even unlike Sherlock Holmes’ fanciful deductions).\n\nMathematicians, as a whole, are far more interested in doing mathematics than in classifying it as this or that.', 'result': {'fake': 0.0457, 'real': 0.9543}, 'status': 'success'}], 'credits_used': 2, 'credits': 1994706, 'subscription': 0, 'content': 'The phrasing of the statement “There is not even consensus on whether mathematics is an art or a science” seems to suggest that it is supposed to be one or the other. This is not the case. Math is not in need of being classified as either an art or a science and, indeed, there’s no consensus that it’s either, because there’s a fairly broad consensus that it is neither.\n\nMath shares some aspects with the sciences, it shares some aspects with art, and it shares some aspects with nothing else. Sometimes mathematicians empirically study phenomena, discern patterns and form hypotheses, as one does in science. Sometimes they dream up structures and methods that elicit a deep sense of aesthetic satisfaction, as one does in the arts. And often times, mathematicians seek to prove things in a way that is quite unlike anything else (even unlike Sherlock Holmes’ fanciful deductions).\n\nMathematicians, as a whole, are far more interested in doing mathematics than in classifying it as this or that.', 'aiModelVersion': '1'}",0.9543
Senia Sheydvasser,1y,What are the classical mathematics textbooks from the 20th century?,"There’s no hope of listing all of them, but I will give you a very short sampling of some.

Principles of Mathematical Analysis, Rudin
Commutative Algebra, Atiyah and Macdonald
Introduction to Mathematical Logic, Mendelson
Finite-Dimensional Vector Spaces, Halmos
Calculus, Spivak
Methods of Modern Mathematical Physics, Reed and Simon
Abstract Algebra, Dummit and Foote
Introduction to Geometry, Coxeter
Algebraic Geometry, Hartshorne
The Arithmetic of Elliptic Curves, Silverman
A Course in Computational Algebraic Number Theory, Cohen
Divergent Series, Hardy
Introduction to Analytic Number Theory, Apostol
Introduction to Quadratic Forms, O’Meara
Trees, Serre","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/by3vlx682uc05opg', 'title': 'What are the classical mathematics textbooks from the 20th century?', 'score': {'original': 0.5302, 'ai': 0.4698}, 'blocks': [{'text': 'There’s no hope of listing all of them, but I will give you a very short sampling of some.\n\nPrinciples of Mathematical Analysis, Rudin\nCommutative Algebra, Atiyah and Macdonald\nIntroduction to Mathematical Logic, Mendelson\nFinite-Dimensional Vector Spaces, Halmos\nCalculus, Spivak\nMethods of Modern Mathematical Physics, Reed and Simon\nAbstract Algebra, Dummit and Foote\nIntroduction to Geometry, Coxeter\nAlgebraic Geometry, Hartshorne\nThe Arithmetic of Elliptic Curves, Silverman\nA Course in Computational Algebraic Number Theory, Cohen\nDivergent Series, Hardy\nIntroduction to Analytic Number Theory, Apostol\nIntroduction to Quadratic Forms, O’Meara\nTrees, Serre', 'result': {'fake': 0.4698, 'real': 0.5302}, 'status': 'success'}], 'credits_used': 1, 'credits': 1994705, 'subscription': 0, 'content': 'There’s no hope of listing all of them, but I will give you a very short sampling of some.\n\nPrinciples of Mathematical Analysis, Rudin\nCommutative Algebra, Atiyah and Macdonald\nIntroduction to Mathematical Logic, Mendelson\nFinite-Dimensional Vector Spaces, Halmos\nCalculus, Spivak\nMethods of Modern Mathematical Physics, Reed and Simon\nAbstract Algebra, Dummit and Foote\nIntroduction to Geometry, Coxeter\nAlgebraic Geometry, Hartshorne\nThe Arithmetic of Elliptic Curves, Silverman\nA Course in Computational Algebraic Number Theory, Cohen\nDivergent Series, Hardy\nIntroduction to Analytic Number Theory, Apostol\nIntroduction to Quadratic Forms, O’Meara\nTrees, Serre', 'aiModelVersion': '1'}",0.5302
Subhrajit Pati,1y,"It is said that number zero was invented in India. Is there any story, proof or theorem supporting this?","Answer - The concept of zero as a placeholder and a number in its own right is attributed to the ancient Hindus in India, who used it as early as the 5th century. The use of zero as a placeholder was first recorded in Indian mathematics, specifically in the Surya Siddhanta, which is a Sanskrit text on mathematics and astronomy. The concept of zero was further developed in the 7th century by the mathematician and astronomer Brahmagupta, who wrote about the concept of zero and how to use it in calculations in his book ""The Brahmasphutasiddhanta.""

.

.

.

The concept of zero was later transmitted to the Islamic world and from there, it was introduced to the Western world by Italian mathematician Fibonacci, who learned about it during his travels to the Middle East. The modern symbol for zero (0) is also believed to have originated in India.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/rh37z8gxtvlpuwn5', 'title': 'It is said that number zero was invented in India. Is there any story, proof or theorem supporting this?', 'score': {'original': 0, 'ai': 1}, 'blocks': [{'text': 'Answer - The concept of zero as a placeholder and a number in its own right is attributed to the ancient Hindus in India, who used it as early as the 5th century. The use of zero as a placeholder was first recorded in Indian mathematics, specifically in the Surya Siddhanta, which is a Sanskrit text on mathematics and astronomy. The concept of zero was further developed in the 7th century by the mathematician and astronomer Brahmagupta, who wrote about the concept of zero and how to use it in calculations in his book ""The Brahmasphutasiddhanta.""\n\n.\n\n.\n\n.\n\nThe concept of zero was later transmitted to the Islamic world and from there, it was introduced to the Western world by Italian mathematician Fibonacci, who learned about it during his travels to the Middle East. The modern symbol for zero (0) is also believed to have originated in India.', 'result': {'fake': 1, 'real': 0}, 'status': 'success'}], 'credits_used': 2, 'credits': 1994703, 'subscription': 0, 'content': 'Answer - The concept of zero as a placeholder and a number in its own right is attributed to the ancient Hindus in India, who used it as early as the 5th century. The use of zero as a placeholder was first recorded in Indian mathematics, specifically in the Surya Siddhanta, which is a Sanskrit text on mathematics and astronomy. The concept of zero was further developed in the 7th century by the mathematician and astronomer Brahmagupta, who wrote about the concept of zero and how to use it in calculations in his book ""The Brahmasphutasiddhanta.""\n\n.\n\n.\n\n.\n\nThe concept of zero was later transmitted to the Islamic world and from there, it was introduced to the Western world by Italian mathematician Fibonacci, who learned about it during his travels to the Middle East. The modern symbol for zero (0) is also believed to have originated in India.', 'aiModelVersion': '1'}",0.0
Louis Cohen,1y,Why did David Hilbert think that Albert Einstein was a poor mathematician?,"Compared to Hilbert, all but a very few people in history have been poor mathematicians.

Einstein was smart enough to get help from his mathematician friends when he needed it. He may not have been a professional mathematician, but he was better at it than almost any other non-mathematician. And he was able to combine that with incredible physical insights.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/fu1rebd3yht9a5io', 'title': 'Why did David Hilbert think that Albert Einstein was a poor mathematician?', 'score': {'original': 0.0004, 'ai': 0.9996}, 'blocks': [{'text': 'Compared to Hilbert, all but a very few people in history have been poor mathematicians.\n\nEinstein was smart enough to get help from his mathematician friends when he needed it. He may not have been a professional mathematician, but he was better at it than almost any other non-mathematician. And he was able to combine that with incredible physical insights.', 'result': {'fake': 0.9996, 'real': 0.0004}, 'status': 'success'}], 'credits_used': 1, 'credits': 1994702, 'subscription': 0, 'content': 'Compared to Hilbert, all but a very few people in history have been poor mathematicians.\n\nEinstein was smart enough to get help from his mathematician friends when he needed it. He may not have been a professional mathematician, but he was better at it than almost any other non-mathematician. And he was able to combine that with incredible physical insights.', 'aiModelVersion': '1'}",0.0004
Brent Meeker,7mo,Why did David Hilbert think that Albert Einstein was a poor mathematician?,"The famous quote by Hilbert is: ""Every boy in the streets of Gottingen understands more about four-dimensional geometry than Einstein. Yet, in spite of that, Einstein did the work and not the mathematicians."" Einstein was not a mathematician and didn’t try to be, he just wanted to use mathematics to make his ideas clear, precise, and testable.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/kdegjczvys7rh159', 'title': 'Why did David Hilbert think that Albert Einstein was a poor mathematician?', 'score': {'original': 0.1646, 'ai': 0.8354}, 'blocks': [{'text': 'The famous quote by Hilbert is: ""Every boy in the streets of Gottingen understands more about four-dimensional geometry than Einstein. Yet, in spite of that, Einstein did the work and not the mathematicians."" Einstein was not a mathematician and didn’t try to be, he just wanted to use mathematics to make his ideas clear, precise, and testable.', 'result': {'fake': 0.9881, 'real': 0.0119}, 'status': 'success'}], 'credits_used': 1, 'credits': 1994701, 'subscription': 0, 'content': 'The famous quote by Hilbert is: ""Every boy in the streets of Gottingen understands more about four-dimensional geometry than Einstein. Yet, in spite of that, Einstein did the work and not the mathematicians."" Einstein was not a mathematician and didn’t try to be, he just wanted to use mathematics to make his ideas clear, precise, and testable.', 'aiModelVersion': '1'}",0.1646
David Joyce,1y,"What do mathematicians think of Marx's ""Note on Mathematics""?","I didn’t know Karl Marx did anything in mathematics. There’s an article, though, in Wikipedia on Mathematical manuscripts of Karl Marx
.

From the introduction of that article:

The mathematical manuscripts of Karl Marx are a manuscript collection of Karl Marx's mathematical notes where he attempted to derive the foundations of infinitesimal calculus from first principles.

The notes that Marx took have been collected into four independent treatises: On the Concept of the Derived Function, On the Differential, On the History of Differential Calculus, and Taylor's Theorem, MacLaurin's Theorem, and Lagrange's Theory of Derived Functions, along with several notes, additional drafts, and supplements to these four treatises. These treatises attempt to construct a rigorous foundation for calculus and use historical materialism to analyze the history of mathematics.

Marx's contributions to mathematics did not have any impact on the historical development of calculus, and he was unaware of many more recent developments in the field at the time, such as the work of Cauchy. However, his work in some ways anticipated, but did not influence, some later developments in 20th century mathematics. These manuscripts, which are from around 1873–1883, were not published in any language until 1968 when they were published in the Soviet Union alongside a Russian translation. Since their publication, Marx's independent contributions to mathematics have been analyzed in terms of both his own historical and economic theories, and in light of their potential applications of nonstandard analysis.

There’s not much to say without access to what he actually wrote. (The sources are all behind paywalls). He was interested in the foundations of calculus enough to work on that for a while using what looks like a version of Leibniz’ infinitesimals which were standard in calculus textbooks at the time.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/qrw0dc493ngub16y', 'title': 'What do mathematicians think of Marx\'s ""Note on Mathematics""?', 'score': {'original': 0.9997, 'ai': 0.0003}, 'blocks': [{'text': ""I didn’t know Karl Marx did anything in mathematics. There’s an article, though, in Wikipedia on Mathematical manuscripts of Karl Marx\n.\n\nFrom the introduction of that article:\n\nThe mathematical manuscripts of Karl Marx are a manuscript collection of Karl Marx's mathematical notes where he attempted to derive the foundations of infinitesimal calculus from first principles.\n\nThe notes that Marx took have been collected into four independent treatises: On the Concept of the Derived Function, On the Differential, On the History of Differential Calculus, and Taylor's Theorem, MacLaurin's Theorem, and Lagrange's Theory of Derived Functions, along with several notes, additional drafts, and supplements to these four treatises. These treatises attempt to construct a rigorous foundation for calculus and use historical materialism to analyze the history of mathematics.\n\nMarx's contributions to mathematics did not have any impact on the historical development of calculus, and he was unaware of many more recent developments in the field at the time, such as the work of Cauchy. However, his work in some ways anticipated, but did not influence, some later developments in 20th century mathematics. These manuscripts, which are from around 1873–1883, were not published in any language until 1968 when they were published in the Soviet Union alongside a Russian translation. Since their publication, Marx's independent contributions to mathematics have been analyzed in terms of both his own historical and economic theories, and in light of their potential applications of nonstandard analysis.\n\nThere’s not much to say without access to what he actually wrote. (The sources are all behind paywalls). He was interested in the foundations of calculus enough to work on that for a while using what looks like a version of Leibniz’ infinitesimals which were standard in calculus textbooks at the time."", 'result': {'fake': 0.0003, 'real': 0.9997}, 'status': 'success'}], 'credits_used': 3, 'credits': 1994698, 'subscription': 0, 'content': ""I didn’t know Karl Marx did anything in mathematics. There’s an article, though, in Wikipedia on Mathematical manuscripts of Karl Marx\n.\n\nFrom the introduction of that article:\n\nThe mathematical manuscripts of Karl Marx are a manuscript collection of Karl Marx's mathematical notes where he attempted to derive the foundations of infinitesimal calculus from first principles.\n\nThe notes that Marx took have been collected into four independent treatises: On the Concept of the Derived Function, On the Differential, On the History of Differential Calculus, and Taylor's Theorem, MacLaurin's Theorem, and Lagrange's Theory of Derived Functions, along with several notes, additional drafts, and supplements to these four treatises. These treatises attempt to construct a rigorous foundation for calculus and use historical materialism to analyze the history of mathematics.\n\nMarx's contributions to mathematics did not have any impact on the historical development of calculus, and he was unaware of many more recent developments in the field at the time, such as the work of Cauchy. However, his work in some ways anticipated, but did not influence, some later developments in 20th century mathematics. These manuscripts, which are from around 1873–1883, were not published in any language until 1968 when they were published in the Soviet Union alongside a Russian translation. Since their publication, Marx's independent contributions to mathematics have been analyzed in terms of both his own historical and economic theories, and in light of their potential applications of nonstandard analysis.\n\nThere’s not much to say without access to what he actually wrote. (The sources are all behind paywalls). He was interested in the foundations of calculus enough to work on that for a while using what looks like a version of Leibniz’ infinitesimals which were standard in calculus textbooks at the time."", 'aiModelVersion': '1'}",0.9997
Will Scathlocke,1y,Why did mathematicians literally invent imaginary numbers instead of admitting that their theories could be wrong?,"I ordinarily leave questions on mathematics to those who are far, far more qualified than I to answer them, but since I just went through this with my daughter, I flatter myself that I can actually answer this one. (And if a real mathematician comes along and corrects me, then I will really have embarrassed myself.)

In 1545 the Italian scholar Girolamo Cardano was trying to find out if there were two numbers such that when they were added would come to 10 and when multiplied would come to 40. To wit:

x + y = 10 (i.e. x = 10 - y)

xy = 40

So, (10 - y)y = 40

I.e. 10y - y^2 = 40

Or: y^2 - 10y + 40 = 0

This, of course, is a perfectly ordinary quadratic equation. Once solved (i.e. by completing the square), there are two roots:

5 + √-15 and 5 - √-15

What Cardano then did was to treat those two roots as perfectly ordinary numbers. After all, he was looking for two numbers which, when added, came to 10. To wit:

(5 + √-15) + (5 - √-15) = 10

Because, whatever √-15 may be, √-15 - √-15 had to be equal to zero; and 5 and 5 were 10.

Next: Cardano needed his two roots, when they were multiplied, to equal 40.

So the next problem was this: (5 + √-15) x (5 - √-15) = ?

That works out to: (5 x 5) + 5√-15 - 5√-15 - (√-15 x √-15)

Or: 25 - (-15) or 25 + 15 = 40.

So, yes: Cardano discovered that there were indeed two numbers which, when added, came to 10 and when multiplied came to 40.

That is how imaginary numbers were discovered. Moreover, this also demonstrates their immediate utility. There were extraordinarily useful in solving quadratic equations which otherwise would have been insoluble. All that remained to do was to introduce notation to make things easier. To wit:

√-1 was written as i.

So √-15 would now be written as i√15.

There were no theories involved which might have been invalidated.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/k137eisovfplhnum', 'title': 'Why did mathematicians literally invent imaginary numbers instead of admitting that their theories could be wrong?', 'score': {'original': 0.9998, 'ai': 0.0002}, 'blocks': [{'text': 'I ordinarily leave questions on mathematics to those who are far, far more qualified than I to answer them, but since I just went through this with my daughter, I flatter myself that I can actually answer this one. (And if a real mathematician comes along and corrects me, then I will really have embarrassed myself.)\n\nIn 1545 the Italian scholar Girolamo Cardano was trying to find out if there were two numbers such that when they were added would come to 10 and when multiplied would come to 40. To wit:\n\nx + y = 10 (i.e. x = 10 - y)\n\nxy = 40\n\nSo, (10 - y)y = 40\n\nI.e. 10y - y^2 = 40\n\nOr: y^2 - 10y + 40 = 0\n\nThis, of course, is a perfectly ordinary quadratic equation. Once solved (i.e. by completing the square), there are two roots:\n\n5 + √-15 and 5 - √-15\n\nWhat Cardano then did was to treat those two roots as perfectly ordinary numbers. After all, he was looking for two numbers which, when added, came to 10. To wit:\n\n(5 + √-15) + (5 - √-15) = 10\n\nBecause, whatever √-15 may be, √-15 - √-15 had to be equal to zero; and 5 and 5 were 10.\n\nNext: Cardano needed his two roots, when they were multiplied, to equal 40.\n\nSo the next problem was this: (5 + √-15) x (5 - √-15) = ?\n\nThat works out to: (5 x 5) + 5√-15 - 5√-15 - (√-15 x √-15)\n\nOr: 25 - (-15) or 25 + 15 = 40.\n\nSo, yes: Cardano discovered that there were indeed two numbers which, when added, came to 10 and when multiplied came to 40.\n\nThat is how imaginary numbers were discovered. Moreover, this also demonstrates their immediate utility. There were extraordinarily useful in solving quadratic equations which otherwise would have been insoluble. All that remained to do was to introduce notation to make things easier. To wit:\n\n√-1 was written as i.\n\nSo √-15 would now be written as i√15.\n\nThere were no theories involved which might have been invalidated.', 'result': {'fake': 0.0002, 'real': 0.9998}, 'status': 'success'}], 'credits_used': 4, 'credits': 1994694, 'subscription': 0, 'content': 'I ordinarily leave questions on mathematics to those who are far, far more qualified than I to answer them, but since I just went through this with my daughter, I flatter myself that I can actually answer this one. (And if a real mathematician comes along and corrects me, then I will really have embarrassed myself.)\n\nIn 1545 the Italian scholar Girolamo Cardano was trying to find out if there were two numbers such that when they were added would come to 10 and when multiplied would come to 40. To wit:\n\nx + y = 10 (i.e. x = 10 - y)\n\nxy = 40\n\nSo, (10 - y)y = 40\n\nI.e. 10y - y^2 = 40\n\nOr: y^2 - 10y + 40 = 0\n\nThis, of course, is a perfectly ordinary quadratic equation. Once solved (i.e. by completing the square), there are two roots:\n\n5 + √-15 and 5 - √-15\n\nWhat Cardano then did was to treat those two roots as perfectly ordinary numbers. After all, he was looking for two numbers which, when added, came to 10. To wit:\n\n(5 + √-15) + (5 - √-15) = 10\n\nBecause, whatever √-15 may be, √-15 - √-15 had to be equal to zero; and 5 and 5 were 10.\n\nNext: Cardano needed his two roots, when they were multiplied, to equal 40.\n\nSo the next problem was this: (5 + √-15) x (5 - √-15) = ?\n\nThat works out to: (5 x 5) + 5√-15 - 5√-15 - (√-15 x √-15)\n\nOr: 25 - (-15) or 25 + 15 = 40.\n\nSo, yes: Cardano discovered that there were indeed two numbers which, when added, came to 10 and when multiplied came to 40.\n\nThat is how imaginary numbers were discovered. Moreover, this also demonstrates their immediate utility. There were extraordinarily useful in solving quadratic equations which otherwise would have been insoluble. All that remained to do was to introduce notation to make things easier. To wit:\n\n√-1 was written as i.\n\nSo √-15 would now be written as i√15.\n\nThere were no theories involved which might have been invalidated.', 'aiModelVersion': '1'}",0.9998
Mo Nastri,4y,Who are some notable mathematicians that rejected or moved on from mathematics later in life?,"“Rejected” isn’t perhaps the proper term, but Grigori Perelman resigned from his position as Senior Researcher at the Steklov Mathematics Institute in Dec 2005, three years after he first posted on the arXiv the series of papers constituting a proof of the Poincare conjecture that catapulted him to unwanted fame, because he said he was disappointed in mathematics
 and wanted to try something else.

When the Clay Mathematics Institute announced that he’d won the Millennium Prize for his solution Perelman refused:

I do not like their decision, I consider it unfair. I consider that the American mathematician [Richard] Hamilton's contribution to the solution of the problem is no less than mine.

Seven years prior to posting his solution, in 1995, Perelman had reached out to Hamilton offering to collaborate, because he noticed in the latter’s latest papers discussing ideas on how to prove the Poincare conjecture that he hadn’t made much progress, and Perelman had some ideas to bridge the impasse stemming from a paper he’d written earlier on Alexandrov spaces, but eventually decided to continue alone when he didn’t get a reply.

This isn’t to say that Hamilton was secretive or shunned him — precisely the opposite. When Hamilton finished giving a talk at the IAS regarding his investigation of the Ricci flow equation, which later became the basis of the solution, Perelman shyly approached him:

I really wanted to ask him something. He was smiling, and he was quite patient. He actually told me a couple of things that he published a few years later. He did not hesitate to tell me. Hamilton’s openness and generosity—it really attracted me. I can’t say that most mathematicians act like that.

As far as anyone knows, he’s still living in an apartment in the southern suburbs of St Petersburg with his mother Lubov Lvovna, a former math teacher at a technical college who gave up her own graduate work in mathematics to raise him, living on savings accrued from the two-year Miller Research Fellowship that funded his postdoc at Berkeley in 1993–95, occasionally going to the opera. (Perelman has always loved the opera. He began going at age 6 because his mom took him there, and by age 15 was spending his pocket money on records. He particularly admired soprano singer Licia Albanese
, a leading artist with the Metropolitan Opera in her time, and her portrayal of Violetta in the 1946 performance “La Traviata”, saying “her voice was very good”.)

He did confide to Yakov Eliashberg
, a mathematician at Stanford who was also born in Leningrad and knew Perelman at Berkeley, back in 2007 that he was “working on other things but it was too premature to talk about it”, but there’s been no update on that. When Valery Ryzhik, his former teacher at Leningrad's Special Mathematics and Physics School Number 239, called Perelman to “help me solve a small geometry problem”, he replied that
 he “was not interested in that anymore”.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/zvy9le2iutck6nxg', 'title': 'Who are some notable mathematicians that rejected or moved on from mathematics later in life?', 'score': {'original': 0.9994, 'ai': 0.0006}, 'blocks': [{'text': ""“Rejected” isn’t perhaps the proper term, but Grigori Perelman resigned from his position as Senior Researcher at the Steklov Mathematics Institute in Dec 2005, three years after he first posted on the arXiv the series of papers constituting a proof of the Poincare conjecture that catapulted him to unwanted fame, because he said he was disappointed in mathematics\n and wanted to try something else.\n\nWhen the Clay Mathematics Institute announced that he’d won the Millennium Prize for his solution Perelman refused:\n\nI do not like their decision, I consider it unfair. I consider that the American mathematician [Richard] Hamilton's contribution to the solution of the problem is no less than mine.\n\nSeven years prior to posting his solution, in 1995, Perelman had reached out to Hamilton offering to collaborate, because he noticed in the latter’s latest papers discussing ideas on how to prove the Poincare conjecture that he hadn’t made much progress, and Perelman had some ideas to bridge the impasse stemming from a paper he’d written earlier on Alexandrov spaces, but eventually decided to continue alone when he didn’t get a reply.\n\nThis isn’t to say that Hamilton was secretive or shunned him — precisely the opposite. When Hamilton finished giving a talk at the IAS regarding his investigation of the Ricci flow equation, which later became the basis of the solution, Perelman shyly approached him:\n\nI really wanted to ask him something. He was smiling, and he was quite patient. He actually told me a couple of things that he published a few years later. He did not hesitate to tell me. Hamilton’s openness and generosity—it really attracted me. I can’t say that most mathematicians act like that.\n\nAs far as anyone knows, he’s still living in an apartment in the southern suburbs of St Petersburg with his mother Lubov Lvovna, a former math teacher at a technical college who gave up her own graduate work in mathematics to raise him, living on savings accrued from the two-year Miller Research Fellowship that funded his postdoc at Berkeley in 1993–95, occasionally going to the opera. (Perelman has always loved the opera. He began going at age 6 because his mom took him there, and by age 15 was spending his pocket money on records. He particularly admired soprano singer Licia Albanese\n, a leading artist with the Metropolitan Opera in her time, and her portrayal of Violetta in the 1946 performance “La Traviata”, saying “her voice was very good”.)\n\nHe did confide to Yakov Eliashberg\n, a mathematician at Stanford who was also born in Leningrad and knew Perelman at Berkeley, back in 2007 that he was “working on other things but it was too premature to talk about it”, but there’s been no update on that. When Valery Ryzhik, his former teacher at Leningrad's Special Mathematics and Physics School Number 239, called Perelman to “help me solve a small geometry problem”, he replied that\n he “was not interested in that anymore”."", 'result': {'fake': 0.0006, 'real': 0.9994}, 'status': 'success'}], 'credits_used': 5, 'credits': 1994689, 'subscription': 0, 'content': ""“Rejected” isn’t perhaps the proper term, but Grigori Perelman resigned from his position as Senior Researcher at the Steklov Mathematics Institute in Dec 2005, three years after he first posted on the arXiv the series of papers constituting a proof of the Poincare conjecture that catapulted him to unwanted fame, because he said he was disappointed in mathematics\n and wanted to try something else.\n\nWhen the Clay Mathematics Institute announced that he’d won the Millennium Prize for his solution Perelman refused:\n\nI do not like their decision, I consider it unfair. I consider that the American mathematician [Richard] Hamilton's contribution to the solution of the problem is no less than mine.\n\nSeven years prior to posting his solution, in 1995, Perelman had reached out to Hamilton offering to collaborate, because he noticed in the latter’s latest papers discussing ideas on how to prove the Poincare conjecture that he hadn’t made much progress, and Perelman had some ideas to bridge the impasse stemming from a paper he’d written earlier on Alexandrov spaces, but eventually decided to continue alone when he didn’t get a reply.\n\nThis isn’t to say that Hamilton was secretive or shunned him — precisely the opposite. When Hamilton finished giving a talk at the IAS regarding his investigation of the Ricci flow equation, which later became the basis of the solution, Perelman shyly approached him:\n\nI really wanted to ask him something. He was smiling, and he was quite patient. He actually told me a couple of things that he published a few years later. He did not hesitate to tell me. Hamilton’s openness and generosity—it really attracted me. I can’t say that most mathematicians act like that.\n\nAs far as anyone knows, he’s still living in an apartment in the southern suburbs of St Petersburg with his mother Lubov Lvovna, a former math teacher at a technical college who gave up her own graduate work in mathematics to raise him, living on savings accrued from the two-year Miller Research Fellowship that funded his postdoc at Berkeley in 1993–95, occasionally going to the opera. (Perelman has always loved the opera. He began going at age 6 because his mom took him there, and by age 15 was spending his pocket money on records. He particularly admired soprano singer Licia Albanese\n, a leading artist with the Metropolitan Opera in her time, and her portrayal of Violetta in the 1946 performance “La Traviata”, saying “her voice was very good”.)\n\nHe did confide to Yakov Eliashberg\n, a mathematician at Stanford who was also born in Leningrad and knew Perelman at Berkeley, back in 2007 that he was “working on other things but it was too premature to talk about it”, but there’s been no update on that. When Valery Ryzhik, his former teacher at Leningrad's Special Mathematics and Physics School Number 239, called Perelman to “help me solve a small geometry problem”, he replied that\n he “was not interested in that anymore”."", 'aiModelVersion': '1'}",0.9994
David Joyce,Updated Feb 2,"Why do logarithms appear to be named after algorithms, despite the two being wildly different from one another?","John Napier called them that when he invented them about 1610. He merged two words with Greek roots, “logos” which was used for ratios, and “arithmos” for number: “logarithms” if you drop a couple of letters. He compared two sequences. One sequence was a geometric sequence where adjacent terms have a common ratio, like the sequence 2,4,8,16,32,…,2,4,8,16,32,…,2, 4, 8, 16, 32,\ldots, and the other was an arithmetic sequence where adjacent terms have a common difference like 1,2,3,4,5,….1,2,3,4,5,….1, 2, 3, 4, 5,\ldots.  Going from the arithmetic sequence to the geometric sequence involves exponentiation nnn goes to 2n2n2^n for this pair of sequences. Napier realized the opposite operation could be useful, going from the geometric sequence to the arithmetic sequence. For that he invented the inverse of exponentiation, which he called logarithms. The reason it can be useful is that with a table of logs (and reading backwards gives exponents), you can perform multiplications by doing additions, divisions by doing subtractions, and square roots by halving. Difficult computations become easy. It’s mainly coincidence that “logarithm” and “algorithm” are so similar. At the time of Napier, the usual way of spelling “algorithm” was “algorism” as it was based on the name Muhammad ibn Musa al-Khwarizmi which was spelled with several variations. The word “logarithm” may have encouraged spelling “algorism” with a “th” instead of an “s”.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/xoe8sg1kbzy03vlj', 'title': 'Why do logarithms appear to be named after algorithms, despite the two being wildly different from one another?', 'score': {'original': 0.9992, 'ai': 0.0008}, 'blocks': [{'text': 'John Napier called them that when he invented them about 1610. He merged two words with Greek roots, “logos” which was used for ratios, and “arithmos” for number: “logarithms” if you drop a couple of letters. He compared two sequences. One sequence was a geometric sequence where adjacent terms have a common ratio, like the sequence 2,4,8,16,32,…,2,4,8,16,32,…,2, 4, 8, 16, 32,\\ldots, and the other was an arithmetic sequence where adjacent terms have a common difference like 1,2,3,4,5,….1,2,3,4,5,….1, 2, 3, 4, 5,\\ldots.  Going from the arithmetic sequence to the geometric sequence involves exponentiation nnn goes to 2n2n2^n for this pair of sequences. Napier realized the opposite operation could be useful, going from the geometric sequence to the arithmetic sequence. For that he invented the inverse of exponentiation, which he called logarithms. The reason it can be useful is that with a table of logs (and reading backwards gives exponents), you can perform multiplications by doing additions, divisions by doing subtractions, and square roots by halving. Difficult computations become easy. It’s mainly coincidence that “logarithm” and “algorithm” are so similar. At the time of Napier, the usual way of spelling “algorithm” was “algorism” as it was based on the name Muhammad ibn Musa al-Khwarizmi which was spelled with several variations. The word “logarithm” may have encouraged spelling “algorism” with a “th” instead of an “s”.', 'result': {'fake': 0.0008, 'real': 0.9992}, 'status': 'success'}], 'credits_used': 3, 'credits': 1994686, 'subscription': 0, 'content': 'John Napier called them that when he invented them about 1610. He merged two words with Greek roots, “logos” which was used for ratios, and “arithmos” for number: “logarithms” if you drop a couple of letters. He compared two sequences. One sequence was a geometric sequence where adjacent terms have a common ratio, like the sequence 2,4,8,16,32,…,2,4,8,16,32,…,2, 4, 8, 16, 32,\\ldots, and the other was an arithmetic sequence where adjacent terms have a common difference like 1,2,3,4,5,….1,2,3,4,5,….1, 2, 3, 4, 5,\\ldots.  Going from the arithmetic sequence to the geometric sequence involves exponentiation nnn goes to 2n2n2^n for this pair of sequences. Napier realized the opposite operation could be useful, going from the geometric sequence to the arithmetic sequence. For that he invented the inverse of exponentiation, which he called logarithms. The reason it can be useful is that with a table of logs (and reading backwards gives exponents), you can perform multiplications by doing additions, divisions by doing subtractions, and square roots by halving. Difficult computations become easy. It’s mainly coincidence that “logarithm” and “algorithm” are so similar. At the time of Napier, the usual way of spelling “algorithm” was “algorism” as it was based on the name Muhammad ibn Musa al-Khwarizmi which was spelled with several variations. The word “logarithm” may have encouraged spelling “algorism” with a “th” instead of an “s”.', 'aiModelVersion': '1'}",0.9992
David Joyce,Updated 3y,How did the Pythagorean theorem look in the original symbols or writing of Pythagoras’ time?,"Here’s Euclid’s proof, the earliest one we have. Euclid lived about 2300 years ago, about 200 years after Pythagoras.

This is my translation from the original Greek. The differences are (1) Euclid’s was in Greek, not English, (2) his diagram was hand drawn and there was no color, (3) he wrote Greek letters to name points, and (4) the column of justifications (like I.46) was added long after Euclid to help the reader find the justifications.

Pythagoras may not have had any proof of this theorem. If he did, it was probably based on properties of similar figures. Proofs developed between the time of Pythagoras and Euclid. They were well developed by the time of Theatetus and Eudoxus (over 50 years before Euclid). Hippocrates of Chios (about 120 years before Euclid and 80 years after Pythagoras) wrote the first book of Elements, now lost, and it probably had proofs in the style of Euclid that you see above.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/ifsqa7hp9no6xdkb', 'title': 'How did the Pythagorean theorem look in the original symbols or writing of Pythagoras’ time?', 'score': {'original': 0.9975, 'ai': 0.0025}, 'blocks': [{'text': 'Here’s Euclid’s proof, the earliest one we have. Euclid lived about 2300 years ago, about 200 years after Pythagoras.\n\nThis is my translation from the original Greek. The differences are (1) Euclid’s was in Greek, not English, (2) his diagram was hand drawn and there was no color, (3) he wrote Greek letters to name points, and (4) the column of justifications (like I.46) was added long after Euclid to help the reader find the justifications.\n\nPythagoras may not have had any proof of this theorem. If he did, it was probably based on properties of similar figures. Proofs developed between the time of Pythagoras and Euclid. They were well developed by the time of Theatetus and Eudoxus (over 50 years before Euclid). Hippocrates of Chios (about 120 years before Euclid and 80 years after Pythagoras) wrote the first book of Elements, now lost, and it probably had proofs in the style of Euclid that you see above.', 'result': {'fake': 0.0025, 'real': 0.9975}, 'status': 'success'}], 'credits_used': 2, 'credits': 1994684, 'subscription': 0, 'content': 'Here’s Euclid’s proof, the earliest one we have. Euclid lived about 2300 years ago, about 200 years after Pythagoras.\n\nThis is my translation from the original Greek. The differences are (1) Euclid’s was in Greek, not English, (2) his diagram was hand drawn and there was no color, (3) he wrote Greek letters to name points, and (4) the column of justifications (like I.46) was added long after Euclid to help the reader find the justifications.\n\nPythagoras may not have had any proof of this theorem. If he did, it was probably based on properties of similar figures. Proofs developed between the time of Pythagoras and Euclid. They were well developed by the time of Theatetus and Eudoxus (over 50 years before Euclid). Hippocrates of Chios (about 120 years before Euclid and 80 years after Pythagoras) wrote the first book of Elements, now lost, and it probably had proofs in the style of Euclid that you see above.', 'aiModelVersion': '1'}",0.9975
Alon Amit,1y,"Is it true that the Chinese created some form of integral calculus before the Europeans? If it is, how different was the method?","First, some general comments on this type of questions.

Whatever form of integral calculus was created or discovered by whomever, it wasn’t “The Chinese”. You may be thinking of a person or a small group of people, and attributing it to an entire nation makes no sense. Much of the modern idea of calculus was developed by Isaac Newton, not “The English” nor “The lifelong bachelors”.

It is reasonable to ascribe the development of some theory or technology to a culture, or a nation, rather than to a person or a small group of people, when that culture embraced those ideas en masse, teaching them, developing them, applying them and spreading them. The Old Kingdom of Ancient Egypt, for example, developed techniques for building great pyramids. Whatever it took to build those pyramids, the Old Kingdom culture knew how to do it, and improved it over centuries. It’s reasonable to assert that the Old Kingdom developed the practice of pyramid building. But it doesn’t make sense to assert that this or that Nation created this or that body of knowledge because a person wrote a book with some deep ideas ahead of their time.

It is interesting, and often useful, to observe the germs of some big idea being noted or developed by some individual centuries before it matured. What I intensely dislike, and also find baffling, is the attribution of such achievements to “My People and not Your People”. It breeds outlandish jingoistic perspectives such as the one expressed in an answer to this very question:

The evolution of mathematics (or “everything”) is not some childish race between nations.

So, was “some form” of integral calculus developed by a Chinese mathematician before “The Europeans” (presumably, Newton and Leibniz)? It’s hard to say what, specifically, the OP has been told, but perhaps it is something along those lines (found here
, and apparently lifted from an old version
 of the Wikipedia article on the History of Calculus
):

In the third century Liu Hui wrote his Nine Chapters and also Haidao suanjing (Sea Island Mathematical Manual), which dealt with using the Pythagorean theorem (already stated in the Nine Chapters), known in China as the Gougu theorem, to measure the size of things. He discovered the usage of Cavalieri's principle to find an accurate formula for the volume of a cylinder, showing a grasp of elementary concepts associated with the differential and integral calculus. In the 11th century, the Chinese polymath, Shen Kuo, developed 'packing' equations that dealt with integration.

This is the kind of vague reductionism that one often finds in this kind of discussions. Cavalieri’s principle is an important idea, but it has much older roots (the Method of Exhaustion was developed with surprising rigor by Eudoxus in the 4th century BCE, and possibly earlier by Antiphon), and while it can be viewed as an early glimpse of the idea of integration, it is not in any way an “integral calculus”.

There’s no doubt that Chinese mathematicians of antiquity such as Liu Hui
, Zu Chongzhi
 and, later, Shen Kuo
 made innovative, important discoveries. I can’t, however, justify describing their work as “a form of integral calculus” without stretching “a form of” beyond reason.

What Newton and Leibniz (and before them, Gregory and Barrow) developed was a coherent, comprehensive set of techniques for manipulating and computing with differential and integral entities – an actual calculus – with which they, and every modern student of mathematics at the high-school level, could solve problems that were completely out of reach previously, to anyone, in any culture.

This takes nothing away from the ingenuity and achievements of Eudoxus, Archimedes, Liu Hui or Āryabhaṭa. But I don’t feel it’s valuable to compare “The Chinese” with “The Europeans”, or to brand observations like exhaustion and Cavalieri’s principle “a form of integral calculus”. Those are important precursors, but nowhere near the depth and rigor obtained in the 17th century by Newton and his contemporaries.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/sc18eakqf35tv4dw', 'title': 'Is it true that the Chinese created some form of integral calculus before the Europeans? If it is, how different was the method?', 'score': {'original': 0.84005, 'ai': 0.15995}, 'blocks': [{'text': ""First, some general comments on this type of questions.\n\nWhatever form of integral calculus was created or discovered by whomever, it wasn’t “The Chinese”. You may be thinking of a person or a small group of people, and attributing it to an entire nation makes no sense. Much of the modern idea of calculus was developed by Isaac Newton, not “The English” nor “The lifelong bachelors”.\n\nIt is reasonable to ascribe the development of some theory or technology to a culture, or a nation, rather than to a person or a small group of people, when that culture embraced those ideas en masse, teaching them, developing them, applying them and spreading them. The Old Kingdom of Ancient Egypt, for example, developed techniques for building great pyramids. Whatever it took to build those pyramids, the Old Kingdom culture knew how to do it, and improved it over centuries. It’s reasonable to assert that the Old Kingdom developed the practice of pyramid building. But it doesn’t make sense to assert that this or that Nation created this or that body of knowledge because a person wrote a book with some deep ideas ahead of their time.\n\nIt is interesting, and often useful, to observe the germs of some big idea being noted or developed by some individual centuries before it matured. What I intensely dislike, and also find baffling, is the attribution of such achievements to “My People and not Your People”. It breeds outlandish jingoistic perspectives such as the one expressed in an answer to this very question:\n\nThe evolution of mathematics (or “everything”) is not some childish race between nations.\n\nSo, was “some form” of integral calculus developed by a Chinese mathematician before “The Europeans” (presumably, Newton and Leibniz)? It’s hard to say what, specifically, the OP has been told, but perhaps it is something along those lines (found here\n, and apparently lifted from an old version\n of the Wikipedia article on the History of Calculus\n):\n\nIn the third century Liu Hui wrote his Nine Chapters and also Haidao suanjing (Sea Island Mathematical Manual), which dealt with using the Pythagorean theorem (already stated in the Nine Chapters), known in China as the Gougu theorem, to measure the size of things. He discovered the usage of Cavalieri's principle to find an accurate formula for the volume of a cylinder, showing a grasp of elementary concepts associated with the differential and integral calculus. In the 11th century, the Chinese polymath, Shen Kuo, developed 'packing' equations that dealt with integration.\n\nThis is the kind of vague reductionism that one often finds in this kind of discussions. Cavalieri’s principle is an important idea, but it has much older roots (the Method of Exhaustion was developed with surprising rigor by Eudoxus in the 4th century BCE, and possibly earlier by Antiphon), and while it can be viewed as an early glimpse of the idea of integration, it is not in any way an “integral calculus”.\n\nThere’s no doubt that Chinese mathematicians of antiquity such as Liu Hui\n, Zu Chongzhi\n and, later, Shen Kuo\n made innovative, important discoveries. I can’t, however, justify describing their work as"", 'result': {'fake': 0.0119, 'real': 0.9881}, 'status': 'success'}, {'text': '“a form of integral calculus” without stretching “a form of” beyond reason.\n\nWhat Newton and Leibniz (and before them, Gregory and Barrow) developed was a coherent, comprehensive set of techniques for manipulating and computing with differential and integral entities – an actual calculus – with which they, and every modern student of mathematics at the high-school level, could solve problems that were completely out of reach previously, to anyone, in any culture.\n\nThis takes nothing away from the ingenuity and achievements of Eudoxus, Archimedes, Liu Hui or Āryabhaṭa. But I don’t feel it’s valuable to compare “The Chinese” with “The Europeans”, or to brand observations like exhaustion and Cavalieri’s principle “a form of integral calculus”. Those are important precursors, but nowhere near the depth and rigor obtained in the 17th century by Newton and his contemporaries.', 'result': {'fake': 0.0616, 'real': 0.9384}, 'status': 'success'}], 'credits_used': 7, 'credits': 1994677, 'subscription': 0, 'content': ""First, some general comments on this type of questions.\n\nWhatever form of integral calculus was created or discovered by whomever, it wasn’t “The Chinese”. You may be thinking of a person or a small group of people, and attributing it to an entire nation makes no sense. Much of the modern idea of calculus was developed by Isaac Newton, not “The English” nor “The lifelong bachelors”.\n\nIt is reasonable to ascribe the development of some theory or technology to a culture, or a nation, rather than to a person or a small group of people, when that culture embraced those ideas en masse, teaching them, developing them, applying them and spreading them. The Old Kingdom of Ancient Egypt, for example, developed techniques for building great pyramids. Whatever it took to build those pyramids, the Old Kingdom culture knew how to do it, and improved it over centuries. It’s reasonable to assert that the Old Kingdom developed the practice of pyramid building. But it doesn’t make sense to assert that this or that Nation created this or that body of knowledge because a person wrote a book with some deep ideas ahead of their time.\n\nIt is interesting, and often useful, to observe the germs of some big idea being noted or developed by some individual centuries before it matured. What I intensely dislike, and also find baffling, is the attribution of such achievements to “My People and not Your People”. It breeds outlandish jingoistic perspectives such as the one expressed in an answer to this very question:\n\nThe evolution of mathematics (or “everything”) is not some childish race between nations.\n\nSo, was “some form” of integral calculus developed by a Chinese mathematician before “The Europeans” (presumably, Newton and Leibniz)? It’s hard to say what, specifically, the OP has been told, but perhaps it is something along those lines (found here\n, and apparently lifted from an old version\n of the Wikipedia article on the History of Calculus\n):\n\nIn the third century Liu Hui wrote his Nine Chapters and also Haidao suanjing (Sea Island Mathematical Manual), which dealt with using the Pythagorean theorem (already stated in the Nine Chapters), known in China as the Gougu theorem, to measure the size of things. He discovered the usage of Cavalieri's principle to find an accurate formula for the volume of a cylinder, showing a grasp of elementary concepts associated with the differential and integral calculus. In the 11th century, the Chinese polymath, Shen Kuo, developed 'packing' equations that dealt with integration.\n\nThis is the kind of vague reductionism that one often finds in this kind of discussions. Cavalieri’s principle is an important idea, but it has much older roots (the Method of Exhaustion was developed with surprising rigor by Eudoxus in the 4th century BCE, and possibly earlier by Antiphon), and while it can be viewed as an early glimpse of the idea of integration, it is not in any way an “integral calculus”.\n\nThere’s no doubt that Chinese mathematicians of antiquity such as Liu Hui\n, Zu Chongzhi\n and, later, Shen Kuo\n made innovative, important discoveries. I can’t, however, justify describing their work as “a form of integral calculus” without stretching “a form of” beyond reason.\n\nWhat Newton and Leibniz (and before them, Gregory and Barrow) developed was a coherent, comprehensive set of techniques for manipulating and computing with differential and integral entities – an actual calculus – with which they, and every modern student of mathematics at the high-school level, could solve problems that were completely out of reach previously, to anyone, in any culture.\n\nThis takes nothing away from the ingenuity and achievements of Eudoxus, Archimedes, Liu Hui or Āryabhaṭa. But I don’t feel it’s valuable to compare “The Chinese” with “The Europeans”, or to brand observations like exhaustion and Cavalieri’s principle “a form of integral calculus”. Those are important precursors, but nowhere near the depth and rigor obtained in the 17th century by Newton and his contemporaries."", 'aiModelVersion': '1'}",0.84005
Alon Amit,2y,"The French genius Evariste Galois, one of the greatest mathematical talents of all time, is said to have foretold his own death. Having proved the Fundamental Theorem of Algebra, Evariste Galois then died in which manner?","Galois did not prove the Fundamental Theorem of Algebra. It was already well-established when he was born.

During his very short life he succeeded in developing what is now known as Galois Theory, which lays down the profound connections between polynomials, fields and symmetry groups. In modern presentations of the theory, some of the key results are often collected under the headline “Fundamental Theorem of Galois Theory”. It doesn’t imply or depend on the Fundamental Theorem of Algebra.

The tragic circumstances of Galois’ death are documented in about a million online and offline sources, including his biography
 on Wikipedia.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/lqni8ecum5s79yw1', 'title': 'The French genius Evariste Galois, one of the greatest mathematical talents of all time, is said to have foretold his own death. Having proved the Fundamental Theorem of Algebra, Evariste Galois then died in which manner?', 'score': {'original': 0.9476, 'ai': 0.0524}, 'blocks': [{'text': 'Galois did not prove the Fundamental Theorem of Algebra. It was already well-established when he was born.\n\nDuring his very short life he succeeded in developing what is now known as Galois Theory, which lays down the profound connections between polynomials, fields and symmetry groups. In modern presentations of the theory, some of the key results are often collected under the headline “Fundamental Theorem of Galois Theory”. It doesn’t imply or depend on the Fundamental Theorem of Algebra.\n\nThe tragic circumstances of Galois’ death are documented in about a million online and offline sources, including his biography\n on Wikipedia.', 'result': {'fake': 0.0524, 'real': 0.9476}, 'status': 'success'}], 'credits_used': 1, 'credits': 1994676, 'subscription': 0, 'content': 'Galois did not prove the Fundamental Theorem of Algebra. It was already well-established when he was born.\n\nDuring his very short life he succeeded in developing what is now known as Galois Theory, which lays down the profound connections between polynomials, fields and symmetry groups. In modern presentations of the theory, some of the key results are often collected under the headline “Fundamental Theorem of Galois Theory”. It doesn’t imply or depend on the Fundamental Theorem of Algebra.\n\nThe tragic circumstances of Galois’ death are documented in about a million online and offline sources, including his biography\n on Wikipedia.', 'aiModelVersion': '1'}",0.9476
Daniel Schwartz,1y,Would many advances responsible for calculus likely still have occurred without Newton or Leibniz?,"“Would many advances responsible for calculus likely still have occurred without Newton or Leibniz?”

Eventually, no doubt. But who knows how long it would have taken? Sometimes humanity's knowledge leaps forward due to genius. In that case, the genius truly is indispensable.

Remember, Newton was the man who wanted to prove the mathematical foundation of his Theory of Universal Gravitation… but he needed integral calculus, and it simply didn't exist. So he took two years off, invented integral calculus, and then went back to work. And he did this as a graduate student!

Many mathematical historians have observed that, before Newton, to find a comparable mathematical intellect — one who could invent his own mathematics, if the math of the day wasn't enough — you have to go all the way back to Archimedes. In other words, we had to wait almost two thousand years for another genius of that level to come by.

We can give thanks that such pioneers existed. Our world is tremendously richer thanks to them… and also thanks to them, we understand that world much better.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/mwzo7f4e6rx3tsid', 'title': 'Would many advances responsible for calculus likely still have occurred without Newton or Leibniz?', 'score': {'original': 0.9952, 'ai': 0.0048}, 'blocks': [{'text': ""“Would many advances responsible for calculus likely still have occurred without Newton or Leibniz?”\n\nEventually, no doubt. But who knows how long it would have taken? Sometimes humanity's knowledge leaps forward due to genius. In that case, the genius truly is indispensable.\n\nRemember, Newton was the man who wanted to prove the mathematical foundation of his Theory of Universal Gravitation… but he needed integral calculus, and it simply didn't exist. So he took two years off, invented integral calculus, and then went back to work. And he did this as a graduate student!\n\nMany mathematical historians have observed that, before Newton, to find a comparable mathematical intellect — one who could invent his own mathematics, if the math of the day wasn't enough — you have to go all the way back to Archimedes. In other words, we had to wait almost two thousand years for another genius of that level to come by.\n\nWe can give thanks that such pioneers existed. Our world is tremendously richer thanks to them… and also thanks to them, we understand that world much better."", 'result': {'fake': 0.0048, 'real': 0.9952}, 'status': 'success'}], 'credits_used': 2, 'credits': 1994674, 'subscription': 0, 'content': ""“Would many advances responsible for calculus likely still have occurred without Newton or Leibniz?”\n\nEventually, no doubt. But who knows how long it would have taken? Sometimes humanity's knowledge leaps forward due to genius. In that case, the genius truly is indispensable.\n\nRemember, Newton was the man who wanted to prove the mathematical foundation of his Theory of Universal Gravitation… but he needed integral calculus, and it simply didn't exist. So he took two years off, invented integral calculus, and then went back to work. And he did this as a graduate student!\n\nMany mathematical historians have observed that, before Newton, to find a comparable mathematical intellect — one who could invent his own mathematics, if the math of the day wasn't enough — you have to go all the way back to Archimedes. In other words, we had to wait almost two thousand years for another genius of that level to come by.\n\nWe can give thanks that such pioneers existed. Our world is tremendously richer thanks to them… and also thanks to them, we understand that world much better."", 'aiModelVersion': '1'}",0.9952
Alex Eustis,3y,How did the Pythagoreans know that the square root of two was irrational if they didn't have decimal numbers?,"The Greeks (more specifically, the Pythagoreans) knew that

Isoceles right triangles exist
You can form the ratio of the hypotenuse to the leg
The square of that ratio is 2 (by the Pythagorean Theorem).
However, there is not a ratio of two integers whose square is 2.

As a result, they would have been forced to conclude that there exist incommensurable ratios; i.e. a ratio of two magnitudes that is not equal to a ratio of two integers.

From there, it's not such a big leap to irrational numbers. (Arguably, they're precisely the same thing). According to Commensurability (mathematics) - Wikipedia
 (and linked sources), the Pythagoreans are credited with the discovery of irrational numbers, based on mathematical reasoning such as 1–4 above.

Strangely enough, even though irrational numbers are an unavoidable consequence of the mathematics that they developed, the Pythagoreans considered them a form a heresy. See for instance Hippasus - Wikipedia
, who was purported to have been drowned at sea for the crime of divulging the nature of the the irrational. The details of exactly what happened are conflicted and probably lost to history, but what's certain is that the discovery of irrational numbers would have been troubling to the Pythagoreans, to say the least — for they preached that all quantities could be expressed as the ratio of two whole numbers, and were even said to have ascribed religious significance to this belief.

Note: this question mentions decimal representation, which the Pythagoreans indeed did not have — but that is entirely irrelevant to the discovery or proof of irrationality, which simply means “not rational.”","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/neo1ylrbjzqapi0v', 'title': ""How did the Pythagoreans know that the square root of two was irrational if they didn't have decimal numbers?"", 'score': {'original': 0.9997, 'ai': 0.0003}, 'blocks': [{'text': ""The Greeks (more specifically, the Pythagoreans) knew that\n\nIsoceles right triangles exist\nYou can form the ratio of the hypotenuse to the leg\nThe square of that ratio is 2 (by the Pythagorean Theorem).\nHowever, there is not a ratio of two integers whose square is 2.\n\nAs a result, they would have been forced to conclude that there exist incommensurable ratios; i.e. a ratio of two magnitudes that is not equal to a ratio of two integers.\n\nFrom there, it's not such a big leap to irrational numbers. (Arguably, they're precisely the same thing). According to Commensurability (mathematics) - Wikipedia\n (and linked sources), the Pythagoreans are credited with the discovery of irrational numbers, based on mathematical reasoning such as 1–4 above.\n\nStrangely enough, even though irrational numbers are an unavoidable consequence of the mathematics that they developed, the Pythagoreans considered them a form a heresy. See for instance Hippasus - Wikipedia\n, who was purported to have been drowned at sea for the crime of divulging the nature of the the irrational. The details of exactly what happened are conflicted and probably lost to history, but what's certain is that the discovery of irrational numbers would have been troubling to the Pythagoreans, to say the least — for they preached that all quantities could be expressed as the ratio of two whole numbers, and were even said to have ascribed religious significance to this belief.\n\nNote: this question mentions decimal representation, which the Pythagoreans indeed did not have — but that is entirely irrelevant to the discovery or proof of irrationality, which simply means “not rational.”"", 'result': {'fake': 0.0003, 'real': 0.9997}, 'status': 'success'}], 'credits_used': 3, 'credits': 1994671, 'subscription': 0, 'content': ""The Greeks (more specifically, the Pythagoreans) knew that\n\nIsoceles right triangles exist\nYou can form the ratio of the hypotenuse to the leg\nThe square of that ratio is 2 (by the Pythagorean Theorem).\nHowever, there is not a ratio of two integers whose square is 2.\n\nAs a result, they would have been forced to conclude that there exist incommensurable ratios; i.e. a ratio of two magnitudes that is not equal to a ratio of two integers.\n\nFrom there, it's not such a big leap to irrational numbers. (Arguably, they're precisely the same thing). According to Commensurability (mathematics) - Wikipedia\n (and linked sources), the Pythagoreans are credited with the discovery of irrational numbers, based on mathematical reasoning such as 1–4 above.\n\nStrangely enough, even though irrational numbers are an unavoidable consequence of the mathematics that they developed, the Pythagoreans considered them a form a heresy. See for instance Hippasus - Wikipedia\n, who was purported to have been drowned at sea for the crime of divulging the nature of the the irrational. The details of exactly what happened are conflicted and probably lost to history, but what's certain is that the discovery of irrational numbers would have been troubling to the Pythagoreans, to say the least — for they preached that all quantities could be expressed as the ratio of two whole numbers, and were even said to have ascribed religious significance to this belief.\n\nNote: this question mentions decimal representation, which the Pythagoreans indeed did not have — but that is entirely irrelevant to the discovery or proof of irrationality, which simply means “not rational.”"", 'aiModelVersion': '1'}",0.9997
Senia Sheydvasser,1y,Which mathematician first published what we now call the shell method to calculate the volume of rotational solids? How much later was this discovery compared to the disk/washer methods?,"I genuinely think that this might be lost to history.

Methods for computing the volumes of rotational solids are old—Archimedes knew how to find the volumes of cones and spheres back in the 3rd century BCE. Pappus worked out the volume of a torus in the 4th century CE.

Of course, it would be inaccurate to describe either as using either washers or shells. But even so, I’m not sure the question of which mathematician was the first to use one of these methods is properly well-defined. To wit, the idea of splitting up a rotational solid into infinitesimal washers to compute its volume is usually attributed to Kepler—specifically, his 1615 book New solid geometry of wine barrels. But one should note that this was well over 50 years before there was even a whisper of a general theory of integration. The fundamental theorem of calculus simply didn’t exist at this point.

In short, the usual type of problem that a modern calculus student would expect to see as part of their unit on the washer method of integration would have been completely out of Kepler’s reach.

This is particularly relevant when one considers the washer vs. shell method, because for the types of problems that Kepler and his predecessors would have been able to solve, there would either be no difference between the two, or the washer method would have been simply easier to work with. The shell method only really starts to become relevant when you are properly trying to compute complicated integrals—there, it can make a big difference. But if you don’t have the other components for computing integrals (i.e. 
u
u
-substitution, integration by parts), then this just doesn’t come up.

As such, I would suspect that probably there is a hundred year gap (perhaps longer) between use of the washer method and the shell method.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/5nips3lm6wxqbtz7', 'title': 'Which mathematician first published what we now call the shell method to calculate the volume of rotational solids? How much later was this discovery compared to the disk/washer methods?', 'score': {'original': 0.9997, 'ai': 0.0003}, 'blocks': [{'text': 'I genuinely think that this might be lost to history.\n\nMethods for computing the volumes of rotational solids are old—Archimedes knew how to find the volumes of cones and spheres back in the 3rd century BCE. Pappus worked out the volume of a torus in the 4th century CE.\n\nOf course, it would be inaccurate to describe either as using either washers or shells. But even so, I’m not sure the question of which mathematician was the first to use one of these methods is properly well-defined. To wit, the idea of splitting up a rotational solid into infinitesimal washers to compute its volume is usually attributed to Kepler—specifically, his 1615 book New solid geometry of wine barrels. But one should note that this was well over 50 years before there was even a whisper of a general theory of integration. The fundamental theorem of calculus simply didn’t exist at this point.\n\nIn short, the usual type of problem that a modern calculus student would expect to see as part of their unit on the washer method of integration would have been completely out of Kepler’s reach.\n\nThis is particularly relevant when one considers the washer vs. shell method, because for the types of problems that Kepler and his predecessors would have been able to solve, there would either be no difference between the two, or the washer method would have been simply easier to work with. The shell method only really starts to become relevant when you are properly trying to compute complicated integrals—there, it can make a big difference. But if you don’t have the other components for computing integrals (i.e. \nu\nu\n-substitution, integration by parts), then this just doesn’t come up.\n\nAs such, I would suspect that probably there is a hundred year gap (perhaps longer) between use of the washer method and the shell method.', 'result': {'fake': 0.0003, 'real': 0.9997}, 'status': 'success'}], 'credits_used': 4, 'credits': 1994667, 'subscription': 0, 'content': 'I genuinely think that this might be lost to history.\n\nMethods for computing the volumes of rotational solids are old—Archimedes knew how to find the volumes of cones and spheres back in the 3rd century BCE. Pappus worked out the volume of a torus in the 4th century CE.\n\nOf course, it would be inaccurate to describe either as using either washers or shells. But even so, I’m not sure the question of which mathematician was the first to use one of these methods is properly well-defined. To wit, the idea of splitting up a rotational solid into infinitesimal washers to compute its volume is usually attributed to Kepler—specifically, his 1615 book New solid geometry of wine barrels. But one should note that this was well over 50 years before there was even a whisper of a general theory of integration. The fundamental theorem of calculus simply didn’t exist at this point.\n\nIn short, the usual type of problem that a modern calculus student would expect to see as part of their unit on the washer method of integration would have been completely out of Kepler’s reach.\n\nThis is particularly relevant when one considers the washer vs. shell method, because for the types of problems that Kepler and his predecessors would have been able to solve, there would either be no difference between the two, or the washer method would have been simply easier to work with. The shell method only really starts to become relevant when you are properly trying to compute complicated integrals—there, it can make a big difference. But if you don’t have the other components for computing integrals (i.e. \nu\nu\n-substitution, integration by parts), then this just doesn’t come up.\n\nAs such, I would suspect that probably there is a hundred year gap (perhaps longer) between use of the washer method and the shell method.', 'aiModelVersion': '1'}",0.9997
Alon Amit,1y,Could someone help me better understand the contribution of mathematician Johann August Grunert to Fermat's Last Theorem?,"As far as I can tell, Grünert contributed one paper to research around Fermat’s Last Theorem. I cannot find an online link to it, but the reference is:

Wenn 
n
>
1
n>1
, so gibt es unter den ganzen Zahlen von 
1
1
 bis 
n
n
 nicht zwei Werte von 
x
x
 und 
y
y
, für welche, wenn 
z
z
 einen ganzen Wert bezeichnet, 
x
n
+
y
n
=
z
n
xn+yn=zn
 ist. Archiv Math. Phys., 27, 1856, 119–120.

The title is a bit of a mouthful. In English, it reads “when 
n
>
1
n>1
, among the integers from 
1
1
 to 
n
n
 there aren’t two values for 
x
x
 and 
y
y
 for which, if 
z
z
 is an integer, then 
x
n
+
y
n
=
z
n
xn+yn=zn
”.

In short, this says that if 
x
n
+
y
n
=
z
n
xn+yn=zn
 is a nonzero solution to FLT then both 
x
x
 and 
y
y
 must be larger than 
n
n
.

I wouldn’t say that this paper left a lasting mark on the centuries-long effort to prove FLT. In fact, you should be able to prove this yourself in about two lines of algebra, starting from

x
n
=
z
n
−
y
n
=
(
z
−
y
)
(
z
n
−
1
+
z
n
−
2
y
+
…
+
y
n
−
1
)
xn=zn−yn=(z−y)(zn−1+zn−2y+…+yn−1)

This was, to be honest, a very minor observation even back in 1856. Estimates on the relative sizes of 
x
,
y
,
z
x,y,z
 and 
n
n
 have been a significant thread of research over the years, with some highly non-trivial results. This one is truly elementary.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/fnazjhir209qywse', 'title': ""Could someone help me better understand the contribution of mathematician Johann August Grunert to Fermat's Last Theorem?"", 'score': {'original': 0.9997, 'ai': 0.0003}, 'blocks': [{'text': 'As far as I can tell, Grünert contributed one paper to research around Fermat’s Last Theorem. I cannot find an online link to it, but the reference is:\n\nWenn \nn\n>\n1\nn>1\n, so gibt es unter den ganzen Zahlen von \n1\n1\n bis \nn\nn\n nicht zwei Werte von \nx\nx\n und \ny\ny\n, für welche, wenn \nz\nz\n einen ganzen Wert bezeichnet, \nx\nn\n+\ny\nn\n=\nz\nn\nxn+yn=zn\n ist. Archiv Math. Phys., 27, 1856, 119–120.\n\nThe title is a bit of a mouthful. In English, it reads “when \nn\n>\n1\nn>1\n, among the integers from \n1\n1\n to \nn\nn\n there aren’t two values for \nx\nx\n and \ny\ny\n for which, if \nz\nz\n is an integer, then \nx\nn\n+\ny\nn\n=\nz\nn\nxn+yn=zn\n”.\n\nIn short, this says that if \nx\nn\n+\ny\nn\n=\nz\nn\nxn+yn=zn\n is a nonzero solution to FLT then both \nx\nx\n and \ny\ny\n must be larger than \nn\nn\n.\n\nI wouldn’t say that this paper left a lasting mark on the centuries-long effort to prove FLT. In fact, you should be able to prove this yourself in about two lines of algebra, starting from\n\nx\nn\n=\nz\nn\n−\ny\nn\n=\n(\nz\n−\ny\n)\n(\nz\nn\n−\n1\n+\nz\nn\n−\n2\ny\n+\n…\n+\ny\nn\n−\n1\n)\nxn=zn−yn=(z−y)(zn−1+zn−2y+…+yn−1)\n\nThis was, to be honest, a very minor observation even back in 1856. Estimates on the relative sizes of \nx\n,\ny\n,\nz\nx,y,z\n and \nn\nn\n have been a significant thread of research over the years, with some highly non-trivial results. This one is truly elementary.', 'result': {'fake': 0.0003, 'real': 0.9997}, 'status': 'success'}], 'credits_used': 3, 'credits': 1994664, 'subscription': 0, 'content': 'As far as I can tell, Grünert contributed one paper to research around Fermat’s Last Theorem. I cannot find an online link to it, but the reference is:\n\nWenn \nn\n>\n1\nn>1\n, so gibt es unter den ganzen Zahlen von \n1\n1\n bis \nn\nn\n nicht zwei Werte von \nx\nx\n und \ny\ny\n, für welche, wenn \nz\nz\n einen ganzen Wert bezeichnet, \nx\nn\n+\ny\nn\n=\nz\nn\nxn+yn=zn\n ist. Archiv Math. Phys., 27, 1856, 119–120.\n\nThe title is a bit of a mouthful. In English, it reads “when \nn\n>\n1\nn>1\n, among the integers from \n1\n1\n to \nn\nn\n there aren’t two values for \nx\nx\n and \ny\ny\n for which, if \nz\nz\n is an integer, then \nx\nn\n+\ny\nn\n=\nz\nn\nxn+yn=zn\n”.\n\nIn short, this says that if \nx\nn\n+\ny\nn\n=\nz\nn\nxn+yn=zn\n is a nonzero solution to FLT then both \nx\nx\n and \ny\ny\n must be larger than \nn\nn\n.\n\nI wouldn’t say that this paper left a lasting mark on the centuries-long effort to prove FLT. In fact, you should be able to prove this yourself in about two lines of algebra, starting from\n\nx\nn\n=\nz\nn\n−\ny\nn\n=\n(\nz\n−\ny\n)\n(\nz\nn\n−\n1\n+\nz\nn\n−\n2\ny\n+\n…\n+\ny\nn\n−\n1\n)\nxn=zn−yn=(z−y)(zn−1+zn−2y+…+yn−1)\n\nThis was, to be honest, a very minor observation even back in 1856. Estimates on the relative sizes of \nx\n,\ny\n,\nz\nx,y,z\n and \nn\nn\n have been a significant thread of research over the years, with some highly non-trivial results. This one is truly elementary.', 'aiModelVersion': '1'}",0.9997
David Joyce,1y,Would many advances responsible for calculus likely still have occurred without Newton or Leibniz?,"Much of calculus was developed before Newton and Leibniz. For example, the idea of finding areas by polygonal estimates was used by Euclid (and predates him). The concept of variable rates of change was studied by the Merton scholars in the early 1300s, and by 1350 Oresme proved the Fundamental Theorem of Calculus. Fermat computed integrals and derivatives by 1640. In the next decade others showed the natural logarithm was the integral of 
1
/
x
.
1/x.
 Calvalieri, Torricelli, and Wallace used infinitesimals to prove theorems about integrals.

It makes you wonder what Newton and Leibniz actually contributed. Each in their own way collected these results, founded notations for them, and developed new theorems. If they hadn’t, someone else would have. Without their contributions, mathematical analysis might have been delayed a couple of decades.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/fxqdysw60viuph7c', 'title': 'Would many advances responsible for calculus likely still have occurred without Newton or Leibniz?', 'score': {'original': 0.9951, 'ai': 0.0049}, 'blocks': [{'text': 'Much of calculus was developed before Newton and Leibniz. For example, the idea of finding areas by polygonal estimates was used by Euclid (and predates him). The concept of variable rates of change was studied by the Merton scholars in the early 1300s, and by 1350 Oresme proved the Fundamental Theorem of Calculus. Fermat computed integrals and derivatives by 1640. In the next decade others showed the natural logarithm was the integral of \n1\n/\nx\n.\n1/x.\n Calvalieri, Torricelli, and Wallace used infinitesimals to prove theorems about integrals.\n\nIt makes you wonder what Newton and Leibniz actually contributed. Each in their own way collected these results, founded notations for them, and developed new theorems. If they hadn’t, someone else would have. Without their contributions, mathematical analysis might have been delayed a couple of decades.', 'result': {'fake': 0.0049, 'real': 0.9951}, 'status': 'success'}], 'credits_used': 2, 'credits': 1994662, 'subscription': 0, 'content': 'Much of calculus was developed before Newton and Leibniz. For example, the idea of finding areas by polygonal estimates was used by Euclid (and predates him). The concept of variable rates of change was studied by the Merton scholars in the early 1300s, and by 1350 Oresme proved the Fundamental Theorem of Calculus. Fermat computed integrals and derivatives by 1640. In the next decade others showed the natural logarithm was the integral of \n1\n/\nx\n.\n1/x.\n Calvalieri, Torricelli, and Wallace used infinitesimals to prove theorems about integrals.\n\nIt makes you wonder what Newton and Leibniz actually contributed. Each in their own way collected these results, founded notations for them, and developed new theorems. If they hadn’t, someone else would have. Without their contributions, mathematical analysis might have been delayed a couple of decades.', 'aiModelVersion': '1'}",0.9951
Alon Amit,3y,Who contributed more to mathematics - Fermat or Galois?,"They contributed differently. The naive desire to linearly rank and sort and award medals isn’t helpful or meaningful.

Galois was born more than 200 years after Fermat. Mathematics in their lifetime was in a very, very different state: in between, Newton happened, and Euler, and Lagrange, and Gauss. Fermat had to discover methods of infinitesimal calculus, and rekindle an interest in the ancient field of number theory; both were already deeply established by the time Galois was born. Fermat asked great questions. Galois gave great answers. Doing either advances mathematics, in a different way.

Really, there’s no point in arguing over who did “more”.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/4tfolkx3gzr5acue', 'title': 'Who contributed more to mathematics - Fermat or Galois?', 'score': {'original': 0.9995, 'ai': 0.0005}, 'blocks': [{'text': 'They contributed differently. The naive desire to linearly rank and sort and award medals isn’t helpful or meaningful.\n\nGalois was born more than 200 years after Fermat. Mathematics in their lifetime was in a very, very different state: in between, Newton happened, and Euler, and Lagrange, and Gauss. Fermat had to discover methods of infinitesimal calculus, and rekindle an interest in the ancient field of number theory; both were already deeply established by the time Galois was born. Fermat asked great questions. Galois gave great answers. Doing either advances mathematics, in a different way.\n\nReally, there’s no point in arguing over who did “more”.', 'result': {'fake': 0.0005, 'real': 0.9995}, 'status': 'success'}], 'credits_used': 2, 'credits': 1994660, 'subscription': 0, 'content': 'They contributed differently. The naive desire to linearly rank and sort and award medals isn’t helpful or meaningful.\n\nGalois was born more than 200 years after Fermat. Mathematics in their lifetime was in a very, very different state: in between, Newton happened, and Euler, and Lagrange, and Gauss. Fermat had to discover methods of infinitesimal calculus, and rekindle an interest in the ancient field of number theory; both were already deeply established by the time Galois was born. Fermat asked great questions. Galois gave great answers. Doing either advances mathematics, in a different way.\n\nReally, there’s no point in arguing over who did “more”.', 'aiModelVersion': '1'}",0.9995
Doug White,1y,"Why is the obelus ""÷"" symbol seldom used to denote the division operation in higher math?","Very often, one needs to inspect the relationship between the numerator expression and the denominator expression (dividend and divisor).

As the expressions become complex, use of

[(Some long multi-term expression)] ÷ [(Some other long expression)]

makes it difficult to see the whole, as the whole is not visible all at once.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/i1amplg7rhnvw5f9', 'title': 'Why is the obelus ""÷"" symbol seldom used to denote the division operation in higher math?', 'score': {'original': 0.9309, 'ai': 0.0691}, 'blocks': [{'text': 'Very often, one needs to inspect the relationship between the numerator expression and the denominator expression (dividend and divisor).\n\nAs the expressions become complex, use of\n\n[(Some long multi-term expression)] ÷ [(Some other long expression)]\n\nmakes it difficult to see the whole, as the whole is not visible all at once.', 'result': {'fake': 0.0691, 'real': 0.9309}, 'status': 'success'}], 'credits_used': 1, 'credits': 1994659, 'subscription': 0, 'content': 'Very often, one needs to inspect the relationship between the numerator expression and the denominator expression (dividend and divisor).\n\nAs the expressions become complex, use of\n\n[(Some long multi-term expression)] ÷ [(Some other long expression)]\n\nmakes it difficult to see the whole, as the whole is not visible all at once.', 'aiModelVersion': '1'}",0.9309
