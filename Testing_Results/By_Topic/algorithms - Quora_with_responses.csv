Authors,Time,Questions,Answers,api_response,originality_score
Luis Argerich,Updated 7y,"With more than 8 million accounts, how do giant sites like Reddit verify so quickly that a username isn't taken?","Surprised there has been only one mention of a Bloom Filter so far.

A Bloom filter is practically perfect for this application, let’s see why.

Using a Bloom filter you have a big array of bits and a number of hash functions, say k hash functions. When you add a new username you hash it k times and turn on those k bits.

When you want to check if a username is taken you hash it k times and if one of those bits is 0 then the username is available, because otherwise the bit would have been turned on.

With a 22Mb filter and using only 7 hash functions you can store 20 million items with a 0.01 probability for false positives. A false positive occurs when you say a username is taken but it really isn’t it just happens that all the bits have been turned on by some other strings.

You can compute this using an online bloom filter calculator: Bloomfilter calculator

The nicest thing about this is that if you say a username is taken when it really isn’t it doesn’t hurt that much, the user just picks another username. This makes a Bloom filter perfect for this application, they are also very nice to filter unsecure passwords, just add all known bad passwords to the filter, with a low probability you can forbid a secure password but the user can just pick something else.

Bloom filters are frequently used as a cache for DB queries, if the filter says the item is not in the DB then you don’t need to query because false negatives are impossible, if the item says the item might be in the DB then you query. The idea is to save disk accesses/queries for things that are not in the DB.

Notice that checking is O(1) and is done in memory, no need for disk accesses or database queries.

This is far better from a linear search and there is no need to resolve collisions as when you use regular hashing, you automatically say if the username is taken ornot. Without storing a single string!","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/14wy0jr297chtkzo', 'title': ""With more than 8 million accounts, how do giant sites like Reddit verify so quickly that a username isn't taken?"", 'score': {'original': 0.9998, 'ai': 0.0002}, 'blocks': [{'text': 'Surprised there has been only one mention of a Bloom Filter so far.\n\nA Bloom filter is practically perfect for this application, let’s see why.\n\nUsing a Bloom filter you have a big array of bits and a number of hash functions, say k hash functions. When you add a new username you hash it k times and turn on those k bits.\n\nWhen you want to check if a username is taken you hash it k times and if one of those bits is 0 then the username is available, because otherwise the bit would have been turned on.\n\nWith a 22Mb filter and using only 7 hash functions you can store 20 million items with a 0.01 probability for false positives. A false positive occurs when you say a username is taken but it really isn’t it just happens that all the bits have been turned on by some other strings.\n\nYou can compute this using an online bloom filter calculator: Bloomfilter calculator\n\nThe nicest thing about this is that if you say a username is taken when it really isn’t it doesn’t hurt that much, the user just picks another username. This makes a Bloom filter perfect for this application, they are also very nice to filter unsecure passwords, just add all known bad passwords to the filter, with a low probability you can forbid a secure password but the user can just pick something else.\n\nBloom filters are frequently used as a cache for DB queries, if the filter says the item is not in the DB then you don’t need to query because false negatives are impossible, if the item says the item might be in the DB then you query. The idea is to save disk accesses/queries for things that are not in the DB.\n\nNotice that checking is O(1) and is done in memory, no need for disk accesses or database queries.\n\nThis is far better from a linear search and there is no need to resolve collisions as when you use regular hashing, you automatically say if the username is taken ornot. Without storing a single string!', 'result': {'fake': 0.0002, 'real': 0.9998}, 'status': 'success'}], 'credits_used': 4, 'credits': 1986638, 'subscription': 0, 'content': 'Surprised there has been only one mention of a Bloom Filter so far.\n\nA Bloom filter is practically perfect for this application, let’s see why.\n\nUsing a Bloom filter you have a big array of bits and a number of hash functions, say k hash functions. When you add a new username you hash it k times and turn on those k bits.\n\nWhen you want to check if a username is taken you hash it k times and if one of those bits is 0 then the username is available, because otherwise the bit would have been turned on.\n\nWith a 22Mb filter and using only 7 hash functions you can store 20 million items with a 0.01 probability for false positives. A false positive occurs when you say a username is taken but it really isn’t it just happens that all the bits have been turned on by some other strings.\n\nYou can compute this using an online bloom filter calculator: Bloomfilter calculator\n\nThe nicest thing about this is that if you say a username is taken when it really isn’t it doesn’t hurt that much, the user just picks another username. This makes a Bloom filter perfect for this application, they are also very nice to filter unsecure passwords, just add all known bad passwords to the filter, with a low probability you can forbid a secure password but the user can just pick something else.\n\nBloom filters are frequently used as a cache for DB queries, if the filter says the item is not in the DB then you don’t need to query because false negatives are impossible, if the item says the item might be in the DB then you query. The idea is to save disk accesses/queries for things that are not in the DB.\n\nNotice that checking is O(1) and is done in memory, no need for disk accesses or database queries.\n\nThis is far better from a linear search and there is no need to resolve collisions as when you use regular hashing, you automatically say if the username is taken ornot. Without storing a single string!', 'aiModelVersion': '1'}",0.9998
Sander Kuusemets,4y,"With more than 8 million accounts, how do giant sites like Reddit verify so quickly that a username isn't taken?","In response to your question I got curious, and decided to test this out on fairly modern hardware.

I generated a text file with 8 million rows, each row a 6–32 characters long alphanumberic string. This will represent our “username”. This file is 176 MB large.

Now, using very basic python code, I decided to search over this file. I took a username from the end of the list (but not the last one). I am running this on a 2019 Macbook Pro.

import mmap 
 
f = open('username_list.txt') 
s = mmap.mmap(f.fileno(), 0, access=mmap.ACCESS_READ) 
if s.find(b'wvdvajlo\n') != -1: 
    print('true') 

Running this program takes:

bash-5.0$ time python3 test.py 
true 
 
real    0m1.097s 
user    0m0.369s 
sys     0m0.109s		 

This was the first time the file had been opened after the write, so kernel had not cached this file properly.

Subsequent runs, or runs searching for a username closer to the beginning, take less time, around 0.4 seconds.

So here’s the bottom line. Eight million usernames is not that much to search over with modern hardware.

A proper search- or a database engine would drop this search time down a ten-, if not a hundredfold, and these are most likely used.

Bigger sites, like Facebook with it’s 1,5 billion users, are the ones that need to start engineering special solutions that everyone is commenting about, to solve the username storage and lookup issues arising there.

But with 8 million users, it really is not a problem.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/una1vfo80dg5reik', 'title': ""With more than 8 million accounts, how do giant sites like Reddit verify so quickly that a username isn't taken?"", 'score': {'original': 0.9993, 'ai': 0.0007}, 'blocks': [{'text': ""In response to your question I got curious, and decided to test this out on fairly modern hardware.\n\nI generated a text file with 8 million rows, each row a 6–32 characters long alphanumberic string. This will represent our “username”. This file is 176 MB large.\n\nNow, using very basic python code, I decided to search over this file. I took a username from the end of the list (but not the last one). I am running this on a 2019 Macbook Pro.\n\nimport mmap\xa0\n\xa0\nf = open('username_list.txt')\xa0\ns = mmap.mmap(f.fileno(), 0, access=mmap.ACCESS_READ)\xa0\nif s.find(b'wvdvajlo\\n') != -1:\xa0\n    print('true')\xa0\n\nRunning this program takes:\n\nbash-5.0$ time python3 test.py\xa0\ntrue\xa0\n\xa0\nreal    0m1.097s\xa0\nuser    0m0.369s\xa0\nsys     0m0.109s\t\t\xa0\n\nThis was the first time the file had been opened after the write, so kernel had not cached this file properly.\n\nSubsequent runs, or runs searching for a username closer to the beginning, take less time, around 0.4 seconds.\n\nSo here’s the bottom line. Eight million usernames is not that much to search over with modern hardware.\n\nA proper search- or a database engine would drop this search time down a ten-, if not a hundredfold, and these are most likely used.\n\nBigger sites, like Facebook with it’s 1,5 billion users, are the ones that need to start engineering special solutions that everyone is commenting about, to solve the username storage and lookup issues arising there.\n\nBut with 8 million users, it really is not a problem."", 'result': {'fake': 0.0007, 'real': 0.9993}, 'status': 'success'}], 'credits_used': 3, 'credits': 1986635, 'subscription': 0, 'content': ""In response to your question I got curious, and decided to test this out on fairly modern hardware.\n\nI generated a text file with 8 million rows, each row a 6–32 characters long alphanumberic string. This will represent our “username”. This file is 176 MB large.\n\nNow, using very basic python code, I decided to search over this file. I took a username from the end of the list (but not the last one). I am running this on a 2019 Macbook Pro.\n\nimport mmap\xa0\n\xa0\nf = open('username_list.txt')\xa0\ns = mmap.mmap(f.fileno(), 0, access=mmap.ACCESS_READ)\xa0\nif s.find(b'wvdvajlo\\n') != -1:\xa0\n    print('true')\xa0\n\nRunning this program takes:\n\nbash-5.0$ time python3 test.py\xa0\ntrue\xa0\n\xa0\nreal    0m1.097s\xa0\nuser    0m0.369s\xa0\nsys     0m0.109s\t\t\xa0\n\nThis was the first time the file had been opened after the write, so kernel had not cached this file properly.\n\nSubsequent runs, or runs searching for a username closer to the beginning, take less time, around 0.4 seconds.\n\nSo here’s the bottom line. Eight million usernames is not that much to search over with modern hardware.\n\nA proper search- or a database engine would drop this search time down a ten-, if not a hundredfold, and these are most likely used.\n\nBigger sites, like Facebook with it’s 1,5 billion users, are the ones that need to start engineering special solutions that everyone is commenting about, to solve the username storage and lookup issues arising there.\n\nBut with 8 million users, it really is not a problem."", 'aiModelVersion': '1'}",0.9993
Alon Amit,3y,"In what sense is it said that Conway's Game of Life exhibits computation universality? Is it possible to use it directly to solve a real problem, such as computing the sum of 1 + 1? Is there a computable procedure for translating a problem into GoL?","It is possible to represent bits of memory, basic logic and states in a suitable Game of Life configuration. Yes, there’s a computable procedure to translate any Turing Machine (in other words, any computer program) to a Life configuration which would evolve in the the same way as the program would get run.

“Is it possible to use it directly to solve a real problem such as computing the sum 1+1”: computing the sum 1+1 is not a real problem. A program that merely prints “2” solves that problem. A real problem is “given the binary representation of two natural numbers, produce the binary representation of their sum”.

Yes, such a program can be implemented as a Game of Life configuration. Yes, it would output “10” (the binary representation of 2) given the input “1,1”. No, this isn’t recommended to actually carry out: it would be terribly slow. But, in principle, it is perfectly doable.

This is a sample Life configuration implementing a simpler program which takes a string of 1’s and doubles its length. You can think of it as “doubling in unary notation”. The details of its operation are in this paper
 by Paul Rendell.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/2slh79iwj5nzp1vu', 'title': ""In what sense is it said that Conway's Game of Life exhibits computation universality? Is it possible to use it directly to solve a real problem, such as computing the sum of 1 + 1? Is there a computable procedure for translating a problem into GoL?"", 'score': {'original': 0.9996, 'ai': 0.0004}, 'blocks': [{'text': 'It is possible to represent bits of memory, basic logic and states in a suitable Game of Life configuration. Yes, there’s a computable procedure to translate any Turing Machine (in other words, any computer program) to a Life configuration which would evolve in the the same way as the program would get run.\n\n“Is it possible to use it directly to solve a real problem such as computing the sum 1+1”: computing the sum 1+1 is not a real problem. A program that merely prints “2” solves that problem. A real problem is “given the binary representation of two natural numbers, produce the binary representation of their sum”.\n\nYes, such a program can be implemented as a Game of Life configuration. Yes, it would output “10” (the binary representation of 2) given the input “1,1”. No, this isn’t recommended to actually carry out: it would be terribly slow. But, in principle, it is perfectly doable.\n\nThis is a sample Life configuration implementing a simpler program which takes a string of 1’s and doubles its length. You can think of it as “doubling in unary notation”. The details of its operation are in this paper\n by Paul Rendell.', 'result': {'fake': 0.0004, 'real': 0.9996}, 'status': 'success'}], 'credits_used': 2, 'credits': 1986633, 'subscription': 0, 'content': 'It is possible to represent bits of memory, basic logic and states in a suitable Game of Life configuration. Yes, there’s a computable procedure to translate any Turing Machine (in other words, any computer program) to a Life configuration which would evolve in the the same way as the program would get run.\n\n“Is it possible to use it directly to solve a real problem such as computing the sum 1+1”: computing the sum 1+1 is not a real problem. A program that merely prints “2” solves that problem. A real problem is “given the binary representation of two natural numbers, produce the binary representation of their sum”.\n\nYes, such a program can be implemented as a Game of Life configuration. Yes, it would output “10” (the binary representation of 2) given the input “1,1”. No, this isn’t recommended to actually carry out: it would be terribly slow. But, in principle, it is perfectly doable.\n\nThis is a sample Life configuration implementing a simpler program which takes a string of 1’s and doubles its length. You can think of it as “doubling in unary notation”. The details of its operation are in this paper\n by Paul Rendell.', 'aiModelVersion': '1'}",0.9996
Jeff Erickson,3y,How do I start to read Algorithms by Jeff Erickson? What should be my plan and within how much time should I be able to complete it?,"Start at the beginning.
Take notes.
Whenever you read a claim, verify for yourself that it’s correct. Never just take my word for anything. I am human; sometimes I make mistakes.
Whenever the textbook solves a problem, try to solve it yourself first, or at least try staying one step ahead of my solution.
Don’t confuse “understanding” with actual mastery. I’ve tried to make my book easy to read, but reading is only going to get you started. The only way to get better at designing algorithms is to design algorithms.
Solve some of the exercises in every chapter, but don’t feel like you have to solve all of them. I tend to group the exercises into similar techniques, so if you can comfortably solve problems 11 and 12, you can probably skip problems 13 and 14.
Use other sources. There are lots of other great resources available for learning algorithms; my book might not be the one that best fits your needs/intuition/background.
Have fun! Make up your own problems and solve them! Write some python code! Make algorithm animations! Build physical models of dynamic programming tables and flow networks! Teach your little sister! Let your little sister teach you!

All that said, I’ve never been able to read textbooks cover to cover myself. I tend to read everything backward—starting with the problem, trying to solve it, finding gaps in my background, trying to fill in those gaps, finding even deeper gaps in my background, and so on. So, my last point:

Don’t worry about getting through everything. Just try to learn something new every day.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/0n4u5idvz2pckt7e', 'title': 'How do I start to read Algorithms by Jeff Erickson? What should be my plan and within how much time should I be able to complete it?', 'score': {'original': 0.9988, 'ai': 0.0012}, 'blocks': [{'text': 'Start at the beginning.\nTake notes.\nWhenever you read a claim, verify for yourself that it’s correct. Never just take my word for anything. I am human; sometimes I make mistakes.\nWhenever the textbook solves a problem, try to solve it yourself first, or at least try staying one step ahead of my solution.\nDon’t confuse “understanding” with actual mastery. I’ve tried to make my book easy to read, but reading is only going to get you started. The only way to get better at designing algorithms is to design algorithms.\nSolve some of the exercises in every chapter, but don’t feel like you have to solve all of them. I tend to group the exercises into similar techniques, so if you can comfortably solve problems 11 and 12, you can probably skip problems 13 and 14.\nUse other sources. There are lots of other great resources available for learning algorithms; my book might not be the one that best fits your needs/intuition/background.\nHave fun! Make up your own problems and solve them! Write some python code! Make algorithm animations! Build physical models of dynamic programming tables and flow networks! Teach your little sister! Let your little sister teach you!\n\nAll that said, I’ve never been able to read textbooks cover to cover myself. I tend to read everything backward—starting with the problem, trying to solve it, finding gaps in my background, trying to fill in those gaps, finding even deeper gaps in my background, and so on. So, my last point:\n\nDon’t worry about getting through everything. Just try to learn something new every day.', 'result': {'fake': 0.0012, 'real': 0.9988}, 'status': 'success'}], 'credits_used': 3, 'credits': 1986630, 'subscription': 0, 'content': 'Start at the beginning.\nTake notes.\nWhenever you read a claim, verify for yourself that it’s correct. Never just take my word for anything. I am human; sometimes I make mistakes.\nWhenever the textbook solves a problem, try to solve it yourself first, or at least try staying one step ahead of my solution.\nDon’t confuse “understanding” with actual mastery. I’ve tried to make my book easy to read, but reading is only going to get you started. The only way to get better at designing algorithms is to design algorithms.\nSolve some of the exercises in every chapter, but don’t feel like you have to solve all of them. I tend to group the exercises into similar techniques, so if you can comfortably solve problems 11 and 12, you can probably skip problems 13 and 14.\nUse other sources. There are lots of other great resources available for learning algorithms; my book might not be the one that best fits your needs/intuition/background.\nHave fun! Make up your own problems and solve them! Write some python code! Make algorithm animations! Build physical models of dynamic programming tables and flow networks! Teach your little sister! Let your little sister teach you!\n\nAll that said, I’ve never been able to read textbooks cover to cover myself. I tend to read everything backward—starting with the problem, trying to solve it, finding gaps in my background, trying to fill in those gaps, finding even deeper gaps in my background, and so on. So, my last point:\n\nDon’t worry about getting through everything. Just try to learn something new every day.', 'aiModelVersion': '1'}",0.9988
Joe Zbiciak,4y,"Why is quicksort more common than heapsort, even though they have equal time complexities?","Benchmark them! I’m serious, benchmark them!

Write yourself up a Heapsort and a Quicksort. Copy the classic versions of each out of your textbook.

Then measure how long each takes to sort a random array of N elements for several values of N. To save time, double N each time. Be sure to let N get fairly large—say, at least 
2
24
224
, or maybe 
2
28
228
 if you’re up for it.

And, just to be sure, have each sort several randomized arrays of each size. After all, even with randomized arrays, you might get a “lucky” input.

You’ll find that both grow at 
O
(
N
lg
N
)
O(Nlg⁡N)
. I think you’ll also find that, pretty consistently, Quicksort is faster.

I did this experiment waaay back in 1994 when I took my data structures and algorithms class, and sure enough, Quicksort was noticeably faster, even back then, on much simpler hardware. I haven’t run the experiment recently, but I suspect on modern machines the effect is more pronounced.

The big-Oh time complexity measure isn’t everything!

Why is that? The time complexity measure ignores constant factors.

Spend some time meditating on why that might be.

Hint: What’s your data locality look like, and what do your inner and outer loops look like for each?

You’ll also notice that I said “use randomized arrays” with your textbook Quicksort. You might consult your textbook for why I suggested that.

In practice, the pure, classic Quicksort isn’t all that common either. Usually, they doll it up with various improvements, such as:

Randomized pivot selection.
Select pivot from a median of multiple potential pivots.
Hybrid sorts that use selection, merge, insertion, or even heap sort once the partition size gets below a certain threshold.

That’s if they use a Quicksort variant at all. Timsort
 is pretty popular these days, I hear.

(And, to be fair, there’s modified and improved versions of Heapsort as well. Real world modern practical implementations don’t tend to use the original classic textbook algorithms from the 1950s and 1960s directly. We’ve learned a lot since then.)","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/j8nkmiv7t91uaghs', 'title': 'Why is quicksort more common than heapsort, even though they have equal time complexities?', 'score': {'original': 0.9999, 'ai': 0.0001}, 'blocks': [{'text': 'Benchmark them! I’m serious, benchmark them!\n\nWrite yourself up a Heapsort and a Quicksort. Copy the classic versions of each out of your textbook.\n\nThen measure how long each takes to sort a random array of N elements for several values of N. To save time, double N each time. Be sure to let N get fairly large—say, at least \n2\n24\n224\n, or maybe \n2\n28\n228\n if you’re up for it.\n\nAnd, just to be sure, have each sort several randomized arrays of each size. After all, even with randomized arrays, you might get a “lucky” input.\n\nYou’ll find that both grow at \nO\n(\nN\nlg\nN\n)\nO(Nlg\u2061N)\n. I think you’ll also find that, pretty consistently, Quicksort is faster.\n\nI did this experiment waaay back in 1994 when I took my data structures and algorithms class, and sure enough, Quicksort was noticeably faster, even back then, on much simpler hardware. I haven’t run the experiment recently, but I suspect on modern machines the effect is more pronounced.\n\nThe big-Oh time complexity measure isn’t everything!\n\nWhy is that? The time complexity measure ignores constant factors.\n\nSpend some time meditating on why that might be.\n\nHint: What’s your data locality look like, and what do your inner and outer loops look like for each?\n\nYou’ll also notice that I said “use randomized arrays” with your textbook Quicksort. You might consult your textbook for why I suggested that.\n\nIn practice, the pure, classic Quicksort isn’t all that common either. Usually, they doll it up with various improvements, such as:\n\nRandomized pivot selection.\nSelect pivot from a median of multiple potential pivots.\nHybrid sorts that use selection, merge, insertion, or even heap sort once the partition size gets below a certain threshold.\n\nThat’s if they use a Quicksort variant at all. Timsort\n is pretty popular these days, I hear.\n\n(And, to be fair, there’s modified and improved versions of Heapsort as well. Real world modern practical implementations don’t tend to use the original classic textbook algorithms from the 1950s and 1960s directly. We’ve learned a lot since then.)', 'result': {'fake': 0.0001, 'real': 0.9999}, 'status': 'success'}], 'credits_used': 4, 'credits': 1986626, 'subscription': 0, 'content': 'Benchmark them! I’m serious, benchmark them!\n\nWrite yourself up a Heapsort and a Quicksort. Copy the classic versions of each out of your textbook.\n\nThen measure how long each takes to sort a random array of N elements for several values of N. To save time, double N each time. Be sure to let N get fairly large—say, at least \n2\n24\n224\n, or maybe \n2\n28\n228\n if you’re up for it.\n\nAnd, just to be sure, have each sort several randomized arrays of each size. After all, even with randomized arrays, you might get a “lucky” input.\n\nYou’ll find that both grow at \nO\n(\nN\nlg\nN\n)\nO(Nlg\u2061N)\n. I think you’ll also find that, pretty consistently, Quicksort is faster.\n\nI did this experiment waaay back in 1994 when I took my data structures and algorithms class, and sure enough, Quicksort was noticeably faster, even back then, on much simpler hardware. I haven’t run the experiment recently, but I suspect on modern machines the effect is more pronounced.\n\nThe big-Oh time complexity measure isn’t everything!\n\nWhy is that? The time complexity measure ignores constant factors.\n\nSpend some time meditating on why that might be.\n\nHint: What’s your data locality look like, and what do your inner and outer loops look like for each?\n\nYou’ll also notice that I said “use randomized arrays” with your textbook Quicksort. You might consult your textbook for why I suggested that.\n\nIn practice, the pure, classic Quicksort isn’t all that common either. Usually, they doll it up with various improvements, such as:\n\nRandomized pivot selection.\nSelect pivot from a median of multiple potential pivots.\nHybrid sorts that use selection, merge, insertion, or even heap sort once the partition size gets below a certain threshold.\n\nThat’s if they use a Quicksort variant at all. Timsort\n is pretty popular these days, I hear.\n\n(And, to be fair, there’s modified and improved versions of Heapsort as well. Real world modern practical implementations don’t tend to use the original classic textbook algorithms from the 1950s and 1960s directly. We’ve learned a lot since then.)', 'aiModelVersion': '1'}",0.9999
Mayukh Mukhopadhyay,Updated 5y,Who wrote the Google Search algorithm?,"The search algorithm of Google as we know today is the artwork of this man.

Amit Singhal (King of Ranking)

Alumnus of IIT Roorkee.

Phd from Cornell University.

He moved to Google in 2000, at the insistence of his friend Krishna Bharat, an IIT-Madras alumnus who went on to develop Google News. Coming on-board only two years after Google was founded, Singhal got to work on rewriting the algorithms
 that founders Larry Page and Sergey Brin had developed. As Nicholas Carlson describes in his 2015 book
, Marissa Mayer and the Fight to Save Yahoo!:

Soon after joining, Singhal decided the code Google used for figuring out how to rank its search results needed a major overhaul. It had been written by Sergey Brin, and it was very sloppy. Singhal rewrote the whole thing in two months, adding huge improvements to relevancy and speed. In 2006, Singhal was named a Google Fellow, an award with a prize in the millions of dollars. He earned a nickname around campus: King of the Ranking

Source:

The rise and fall of Amit Singhal, the former Google star just fired by Uber

Phd Thesis: Term Weighting Revisited

***Another Man behind the rising Google***

Ram Shriram (Sherpa with Midas Touch)

Alma Mater: University of Madras, University of Michigan

When two young geeks — Larry Page and Sergey Brin — approached the venture capitalist Shriram for funds for their garage start-up that had yet not called itself ‘Google', he dished out a cheque for half-a-million dollars.

Source:

The sherpa who funded Google's ascent

***Timeline of Google Search Algorithm 9-Major updates, by Zuan Education***","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/bnvqajxgksdwet49', 'title': 'Who wrote the Google Search algorithm?', 'score': {'original': 0.9995, 'ai': 0.0005}, 'blocks': [{'text': ""The search algorithm of Google as we know today is the artwork of this man.\n\nAmit Singhal (King of Ranking)\n\nAlumnus of IIT Roorkee.\n\nPhd from Cornell University.\n\nHe moved to Google in 2000, at the insistence of his friend Krishna Bharat, an IIT-Madras alumnus who went on to develop Google News. Coming on-board only two years after Google was founded, Singhal got to work on rewriting the algorithms\n that founders Larry Page and Sergey Brin had developed. As Nicholas Carlson describes in his 2015 book\n, Marissa Mayer and the Fight to Save Yahoo!:\n\nSoon after joining, Singhal decided the code Google used for figuring out how to rank its search results needed a major overhaul. It had been written by Sergey Brin, and it was very sloppy. Singhal rewrote the whole thing in two months, adding huge improvements to relevancy and speed. In 2006, Singhal was named a Google Fellow, an award with a prize in the millions of dollars. He earned a nickname around campus: King of the Ranking\n\nSource:\n\nThe rise and fall of Amit Singhal, the former Google star just fired by Uber\n\nPhd Thesis: Term Weighting Revisited\n\n***Another Man behind the rising Google***\n\nRam Shriram (Sherpa with Midas Touch)\n\nAlma Mater: University of Madras, University of Michigan\n\nWhen two young geeks — Larry Page and Sergey Brin — approached the venture capitalist Shriram for funds for their garage start-up that had yet not called itself ‘Google', he dished out a cheque for half-a-million dollars.\n\nSource:\n\nThe sherpa who funded Google's ascent\n\n***Timeline of Google Search Algorithm 9-Major updates, by Zuan Education***"", 'result': {'fake': 0.0005, 'real': 0.9995}, 'status': 'success'}], 'credits_used': 3, 'credits': 1986623, 'subscription': 0, 'content': ""The search algorithm of Google as we know today is the artwork of this man.\n\nAmit Singhal (King of Ranking)\n\nAlumnus of IIT Roorkee.\n\nPhd from Cornell University.\n\nHe moved to Google in 2000, at the insistence of his friend Krishna Bharat, an IIT-Madras alumnus who went on to develop Google News. Coming on-board only two years after Google was founded, Singhal got to work on rewriting the algorithms\n that founders Larry Page and Sergey Brin had developed. As Nicholas Carlson describes in his 2015 book\n, Marissa Mayer and the Fight to Save Yahoo!:\n\nSoon after joining, Singhal decided the code Google used for figuring out how to rank its search results needed a major overhaul. It had been written by Sergey Brin, and it was very sloppy. Singhal rewrote the whole thing in two months, adding huge improvements to relevancy and speed. In 2006, Singhal was named a Google Fellow, an award with a prize in the millions of dollars. He earned a nickname around campus: King of the Ranking\n\nSource:\n\nThe rise and fall of Amit Singhal, the former Google star just fired by Uber\n\nPhd Thesis: Term Weighting Revisited\n\n***Another Man behind the rising Google***\n\nRam Shriram (Sherpa with Midas Touch)\n\nAlma Mater: University of Madras, University of Michigan\n\nWhen two young geeks — Larry Page and Sergey Brin — approached the venture capitalist Shriram for funds for their garage start-up that had yet not called itself ‘Google', he dished out a cheque for half-a-million dollars.\n\nSource:\n\nThe sherpa who funded Google's ascent\n\n***Timeline of Google Search Algorithm 9-Major updates, by Zuan Education***"", 'aiModelVersion': '1'}",0.9995
Chris O'Leary,Updated 3y,Have you cracked the Quora algorithm yet?,"I think so.

I tested an idea last night, and I’m comfortable calling the results a huge success.

To begin with, there appears to be something like a “visibility rotation” going on. For a few days, you’ll be REALLY visible, followed by a few days of just NOTHING, followed by a few days of normal, back to BOOM.

I’m not the only one who’s noticed this. What I think is happening, is the Algorithm has everyone sorted into 3–4 groups, Call it A, B, C, D and every 2–3 days it rotates the groups into more or less visible status, kind of like this:

So say I’m in Group B, Right now, for the most part practically no one is seeing my stuff, not even my followers, most of what is happening is new people are being shown my old stuff, so I see a bunch of notifications about activity on old answers but whatever I write today is not very likely to get very many views at all.

Then it seems to relax. And it’s a period of normal. That’s what Group C is in right now, sort of baseline visibility. Group D is accelerating. They start showing up in their followers feeds often again, and start seeing a few answers really pop.

Group A meanwhile feels like they can do no wrong right now. They’ll write a 5 sentence answer off the top of their head while grocery shopping and see it hit 1K upvotes within a day and wonder how the hell that happened.

Now, this is just an idea I have based on a perceived pattern in visibility, but it seems to make sense.

At any point in the cycle though, there are factors that make each individual answer more or less visible, outside of just the popularity of the topic and the size of the writer’s following, both of which have a big impact.

I’ve suspected for a while that engagement statistics: Upvote rate (Upvotes/Views) comments, and engagement in the comments section (Upvotes and replies) and # of Shares or possibly share rate (Shares/Views) have a significant impact on how often an answer will be shown in user’s feeds, and how prominently.

I strongly suspect “Click Through Rate” has a big impact as well (Clicks/appearances in the feed) if an answer is appearing in feeds and no one is clicking, it stops appearing, if a lot of people are, then it will be shown to more people. I don’t have a way to test that though.

I tested engagement last night. Now one test does not constitute proof, but, the evidence suggests that I’m right.

I was pretty clearly in Group D Yesterday. Very low visibility after a period of very high visibility. None of my answers were getting very many views. I wrote one on what is normally a very hot topic, hit send and waited. and waited. The ULTIMATE THUD. An hour had passed, and it still only had one view, my own.

“This is the one!” I said.

So I enlisted the help of a few friends. Thank you, Michelle - MAD PIRATE QUEEN, Cecily Ruth, Lana Nichol, Dot McHale, Tim Cole, Nate VanDuser, and Habib F

I asked them each to go to the answer and hit the trifecta. Upvote, Comment, and Share. Then I went in and interacted with all the comments, upvoted and responded to them, and upvoted and commented on all the shares.

For a while, It looked like my conclusion was totally wrong. That there was no way to influence the midichlorians and Jedi Mind Trick the Algorithm. There was a period of time when the answer had a greater than 40% upvote rate and a 30% share rate. BUT that was with about 8 upvotes and 5 shares. Still sitting at 25 views. (Note here…What I was trying to impact was views, so the 25 views after about 4 hours was the thing I was looking at and saying, no, it’s not happening.

Until I woke up this morning and saw it had about 450 views and about 30 upvotes. ….Not….Bad…. That’s a little bit of movement….

Then it started accelerating. And ACCELERATING.

It just passed 35K views.

Chris O'Leary's answer to Do you think that Donald Trump lies about his golf scores, or has all of the time that he has spent golfing simply paid off in terms of increasing his skill?

This on an answer that was DEAD in the water. I might have to try the experiment again the next time I feel like I’m in Group D and I have an answer go THUD to see if the results are the same….But….

This is evidence that interaction signals are a big part of how the algorithm decides how visible to make a piece of content.

(A crap experiment, I know, but it’s a start.)","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/hj1t5zu4aieynq6s', 'title': 'Have you cracked the Quora algorithm yet?', 'score': {'original': 0.6881, 'ai': 0.3119}, 'blocks': [{'text': 'I think so.\n\nI tested an idea last night, and I’m comfortable calling the results a huge success.\n\nTo begin with, there appears to be something like a “visibility rotation” going on. For a few days, you’ll be REALLY visible, followed by a few days of just NOTHING, followed by a few days of normal, back to BOOM.\n\nI’m not the only one who’s noticed this. What I think is happening, is the Algorithm has everyone sorted into 3–4 groups, Call it A, B, C, D and every 2–3 days it rotates the groups into more or less visible status, kind of like this:\n\nSo say I’m in Group B, Right now, for the most part practically no one is seeing my stuff, not even my followers, most of what is happening is new people are being shown my old stuff, so I see a bunch of notifications about activity on old answers but whatever I write today is not very likely to get very many views at all.\n\nThen it seems to relax. And it’s a period of normal. That’s what Group C is in right now, sort of baseline visibility. Group D is accelerating. They start showing up in their followers feeds often again, and start seeing a few answers really pop.\n\nGroup A meanwhile feels like they can do no wrong right now. They’ll write a 5 sentence answer off the top of their head while grocery shopping and see it hit 1K upvotes within a day and wonder how the hell that happened.\n\nNow, this is just an idea I have based on a perceived pattern in visibility, but it seems to make sense.\n\nAt any point in the cycle though, there are factors that make each individual answer more or less visible, outside of just the popularity of the topic and the size of the writer’s following, both of which have a big impact.\n\nI’ve suspected for a while that engagement statistics: Upvote rate (Upvotes/Views) comments, and engagement in the comments section (Upvotes and replies) and # of Shares or possibly share rate (Shares/Views) have a significant impact on how often an answer will be shown in user’s feeds, and how prominently.\n\nI strongly suspect “Click Through Rate” has a big impact as well (Clicks/appearances in the feed) if an answer is appearing in feeds and no one is clicking, it stops appearing, if a lot of people are, then it will be shown to more people. I don’t have a way to test that though.\n\nI tested engagement last night. Now one test does not constitute proof, but, the evidence suggests that I’m right.\n\nI was pretty clearly in Group D Yesterday. Very low visibility after a period of very high visibility. None of my answers were getting very many views. I wrote one on what is normally a very hot topic, hit send and waited. and waited. The ULTIMATE THUD. An hour had passed, and it still only had one view, my own.\n\n“This is the one!” I said.\n\nSo I enlisted the help of a few friends. Thank you, Michelle - MAD PIRATE QUEEN, Cecily Ruth, Lana Nichol,', 'result': {'fake': 0.0661, 'real': 0.9339}, 'status': 'success'}, {'text': ""Dot McHale, Tim Cole, Nate VanDuser, and Habib F\n\nI asked them each to go to the answer and hit the trifecta. Upvote, Comment, and Share. Then I went in and interacted with all the comments, upvoted and responded to them, and upvoted and commented on all the shares.\n\nFor a while, It looked like my conclusion was totally wrong. That there was no way to influence the midichlorians and Jedi Mind Trick the Algorithm. There was a period of time when the answer had a greater than 40% upvote rate and a 30% share rate. BUT that was with about 8 upvotes and 5 shares. Still sitting at 25 views. (Note here…What I was trying to impact was views, so the 25 views after about 4 hours was the thing I was looking at and saying, no, it’s not happening.\n\nUntil I woke up this morning and saw it had about 450 views and about 30 upvotes. ….Not….Bad…. That’s a little bit of movement….\n\nThen it started accelerating. And ACCELERATING.\n\nIt just passed 35K views.\n\nChris O'Leary's answer to Do you think that Donald Trump lies about his golf scores, or has all of the time that he has spent golfing simply paid off in terms of increasing his skill?\n\nThis on an answer that was DEAD in the water. I might have to try the experiment again the next time I feel like I’m in Group D and I have an answer go THUD to see if the results are the same….But….\n\nThis is evidence that interaction signals are a big part of how the algorithm decides how visible to make a piece of content.\n\n(A crap experiment, I know, but it’s a start.)"", 'result': {'fake': 0.0006, 'real': 0.9994}, 'status': 'success'}], 'credits_used': 9, 'credits': 1986614, 'subscription': 0, 'content': ""I think so.\n\nI tested an idea last night, and I’m comfortable calling the results a huge success.\n\nTo begin with, there appears to be something like a “visibility rotation” going on. For a few days, you’ll be REALLY visible, followed by a few days of just NOTHING, followed by a few days of normal, back to BOOM.\n\nI’m not the only one who’s noticed this. What I think is happening, is the Algorithm has everyone sorted into 3–4 groups, Call it A, B, C, D and every 2–3 days it rotates the groups into more or less visible status, kind of like this:\n\nSo say I’m in Group B, Right now, for the most part practically no one is seeing my stuff, not even my followers, most of what is happening is new people are being shown my old stuff, so I see a bunch of notifications about activity on old answers but whatever I write today is not very likely to get very many views at all.\n\nThen it seems to relax. And it’s a period of normal. That’s what Group C is in right now, sort of baseline visibility. Group D is accelerating. They start showing up in their followers feeds often again, and start seeing a few answers really pop.\n\nGroup A meanwhile feels like they can do no wrong right now. They’ll write a 5 sentence answer off the top of their head while grocery shopping and see it hit 1K upvotes within a day and wonder how the hell that happened.\n\nNow, this is just an idea I have based on a perceived pattern in visibility, but it seems to make sense.\n\nAt any point in the cycle though, there are factors that make each individual answer more or less visible, outside of just the popularity of the topic and the size of the writer’s following, both of which have a big impact.\n\nI’ve suspected for a while that engagement statistics: Upvote rate (Upvotes/Views) comments, and engagement in the comments section (Upvotes and replies) and # of Shares or possibly share rate (Shares/Views) have a significant impact on how often an answer will be shown in user’s feeds, and how prominently.\n\nI strongly suspect “Click Through Rate” has a big impact as well (Clicks/appearances in the feed) if an answer is appearing in feeds and no one is clicking, it stops appearing, if a lot of people are, then it will be shown to more people. I don’t have a way to test that though.\n\nI tested engagement last night. Now one test does not constitute proof, but, the evidence suggests that I’m right.\n\nI was pretty clearly in Group D Yesterday. Very low visibility after a period of very high visibility. None of my answers were getting very many views. I wrote one on what is normally a very hot topic, hit send and waited. and waited. The ULTIMATE THUD. An hour had passed, and it still only had one view, my own.\n\n“This is the one!” I said.\n\nSo I enlisted the help of a few friends. Thank you, Michelle - MAD PIRATE QUEEN, Cecily Ruth, Lana Nichol, Dot McHale, Tim Cole, Nate VanDuser, and Habib F\n\nI asked them each to go to the answer and hit the trifecta. Upvote, Comment, and Share. Then I went in and interacted with all the comments, upvoted and responded to them, and upvoted and commented on all the shares.\n\nFor a while, It looked like my conclusion was totally wrong. That there was no way to influence the midichlorians and Jedi Mind Trick the Algorithm. There was a period of time when the answer had a greater than 40% upvote rate and a 30% share rate. BUT that was with about 8 upvotes and 5 shares. Still sitting at 25 views. (Note here…What I was trying to impact was views, so the 25 views after about 4 hours was the thing I was looking at and saying, no, it’s not happening.\n\nUntil I woke up this morning and saw it had about 450 views and about 30 upvotes. ….Not….Bad…. That’s a little bit of movement….\n\nThen it started accelerating. And ACCELERATING.\n\nIt just passed 35K views.\n\nChris O'Leary's answer to Do you think that Donald Trump lies about his golf scores, or has all of the time that he has spent golfing simply paid off in terms of increasing his skill?\n\nThis on an answer that was DEAD in the water. I might have to try the experiment again the next time I feel like I’m in Group D and I have an answer go THUD to see if the results are the same….But….\n\nThis is evidence that interaction signals are a big part of how the algorithm decides how visible to make a piece of content.\n\n(A crap experiment, I know, but it’s a start.)"", 'aiModelVersion': '1'}",0.6881
Alon Amit,3y,Have you seen the latest solution to the traveling salesman problem?,"Yup, sure did. What do you want to know about it? The actual paper is A (Slightly) Improved Approximation Algorithm for Metric TSP. To clarify what the progress is, here is a quick summary. The context is metric TSP, which is TSP when the distances or costs are known to satisfy the triangle inequality. This is an important subclass of the general TSP problem, but it’s not the TSP problem in full generality. A further context is approximation. Of all the possible tours of a given TSP graph there is one which is the absolute best (shortest, cheapest. There may be multiple tours with the exact same cost; this doesn’t matter much.) We know that finding this absolute best is NP-hard, so we’re wondering whether it might be easier to find a tour that is not too far from being the absolute best. If you want to get very close to the absolute best (not more than 0.7% away, say), the problem is still NP-hard. If you are ok with a 3232\frac{3}{2}-approximation, meaning you could be 50% off the optimal tour, then there are efficient algorithms for doing that that have been known since 1976. The final context is randomization. We can sometimes build good random algorithms for doing something without necessarily knowing how to make them deterministic (though some folks believe that all randomized algorithms can be efficiently derandomized). In this case, we are hoping for a random algorithm for which we can prove that the expected quality of the produced tour is better than 50% off the mark. This is what Karlin, Klein and Oveis Gharan have achieved: a random polynomial-time algorithm which produces a TSP tour with an expected cost that is within 32−ϵ32−ϵ\frac{3}{2}-\epsilon of the optimal tour, for some small absolute constant ϵϵ\epsilon. The authors believe the algorithm actually achieves a 4343\frac{4}{3}-approximation, but they can’t prove it yet. People who work on combinatorial optimization in various guises are familiar with the situation where a certain constant magnitude, like this 3232\frac{3}{2}, stands for decades and over time creates the impression of an impenetrable fortification. It’s therefore exciting when people manage to breach that wall, even if by a small amount. The guaranteed value of ϵϵ\epsilon in this paper is 10−3610−3610^{-36}, which is tiny, but it’s still a breach. So, yeah. Fun!","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/ovnj1twa0gdurm7e', 'title': 'Have you seen the latest solution to the traveling salesman problem?', 'score': {'original': 0.9993, 'ai': 0.0007}, 'blocks': [{'text': 'Yup, sure did. What do you want to know about it? The actual paper is A (Slightly) Improved Approximation Algorithm for Metric TSP. To clarify what the progress is, here is a quick summary. The context is metric TSP, which is TSP when the distances or costs are known to satisfy the triangle inequality. This is an important subclass of the general TSP problem, but it’s not the TSP problem in full generality. A further context is approximation. Of all the possible tours of a given TSP graph there is one which is the absolute best (shortest, cheapest. There may be multiple tours with the exact same cost; this doesn’t matter much.) We know that finding this absolute best is NP-hard, so we’re wondering whether it might be easier to find a tour that is not too far from being the absolute best. If you want to get very close to the absolute best (not more than 0.7% away, say), the problem is still NP-hard. If you are ok with a 3232\\frac{3}{2}-approximation, meaning you could be 50% off the optimal tour, then there are efficient algorithms for doing that that have been known since 1976. The final context is randomization. We can sometimes build good random algorithms for doing something without necessarily knowing how to make them deterministic (though some folks believe that all randomized algorithms can be efficiently derandomized). In this case, we are hoping for a random algorithm for which we can prove that the expected quality of the produced tour is better than 50% off the mark. This is what Karlin, Klein and Oveis Gharan have achieved: a random polynomial-time algorithm which produces a TSP tour with an expected cost that is within 32−ϵ32−ϵ\\frac{3}{2}-\\epsilon of the optimal tour, for some small absolute constant ϵϵ\\epsilon. The authors believe the algorithm actually achieves a 4343\\frac{4}{3}-approximation, but they can’t prove it yet. People who work on combinatorial optimization in various guises are familiar with the situation where a certain constant magnitude, like this 3232\\frac{3}{2}, stands for decades and over time creates the impression of an impenetrable fortification. It’s therefore exciting when people manage to breach that wall, even if by a small amount. The guaranteed value of ϵϵ\\epsilon in this paper is 10−3610−3610^{-36}, which is tiny, but it’s still a breach. So, yeah. Fun!', 'result': {'fake': 0.0007, 'real': 0.9993}, 'status': 'success'}], 'credits_used': 4, 'credits': 1986610, 'subscription': 0, 'content': 'Yup, sure did. What do you want to know about it? The actual paper is A (Slightly) Improved Approximation Algorithm for Metric TSP. To clarify what the progress is, here is a quick summary. The context is metric TSP, which is TSP when the distances or costs are known to satisfy the triangle inequality. This is an important subclass of the general TSP problem, but it’s not the TSP problem in full generality. A further context is approximation. Of all the possible tours of a given TSP graph there is one which is the absolute best (shortest, cheapest. There may be multiple tours with the exact same cost; this doesn’t matter much.) We know that finding this absolute best is NP-hard, so we’re wondering whether it might be easier to find a tour that is not too far from being the absolute best. If you want to get very close to the absolute best (not more than 0.7% away, say), the problem is still NP-hard. If you are ok with a 3232\\frac{3}{2}-approximation, meaning you could be 50% off the optimal tour, then there are efficient algorithms for doing that that have been known since 1976. The final context is randomization. We can sometimes build good random algorithms for doing something without necessarily knowing how to make them deterministic (though some folks believe that all randomized algorithms can be efficiently derandomized). In this case, we are hoping for a random algorithm for which we can prove that the expected quality of the produced tour is better than 50% off the mark. This is what Karlin, Klein and Oveis Gharan have achieved: a random polynomial-time algorithm which produces a TSP tour with an expected cost that is within 32−ϵ32−ϵ\\frac{3}{2}-\\epsilon of the optimal tour, for some small absolute constant ϵϵ\\epsilon. The authors believe the algorithm actually achieves a 4343\\frac{4}{3}-approximation, but they can’t prove it yet. People who work on combinatorial optimization in various guises are familiar with the situation where a certain constant magnitude, like this 3232\\frac{3}{2}, stands for decades and over time creates the impression of an impenetrable fortification. It’s therefore exciting when people manage to breach that wall, even if by a small amount. The guaranteed value of ϵϵ\\epsilon in this paper is 10−3610−3610^{-36}, which is tiny, but it’s still a breach. So, yeah. Fun!', 'aiModelVersion': '1'}",0.9993
Jeremy Edberg,8y,Where do the constants 1134028003 and 45000 come from in reddit's hotness algorithm?,"1134028003 is the Unix timestamp for the oldest submission, so it basically makes the math easier since nothing can be older than that. 45000 is the number of seconds in 12.5 hours.  The way the algo works is that something needs to have 10 times as many points to be ""hot"" as something 12.5. hours younger.  In other words, that's the boundary for the log. 12.5 is just random and something we thought worked well.  Originally it was 25 hours.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/75x904jaui8vfdnt', 'title': ""Where do the constants 1134028003 and 45000 come from in reddit's hotness algorithm?"", 'score': {'original': 0.9915, 'ai': 0.0085}, 'blocks': [{'text': '1134028003 is the Unix timestamp for the oldest submission, so it basically makes the math easier since nothing can be older than that. 45000 is the number of seconds in 12.5 hours.  The way the algo works is that something needs to have 10 times as many points to be ""hot"" as something 12.5. hours younger.  In other words, that\'s the boundary for the log. 12.5 is just random and something we thought worked well.  Originally it was 25 hours.', 'result': {'fake': 0.0759, 'real': 0.9241}, 'status': 'success'}], 'credits_used': 1, 'credits': 1986609, 'subscription': 0, 'content': '1134028003 is the Unix timestamp for the oldest submission, so it basically makes the math easier since nothing can be older than that. 45000 is the number of seconds in 12.5 hours.  The way the algo works is that something needs to have 10 times as many points to be ""hot"" as something 12.5. hours younger.  In other words, that\'s the boundary for the log. 12.5 is just random and something we thought worked well.  Originally it was 25 hours.', 'aiModelVersion': '1'}",0.9915
Quinn Ngo,6y,Is there life after a data structures course?,"No. You won’t be able to look at things the same way ever again. The lunch line is now a queue. The DMV is a priority queue. Maps are graphs. You don’t take plates from the top of the stack anymore. You pop them. Trees that don’t have enough leaves need balancing. And they look upside down.

I’m sorry, but after data structures, life as you know it is over.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/25ti9qwnr1lxzm7p', 'title': 'Is there life after a data structures course?', 'score': {'original': 0.9289, 'ai': 0.0711}, 'blocks': [{'text': 'No. You won’t be able to look at things the same way ever again. The lunch line is now a queue. The DMV is a priority queue. Maps are graphs. You don’t take plates from the top of the stack anymore. You pop them. Trees that don’t have enough leaves need balancing. And they look upside down.\n\nI’m sorry, but after data structures, life as you know it is over.', 'result': {'fake': 0.0711, 'real': 0.9289}, 'status': 'success'}], 'credits_used': 1, 'credits': 1986608, 'subscription': 0, 'content': 'No. You won’t be able to look at things the same way ever again. The lunch line is now a queue. The DMV is a priority queue. Maps are graphs. You don’t take plates from the top of the stack anymore. You pop them. Trees that don’t have enough leaves need balancing. And they look upside down.\n\nI’m sorry, but after data structures, life as you know it is over.', 'aiModelVersion': '1'}",0.9289
Sean Kernan,Updated 4y,What are the most incredible AI algorithms?,"The Gaydar is real, people.

Stanford scientists developed a new algorithm that reads images of a person’s face and then determines their sexuality.

It did this by starting with a base set of data where it already knew the sexuality of each person, measuring points on their faces and marking those vectors.

Then the algorithm began learning as it scanned the faces, seeing trends.

When they tested the algorithm with actual candidates, it guessed if a man was gay 81% of the time with accuracy and 71% of the time with women. (Source: Deep Neural Networks Can Detect Sexual Orientation of Faces. Wang & Kosinski)

On one hand—this is amazing, impressive technology.

On the other—it’s a bit terrifying. It whiffs a bit of physiognomy. Which is the classification of people based on facial features.

At first glance, physiognomy isn’t terribly bad. But there are levels to it.

On one hand it’s cutsie, sort of like reading a fortune cookie. But then it moves to guessing sexuality and even further, can you then use technology to predict if someone is evil and needs to be watched? Do they use the same technology to scan and see if your face suddenly resembles child molesters? Or other criminals?

But what if it is only accurate 89% of the time and you are the 11%?

Is it far fetched that this will happen? Sure.

But it’s worth raising the flag. Technology is evolving as quickly as privacy is vanishing. The last thing we need is another marker to be assigned to us, another number indicator to the soon-Cyber Overlord.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/1r9i5l2etqnzj4fw', 'title': 'What are the most incredible AI algorithms?', 'score': {'original': 0.9998, 'ai': 0.0002}, 'blocks': [{'text': 'The Gaydar is real, people.\n\nStanford scientists developed a new algorithm that reads images of a person’s face and then determines their sexuality.\n\nIt did this by starting with a base set of data where it already knew the sexuality of each person, measuring points on their faces and marking those vectors.\n\nThen the algorithm began learning as it scanned the faces, seeing trends.\n\nWhen they tested the algorithm with actual candidates, it guessed if a man was gay 81% of the time with accuracy and 71% of the time with women. (Source: Deep Neural Networks Can Detect Sexual Orientation of Faces. Wang & Kosinski)\n\nOn one hand—this is amazing, impressive technology.\n\nOn the other—it’s a bit terrifying. It whiffs a bit of physiognomy. Which is the classification of people based on facial features.\n\nAt first glance, physiognomy isn’t terribly bad. But there are levels to it.\n\nOn one hand it’s cutsie, sort of like reading a fortune cookie. But then it moves to guessing sexuality and even further, can you then use technology to predict if someone is evil and needs to be watched? Do they use the same technology to scan and see if your face suddenly resembles child molesters? Or other criminals?\n\nBut what if it is only accurate 89% of the time and you are the 11%?\n\nIs it far fetched that this will happen? Sure.\n\nBut it’s worth raising the flag. Technology is evolving as quickly as privacy is vanishing. The last thing we need is another marker to be assigned to us, another number indicator to the soon-Cyber Overlord.', 'result': {'fake': 0.0002, 'real': 0.9998}, 'status': 'success'}], 'credits_used': 3, 'credits': 1986605, 'subscription': 0, 'content': 'The Gaydar is real, people.\n\nStanford scientists developed a new algorithm that reads images of a person’s face and then determines their sexuality.\n\nIt did this by starting with a base set of data where it already knew the sexuality of each person, measuring points on their faces and marking those vectors.\n\nThen the algorithm began learning as it scanned the faces, seeing trends.\n\nWhen they tested the algorithm with actual candidates, it guessed if a man was gay 81% of the time with accuracy and 71% of the time with women. (Source: Deep Neural Networks Can Detect Sexual Orientation of Faces. Wang & Kosinski)\n\nOn one hand—this is amazing, impressive technology.\n\nOn the other—it’s a bit terrifying. It whiffs a bit of physiognomy. Which is the classification of people based on facial features.\n\nAt first glance, physiognomy isn’t terribly bad. But there are levels to it.\n\nOn one hand it’s cutsie, sort of like reading a fortune cookie. But then it moves to guessing sexuality and even further, can you then use technology to predict if someone is evil and needs to be watched? Do they use the same technology to scan and see if your face suddenly resembles child molesters? Or other criminals?\n\nBut what if it is only accurate 89% of the time and you are the 11%?\n\nIs it far fetched that this will happen? Sure.\n\nBut it’s worth raising the flag. Technology is evolving as quickly as privacy is vanishing. The last thing we need is another marker to be assigned to us, another number indicator to the soon-Cyber Overlord.', 'aiModelVersion': '1'}",0.9998
Joe Zbiciak,Updated 7mo,"What's the actual algorithm(s) being implemented by printf(), in terms of assembly code instructions?","Let’s ignore assembly code for a moment. Most printf() implementations are written in C. How do the printf()-family functions work in C code?

I’ll break this down into four major components:

Parsing the format string.
Reading the variadic argument list.
Converting the arguments to text.
Outputting the converted text to the specified location.

In preparation for this answer, I whipped up a few simplified printf() implementations that you can find at https://github.com/intvnut/simple_printf/.

Parsing the Format String

The format string is just a standard null-terminated C string. Most of the characters in the format string represent themselves. printf() will merely copy them directly to the output as is.

Consider:

printf(""Hello, world!\n""); 

That prints the string “Hello, world!” followed by a newline. printf() doesn’t add the newline. The compiler translates \n to a newline character when it translates the string into its compiled form.

The fun comes in with conversions. These are places where you ask printf() to convert an argument to output text. These start with a % character, followed by the details of the conversion. To print a %, use %%.

The following stripped down example supports %s, %d, and %%. This is from simple_printf_v1.c at the GitHub link above, reformatted for Quora.

/* 
 * Simplified printf that only 
 * understands %s, %d, and %%. 
 */ 
void simple_printf( 
    const char *fmt, ... 
) { 
  va_list args; 
  va_start(args, fmt); 
 
  for (int ch = *fmt++; 
       ch; ch = *fmt++) { 
    /* 
     * If it's not %, just 
     * print the character. 
     */ 
    if (ch != '%') { 
      fputc(ch, stdout); 
      continue; 
    } 
 
    /*  
     * It's (potentially) a 
     * conversion.  Let's  
     * take a look.  
     */ 
    int conv = *fmt++; 
 
    switch (conv) { 
      case 's': { 
        /* %s is a string. */ 
        const char *s = 
          va_arg(args, const char *); 
        fputs(s, stdout); 
        break; 
      } 
 
      case 'd': { 
        /* %d is a signed integer. */ 
        int d = va_arg(args, int); 
        print_int(d); 
        break; 
      } 
 
      case '%': { 
        /* %% prints '%' */ 
        putchar('%'); 
        break; 
      } 
 
      default: { 
        /* 
         * Not a valid conversion. 
         * Print the '%' and back up. 
         */ 
        putchar('%'); 
        --fmt; 
        break; 
      } 
    } 
  } 
 
  va_end(args); 
} 

For now, let’s ignore the ... and va_xxx() calls. I will get to those in a moment.

The core of this function is a for-loop that steps character by character through the format string. For most characters, it just copies the character straight to the output. When it reaches '%', it drops into the conversion parsing logic.

In this extremely simplified version, it looks at the next character. If it’s 's', it fetches the pointer to the string from the argument list and prints it. If it’s 'd', it fetches an int from the argument list and prints it. And if it’s '%', it prints a %.

The C99 standard says an invalid conversion specifier results in undefined behavior. I’ve chosen to be nice and output the failed conversion specifier to the output, in the hopes it might be useful for debugging. So the default case in the switch statement prints a % and then backs up our format pointer so that the loop will print what remains. We still might crash soon, though, as our format string and argument list are now out of sync.

I haven’t included the code for printing the decimalized integer; however, you can find it at the GitHub link.

The version above doesn’t do very much parsing, and falls well short of the standard. The standard specifies that a conversion has multiple elements after the %:

Optional flags, in any order:
'-' for left justification.
' ' and '+' to control printing the sign on non-negative signed values.
'0' to request leading zero padding.
'#' for alternate form conversions. This guarantees a leading '0' on octal conversions and adds ""0x"" or ""0X"" on hexadecimal conversions.
Optional field width, either in decimal or '*'. '*' means it’s supplied as an int argument.
Optional precision, either in decimal or '*'. '*' means it’s supplied as an int argument.
Optional operand length modifier:
""hh"" and 'h' for signed char and short.
'l' and ""ll"" for long and long long. 'l' also specifies wide-character in the case of character and string conversions.
'j', 'z', and 't' for intmax_t, size_t, and ptrdiff_t, respectively.
'L' for long double.
The conversion specifier:
'c' for characters.
's' for strings.
'd' and 'i' for signed decimal integers.
'u' for unsigned decimal integers.
'o' for octal integers.
'x' and 'X' for hexadecimal integers.
'p' for pointers.
'a', 'A', 'e', 'E', 'f', 'F', 'g', and 'G' for various floating point conversions.
Note: I am going to completely ignore floating point conversions in the remainder of this answer. They’re somewhat involved. Rather than doing a poor job of it, I simply will leave them out. I considered printing ""floating point formats not linked"" for these, but only folks of a certain age are likely to get the joke.

So, what does it take to parse that? I use the following approach:

Set all my flags to default values, and set width = 0, precision = 0. I also keep flags saying whether a width or precision was supplied in the format string.
Parse optional flags:
While the next character of the string is a flag character (one of "" #+-0""):
Set the corresponding flag.
Consume the character.
Parse optional width:
If the next character is '*', consume it and fetch the width from the argument list.
Otherwise, while the next character is a digit:
Multiply width by 10 and add the digit value.
Consume the character.
Parse optional precision, only if the next character is '.':
Consume the '.'.
If the next character is '*', consume it fetch the precision from the argument list.
Otherwise, while the next character is a digit:
Multiply precision by 10 and add the digit value.
Consume the character.
Parse optional length modifier:
If the next character is one of ""hljztL"", set the operand size accordingly and consume the character.
In case of 'h' or 'l', look for a second 'h' or 'l'. If found, consume it and update accordingly.
Fetch the conversion specifier:
If it’s a valid conversion, perform the conversion.
Otherwise, output '%' and rewind the format pointer to the first character after '%'.

In the description above, “consume” means “advance the pointer into the format string by a character.”

What does that look like as code? This is the core loop from simple_printf_v7.c:

Note: I’m sorry-not-sorry about using screenshots here. Reformatting that code for Quora’s narrow code blocks is just too tedious. Plus, I like the syntax highlighting. You can see the actual code at the GitHub link.

I’ll cover struct printer in the final section. struct conv keeps track of all the conversion details. It also holds pointers to struct printer and our variadic argument list. I’ll cover the argument list in the next section.

The first part of the loop outputs spans of non-conversion characters to the output. If we reach a '%' we fall into the conversion logic.

In simple_printf_v7.c, struct conv keeps track of all the details for a conversion:

Most of these tie directly back to parts of the conversion syntax. As noted above, args and printer are special. Also, soft_prec represents an implementation choice on my part that I might reconsider in a future version of the code.

The main loop calls four separate functions to collect the four optional components of the conversion specifier.

Flag parsing is pretty simple:

The one curlicue is to give '+' priority over ' ' if both are present. This is required by the standard.

Parsing width and precision are similar. For width, we need to look for a digit, and '0' in the flags doesn’t count. For precision, we know it’s present or absent based on whether the conversion has a '.'. A '.' without any digits after it is an explicit precision of 0.

For length modifiers (which in simple_printf_v6.c I call “operand size,” as I felt that was clearer at the time), most are a single character.

In simple_printf_v7.c, I adopted an approach that streamlines recognizing ""ll"" and ""hh"" with some cleverness: the PACK_CHAR_ macro recognizes a repeated character and sets a bit that switch() can examine. In simple_printf_v7.c,

I also peek ahead to see if the conversion is %p (for a pointer) to pick a special “operand length” for (void *). Previous versions handle that differently. The simple_printf_v7.c approach leads to different behavior in case of an invalid format conversion such as %hp. Such a conversion ends up behaving similarly to %#x with modifiers. That’s OK, because invalid format conversions bring undefined behavior.

You might notice I omit 'L', as it’s only used for floating point conversions.

Once I’ve parsed all the optional details of the conversion, I grab the conversion character and drop into a dispatcher that invokes the specific conversion requested. I’ll cover the actual conversions themselves in the section after the next one.

Reading the Variadic Argument List

Now we come back to the part I hand-waved above: the ... parameter and the va_xxx() calls.

The token ... in the function’s parameter list declares the function as a variadic function. This means it can take a variable number of arguments. For C89 through C18, variadic functions require at least one fixed parameter before the ... parameter. That notionally serves as an anchor for the argument list. In C23, it becomes optional. It turns out real-world implementations rely on compiler magic to initialize va_list and don’t need the anchor.

The C standard header <stdarg.h> provides a set of macros and a special data type for working with variadic argument lists:

va_list, a special type that represents the variable argument list. Below, args is a variable of type va_list.
va_start(args, anchor). This initializes args to point to the first variadic argument. Until C23, anchor should be the last fixed argument.
va_arg(args, type). This fetches an argument of the specified type from the variadic argument list. The type is literally a type name and can even have spaces and punctuation: va_args(args, unsigned long long *).
va_copy(dst_args, src_args). Copies a variadic argument list, so that you can walk through it more than once.
va_end(args). Ends processing of a variadic argument list. Every va_start() must be paired with va_end().

How do these macros work? That’s completely platform specific, unfortunately.

Historically, many C compilers pushed arguments onto the stack, either left-to-right or right-to-left. If you can find the address of the first variadic argument, you can step through a sequence of variadic arguments with pointer arithmetic.

Modern processor ABIs are more complex. Most modern ABIs pass parameters in a mix of registers and memory locations. Mainstream processors usually have multiple register sets for different types—scalar integer, floating point, vector—and so that also adds some complication.

This is potentially where delving into assembly language makes the most sense; however, the details will be different both by processor architecture and platform. For instance, the SysV x86-64 approach (used by Linux and Mac) differs from Microsoft’s x64 approach, even though they target the same instruction sets (AMD64™ and Intel64®).

Therefore, I won’t dive into assembly here. This answer is going to be long enough without it.

One of the trickiest aspects of variadic arguments is determining how many arguments there are, and what types they have. The language offers no safeties here. With printf(), that detail comes from the format string. The length modifier and conversion specifier determine the data type of each argument.

When it comes time to extract the argument, you need to invoke va_arg() with the correct type name. The compiler doesn’t store any type information with the arguments. The program has to get it right.

As a result, my code has a number of switch-case statements to handle the variety of types, like these:

You might notice something odd with kLengthChar and kLengthShort above. These correspond to the ‘h’ and “hh” length modifiers.

The C language specifies that variadic arguments go through a set of promotions before being stored to the variadic argument list:

Integers with rank below int get promoted to int or unsigned int.
Floating point types with rank below double get promoted to double. (Currently, that’s just float, but you could imagine a short float as a language extension.)

Thus, for 'h' and ""hh"", the argument will arrive as an int or unsigned int. The modifier doesn’t actually modify the size of the operand that it fetches with va_arg(); rather, it truncates the fetched value to the specified size after fetching it.

You might also notice a slight oddity with kLengthSizeT and kLengthPtrDiffT cases. When fetching a size_t for a conversion, the C language specifies that the argument is “a size_t or the corresponding signed integer type argument.” I interpreted that (perhaps unnecessarily) as needing to fetch an argument of that corresponding signed type when performing a signed conversion, and so I have a typedef for that (ssize_type). A similar situation exists with ptrdiff_t and unsigned conversions.

One other detail you might notice: both functions return uintmax_t, which is an unsigned data type. This is a design decision on my part. I use a single integer conversion function for both signed and unsigned values. Except on some really obscure machines, a uintmax_t can represent all the values an intmax_t can hold. Negative values get converted to large positive values by modulo wraparound. I just keep track of whether the conversion intends the value to be signed so I can handle negative values correctly.

Which brings us to…

Converting the Arguments to Text

This is another bucket of fun all its own.

Character and string arguments are the most straightforward, I think. Character conversions act like a string of length 1, and so my implementation just reuses the string conversion for both, setting precision to 1.

For strings, the field width specifies the minimum field width for the conversion. Longer strings are not truncated. If the conversion is left justified, the string contents are output first, followed by any necessary padding required to meet the minimum field width. Otherwise, the padding is output first, followed by the string. The default minimum field width is 0.

The precision specifies the maximum number of characters to include from the string. If the string is shorter than the precision, the precision has no effect. If it’s longer, then the string gets truncated. String conversion stops at a null terminator or after precision characters are copied. The string does not require a null terminator if it’s truncated by the specified precision.

This example…

printf(""[%-7s] [%7s] [%-7.2s] [%7.2s]\n"", 
       ""hello"", ""hello"", ""hello"", ""hello""); 

…prints this:

[hello  ] [  hello] [he     ] [     he] 

Integer conversions are much more involved.

My final code takes the approach of converting the integer to a string in a buffer, and then printing that buffer with the string conversion routine. One advantage of this approach is that it doesn’t need to handle left/right justification itself (mostly). One disadvantage is that my implementation puts an upper limit on the number of leading zeros you can request that’s lower than the standard mandates.

I use a single conversion function for all integers. It accepts a uintmax_t to convert, and the various flags and parameters that affect the conversion: signed/unsigned, caps/lowercase, regular/alternate, precision, and numeric base.

For signed values, it tests the sign bit in the uintmax_t. If it’s set, then it records that the value is negative and negates the value. Yes, you can negate an unsigned variable. It performs the negation modulo the power of 2 associated with its size (
2
64
264
 in my case). Negating an unsigned value avoids undefined behavior trying to negate INTMAX_MIN, the largest magnitude negative value. -INTMAX_MIN would be larger than INTMAX_MAX on most systems.

I convert the value to characters starting at the least-significant digit and working my way up. This fills the conversion buffer from the end, working toward the beginning. I stop when I’ve converted all the digits.

The precision specifies the minimum number of digits to output. If I didn’t output enough digits, I output additional 0s to meet the specified precision. The default precision is 1, so the value 0 displays as 0. A precision of 0 with the value 0 outputs no characters (except for alternate-form octal).

When the alternate format flag is set, octal conversions get a leading 0 if the leftmost digit output isn’t already 0, even if the requested precision is 0. Hexadecimal conversions unconditionally get a ""0x"" or ""0X"" prefix, depending on whether it’s an x or X conversion.

And finally, we prepend the sign for signed conversions. If it was negative, it automatically gets a '-'. If it’s non-negative, and either the ' ' or '+' flags were specified, the code prepends a ' ' or '+' accordingly. The '+' flag takes precedence over the ' ' if both appear in the conversion specification.

The width specification mostly governs the width of the field the converted number will display in. However, if the conversion includes a width and the '0' flag, and omits a precision and the left-justify flag, then the number must be padded on the left by zeros, but after any sign or radix prefix. In my code, I handle this case by converting the width into a precision, and marking the precision as soft. By soft, I mean that any sign or prefix can eat into the zero fill, unlike an actual precision spec. Otherwise, I pass the width to the string formatter after converting the integer to the string.

For example, consider:

printf(""%04d %.4d %04d %.4d\n"", 1, 1, -1, -1); 
printf(""%#04x %#.4x"", 1, 1); 

That prints:

0001 0001 -001 -0001 
0x01 0x0001 

The resulting integer conversion code has a lot more going on, subsequently:

Is it my most elegant code? Probably not.

Other integer conversion approaches have to contend with similar issues. I honestly haven’t looked at any in depth recently.

Pointer conversions are fairly straightforward: I chose to implement them as equivalent to %#x, with an appropriate implicit length modifier. Since I fetch a void * from the argument list, I don’t need to know what length modifier that is. I just convert the void * to uintptr_t and then run it through the same integer conversion as the others. I believe other implementations do something similar.

The remaining conversion is an odd one: %n. This doesn’t output any text. Rather, it records the number of characters converted so far in a location pointed to by the next argument. The length modifiers tell us what sort of pointer that is. In my code I implement that as follows:

A quick aside: printf() isn’t a single function. It is a family of functions that share a common core. As I get into in the next section, some of the family members output to a FILE* or stdout, and the others output to a buffer. As of C99, ignoring the wide-character variants, we have printf, fprintf, sprintf, snprintf, vprintf, vfprintf, vsprintf, and vsnprintf.

The v variants of the functions have a va_list parameter, rather than taking the variadic arguments as directly. This makes it possible for you to write your own wrappers around the printf() core. The non-v variants provide a default set of wrappers.

Conceptually, they look like this:

int vfprintf(FILE *file, const char *fmt, 
             va_list args) { 
  ... calls into the printf core ... 
} 
 
int vprintf(const char *fmt, va_list args) { 
  return vfprintf(stdin, fmt, args); 
} 
 
int vsnprintf(char *buf, size_t bufsz, 
              const char *fmt, va_list args) { 
  ... calls into the printf core ... 
} 
 
int vsprintf(char *buf, const char *fmt, 
             va_list args) { 
  // UNSAFE! 
  return vsnprintf(buf, SIZE_MAX, fmt, args); 
} 
 
int fprintf(FILE *file, const char *fmt, ...) { 
  va_list args; 
  va_start(args, fmt); 
  int ret = vfprintf(file, fmt, args); 
  va_end(args); 
  return ret; 
} 
 
int printf(const char *fmt, ...) { 
  va_list args; 
  va_start(args, fmt); 
  int ret = vfprintf(stdin, fmt, args); 
  va_end(args); 
  return ret; 
} 
 
int snprintf(char *buf, size_t bufsz, 
             const char *fmt, ...) { 
  va_list args; 
  va_start(args, fmt); 
  int ret = vsnprintf(buf, bufsz, fmt, args); 
  va_end(args); 
  return ret; 
} 
 
int sprintf(char *buf, const char *fmt, ...) { 
  va_list args; 
  va_start(args, fmt); 
  // UNSAFE! 
  int ret = vsnprintf(buf, SIZE_MAX, fmt, args); 
  va_end(args); 
  return ret; 
} 

I marked sprintf and vsprintf above as UNSAFE, because there’s no way to state the size of the output buffer. Unless you’re very careful about how you construct your format string, you could open yourself to buffer overflows. Prefer snprintf, or C11’s new sprintf_s / snprintf_s.

When you pass a variadic argument list to a function by value like this, the callee processes arguments exactly as they would if they called va_start() themselves. The caller, however, must stop using the va_list at that point. It still must call va_end() to clean up after va_start(), however.

Earlier, I hand-waved the presence of va_list* args in struct conv. If you pass a va_list by pointer among cooperating functions, all of them can extract arguments from the variadic argument list cooperatively. Sharing the variadic argument list doesn’t add any new requirements.

I generally try to set things up so that the function that calls va_start is also the function that calls va_end. That’s how simple_printf_v6.c and simple_printf_v7.c structure things. I pass va_list by copy into the printf_core(), which absolves it of the responsibility of calling va_end(). Meanwhile, printf_core() arranges for all the other helpers to have access to the va_list by pointer, to avoid the cost of copying it around. This seems like a decent division of responsibility.

And that quite handily brings us to the next section.

Outputting the Converted Text to the Specified Location

If you recall, near the beginning of this answer, I provided a very simplified simple_printf() that output directly to stdout. I have calls to fputc() and fwrite() and such directly embedded in the code.

The real printf() doesn’t work that way, obviously. printf() outputs to stdout, fprintf() outputs to a FILE*, and sprintf() / snprintf() both output to a string buffer. The actual character output needs to be abstracted away.

The way I handled this in my code is to introduce an abstraction I called struct printer.

/* 
 * Abstracts away how text gets output, 
 * and how much was actually output. 
 */ 
struct printer { 
  union { 
    FILE *file; 
    char *buf; 
  }; 
  size_t max; 
  size_t total; 
 
  void (*copy)(struct printer *p, 
               const char *s, 
               size_t length); 
 
  void (*fill)(struct printer *p, 
               char c, 
               size_t length); 
 
  void (*putc)(struct printer *p, 
               char c); 
 
  void (*done)(struct printer *p); 
}; 

This has four data fields, and four function pointers. I specified four functions:

copy(), which copies a string of a given length to the output. You can think of it as similar to memcpy(), although the target may be a file stream.
fill(), which writes multiple copies of a fill character to the output. You can think of it as similar to memset(), although the target may be a file stream.
putc(), which writes a single character to the output. You can think of this as similar to either *p++ = c, or fputc(c, file), depending on whether your target is a string buffer or a file stream.
done(), which finalizes the output. For snprintf() type functions, this adds the null terminator. For output to a file, it could call fflush() or similar if appropriate.

Inside the printf() core, I can replace all of my calls to fputc(), putchar(), and fwrite() with calls to the function pointers in a struct printer object. For example, print_converted_string() becomes:

The total and max fields serve two related purposes. The total field keeps track of the total length of the converted output. The max field sets the maximum output length for snprintf() and vsnprintf(). Note that snprintf() and vsnprintf() still return the total length of the converted output, even if it’s longer than the provided buffer.

In simple_printf_v6.c, I don’t implement the full complement of printf-family functions. In simple_printf_v7.c, I implement all 8 basic non-wide versions: printf, vprintf, fprintf, vfprintf, sprintf, vsprintf, snprintf, and vsnprintf.

In simple_printf_v7.c, everything ultimately ends up at simple_vfprintf and simple_vsnprintf. The other functions forward to these two.

/* 
 * Prints to a FILE*, accepting 
 * arguments from va_list. 
 */ 
int simple_vfprintf( 
    FILE *file, const char *fmt, 
    va_list args) { 
  struct printer printer = { 
    .file = file, 
    .total = 0, 
    .copy = printer_file_copy, 
    .fill = printer_file_fill, 
    .putc = printer_file_putc, 
    .done = printer_file_done 
  }; 
 
  return printf_core(&printer, fmt, args); 
} 

…and…

/* 
 * Prints up to max chars in a buffer, 
 * accepting arguments from va_list. 
 */ 
int simple_vsnprintf( 
    char *buf, size_t max, 
    const char *fmt, va_list args) { 
  struct printer printer = { 
    .buf = buf, 
    .max = max > 0 ? max - 1 : 0,  /* Save room for null! */ 
    .total = 0, 
    .copy = printer_buf_copy, 
    .fill = printer_buf_fill, 
    .putc = printer_buf_putc, 
    .done = printer_buf_done 
  }; 
 
  return printf_core(&printer, fmt, args); 
} 

The wrapper functions which take a variadic argument list directly call va_start and va_end as needed. For example:

/*  
 * Prints to stdout, accepting  
 * a variadic argument list. 
 */ 
int simple_printf(const char *fmt, ...) { 
  va_list args; 
  va_start(args, fmt); 
  int ret = simple_vfprintf(stdout, fmt, args); 
  va_end(args); 
 
  return ret; 
} 

And:

/* 
 * Prints up to max chars in a  
 * buffer, accepting a variadic 
 * argument list. 
 */ 
int simple_snprintf( 
    char *buf, size_t max, 
    const char *fmt, ...) { 
  va_list args; 
  va_start(args, fmt); 
  int ret = simple_vsnprintf(buf, max, fmt, args); 
  va_end(args); 
  return ret;  /* Total converted characters, possibly more than max. */ 
} 

Ta da! That’s all there is to it. Now the printf() core doesn’t know or care whether it’s outputting to a string buffer or a file.

So what to the actual printer functions look like? For the file printer, these just forward through to the functions I called before. The only fancy bit is that the fill function tries to be a little smarter.

The string buffer versions use memcpy() and memset(); however, they also enforce max. Once total goes beyond max, they drop further output while updating total.

*whew*

Conclusion

The code we walked through is a simplified version of printf() that still manages to capture most of the requirements imposed by C99. It leaves a few things out, such as wide-character support and floating point.

Actual industrial printf() implementations will have many of the same characteristics as my simplified implementation. They might go to greater lengths to optimize the interactions with the rest of the file I/O implementation, though. And, most platforms offer a range of extensions beyond what C99 requires. For example, POSIX adds its own set of extensions.

If you understood my implementation above, you’re in good shape to understand key portions of an industrial implementation.

I took a quick peek at the GNU C Library (glibc) implementation, after I had written most of the text above. While they made some different implementation choices, you’ll still find a common spirit. And, amusingly, they made a similar split between putting a character, filling with a character, and copying an entire buffer. (I was actually a little surprised and mildly amused!)

I didn’t dive into what the assembly language would look like, because quite honestly, nobody would code this in assembly language if they could implement it adequately from C.

Some early implementations did lean on assembly language for speed and size reasons. See _doprnt() in Seventh Edition UNIX™ for example: https://www.tuhs.org/cgi-bin/utree.pl?file=V7/usr/src/libc/stdio/doprnt.s That’s similar in purpose to my printf_core(). As printf() became more involved and computers became more powerful, assembly implementations became less attractive.

Hopefully my walkthrough of my C implementation answered most of your questions. Feel free to ask questions in the comments.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/540heotczwxbkd93', 'title': ""What's the actual algorithm(s) being implemented by printf(), in terms of assembly code instructions?"", 'score': {'original': 0.9501, 'ai': 0.0499}, 'blocks': [{'text': 'Let’s ignore assembly code for a moment. Most printf() implementations are written in C. How do the printf()-family functions work in C code?\n\nI’ll break this down into four major components:\n\nParsing the format string.\nReading the variadic argument list.\nConverting the arguments to text.\nOutputting the converted text to the specified location.\n\nIn preparation for this answer, I whipped up a few simplified printf() implementations that you can find at https://github.com/intvnut/simple_printf/.\n\nParsing the Format String\n\nThe format string is just a standard null-terminated C string. Most of the characters in the format string represent themselves. printf() will merely copy them directly to the output as is.\n\nConsider:\n\nprintf(""Hello, world!\\n"");\xa0\n\nThat prints the string “Hello, world!” followed by a newline. printf() doesn’t add the newline. The compiler translates \\n to a newline character when it translates the string into its compiled form.\n\nThe fun comes in with conversions. These are places where you ask printf() to convert an argument to output text. These start with a % character, followed by the details of the conversion. To print a %, use %%.\n\nThe following stripped down example supports %s, %d, and %%. This is from simple_printf_v1.c at the GitHub link above, reformatted for Quora.\n\n/*\xa0\n * Simplified printf that only\xa0\n * understands %s, %d, and %%.\xa0\n */\xa0\nvoid simple_printf(\xa0\n    const char *fmt, ...\xa0\n) {\xa0\n  va_list args;\xa0\n  va_start(args, fmt);\xa0\n\xa0\n  for (int ch = *fmt++;\xa0\n       ch; ch = *fmt++) {\xa0\n    /*\xa0\n     * If it\'s not %, just\xa0\n     * print the character.\xa0\n     */\xa0\n    if (ch != \'%\') {\xa0\n      fputc(ch, stdout);\xa0\n      continue;\xa0\n    }\xa0\n\xa0\n    /* \xa0\n     * It\'s (potentially) a\xa0\n     * conversion.  Let\'s \xa0\n     * take a look. \xa0\n     */\xa0\n    int conv = *fmt++;\xa0\n\xa0\n    switch (conv) {\xa0\n      case \'s\': {\xa0\n        /* %s is a string. */\xa0\n        const char *s =\xa0\n          va_arg(args, const char *);\xa0\n        fputs(s, stdout);\xa0\n        break;\xa0\n      }\xa0\n\xa0\n      case \'d\': {\xa0\n        /* %d is a signed integer. */\xa0\n        int d = va_arg(args, int);\xa0\n        print_int(d);\xa0\n        break;\xa0\n      }\xa0\n\xa0\n      case \'%\': {\xa0\n        /* %% prints \'%\' */\xa0\n        putchar(\'%\');\xa0\n        break;\xa0\n      }\xa0\n\xa0\n      default: {\xa0\n    ', 'result': {'fake': 0.0096, 'real': 0.9904}, 'status': 'success'}, {'text': '   /*\xa0\n         * Not a valid conversion.\xa0\n         * Print the \'%\' and back up.\xa0\n         */\xa0\n        putchar(\'%\');\xa0\n        --fmt;\xa0\n        break;\xa0\n      }\xa0\n    }\xa0\n  }\xa0\n\xa0\n  va_end(args);\xa0\n}\xa0\n\nFor now, let’s ignore the ... and va_xxx() calls. I will get to those in a moment.\n\nThe core of this function is a for-loop that steps character by character through the format string. For most characters, it just copies the character straight to the output. When it reaches \'%\', it drops into the conversion parsing logic.\n\nIn this extremely simplified version, it looks at the next character. If it’s \'s\', it fetches the pointer to the string from the argument list and prints it. If it’s \'d\', it fetches an int from the argument list and prints it. And if it’s \'%\', it prints a %.\n\nThe C99 standard says an invalid conversion specifier results in undefined behavior. I’ve chosen to be nice and output the failed conversion specifier to the output, in the hopes it might be useful for debugging. So the default case in the switch statement prints a % and then backs up our format pointer so that the loop will print what remains. We still might crash soon, though, as our format string and argument list are now out of sync.\n\nI haven’t included the code for printing the decimalized integer; however, you can find it at the GitHub link.\n\nThe version above doesn’t do very much parsing, and falls well short of the standard. The standard specifies that a conversion has multiple elements after the %:\n\nOptional flags, in any order:\n\'-\' for left justification.\n\' \' and \'+\' to control printing the sign on non-negative signed values.\n\'0\' to request leading zero padding.\n\'#\' for alternate form conversions. This guarantees a leading \'0\' on octal conversions and adds ""0x"" or ""0X"" on hexadecimal conversions.\nOptional field width, either in decimal or \'*\'. \'*\' means it’s supplied as an int argument.\nOptional precision, either in decimal or \'*\'. \'*\' means it’s supplied as an int argument.\nOptional operand length modifier:\n""hh"" and \'h\' for signed char and short.\n\'l\' and ""ll"" for long and long long. \'l\' also specifies wide-character in the case of character and string conversions.\n\'j\', \'z\', and \'t\' for intmax_t, size_t, and ptrdiff_t, respectively.\n\'L\' for long double.\nThe conversion specifier:\n\'c\' for characters.\n\'s\' for strings.\n\'d\' and \'i\' for signed decimal integers.\n\'u\' for unsigned decimal integers.\n\'o\' for octal integers.\n\'x\' and \'X\' for hexadecimal integers.\n\'p\' for pointers.\n\'a\', \'A\', \'e\', \'E\', \'f\', \'F\', \'g\', and \'G\' for various floating point conversions.\nNote: I am going to completely ignore floating point conversions in the remainder of this answer. They’re somewhat involved. Rather than doing a poor job of it, I simply will leave them out. I considered printing ""floating point formats not linked"" for these, but only folks of a certain age are likely to get the', 'result': {'fake': 0.0572, 'real': 0.9428}, 'status': 'success'}, {'text': 'joke.\n\nSo, what does it take to parse that? I use the following approach:\n\nSet all my flags to default values, and set width = 0, precision = 0. I also keep flags saying whether a width or precision was supplied in the format string.\nParse optional flags:\nWhile the next character of the string is a flag character (one of "" #+-0""):\nSet the corresponding flag.\nConsume the character.\nParse optional width:\nIf the next character is \'*\', consume it and fetch the width from the argument list.\nOtherwise, while the next character is a digit:\nMultiply width by 10 and add the digit value.\nConsume the character.\nParse optional precision, only if the next character is \'.\':\nConsume the \'.\'.\nIf the next character is \'*\', consume it fetch the precision from the argument list.\nOtherwise, while the next character is a digit:\nMultiply precision by 10 and add the digit value.\nConsume the character.\nParse optional length modifier:\nIf the next character is one of ""hljztL"", set the operand size accordingly and consume the character.\nIn case of \'h\' or \'l\', look for a second \'h\' or \'l\'. If found, consume it and update accordingly.\nFetch the conversion specifier:\nIf it’s a valid conversion, perform the conversion.\nOtherwise, output \'%\' and rewind the format pointer to the first character after \'%\'.\n\nIn the description above, “consume” means “advance the pointer into the format string by a character.”\n\nWhat does that look like as code? This is the core loop from simple_printf_v7.c:\n\nNote: I’m sorry-not-sorry about using screenshots here. Reformatting that code for Quora’s narrow code blocks is just too tedious. Plus, I like the syntax highlighting. You can see the actual code at the GitHub link.\n\nI’ll cover struct printer in the final section. struct conv keeps track of all the conversion details. It also holds pointers to struct printer and our variadic argument list. I’ll cover the argument list in the next section.\n\nThe first part of the loop outputs spans of non-conversion characters to the output. If we reach a \'%\' we fall into the conversion logic.\n\nIn simple_printf_v7.c, struct conv keeps track of all the details for a conversion:\n\nMost of these tie directly back to parts of the conversion syntax. As noted above, args and printer are special. Also, soft_prec represents an implementation choice on my part that I might reconsider in a future version of the code.\n\nThe main loop calls four separate functions to collect the four optional components of the conversion specifier.\n\nFlag parsing is pretty simple:\n\nThe one curlicue is to give \'+\' priority over \' \' if both are present. This is required by the standard.\n\nParsing width and precision are similar. For width, we need to look for a digit, and \'0\' in the flags doesn’t count. For precision, we know it’s present or absent based on whether the conversion has a \'.\'. A \'.\' without any digits after it is an explicit precision of 0.\n\nFor length modifiers (which in simple_printf_v6.c I call “operand size,” as I felt that was clearer at the time), most are a single character.\n\nIn simple_printf_v7.c, I adopted an approach that streamlines recognizing ""ll"" and ""hh"" with some cleverness: the PACK_CHAR_ macro recognizes a repeated character and sets a', 'result': {'fake': 0.1306, 'real': 0.8694}, 'status': 'success'}, {'text': ""bit that switch() can examine. In simple_printf_v7.c,\n\nI also peek ahead to see if the conversion is %p (for a pointer) to pick a special “operand length” for (void *). Previous versions handle that differently. The simple_printf_v7.c approach leads to different behavior in case of an invalid format conversion such as %hp. Such a conversion ends up behaving similarly to %#x with modifiers. That’s OK, because invalid format conversions bring undefined behavior.\n\nYou might notice I omit 'L', as it’s only used for floating point conversions.\n\nOnce I’ve parsed all the optional details of the conversion, I grab the conversion character and drop into a dispatcher that invokes the specific conversion requested. I’ll cover the actual conversions themselves in the section after the next one.\n\nReading the Variadic Argument List\n\nNow we come back to the part I hand-waved above: the ... parameter and the va_xxx() calls.\n\nThe token ... in the function’s parameter list declares the function as a variadic function. This means it can take a variable number of arguments. For C89 through C18, variadic functions require at least one fixed parameter before the ... parameter. That notionally serves as an anchor for the argument list. In C23, it becomes optional. It turns out real-world implementations rely on compiler magic to initialize va_list and don’t need the anchor.\n\nThe C standard header <stdarg.h> provides a set of macros and a special data type for working with variadic argument lists:\n\nva_list, a special type that represents the variable argument list. Below, args is a variable of type va_list.\nva_start(args, anchor). This initializes args to point to the first variadic argument. Until C23, anchor should be the last fixed argument.\nva_arg(args, type). This fetches an argument of the specified type from the variadic argument list. The type is literally a type name and can even have spaces and punctuation: va_args(args, unsigned long long *).\nva_copy(dst_args, src_args). Copies a variadic argument list, so that you can walk through it more than once.\nva_end(args). Ends processing of a variadic argument list. Every va_start() must be paired with va_end().\n\nHow do these macros work? That’s completely platform specific, unfortunately.\n\nHistorically, many C compilers pushed arguments onto the stack, either left-to-right or right-to-left. If you can find the address of the first variadic argument, you can step through a sequence of variadic arguments with pointer arithmetic.\n\nModern processor ABIs are more complex. Most modern ABIs pass parameters in a mix of registers and memory locations. Mainstream processors usually have multiple register sets for different types—scalar integer, floating point, vector—and so that also adds some complication.\n\nThis is potentially where delving into assembly language makes the most sense; however, the details will be different both by processor architecture and platform. For instance, the SysV x86-64 approach (used by Linux and Mac) differs from Microsoft’s x64 approach, even though they target the same instruction sets (AMD64™ and Intel64®).\n\nTherefore, I won’t dive into assembly here. This answer is going to be long enough without it.\n\nOne of the trickiest aspects of variadic arguments is determining how many arguments there are, and what types they have. The language offers no safeties here. With printf(), that detail comes"", 'result': {'fake': 0.0637, 'real': 0.9363}, 'status': 'success'}, {'text': 'from the format string. The length modifier and conversion specifier determine the data type of each argument.\n\nWhen it comes time to extract the argument, you need to invoke va_arg() with the correct type name. The compiler doesn’t store any type information with the arguments. The program has to get it right.\n\nAs a result, my code has a number of switch-case statements to handle the variety of types, like these:\n\nYou might notice something odd with kLengthChar and kLengthShort above. These correspond to the ‘h’ and “hh” length modifiers.\n\nThe C language specifies that variadic arguments go through a set of promotions before being stored to the variadic argument list:\n\nIntegers with rank below int get promoted to int or unsigned int.\nFloating point types with rank below double get promoted to double. (Currently, that’s just float, but you could imagine a short float as a language extension.)\n\nThus, for \'h\' and ""hh"", the argument will arrive as an int or unsigned int. The modifier doesn’t actually modify the size of the operand that it fetches with va_arg(); rather, it truncates the fetched value to the specified size after fetching it.\n\nYou might also notice a slight oddity with kLengthSizeT and kLengthPtrDiffT cases. When fetching a size_t for a conversion, the C language specifies that the argument is “a size_t or the corresponding signed integer type argument.” I interpreted that (perhaps unnecessarily) as needing to fetch an argument of that corresponding signed type when performing a signed conversion, and so I have a typedef for that (ssize_type). A similar situation exists with ptrdiff_t and unsigned conversions.\n\nOne other detail you might notice: both functions return uintmax_t, which is an unsigned data type. This is a design decision on my part. I use a single integer conversion function for both signed and unsigned values. Except on some really obscure machines, a uintmax_t can represent all the values an intmax_t can hold. Negative values get converted to large positive values by modulo wraparound. I just keep track of whether the conversion intends the value to be signed so I can handle negative values correctly.\n\nWhich brings us to…\n\nConverting the Arguments to Text\n\nThis is another bucket of fun all its own.\n\nCharacter and string arguments are the most straightforward, I think. Character conversions act like a string of length 1, and so my implementation just reuses the string conversion for both, setting precision to 1.\n\nFor strings, the field width specifies the minimum field width for the conversion. Longer strings are not truncated. If the conversion is left justified, the string contents are output first, followed by any necessary padding required to meet the minimum field width. Otherwise, the padding is output first, followed by the string. The default minimum field width is 0.\n\nThe precision specifies the maximum number of characters to include from the string. If the string is shorter than the precision, the precision has no effect. If it’s longer, then the string gets truncated. String conversion stops at a null terminator or after precision characters are copied. The string does not require a null terminator if it’s truncated by the specified precision.\n\nThis example…\n\nprintf(""[%-7s]', 'result': {'fake': 0.2255, 'real': 0.7745}, 'status': 'success'}, {'text': '[%7s] [%-7.2s] [%7.2s]\\n"",\xa0\n       ""hello"", ""hello"", ""hello"", ""hello"");\xa0\n\n…prints this:\n\n[hello  ] [  hello] [he     ] [     he]\xa0\n\nInteger conversions are much more involved.\n\nMy final code takes the approach of converting the integer to a string in a buffer, and then printing that buffer with the string conversion routine. One advantage of this approach is that it doesn’t need to handle left/right justification itself (mostly). One disadvantage is that my implementation puts an upper limit on the number of leading zeros you can request that’s lower than the standard mandates.\n\nI use a single conversion function for all integers. It accepts a uintmax_t to convert, and the various flags and parameters that affect the conversion: signed/unsigned, caps/lowercase, regular/alternate, precision, and numeric base.\n\nFor signed values, it tests the sign bit in the uintmax_t. If it’s set, then it records that the value is negative and negates the value. Yes, you can negate an unsigned variable. It performs the negation modulo the power of 2 associated with its size (\n2\n64\n264\n in my case). Negating an unsigned value avoids undefined behavior trying to negate INTMAX_MIN, the largest magnitude negative value. -INTMAX_MIN would be larger than INTMAX_MAX on most systems.\n\nI convert the value to characters starting at the least-significant digit and working my way up. This fills the conversion buffer from the end, working toward the beginning. I stop when I’ve converted all the digits.\n\nThe precision specifies the minimum number of digits to output. If I didn’t output enough digits, I output additional 0s to meet the specified precision. The default precision is 1, so the value 0 displays as 0. A precision of 0 with the value 0 outputs no characters (except for alternate-form octal).\n\nWhen the alternate format flag is set, octal conversions get a leading 0 if the leftmost digit output isn’t already 0, even if the requested precision is 0. Hexadecimal conversions unconditionally get a ""0x"" or ""0X"" prefix, depending on whether it’s an x or X conversion.\n\nAnd finally, we prepend the sign for signed conversions. If it was negative, it automatically gets a \'-\'. If it’s non-negative, and either the \' \' or \'+\' flags were specified, the code prepends a \' \' or \'+\' accordingly. The \'+\' flag takes precedence over the \' \' if both appear in the conversion specification.\n\nThe width specification mostly governs the width of the field the converted number will display in. However, if the conversion includes a width and the \'0\' flag, and omits a precision and the left-justify flag, then the number must be padded on the left by zeros, but after any sign or radix prefix. In my code, I handle this case by converting the width into a precision, and marking the precision as soft. By soft, I mean that any sign or prefix can eat into the zero fill, unlike an actual precision spec. Otherwise, I pass the width to the string formatter after converting the integer to the string.\n\nFor example, consider:\n\nprintf(""%04d %.4d %04d %.4d\\n"", 1, 1, -1, -1);\xa0\nprintf(""%#04x %#.4x"", 1,', 'result': {'fake': 0.1116, 'real': 0.8884}, 'status': 'success'}, {'text': '1);\xa0\n\nThat prints:\n\n0001 0001 -001 -0001\xa0\n0x01 0x0001\xa0\n\nThe resulting integer conversion code has a lot more going on, subsequently:\n\nIs it my most elegant code? Probably not.\n\nOther integer conversion approaches have to contend with similar issues. I honestly haven’t looked at any in depth recently.\n\nPointer conversions are fairly straightforward: I chose to implement them as equivalent to %#x, with an appropriate implicit length modifier. Since I fetch a void * from the argument list, I don’t need to know what length modifier that is. I just convert the void * to uintptr_t and then run it through the same integer conversion as the others. I believe other implementations do something similar.\n\nThe remaining conversion is an odd one: %n. This doesn’t output any text. Rather, it records the number of characters converted so far in a location pointed to by the next argument. The length modifiers tell us what sort of pointer that is. In my code I implement that as follows:\n\nA quick aside: printf() isn’t a single function. It is a family of functions that share a common core. As I get into in the next section, some of the family members output to a FILE* or stdout, and the others output to a buffer. As of C99, ignoring the wide-character variants, we have printf, fprintf, sprintf, snprintf, vprintf, vfprintf, vsprintf, and vsnprintf.\n\nThe v variants of the functions have a va_list parameter, rather than taking the variadic arguments as directly. This makes it possible for you to write your own wrappers around the printf() core. The non-v variants provide a default set of wrappers.\n\nConceptually, they look like this:\n\nint vfprintf(FILE *file, const char *fmt,\xa0\n             va_list args) {\xa0\n  ... calls into the printf core ...\xa0\n}\xa0\n\xa0\nint vprintf(const char *fmt, va_list args) {\xa0\n  return vfprintf(stdin, fmt, args);\xa0\n}\xa0\n\xa0\nint vsnprintf(char *buf, size_t bufsz,\xa0\n              const char *fmt, va_list args) {\xa0\n  ... calls into the printf core ...\xa0\n}\xa0\n\xa0\nint vsprintf(char *buf, const char *fmt,\xa0\n             va_list args) {\xa0\n  // UNSAFE!\xa0\n  return vsnprintf(buf, SIZE_MAX, fmt, args);\xa0\n}\xa0\n\xa0\nint fprintf(FILE *file, const char *fmt, ...) {\xa0\n  va_list args;\xa0\n  va_start(args, fmt);\xa0\n  int ret = vfprintf(file, fmt, args);\xa0\n  va_end(args);\xa0\n  return ret;\xa0\n}\xa0\n\xa0\nint printf(const char *fmt, ...) {\xa0\n  va_list args;\xa0\n  va_start(args, fmt);\xa0\n  int ret = vfprintf(stdin, fmt, args);\xa0\n  va_end(args);\xa0\n  return ret;\xa0\n}\xa0\n\xa0\nint snprintf(char *buf, size_t bufsz,\xa0\n             const char *fmt, ...) {\xa0\n  va_list args;\xa0\n  va_start(args, fmt);\xa0\n  int ret = vsnprintf(buf, bufsz, fmt, args);\xa0\n  va_end(args);\xa0\n  return ret;\xa0\n}\xa0\n\xa0\nint sprintf(char *buf, const char *fmt, ...) {\xa0\n  va_list args;\xa0\n  va_start(args, fmt);\xa0\n  // UNSAFE!\xa0\n  int ret = vsnprintf(buf, SIZE_MAX, fmt, args);\xa0\n  va_end(args);\xa0\n  return ret;\xa0\n}\xa0\n\nI marked sprintf and vsprintf above as UNSAFE, because there’s no way to state the size of the output buffer. Unless you’re very careful about how you construct your format string, you', 'result': {'fake': 0.0875, 'real': 0.9125}, 'status': 'success'}, {'text': 'could open yourself to buffer overflows. Prefer snprintf, or C11’s new sprintf_s / snprintf_s.\n\nWhen you pass a variadic argument list to a function by value like this, the callee processes arguments exactly as they would if they called va_start() themselves. The caller, however, must stop using the va_list at that point. It still must call va_end() to clean up after va_start(), however.\n\nEarlier, I hand-waved the presence of va_list* args in struct conv. If you pass a va_list by pointer among cooperating functions, all of them can extract arguments from the variadic argument list cooperatively. Sharing the variadic argument list doesn’t add any new requirements.\n\nI generally try to set things up so that the function that calls va_start is also the function that calls va_end. That’s how simple_printf_v6.c and simple_printf_v7.c structure things. I pass va_list by copy into the printf_core(), which absolves it of the responsibility of calling va_end(). Meanwhile, printf_core() arranges for all the other helpers to have access to the va_list by pointer, to avoid the cost of copying it around. This seems like a decent division of responsibility.\n\nAnd that quite handily brings us to the next section.\n\nOutputting the Converted Text to the Specified Location\n\nIf you recall, near the beginning of this answer, I provided a very simplified simple_printf() that output directly to stdout. I have calls to fputc() and fwrite() and such directly embedded in the code.\n\nThe real printf() doesn’t work that way, obviously. printf() outputs to stdout, fprintf() outputs to a FILE*, and sprintf() / snprintf() both output to a string buffer. The actual character output needs to be abstracted away.\n\nThe way I handled this in my code is to introduce an abstraction I called struct printer.\n\n/*\xa0\n * Abstracts away how text gets output,\xa0\n * and how much was actually output.\xa0\n */\xa0\nstruct printer {\xa0\n  union {\xa0\n    FILE *file;\xa0\n    char *buf;\xa0\n  };\xa0\n  size_t max;\xa0\n  size_t total;\xa0\n\xa0\n  void (*copy)(struct printer *p,\xa0\n               const char *s,\xa0\n               size_t length);\xa0\n\xa0\n  void (*fill)(struct printer *p,\xa0\n               char c,\xa0\n               size_t length);\xa0\n\xa0\n  void (*putc)(struct printer *p,\xa0\n               char c);\xa0\n\xa0\n  void (*done)(struct printer *p);\xa0\n};\xa0\n\nThis has four data fields, and four function pointers. I specified four functions:\n\ncopy(), which copies a string of a given length to the output. You can think of it as similar to memcpy(), although the target may be a file stream.\nfill(), which writes multiple copies of a fill character to the output. You can think of it as similar to memset(), although the target may be a file stream.\nputc(), which writes a single character to the output. You can think of this as similar to either *p++ = c, or fputc(c, file), depending on', 'result': {'fake': 0.068, 'real': 0.932}, 'status': 'success'}, {'text': 'whether your target is a string buffer or a file stream.\ndone(), which finalizes the output. For snprintf() type functions, this adds the null terminator. For output to a file, it could call fflush() or similar if appropriate.\n\nInside the printf() core, I can replace all of my calls to fputc(), putchar(), and fwrite() with calls to the function pointers in a struct printer object. For example, print_converted_string() becomes:\n\nThe total and max fields serve two related purposes. The total field keeps track of the total length of the converted output. The max field sets the maximum output length for snprintf() and vsnprintf(). Note that snprintf() and vsnprintf() still return the total length of the converted output, even if it’s longer than the provided buffer.\n\nIn simple_printf_v6.c, I don’t implement the full complement of printf-family functions. In simple_printf_v7.c, I implement all 8 basic non-wide versions: printf, vprintf, fprintf, vfprintf, sprintf, vsprintf, snprintf, and vsnprintf.\n\nIn simple_printf_v7.c, everything ultimately ends up at simple_vfprintf and simple_vsnprintf. The other functions forward to these two.\n\n/*\xa0\n * Prints to a FILE*, accepting\xa0\n * arguments from va_list.\xa0\n */\xa0\nint simple_vfprintf(\xa0\n    FILE *file, const char *fmt,\xa0\n    va_list args) {\xa0\n  struct printer printer = {\xa0\n    .file = file,\xa0\n    .total = 0,\xa0\n    .copy = printer_file_copy,\xa0\n    .fill = printer_file_fill,\xa0\n    .putc = printer_file_putc,\xa0\n    .done = printer_file_done\xa0\n  };\xa0\n\xa0\n  return printf_core(&printer, fmt, args);\xa0\n}\xa0\n\n…and…\n\n/*\xa0\n * Prints up to max chars in a buffer,\xa0\n * accepting arguments from va_list.\xa0\n */\xa0\nint simple_vsnprintf(\xa0\n    char *buf, size_t max,\xa0\n    const char *fmt, va_list args) {\xa0\n  struct printer printer = {\xa0\n    .buf = buf,\xa0\n    .max = max > 0 ? max - 1 : 0,  /* Save room for null! */\xa0\n    .total = 0,\xa0\n    .copy = printer_buf_copy,\xa0\n    .fill = printer_buf_fill,\xa0\n    .putc = printer_buf_putc,\xa0\n    .done = printer_buf_done\xa0\n  };\xa0\n\xa0\n  return printf_core(&printer, fmt, args);\xa0\n}\xa0\n\nThe wrapper functions which take a variadic argument list directly call va_start and va_end as needed. For example:\n\n/* \xa0\n * Prints to stdout, accepting \xa0\n * a variadic argument list.\xa0\n */\xa0\nint simple_printf(const char *fmt, ...) {\xa0\n  va_list args;\xa0\n  va_start(args, fmt);\xa0\n  int ret = simple_vfprintf(stdout, fmt, args);\xa0\n  va_end(args);\xa0\n\xa0\n  return ret;\xa0\n}\xa0\n\nAnd:\n\n/*\xa0\n * Prints up to max chars in a \xa0\n * buffer, accepting a variadic\xa0\n * argument list.\xa0\n */\xa0\nint simple_snprintf(\xa0\n    char *buf, size_t max,\xa0\n    const char *fmt, ...) {\xa0\n  va_list args;\xa0\n  va_start(args, fmt);\xa0\n  int ret = simple_vsnprintf(buf, max, fmt, args);\xa0\n  va_end(args);\xa0\n  return ret;  /* Total converted characters, possibly more than max. */\xa0\n}\xa0\n\nTa da! That’s all there is to it. Now the printf() core doesn’t know or care whether it’s outputting to a string buffer or a file.\n\nSo what to the actual printer functions look like? For the file printer, these just forward through to the functions I called before. The only fancy bit is that', 'result': {'fake': 0.0393, 'real': 0.9607}, 'status': 'success'}, {'text': 'the fill function tries to be a little smarter.\n\nThe string buffer versions use memcpy() and memset(); however, they also enforce max. Once total goes beyond max, they drop further output while updating total.\n\n*whew*\n\nConclusion\n\nThe code we walked through is a simplified version of printf() that still manages to capture most of the requirements imposed by C99. It leaves a few things out, such as wide-character support and floating point.\n\nActual industrial printf() implementations will have many of the same characteristics as my simplified implementation. They might go to greater lengths to optimize the interactions with the rest of the file I/O implementation, though. And, most platforms offer a range of extensions beyond what C99 requires. For example, POSIX adds its own set of extensions.\n\nIf you understood my implementation above, you’re in good shape to understand key portions of an industrial implementation.\n\nI took a quick peek at the GNU C Library (glibc) implementation, after I had written most of the text above. While they made some different implementation choices, you’ll still find a common spirit. And, amusingly, they made a similar split between putting a character, filling with a character, and copying an entire buffer. (I was actually a little surprised and mildly amused!)\n\nI didn’t dive into what the assembly language would look like, because quite honestly, nobody would code this in assembly language if they could implement it adequately from C.\n\nSome early implementations did lean on assembly language for speed and size reasons. See _doprnt() in Seventh Edition UNIX™ for example: https://www.tuhs.org/cgi-bin/utree.pl?file=V7/usr/src/libc/stdio/doprnt.s That’s similar in purpose to my printf_core(). As printf() became more involved and computers became more powerful, assembly implementations became less attractive.\n\nHopefully my walkthrough of my C implementation answered most of your questions. Feel free to ask questions in the comments.', 'result': {'fake': 0.0277, 'real': 0.9723}, 'status': 'success'}], 'credits_used': 48, 'credits': 1986557, 'subscription': 0, 'content': 'Let’s ignore assembly code for a moment. Most printf() implementations are written in C. How do the printf()-family functions work in C code?\n\nI’ll break this down into four major components:\n\nParsing the format string.\nReading the variadic argument list.\nConverting the arguments to text.\nOutputting the converted text to the specified location.\n\nIn preparation for this answer, I whipped up a few simplified printf() implementations that you can find at https://github.com/intvnut/simple_printf/.\n\nParsing the Format String\n\nThe format string is just a standard null-terminated C string. Most of the characters in the format string represent themselves. printf() will merely copy them directly to the output as is.\n\nConsider:\n\nprintf(""Hello, world!\\n"");\xa0\n\nThat prints the string “Hello, world!” followed by a newline. printf() doesn’t add the newline. The compiler translates \\n to a newline character when it translates the string into its compiled form.\n\nThe fun comes in with conversions. These are places where you ask printf() to convert an argument to output text. These start with a % character, followed by the details of the conversion. To print a %, use %%.\n\nThe following stripped down example supports %s, %d, and %%. This is from simple_printf_v1.c at the GitHub link above, reformatted for Quora.\n\n/*\xa0\n * Simplified printf that only\xa0\n * understands %s, %d, and %%.\xa0\n */\xa0\nvoid simple_printf(\xa0\n    const char *fmt, ...\xa0\n) {\xa0\n  va_list args;\xa0\n  va_start(args, fmt);\xa0\n\xa0\n  for (int ch = *fmt++;\xa0\n       ch; ch = *fmt++) {\xa0\n    /*\xa0\n     * If it\'s not %, just\xa0\n     * print the character.\xa0\n     */\xa0\n    if (ch != \'%\') {\xa0\n      fputc(ch, stdout);\xa0\n      continue;\xa0\n    }\xa0\n\xa0\n    /* \xa0\n     * It\'s (potentially) a\xa0\n     * conversion.  Let\'s \xa0\n     * take a look. \xa0\n     */\xa0\n    int conv = *fmt++;\xa0\n\xa0\n    switch (conv) {\xa0\n      case \'s\': {\xa0\n        /* %s is a string. */\xa0\n        const char *s =\xa0\n          va_arg(args, const char *);\xa0\n        fputs(s, stdout);\xa0\n        break;\xa0\n      }\xa0\n\xa0\n      case \'d\': {\xa0\n        /* %d is a signed integer. */\xa0\n        int d = va_arg(args, int);\xa0\n        print_int(d);\xa0\n        break;\xa0\n      }\xa0\n\xa0\n      case \'%\': {\xa0\n        /* %% prints \'%\' */\xa0\n        putchar(\'%\');\xa0\n        break;\xa0\n      }\xa0\n\xa0\n      default: {\xa0\n        /*\xa0\n         * Not a valid conversion.\xa0\n         * Print the \'%\' and back up.\xa0\n         */\xa0\n        putchar(\'%\');\xa0\n        --fmt;\xa0\n        break;\xa0\n      }\xa0\n    }\xa0\n  }\xa0\n\xa0\n  va_end(args);\xa0\n}\xa0\n\nFor now, let’s ignore the ... and va_xxx() calls. I will get to those in a moment.\n\nThe core of this function is a for-loop that steps character by character through the format string. For most characters, it just copies the character straight to the output. When it reaches \'%\', it drops into the conversion parsing logic.\n\nIn this extremely simplified version, it looks at the next character. If it’s \'s\', it fetches the pointer to the string from the argument list and prints it. If it’s \'d\', it fetches an int from the argument list and prints it. And if it’s \'%\', it prints a %.\n\nThe C99 standard says an invalid conversion specifier results in undefined behavior. I’ve chosen to be nice and output the failed conversion specifier to the output, in the hopes it might be useful for debugging. So the default case in the switch statement prints a % and then backs up our format pointer so that the loop will print what remains. We still might crash soon, though, as our format string and argument list are now out of sync.\n\nI haven’t included the code for printing the decimalized integer; however, you can find it at the GitHub link.\n\nThe version above doesn’t do very much parsing, and falls well short of the standard. The standard specifies that a conversion has multiple elements after the %:\n\nOptional flags, in any order:\n\'-\' for left justification.\n\' \' and \'+\' to control printing the sign on non-negative signed values.\n\'0\' to request leading zero padding.\n\'#\' for alternate form conversions. This guarantees a leading \'0\' on octal conversions and adds ""0x"" or ""0X"" on hexadecimal conversions.\nOptional field width, either in decimal or \'*\'. \'*\' means it’s supplied as an int argument.\nOptional precision, either in decimal or \'*\'. \'*\' means it’s supplied as an int argument.\nOptional operand length modifier:\n""hh"" and \'h\' for signed char and short.\n\'l\' and ""ll"" for long and long long. \'l\' also specifies wide-character in the case of character and string conversions.\n\'j\', \'z\', and \'t\' for intmax_t, size_t, and ptrdiff_t, respectively.\n\'L\' for long double.\nThe conversion specifier:\n\'c\' for characters.\n\'s\' for strings.\n\'d\' and \'i\' for signed decimal integers.\n\'u\' for unsigned decimal integers.\n\'o\' for octal integers.\n\'x\' and \'X\' for hexadecimal integers.\n\'p\' for pointers.\n\'a\', \'A\', \'e\', \'E\', \'f\', \'F\', \'g\', and \'G\' for various floating point conversions.\nNote: I am going to completely ignore floating point conversions in the remainder of this answer. They’re somewhat involved. Rather than doing a poor job of it, I simply will leave them out. I considered printing ""floating point formats not linked"" for these, but only folks of a certain age are likely to get the joke.\n\nSo, what does it take to parse that? I use the following approach:\n\nSet all my flags to default values, and set width = 0, precision = 0. I also keep flags saying whether a width or precision was supplied in the format string.\nParse optional flags:\nWhile the next character of the string is a flag character (one of "" #+-0""):\nSet the corresponding flag.\nConsume the character.\nParse optional width:\nIf the next character is \'*\', consume it and fetch the width from the argument list.\nOtherwise, while the next character is a digit:\nMultiply width by 10 and add the digit value.\nConsume the character.\nParse optional precision, only if the next character is \'.\':\nConsume the \'.\'.\nIf the next character is \'*\', consume it fetch the precision from the argument list.\nOtherwise, while the next character is a digit:\nMultiply precision by 10 and add the digit value.\nConsume the character.\nParse optional length modifier:\nIf the next character is one of ""hljztL"", set the operand size accordingly and consume the character.\nIn case of \'h\' or \'l\', look for a second \'h\' or \'l\'. If found, consume it and update accordingly.\nFetch the conversion specifier:\nIf it’s a valid conversion, perform the conversion.\nOtherwise, output \'%\' and rewind the format pointer to the first character after \'%\'.\n\nIn the description above, “consume” means “advance the pointer into the format string by a character.”\n\nWhat does that look like as code? This is the core loop from simple_printf_v7.c:\n\nNote: I’m sorry-not-sorry about using screenshots here. Reformatting that code for Quora’s narrow code blocks is just too tedious. Plus, I like the syntax highlighting. You can see the actual code at the GitHub link.\n\nI’ll cover struct printer in the final section. struct conv keeps track of all the conversion details. It also holds pointers to struct printer and our variadic argument list. I’ll cover the argument list in the next section.\n\nThe first part of the loop outputs spans of non-conversion characters to the output. If we reach a \'%\' we fall into the conversion logic.\n\nIn simple_printf_v7.c, struct conv keeps track of all the details for a conversion:\n\nMost of these tie directly back to parts of the conversion syntax. As noted above, args and printer are special. Also, soft_prec represents an implementation choice on my part that I might reconsider in a future version of the code.\n\nThe main loop calls four separate functions to collect the four optional components of the conversion specifier.\n\nFlag parsing is pretty simple:\n\nThe one curlicue is to give \'+\' priority over \' \' if both are present. This is required by the standard.\n\nParsing width and precision are similar. For width, we need to look for a digit, and \'0\' in the flags doesn’t count. For precision, we know it’s present or absent based on whether the conversion has a \'.\'. A \'.\' without any digits after it is an explicit precision of 0.\n\nFor length modifiers (which in simple_printf_v6.c I call “operand size,” as I felt that was clearer at the time), most are a single character.\n\nIn simple_printf_v7.c, I adopted an approach that streamlines recognizing ""ll"" and ""hh"" with some cleverness: the PACK_CHAR_ macro recognizes a repeated character and sets a bit that switch() can examine. In simple_printf_v7.c,\n\nI also peek ahead to see if the conversion is %p (for a pointer) to pick a special “operand length” for (void *). Previous versions handle that differently. The simple_printf_v7.c approach leads to different behavior in case of an invalid format conversion such as %hp. Such a conversion ends up behaving similarly to %#x with modifiers. That’s OK, because invalid format conversions bring undefined behavior.\n\nYou might notice I omit \'L\', as it’s only used for floating point conversions.\n\nOnce I’ve parsed all the optional details of the conversion, I grab the conversion character and drop into a dispatcher that invokes the specific conversion requested. I’ll cover the actual conversions themselves in the section after the next one.\n\nReading the Variadic Argument List\n\nNow we come back to the part I hand-waved above: the ... parameter and the va_xxx() calls.\n\nThe token ... in the function’s parameter list declares the function as a variadic function. This means it can take a variable number of arguments. For C89 through C18, variadic functions require at least one fixed parameter before the ... parameter. That notionally serves as an anchor for the argument list. In C23, it becomes optional. It turns out real-world implementations rely on compiler magic to initialize va_list and don’t need the anchor.\n\nThe C standard header <stdarg.h> provides a set of macros and a special data type for working with variadic argument lists:\n\nva_list, a special type that represents the variable argument list. Below, args is a variable of type va_list.\nva_start(args, anchor). This initializes args to point to the first variadic argument. Until C23, anchor should be the last fixed argument.\nva_arg(args, type). This fetches an argument of the specified type from the variadic argument list. The type is literally a type name and can even have spaces and punctuation: va_args(args, unsigned long long *).\nva_copy(dst_args, src_args). Copies a variadic argument list, so that you can walk through it more than once.\nva_end(args). Ends processing of a variadic argument list. Every va_start() must be paired with va_end().\n\nHow do these macros work? That’s completely platform specific, unfortunately.\n\nHistorically, many C compilers pushed arguments onto the stack, either left-to-right or right-to-left. If you can find the address of the first variadic argument, you can step through a sequence of variadic arguments with pointer arithmetic.\n\nModern processor ABIs are more complex. Most modern ABIs pass parameters in a mix of registers and memory locations. Mainstream processors usually have multiple register sets for different types—scalar integer, floating point, vector—and so that also adds some complication.\n\nThis is potentially where delving into assembly language makes the most sense; however, the details will be different both by processor architecture and platform. For instance, the SysV x86-64 approach (used by Linux and Mac) differs from Microsoft’s x64 approach, even though they target the same instruction sets (AMD64™ and Intel64®).\n\nTherefore, I won’t dive into assembly here. This answer is going to be long enough without it.\n\nOne of the trickiest aspects of variadic arguments is determining how many arguments there are, and what types they have. The language offers no safeties here. With printf(), that detail comes from the format string. The length modifier and conversion specifier determine the data type of each argument.\n\nWhen it comes time to extract the argument, you need to invoke va_arg() with the correct type name. The compiler doesn’t store any type information with the arguments. The program has to get it right.\n\nAs a result, my code has a number of switch-case statements to handle the variety of types, like these:\n\nYou might notice something odd with kLengthChar and kLengthShort above. These correspond to the ‘h’ and “hh” length modifiers.\n\nThe C language specifies that variadic arguments go through a set of promotions before being stored to the variadic argument list:\n\nIntegers with rank below int get promoted to int or unsigned int.\nFloating point types with rank below double get promoted to double. (Currently, that’s just float, but you could imagine a short float as a language extension.)\n\nThus, for \'h\' and ""hh"", the argument will arrive as an int or unsigned int. The modifier doesn’t actually modify the size of the operand that it fetches with va_arg(); rather, it truncates the fetched value to the specified size after fetching it.\n\nYou might also notice a slight oddity with kLengthSizeT and kLengthPtrDiffT cases. When fetching a size_t for a conversion, the C language specifies that the argument is “a size_t or the corresponding signed integer type argument.” I interpreted that (perhaps unnecessarily) as needing to fetch an argument of that corresponding signed type when performing a signed conversion, and so I have a typedef for that (ssize_type). A similar situation exists with ptrdiff_t and unsigned conversions.\n\nOne other detail you might notice: both functions return uintmax_t, which is an unsigned data type. This is a design decision on my part. I use a single integer conversion function for both signed and unsigned values. Except on some really obscure machines, a uintmax_t can represent all the values an intmax_t can hold. Negative values get converted to large positive values by modulo wraparound. I just keep track of whether the conversion intends the value to be signed so I can handle negative values correctly.\n\nWhich brings us to…\n\nConverting the Arguments to Text\n\nThis is another bucket of fun all its own.\n\nCharacter and string arguments are the most straightforward, I think. Character conversions act like a string of length 1, and so my implementation just reuses the string conversion for both, setting precision to 1.\n\nFor strings, the field width specifies the minimum field width for the conversion. Longer strings are not truncated. If the conversion is left justified, the string contents are output first, followed by any necessary padding required to meet the minimum field width. Otherwise, the padding is output first, followed by the string. The default minimum field width is 0.\n\nThe precision specifies the maximum number of characters to include from the string. If the string is shorter than the precision, the precision has no effect. If it’s longer, then the string gets truncated. String conversion stops at a null terminator or after precision characters are copied. The string does not require a null terminator if it’s truncated by the specified precision.\n\nThis example…\n\nprintf(""[%-7s] [%7s] [%-7.2s] [%7.2s]\\n"",\xa0\n       ""hello"", ""hello"", ""hello"", ""hello"");\xa0\n\n…prints this:\n\n[hello  ] [  hello] [he     ] [     he]\xa0\n\nInteger conversions are much more involved.\n\nMy final code takes the approach of converting the integer to a string in a buffer, and then printing that buffer with the string conversion routine. One advantage of this approach is that it doesn’t need to handle left/right justification itself (mostly). One disadvantage is that my implementation puts an upper limit on the number of leading zeros you can request that’s lower than the standard mandates.\n\nI use a single conversion function for all integers. It accepts a uintmax_t to convert, and the various flags and parameters that affect the conversion: signed/unsigned, caps/lowercase, regular/alternate, precision, and numeric base.\n\nFor signed values, it tests the sign bit in the uintmax_t. If it’s set, then it records that the value is negative and negates the value. Yes, you can negate an unsigned variable. It performs the negation modulo the power of 2 associated with its size (\n2\n64\n264\n in my case). Negating an unsigned value avoids undefined behavior trying to negate INTMAX_MIN, the largest magnitude negative value. -INTMAX_MIN would be larger than INTMAX_MAX on most systems.\n\nI convert the value to characters starting at the least-significant digit and working my way up. This fills the conversion buffer from the end, working toward the beginning. I stop when I’ve converted all the digits.\n\nThe precision specifies the minimum number of digits to output. If I didn’t output enough digits, I output additional 0s to meet the specified precision. The default precision is 1, so the value 0 displays as 0. A precision of 0 with the value 0 outputs no characters (except for alternate-form octal).\n\nWhen the alternate format flag is set, octal conversions get a leading 0 if the leftmost digit output isn’t already 0, even if the requested precision is 0. Hexadecimal conversions unconditionally get a ""0x"" or ""0X"" prefix, depending on whether it’s an x or X conversion.\n\nAnd finally, we prepend the sign for signed conversions. If it was negative, it automatically gets a \'-\'. If it’s non-negative, and either the \' \' or \'+\' flags were specified, the code prepends a \' \' or \'+\' accordingly. The \'+\' flag takes precedence over the \' \' if both appear in the conversion specification.\n\nThe width specification mostly governs the width of the field the converted number will display in. However, if the conversion includes a width and the \'0\' flag, and omits a precision and the left-justify flag, then the number must be padded on the left by zeros, but after any sign or radix prefix. In my code, I handle this case by converting the width into a precision, and marking the precision as soft. By soft, I mean that any sign or prefix can eat into the zero fill, unlike an actual precision spec. Otherwise, I pass the width to the string formatter after converting the integer to the string.\n\nFor example, consider:\n\nprintf(""%04d %.4d %04d %.4d\\n"", 1, 1, -1, -1);\xa0\nprintf(""%#04x %#.4x"", 1, 1);\xa0\n\nThat prints:\n\n0001 0001 -001 -0001\xa0\n0x01 0x0001\xa0\n\nThe resulting integer conversion code has a lot more going on, subsequently:\n\nIs it my most elegant code? Probably not.\n\nOther integer conversion approaches have to contend with similar issues. I honestly haven’t looked at any in depth recently.\n\nPointer conversions are fairly straightforward: I chose to implement them as equivalent to %#x, with an appropriate implicit length modifier. Since I fetch a void * from the argument list, I don’t need to know what length modifier that is. I just convert the void * to uintptr_t and then run it through the same integer conversion as the others. I believe other implementations do something similar.\n\nThe remaining conversion is an odd one: %n. This doesn’t output any text. Rather, it records the number of characters converted so far in a location pointed to by the next argument. The length modifiers tell us what sort of pointer that is. In my code I implement that as follows:\n\nA quick aside: printf() isn’t a single function. It is a family of functions that share a common core. As I get into in the next section, some of the family members output to a FILE* or stdout, and the others output to a buffer. As of C99, ignoring the wide-character variants, we have printf, fprintf, sprintf, snprintf, vprintf, vfprintf, vsprintf, and vsnprintf.\n\nThe v variants of the functions have a va_list parameter, rather than taking the variadic arguments as directly. This makes it possible for you to write your own wrappers around the printf() core. The non-v variants provide a default set of wrappers.\n\nConceptually, they look like this:\n\nint vfprintf(FILE *file, const char *fmt,\xa0\n             va_list args) {\xa0\n  ... calls into the printf core ...\xa0\n}\xa0\n\xa0\nint vprintf(const char *fmt, va_list args) {\xa0\n  return vfprintf(stdin, fmt, args);\xa0\n}\xa0\n\xa0\nint vsnprintf(char *buf, size_t bufsz,\xa0\n              const char *fmt, va_list args) {\xa0\n  ... calls into the printf core ...\xa0\n}\xa0\n\xa0\nint vsprintf(char *buf, const char *fmt,\xa0\n             va_list args) {\xa0\n  // UNSAFE!\xa0\n  return vsnprintf(buf, SIZE_MAX, fmt, args);\xa0\n}\xa0\n\xa0\nint fprintf(FILE *file, const char *fmt, ...) {\xa0\n  va_list args;\xa0\n  va_start(args, fmt);\xa0\n  int ret = vfprintf(file, fmt, args);\xa0\n  va_end(args);\xa0\n  return ret;\xa0\n}\xa0\n\xa0\nint printf(const char *fmt, ...) {\xa0\n  va_list args;\xa0\n  va_start(args, fmt);\xa0\n  int ret = vfprintf(stdin, fmt, args);\xa0\n  va_end(args);\xa0\n  return ret;\xa0\n}\xa0\n\xa0\nint snprintf(char *buf, size_t bufsz,\xa0\n             const char *fmt, ...) {\xa0\n  va_list args;\xa0\n  va_start(args, fmt);\xa0\n  int ret = vsnprintf(buf, bufsz, fmt, args);\xa0\n  va_end(args);\xa0\n  return ret;\xa0\n}\xa0\n\xa0\nint sprintf(char *buf, const char *fmt, ...) {\xa0\n  va_list args;\xa0\n  va_start(args, fmt);\xa0\n  // UNSAFE!\xa0\n  int ret = vsnprintf(buf, SIZE_MAX, fmt, args);\xa0\n  va_end(args);\xa0\n  return ret;\xa0\n}\xa0\n\nI marked sprintf and vsprintf above as UNSAFE, because there’s no way to state the size of the output buffer. Unless you’re very careful about how you construct your format string, you could open yourself to buffer overflows. Prefer snprintf, or C11’s new sprintf_s / snprintf_s.\n\nWhen you pass a variadic argument list to a function by value like this, the callee processes arguments exactly as they would if they called va_start() themselves. The caller, however, must stop using the va_list at that point. It still must call va_end() to clean up after va_start(), however.\n\nEarlier, I hand-waved the presence of va_list* args in struct conv. If you pass a va_list by pointer among cooperating functions, all of them can extract arguments from the variadic argument list cooperatively. Sharing the variadic argument list doesn’t add any new requirements.\n\nI generally try to set things up so that the function that calls va_start is also the function that calls va_end. That’s how simple_printf_v6.c and simple_printf_v7.c structure things. I pass va_list by copy into the printf_core(), which absolves it of the responsibility of calling va_end(). Meanwhile, printf_core() arranges for all the other helpers to have access to the va_list by pointer, to avoid the cost of copying it around. This seems like a decent division of responsibility.\n\nAnd that quite handily brings us to the next section.\n\nOutputting the Converted Text to the Specified Location\n\nIf you recall, near the beginning of this answer, I provided a very simplified simple_printf() that output directly to stdout. I have calls to fputc() and fwrite() and such directly embedded in the code.\n\nThe real printf() doesn’t work that way, obviously. printf() outputs to stdout, fprintf() outputs to a FILE*, and sprintf() / snprintf() both output to a string buffer. The actual character output needs to be abstracted away.\n\nThe way I handled this in my code is to introduce an abstraction I called struct printer.\n\n/*\xa0\n * Abstracts away how text gets output,\xa0\n * and how much was actually output.\xa0\n */\xa0\nstruct printer {\xa0\n  union {\xa0\n    FILE *file;\xa0\n    char *buf;\xa0\n  };\xa0\n  size_t max;\xa0\n  size_t total;\xa0\n\xa0\n  void (*copy)(struct printer *p,\xa0\n               const char *s,\xa0\n               size_t length);\xa0\n\xa0\n  void (*fill)(struct printer *p,\xa0\n               char c,\xa0\n               size_t length);\xa0\n\xa0\n  void (*putc)(struct printer *p,\xa0\n               char c);\xa0\n\xa0\n  void (*done)(struct printer *p);\xa0\n};\xa0\n\nThis has four data fields, and four function pointers. I specified four functions:\n\ncopy(), which copies a string of a given length to the output. You can think of it as similar to memcpy(), although the target may be a file stream.\nfill(), which writes multiple copies of a fill character to the output. You can think of it as similar to memset(), although the target may be a file stream.\nputc(), which writes a single character to the output. You can think of this as similar to either *p++ = c, or fputc(c, file), depending on whether your target is a string buffer or a file stream.\ndone(), which finalizes the output. For snprintf() type functions, this adds the null terminator. For output to a file, it could call fflush() or similar if appropriate.\n\nInside the printf() core, I can replace all of my calls to fputc(), putchar(), and fwrite() with calls to the function pointers in a struct printer object. For example, print_converted_string() becomes:\n\nThe total and max fields serve two related purposes. The total field keeps track of the total length of the converted output. The max field sets the maximum output length for snprintf() and vsnprintf(). Note that snprintf() and vsnprintf() still return the total length of the converted output, even if it’s longer than the provided buffer.\n\nIn simple_printf_v6.c, I don’t implement the full complement of printf-family functions. In simple_printf_v7.c, I implement all 8 basic non-wide versions: printf, vprintf, fprintf, vfprintf, sprintf, vsprintf, snprintf, and vsnprintf.\n\nIn simple_printf_v7.c, everything ultimately ends up at simple_vfprintf and simple_vsnprintf. The other functions forward to these two.\n\n/*\xa0\n * Prints to a FILE*, accepting\xa0\n * arguments from va_list.\xa0\n */\xa0\nint simple_vfprintf(\xa0\n    FILE *file, const char *fmt,\xa0\n    va_list args) {\xa0\n  struct printer printer = {\xa0\n    .file = file,\xa0\n    .total = 0,\xa0\n    .copy = printer_file_copy,\xa0\n    .fill = printer_file_fill,\xa0\n    .putc = printer_file_putc,\xa0\n    .done = printer_file_done\xa0\n  };\xa0\n\xa0\n  return printf_core(&printer, fmt, args);\xa0\n}\xa0\n\n…and…\n\n/*\xa0\n * Prints up to max chars in a buffer,\xa0\n * accepting arguments from va_list.\xa0\n */\xa0\nint simple_vsnprintf(\xa0\n    char *buf, size_t max,\xa0\n    const char *fmt, va_list args) {\xa0\n  struct printer printer = {\xa0\n    .buf = buf,\xa0\n    .max = max > 0 ? max - 1 : 0,  /* Save room for null! */\xa0\n    .total = 0,\xa0\n    .copy = printer_buf_copy,\xa0\n    .fill = printer_buf_fill,\xa0\n    .putc = printer_buf_putc,\xa0\n    .done = printer_buf_done\xa0\n  };\xa0\n\xa0\n  return printf_core(&printer, fmt, args);\xa0\n}\xa0\n\nThe wrapper functions which take a variadic argument list directly call va_start and va_end as needed. For example:\n\n/* \xa0\n * Prints to stdout, accepting \xa0\n * a variadic argument list.\xa0\n */\xa0\nint simple_printf(const char *fmt, ...) {\xa0\n  va_list args;\xa0\n  va_start(args, fmt);\xa0\n  int ret = simple_vfprintf(stdout, fmt, args);\xa0\n  va_end(args);\xa0\n\xa0\n  return ret;\xa0\n}\xa0\n\nAnd:\n\n/*\xa0\n * Prints up to max chars in a \xa0\n * buffer, accepting a variadic\xa0\n * argument list.\xa0\n */\xa0\nint simple_snprintf(\xa0\n    char *buf, size_t max,\xa0\n    const char *fmt, ...) {\xa0\n  va_list args;\xa0\n  va_start(args, fmt);\xa0\n  int ret = simple_vsnprintf(buf, max, fmt, args);\xa0\n  va_end(args);\xa0\n  return ret;  /* Total converted characters, possibly more than max. */\xa0\n}\xa0\n\nTa da! That’s all there is to it. Now the printf() core doesn’t know or care whether it’s outputting to a string buffer or a file.\n\nSo what to the actual printer functions look like? For the file printer, these just forward through to the functions I called before. The only fancy bit is that the fill function tries to be a little smarter.\n\nThe string buffer versions use memcpy() and memset(); however, they also enforce max. Once total goes beyond max, they drop further output while updating total.\n\n*whew*\n\nConclusion\n\nThe code we walked through is a simplified version of printf() that still manages to capture most of the requirements imposed by C99. It leaves a few things out, such as wide-character support and floating point.\n\nActual industrial printf() implementations will have many of the same characteristics as my simplified implementation. They might go to greater lengths to optimize the interactions with the rest of the file I/O implementation, though. And, most platforms offer a range of extensions beyond what C99 requires. For example, POSIX adds its own set of extensions.\n\nIf you understood my implementation above, you’re in good shape to understand key portions of an industrial implementation.\n\nI took a quick peek at the GNU C Library (glibc) implementation, after I had written most of the text above. While they made some different implementation choices, you’ll still find a common spirit. And, amusingly, they made a similar split between putting a character, filling with a character, and copying an entire buffer. (I was actually a little surprised and mildly amused!)\n\nI didn’t dive into what the assembly language would look like, because quite honestly, nobody would code this in assembly language if they could implement it adequately from C.\n\nSome early implementations did lean on assembly language for speed and size reasons. See _doprnt() in Seventh Edition UNIX™ for example: https://www.tuhs.org/cgi-bin/utree.pl?file=V7/usr/src/libc/stdio/doprnt.s That’s similar in purpose to my printf_core(). As printf() became more involved and computers became more powerful, assembly implementations became less attractive.\n\nHopefully my walkthrough of my C implementation answered most of your questions. Feel free to ask questions in the comments.', 'aiModelVersion': '1'}",0.9501
Tomasz Smykowski,5y,"With more than 8 million accounts, how do giant sites like Reddit verify so quickly that a username isn't taken?","With a dictionary tree

A dictionary tree consists of nodes. Each node is a letter. Node can indicate other nodes. Reading the tree from tops down gives all variants of nicks used:

So here we have an example of such tree populated with data. There is word dot and word news. And also others.

So a software stores a tree in a memory. When user wants to register a nick, server checks it letter by letter. For example :

You want to register news nickname.

Program checks if top row contains “n” letter. Yes.

And does node of n letter indicate to a “e” node? Yes.

And node e to node w?

Yes.

Does w indicate to s?

Yes.

On this graph it is not visible. But at the end is also end of word node.

So is next node a end node?

Yes.

Ok. So this nickname is reserved.

With 8 mln users checking if a nickname is taken breaks down to checking n+1 times if a indicator exists. Where n is a nickname length.

It takes fractions of a milisecond. And does not depend on how much users are registered.

Upvote and follow cause IT is awesomely interesting!","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/jv1mywih845r9l7g', 'title': ""With more than 8 million accounts, how do giant sites like Reddit verify so quickly that a username isn't taken?"", 'score': {'original': 0.9998, 'ai': 0.0002}, 'blocks': [{'text': 'With a dictionary tree\n\nA dictionary tree consists of nodes. Each node is a letter. Node can indicate other nodes. Reading the tree from tops down gives all variants of nicks used:\n\nSo here we have an example of such tree populated with data. There is word dot and word news. And also others.\n\nSo a software stores a tree in a memory. When user wants to register a nick, server checks it letter by letter. For example :\n\nYou want to register news nickname.\n\nProgram checks if top row contains “n” letter. Yes.\n\nAnd does node of n letter indicate to a “e” node? Yes.\n\nAnd node e to node w?\n\nYes.\n\nDoes w indicate to s?\n\nYes.\n\nOn this graph it is not visible. But at the end is also end of word node.\n\nSo is next node a end node?\n\nYes.\n\nOk. So this nickname is reserved.\n\nWith 8 mln users checking if a nickname is taken breaks down to checking n+1 times if a indicator exists. Where n is a nickname length.\n\nIt takes fractions of a milisecond. And does not depend on how much users are registered.\n\nUpvote and follow cause IT is awesomely interesting!', 'result': {'fake': 0.0002, 'real': 0.9998}, 'status': 'success'}], 'credits_used': 2, 'credits': 1986555, 'subscription': 0, 'content': 'With a dictionary tree\n\nA dictionary tree consists of nodes. Each node is a letter. Node can indicate other nodes. Reading the tree from tops down gives all variants of nicks used:\n\nSo here we have an example of such tree populated with data. There is word dot and word news. And also others.\n\nSo a software stores a tree in a memory. When user wants to register a nick, server checks it letter by letter. For example :\n\nYou want to register news nickname.\n\nProgram checks if top row contains “n” letter. Yes.\n\nAnd does node of n letter indicate to a “e” node? Yes.\n\nAnd node e to node w?\n\nYes.\n\nDoes w indicate to s?\n\nYes.\n\nOn this graph it is not visible. But at the end is also end of word node.\n\nSo is next node a end node?\n\nYes.\n\nOk. So this nickname is reserved.\n\nWith 8 mln users checking if a nickname is taken breaks down to checking n+1 times if a indicator exists. Where n is a nickname length.\n\nIt takes fractions of a milisecond. And does not depend on how much users are registered.\n\nUpvote and follow cause IT is awesomely interesting!', 'aiModelVersion': '1'}",0.9998
Yishan Wong,Updated 6y,"With more than 8 million accounts, how do giant sites like Reddit verify so quickly that a username isn't taken?","There are a lot of good answers here. In honor of Reddit, I will give the highly simplified ELI5 version accessible to a layman without reference to programming or computer science concepts.

The first key trick is that Reddit stores all of the usernames in a sorted, alphabetized list. That means the list of usernames looks like a, aa, aaa, aaab, … xyzzyz, yishan, zz, zztop. It's a big list of usernames, 8 million-some long. It's laid out in an alphabetized list like the words in a dictionary.

When you enter a new username, it checks it against the username in the MIDDLE of the list. That name is something like ManWithAModem. It compares the username to this and asks “is this the same name?” If so, reject. It probably isn't, so then it asks “does this new username come alphabetically before or after this username?”

If it comes before, then it knows that all 4 million+ names after this in the list can't possibly be a match, so it has now eliminated 4 million+ possibilities in a single comparison. If it comes after, then it knows that all 4 million+ names before this in the list can't be a match. In either case, we’ve ruled out an entire half of the list after only one comparison - and all because we sorted the list!

Next, we take the remaining half of the list that we didn't eliminate, look at the username in the middle of THAT list, and compare it to our new username. Once again, if it isn't a perfect match (i.e. found that it's already in use), we can tell whether a match (if it exists) sits before or after that point in the sorted list. And as we did earlier, we again have eliminated another half of the entire remaining possibilities.

By cutting the list in half every time we do a comparison, we can winnow down the list of 8 million+ usernames quite quickly. How quickly?

The answer is “how many times do you need to divide 8 million by 2 until the result is less than 1?” We are trying to cut the segments of the sorted list in half until things get small enough that we’ve gotten down to two usernames which are right next to each other, and then we can compare the new username to each one and if it matches one of them, then the username is already in use; if not, then it's a valid new username.

Well, the answer to that question is 23 times.

That's all. Because we kept the usernames in a sorted list, we only had to do at most 23 comparisons to verify that the new proposed username doesn't exist already. That's much, much faster than 8 million comparisons.

If you want to know more, you can read the other answers here, which explain how this sorted list is called an “index” and that this type of search and comparison process (or something similar to it) is often provided within the database in which the usernames are stored, plus other specifics.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/emv9hawsiz5d4glt', 'title': ""With more than 8 million accounts, how do giant sites like Reddit verify so quickly that a username isn't taken?"", 'score': {'original': 0.4094, 'ai': 0.5906}, 'blocks': [{'text': ""There are a lot of good answers here. In honor of Reddit, I will give the highly simplified ELI5 version accessible to a layman without reference to programming or computer science concepts.\n\nThe first key trick is that Reddit stores all of the usernames in a sorted, alphabetized list. That means the list of usernames looks like a, aa, aaa, aaab, … xyzzyz, yishan, zz, zztop. It's a big list of usernames, 8 million-some long. It's laid out in an alphabetized list like the words in a dictionary.\n\nWhen you enter a new username, it checks it against the username in the MIDDLE of the list. That name is something like ManWithAModem. It compares the username to this and asks “is this the same name?” If so, reject. It probably isn't, so then it asks “does this new username come alphabetically before or after this username?”\n\nIf it comes before, then it knows that all 4 million+ names after this in the list can't possibly be a match, so it has now eliminated 4 million+ possibilities in a single comparison. If it comes after, then it knows that all 4 million+ names before this in the list can't be a match. In either case, we’ve ruled out an entire half of the list after only one comparison - and all because we sorted the list!\n\nNext, we take the remaining half of the list that we didn't eliminate, look at the username in the middle of THAT list, and compare it to our new username. Once again, if it isn't a perfect match (i.e. found that it's already in use), we can tell whether a match (if it exists) sits before or after that point in the sorted list. And as we did earlier, we again have eliminated another half of the entire remaining possibilities.\n\nBy cutting the list in half every time we do a comparison, we can winnow down the list of 8 million+ usernames quite quickly. How quickly?\n\nThe answer is “how many times do you need to divide 8 million by 2 until the result is less than 1?” We are trying to cut the segments of the sorted list in half until things get small enough that we’ve gotten down to two usernames which are right next to each other, and then we can compare the new username to each one and if it matches one of them, then the username is already in use; if not, then it's a valid new username.\n\nWell, the answer to that question is 23 times.\n\nThat's all. Because we kept the usernames in a sorted list, we only had to do at most 23 comparisons to verify that the new proposed username doesn't exist already. That's much, much faster than 8 million comparisons.\n\nIf you want to know more, you can read the other answers here, which explain how this sorted list is called an “index” and that this type of search and comparison process (or something similar to it) is often provided within the database in which the usernames are stored, plus other specifics."", 'result': {'fake': 0.0108, 'real': 0.9892}, 'status': 'success'}], 'credits_used': 6, 'credits': 1986549, 'subscription': 0, 'content': ""There are a lot of good answers here. In honor of Reddit, I will give the highly simplified ELI5 version accessible to a layman without reference to programming or computer science concepts.\n\nThe first key trick is that Reddit stores all of the usernames in a sorted, alphabetized list. That means the list of usernames looks like a, aa, aaa, aaab, … xyzzyz, yishan, zz, zztop. It's a big list of usernames, 8 million-some long. It's laid out in an alphabetized list like the words in a dictionary.\n\nWhen you enter a new username, it checks it against the username in the MIDDLE of the list. That name is something like ManWithAModem. It compares the username to this and asks “is this the same name?” If so, reject. It probably isn't, so then it asks “does this new username come alphabetically before or after this username?”\n\nIf it comes before, then it knows that all 4 million+ names after this in the list can't possibly be a match, so it has now eliminated 4 million+ possibilities in a single comparison. If it comes after, then it knows that all 4 million+ names before this in the list can't be a match. In either case, we’ve ruled out an entire half of the list after only one comparison - and all because we sorted the list!\n\nNext, we take the remaining half of the list that we didn't eliminate, look at the username in the middle of THAT list, and compare it to our new username. Once again, if it isn't a perfect match (i.e. found that it's already in use), we can tell whether a match (if it exists) sits before or after that point in the sorted list. And as we did earlier, we again have eliminated another half of the entire remaining possibilities.\n\nBy cutting the list in half every time we do a comparison, we can winnow down the list of 8 million+ usernames quite quickly. How quickly?\n\nThe answer is “how many times do you need to divide 8 million by 2 until the result is less than 1?” We are trying to cut the segments of the sorted list in half until things get small enough that we’ve gotten down to two usernames which are right next to each other, and then we can compare the new username to each one and if it matches one of them, then the username is already in use; if not, then it's a valid new username.\n\nWell, the answer to that question is 23 times.\n\nThat's all. Because we kept the usernames in a sorted list, we only had to do at most 23 comparisons to verify that the new proposed username doesn't exist already. That's much, much faster than 8 million comparisons.\n\nIf you want to know more, you can read the other answers here, which explain how this sorted list is called an “index” and that this type of search and comparison process (or something similar to it) is often provided within the database in which the usernames are stored, plus other specifics."", 'aiModelVersion': '1'}",0.4094
Vidhya Sagar,Updated 4y,How long does it take to master algorithms and data structures to get a job at Amazon as SDE?,"I was working with TCS for 2.5 years. So if you are a fresher you might be able to crack it in lesser time.

Here is my Experience,

I started my preparation on Jan 10′th of 2019. I did not do much coding in college as i was from a circuit branch. I picked Python in the beginning, as it gave me the felxibility to just think about the logic and not that much about the syntax.

It took a months time to get myself comfortable with loops, variables, scope, storage classes, primitive data types, condition based branching and some basic problems about array’s and strings .

Then i took time to get myself used to Data structures like Linked list, hash map, Binary Tree’s, BST, DP, Backtracking, Greedy Algorithms, Heaps .

All these topics are complex and a lot of times you would feel dumb and useless when you see a new question. It took 6 months for me to not feel scared when i see a new question and see the patterns for these questions. So It was August.

Then i started leetcode grinding, solved problems, everyday. Daily one problem in the morning before i went to work , another problem after i come home. I could see myself getting better at these problems, and i gained confidence every day. I also got myself used to some basic CS fundamentals like Computer Networks, OS and DBMS and this took up two more months . So it came up to November.

And I vividly remember DEC 4 there was a Amazon SDE off campus drive which happened and i had 6 rounds ( 1 online test , followed by 4 rounds, 1 bar raiser round). I remember Acing every question and i was finally told that i am hired after the bar raiser round. I was in tears of joy, because it took a year’s effort for me. Again I was working and i learn things slowly. You might be able to complete it earlier.

There are some paid resources that would help you fast track the learning. But if you learn it the hard way, then you won’t forget it and that will be shown in the interview .

Try practicing problems in white board as you go along.

Note down why your approach did not work and note down why the right approach is working.

Revise everyday . You will be bogged down with information everyday so it is always good to make notes.

Thanks.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/djemgut2n7ask4ib', 'title': 'How long does it take to master algorithms and data structures to get a job at Amazon as SDE?', 'score': {'original': 0.9998, 'ai': 0.0002}, 'blocks': [{'text': 'I was working with TCS for 2.5 years. So if you are a fresher you might be able to crack it in lesser time.\n\nHere is my Experience,\n\nI started my preparation on Jan 10′th of 2019. I did not do much coding in college as i was from a circuit branch. I picked Python in the beginning, as it gave me the felxibility to just think about the logic and not that much about the syntax.\n\nIt took a months time to get myself comfortable with loops, variables, scope, storage classes, primitive data types, condition based branching and some basic problems about array’s and strings .\n\nThen i took time to get myself used to Data structures like Linked list, hash map, Binary Tree’s, BST, DP, Backtracking, Greedy Algorithms, Heaps .\n\nAll these topics are complex and a lot of times you would feel dumb and useless when you see a new question. It took 6 months for me to not feel scared when i see a new question and see the patterns for these questions. So It was August.\n\nThen i started leetcode grinding, solved problems, everyday. Daily one problem in the morning before i went to work , another problem after i come home. I could see myself getting better at these problems, and i gained confidence every day. I also got myself used to some basic CS fundamentals like Computer Networks, OS and DBMS and this took up two more months . So it came up to November.\n\nAnd I vividly remember DEC 4 there was a Amazon SDE off campus drive which happened and i had 6 rounds ( 1 online test , followed by 4 rounds, 1 bar raiser round). I remember Acing every question and i was finally told that i am hired after the bar raiser round. I was in tears of joy, because it took a year’s effort for me. Again I was working and i learn things slowly. You might be able to complete it earlier.\n\nThere are some paid resources that would help you fast track the learning. But if you learn it the hard way, then you won’t forget it and that will be shown in the interview .\n\nTry practicing problems in white board as you go along.\n\nNote down why your approach did not work and note down why the right approach is working.\n\nRevise everyday . You will be bogged down with information everyday so it is always good to make notes.\n\nThanks.', 'result': {'fake': 0.0002, 'real': 0.9998}, 'status': 'success'}], 'credits_used': 5, 'credits': 1986544, 'subscription': 0, 'content': 'I was working with TCS for 2.5 years. So if you are a fresher you might be able to crack it in lesser time.\n\nHere is my Experience,\n\nI started my preparation on Jan 10′th of 2019. I did not do much coding in college as i was from a circuit branch. I picked Python in the beginning, as it gave me the felxibility to just think about the logic and not that much about the syntax.\n\nIt took a months time to get myself comfortable with loops, variables, scope, storage classes, primitive data types, condition based branching and some basic problems about array’s and strings .\n\nThen i took time to get myself used to Data structures like Linked list, hash map, Binary Tree’s, BST, DP, Backtracking, Greedy Algorithms, Heaps .\n\nAll these topics are complex and a lot of times you would feel dumb and useless when you see a new question. It took 6 months for me to not feel scared when i see a new question and see the patterns for these questions. So It was August.\n\nThen i started leetcode grinding, solved problems, everyday. Daily one problem in the morning before i went to work , another problem after i come home. I could see myself getting better at these problems, and i gained confidence every day. I also got myself used to some basic CS fundamentals like Computer Networks, OS and DBMS and this took up two more months . So it came up to November.\n\nAnd I vividly remember DEC 4 there was a Amazon SDE off campus drive which happened and i had 6 rounds ( 1 online test , followed by 4 rounds, 1 bar raiser round). I remember Acing every question and i was finally told that i am hired after the bar raiser round. I was in tears of joy, because it took a year’s effort for me. Again I was working and i learn things slowly. You might be able to complete it earlier.\n\nThere are some paid resources that would help you fast track the learning. But if you learn it the hard way, then you won’t forget it and that will be shown in the interview .\n\nTry practicing problems in white board as you go along.\n\nNote down why your approach did not work and note down why the right approach is working.\n\nRevise everyday . You will be bogged down with information everyday so it is always good to make notes.\n\nThanks.', 'aiModelVersion': '1'}",0.9998
Alon Amit,6y,What all do I need to know about Big O notation?,"This is a pretty terrible video. (For the record, it’s here. I won’t spend too much time tearing it apart but it’s shallow, misleading, and occasionally plain wrong. It doesn’t even provide the definition of big O!). How much you need to know about big O notation I can't tell – my mom doesn't know anything about it and she's a reasonably happy and accomplished person. However, if you want to understand how the growth of functions is being studied, including for the analysis of algorithms, then you should find other sources to learn this from, not this YouTube video. “Knowing” something is never about merely being able to recite the definition. I will give you the definition of big O in a moment, and it's fairly short and clear. In a formal sense, this is all you need to know: everything else can be derived from it. In reality, however, learning to use, apply and play with big O notation takes practice, patience and time. Never, ever, ever expect to know “everything you need to know” about a substantial topic from 5-minute videos on YouTube. Structure your learning around depth of understanding, not pathetic shortcuts. You’ll know all you need to know about big O notation when you can efficiently and consistently solve problems associated with it, not when you’ve watched a video or read an answer on Quora.Ok. Big O notation means this: we have two functions f(n)f(n)f(n) and g(n)g(n)g(n), taking a natural number nnn as input and returning values in real numbers (this can all be generalized further, but never mind now). We say that f(n)=O(g(n))f(n)=O(g(n))f(n)=O(g(n)) if the following conditions are met: there's some “threshold” value n0n0n_0, and some proportionality constant CCC, and |f(n)|≤C|f(n)|≤C|f(n)| \leq C |g(n)|g(n)|g(n)| whenever n≥n0n≥n0n\geq n_0. In words: f(n)f(n)f(n) is big O of g(n)g(n)g(n) if g(n)g(n)g(n), perhaps multiplied by something, is eventually larger than f(n)f(n)f(n), looking at absolute values if necessary. That's all. This is the cold, formal definition, and like I said in some sense this is all you need. But you may feel that the definition is opaque and confusing, and this is fine if you've never seen it before. The hard work is coming to terms with what it means, why it's built that way, and how to use it.The usage of big O notation is extended to allow for O(g(n))O(g(n))O(g(n)) to show up more flexibly in expressions, equations and inequalities. For example, n2+O(log(n))n2+O(log⁡(n))n^2+O(\log(n)) denotes a function that has the form n2+f(n)n2+f(n)n^2+f(n) where f(n)=O(log(n))f(n)=O(log⁡(n))f(n)=O(\log(n)). We don’t specify f(n)f(n)f(n) and we don’t even bother giving it a name: all we care about is that it is O(log(n))O(log⁡(n))O(\log(n)). In this way you find, for example, statements like log(n!)=nlog(n)−n+O(log(n))log⁡(n!)=nlog⁡(n)−n+O(log⁡(n))\log(n!)=n\log(n)-n+O(\log(n)) which expresses the fact that log(n!)log⁡(n!)\log(n!) is dominated by the term nlog(n)nlog⁡(n)n\log(n), and the next most meaningful contribution is a −n−n-n term, and then there’s some leftovers that are less than log(n)log⁡(n)\log(n). This is a great way of understanding Stirling’s approximation.You may have noticed that the word “algorithm” is nowhere to be found in the definition. Big O notation is very useful in the analysis of algorithms, but it's also fantastically useful in a hundred of other contexts. It was invented long before anyone thought about algorithmic complexity, by people (Bachmann, Landau) who studied analytic number theory. We’re talking late 19th century here. Now, why this definition? The purpose of the big O notation is to help us study the growth of functions. When analyzing expressions in combinatorics, number theory, complexity theory, complex analysis and elsewhere it’s very often important to understand who’s going to win eventually, and by how much. For example, if you compare the functions 10n10n10^n and n!n!n!, you may find that initially, 10n10n10^n is way bigger. Check the values of those functions at n=1,2,3,4,5n=1,2,3,4,5n=1,2,3,4,5 and even n=10n=10n=10; what do you see? It seems that 10n10n10^n is winning handily.n=1: 10 vs 1 n=2: 100 vs 2 n=3: 1000 vs 6 n=4: 10,000 vs 24 n=5: 100,000 vs 120 n=10: 10,000,000,000 vs 3,628,800 However, this is misleading. As nnn continues to grow, n!n!n! catches up and eventually surpasses 10n10n10^n. When n=24n=24n=24, 10n10n10^n is about 60% larger than 24!24!24!, but at n=25n=25n=25 it is 36% smaller, and things quickly escalate from there. In fact, once n>24n>24n>24, 10n10n10^n never again wins over n!n!n!. To put it simply: 10n=O(n!)10n=O(n!)10^n = O(n!) This is just a short way of saying “n!n!n! eventually exceeds 10n10n10^n”. The role of n0n0n_0 in the definition is to let us ignore the haphazard behavior of small numbers; we don’t care what happens earlier than n=25n=25n=25, or n=100n=100n=100, or n=10100n=10100n=10^{100}. This may seem strange: for practical purposes, small values of nnn matter more than ridiculously large ones. Nevertheless it was found to be crucial to understand the eventual behavior. The role of the constant CCC in the definition is to let us stop worrying about simple multiplicative constants. As far as big O behavior is concerned, 5n2=O(10n2)5n2=O(10n2)5n^2 = O(10n^2) and also 10n2=O(5n2)10n2=O(5n2)10n^2 = O(5n^2) and both of these are O(n2)O(n2)O(n^2). It’s just convenient, in many contexts, not to have to keep carrying those coefficients around. However, this only goes for multiplicative constants! There’s definitely a difference between n1.8n1.8n^{1.8} and n2n2n^2, even though they only differ in “the constants”. WARNING: There’s a fairly common confusion with the way big O is used in practice. People tend to say “this or that is O(n3)O(n3)O(n^3)"" when they really mean to say that this or that is Θ(n3)Θ(n3)\Theta(n^3), which means that it’s O(n3)O(n3)O(n^3) as well as Ω(n3)Ω(n3)\Omega(n^3). This means that a lot of people give you a look when you say “n2+5=O(n4)n2+5=O(n4)n^2+5=O(n^4)"", even though that’s perfectly correct. Put simply, people really like specifying a more precise asymptotic behavior, but they mostly use the wrong term for that (big O instead of big ΘΘ\Theta). Just be aware.To check your understanding, solve these problems:Is n2−100n−20=O(n1.9)n2−100n−20=O(n1.9)n^2-100n-20=O(n^{1.9})?Is n2+2n+2=O(n3)n2+2n+2=O(n3)n^2+2n+2=O(n^3)?Is n2+2n+2=O((n−1)2)n2+2n+2=O((n−1)2)n^2+2n+2=O((n-1)^2)?Is n2=O(n2−5n+1)n2=O(n2−5n+1)n^2=O(n^2-5n+1)?Is log(n)=O(n0.01)log⁡(n)=O(n0.01)\log(n)=O(n^{0.01})?For which numbers ccc is it true that log(n)=O(nc)log⁡(n)=O(nc)\log(n)=O(n^c)?What does f(n)=O(1)f(n)=O(1)f(n)=O(1) mean? How would you summarize it in words?What does 1=O(f(n))1=O(f(n))1=O(f(n)) mean? How would you summarize it in words?If f(n)=O(g(n))f(n)=O(g(n))f(n)=O(g(n)) and g(n)=O(f(n))g(n)=O(f(n))g(n)=O(f(n)), does it follow that f(n)/g(n)→1f(n)/g(n)→1f(n)/g(n)\to 1  as n→∞n→∞n\to\infty? If so, prove it. If not, find a counterexample.If f(n)=O(n2+ϵ)f(n)=O(n2+ϵ)f(n)=O(n^{2+\epsilon}) for every ϵ>0ϵ>0\epsilon>0, does it follow that f(n)=O(n2)f(n)=O(n2)f(n)=O(n^2)? If so, prove it. If not, find a counterexample.Find a way to arrange the following functions in a sequence where every one is O()O()O() the next one. Indicate which pairs in your sequence can be flipped around, and which ones can’t: 2n,n2,n3,nlog(n),2n,n2,n3,nlog⁡(n),2^n,n^2,n^3,n\log(n), 4+5/n,log2(n),log(n)log(log(n)),4+5/n,log2⁡(n),log⁡(n)log⁡(log⁡(n)),4+5/n,\log^2(n),\log(n)\log(\log(n)), log(n!),n!,log⁡(n!),n!,\log(n!),n!, log∗log∗\log^*(n),nlog∗(n),nlog(n),23log(n),5log(n)loglog(n)(n),nlog∗⁡(n),nlog⁡(n),23log⁡(n),5log⁡(n)log⁡log⁡(n)(n),n\log^*(n),n^{\log(n)},2^{3\log(n)},5^{\log(n)\log\log(n)}.If you’ve done all these and are completely comfortable with your work, you’re beginning to understand the idea of big O. You still don’t know all there is to know about it, of course, but that’s quite alright.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/fdb4286molh0neuj', 'title': 'What all do I need to know about Big O notation?', 'score': {'original': 0.73733333333333, 'ai': 0.26266666666667}, 'blocks': [{'text': ""This is a pretty terrible video. (For the record, it’s here. I won’t spend too much time tearing it apart but it’s shallow, misleading, and occasionally plain wrong. It doesn’t even provide the definition of big O!). How much you need to know about big O notation I can't tell – my mom doesn't know anything about it and she's a reasonably happy and accomplished person. However, if you want to understand how the growth of functions is being studied, including for the analysis of algorithms, then you should find other sources to learn this from, not this YouTube video. “Knowing” something is never about merely being able to recite the definition. I will give you the definition of big O in a moment, and it's fairly short and clear. In a formal sense, this is all you need to know: everything else can be derived from it. In reality, however, learning to use, apply and play with big O notation takes practice, patience and time. Never, ever, ever expect to know “everything you need to know” about a substantial topic from 5-minute videos on YouTube. Structure your learning around depth of understanding, not pathetic shortcuts. You’ll know all you need to know about big O notation when you can efficiently and consistently solve problems associated with it, not when you’ve watched a video or read an answer on Quora.Ok. Big O notation means this: we have two functions f(n)f(n)f(n) and g(n)g(n)g(n), taking a natural number nnn as input and returning values in real numbers (this can all be generalized further, but never mind now). We say that f(n)=O(g(n))f(n)=O(g(n))f(n)=O(g(n)) if the following conditions are met: there's some “threshold” value n0n0n_0, and some proportionality constant CCC, and |f(n)|≤C|f(n)|≤C|f(n)| \\leq C |g(n)|g(n)|g(n)| whenever n≥n0n≥n0n\\geq n_0. In words: f(n)f(n)f(n) is big O of g(n)g(n)g(n) if g(n)g(n)g(n), perhaps multiplied by something, is eventually larger than f(n)f(n)f(n), looking at absolute values if necessary. That's all. This is the cold, formal definition, and like I said in some sense this is all you need. But you may feel that the definition is opaque and confusing, and this is fine if you've never seen it before. The hard work is coming to terms with what it means, why it's built that way, and how to use it.The usage of big O notation is extended to allow for O(g(n))O(g(n))O(g(n)) to show up more flexibly in expressions, equations and inequalities. For example, n2+O(log(n))n2+O(log\u2061(n))n^2+O(\\log(n)) denotes a function that has the form n2+f(n)n2+f(n)n^2+f(n) where f(n)=O(log(n))f(n)=O(log\u2061(n))f(n)=O(\\log(n)). We don’t specify f(n)f(n)f(n) and we don’t even bother giving it a name: all we care about is that it is O(log(n))O(log\u2061(n))O(\\log(n)). In this way you find, for example, statements like log(n!)=nlog(n)−n+O(log(n))log\u2061(n!)=nlog\u2061(n)−n+O(log\u2061(n))\\log(n!)=n\\log(n)-n+O(\\log(n)) which expresses the fact that log(n!)log\u2061(n!)\\log(n!) is dominated by the term nlog(n)nlog\u2061(n)n\\log(n), and the next most meaningful contribution is a −n−n-n term, and then there’s some leftovers that are less than log(n)log\u2061(n)\\log(n). This is a great way of understanding Stirling’s approximation.You may have noticed that the word “algorithm” is nowhere to be found in the definition. Big O notation is very useful in the analysis of"", 'result': {'fake': 0.0448, 'real': 0.9552}, 'status': 'success'}, {'text': 'algorithms, but it\'s also fantastically useful in a hundred of other contexts. It was invented long before anyone thought about algorithmic complexity, by people (Bachmann, Landau) who studied analytic number theory. We’re talking late 19th century here. Now, why this definition? The purpose of the big O notation is to help us study the growth of functions. When analyzing expressions in combinatorics, number theory, complexity theory, complex analysis and elsewhere it’s very often important to understand who’s going to win eventually, and by how much. For example, if you compare the functions 10n10n10^n and n!n!n!, you may find that initially, 10n10n10^n is way bigger. Check the values of those functions at n=1,2,3,4,5n=1,2,3,4,5n=1,2,3,4,5 and even n=10n=10n=10; what do you see? It seems that 10n10n10^n is winning handily.n=1: 10 vs 1\xa0n=2: 100 vs 2\xa0n=3: 1000 vs 6\xa0n=4: 10,000 vs 24\xa0n=5: 100,000 vs 120\xa0n=10: 10,000,000,000 vs 3,628,800\xa0However, this is misleading. As nnn continues to grow, n!n!n! catches up and eventually surpasses 10n10n10^n. When n=24n=24n=24, 10n10n10^n is about 60% larger than 24!24!24!, but at n=25n=25n=25 it is 36% smaller, and things quickly escalate from there. In fact, once n>24n>24n>24, 10n10n10^n never again wins over n!n!n!. To put it simply: 10n=O(n!)10n=O(n!)10^n = O(n!) This is just a short way of saying “n!n!n! eventually exceeds 10n10n10^n”. The role of n0n0n_0 in the definition is to let us ignore the haphazard behavior of small numbers; we don’t care what happens earlier than n=25n=25n=25, or n=100n=100n=100, or n=10100n=10100n=10^{100}. This may seem strange: for practical purposes, small values of nnn matter more than ridiculously large ones. Nevertheless it was found to be crucial to understand the eventual behavior. The role of the constant CCC in the definition is to let us stop worrying about simple multiplicative constants. As far as big O behavior is concerned, 5n2=O(10n2)5n2=O(10n2)5n^2 = O(10n^2) and also 10n2=O(5n2)10n2=O(5n2)10n^2 = O(5n^2) and both of these are O(n2)O(n2)O(n^2). It’s just convenient, in many contexts, not to have to keep carrying those coefficients around. However, this only goes for multiplicative constants! There’s definitely a difference between n1.8n1.8n^{1.8} and n2n2n^2, even though they only differ in “the constants”. WARNING: There’s a fairly common confusion with the way big O is used in practice. People tend to say “this or that is O(n3)O(n3)O(n^3)"" when they really mean to say that this or that is Θ(n3)Θ(n3)\\Theta(n^3), which means that it’s O(n3)O(n3)O(n^3) as well as Ω(n3)Ω(n3)\\Omega(n^3). This means that a lot of people give you a look when you say “n2+5=O(n4)n2+5=O(n4)n^2+5=O(n^4)"", even though that’s perfectly correct. Put simply, people really like specifying a more precise asymptotic behavior, but they mostly use the wrong term for that (big O instead of big ΘΘ\\Theta). Just be aware.To check your understanding, solve these problems:Is n2−100n−20=O(n1.9)n2−100n−20=O(n1.9)n^2-100n-20=O(n^{1.9})?Is n2+2n+2=O(n3)n2+2n+2=O(n3)n^2+2n+2=O(n^3)?Is n2+2n+2=O((n−1)2)n2+2n+2=O((n−1)2)n^2+2n+2=O((n-1)^2)?Is n2=O(n2−5n+1)n2=O(n2−5n+1)n^2=O(n^2-5n+1)?Is log(n)=O(n0.01)log\u2061(n)=O(n0.01)\\log(n)=O(n^{0.01})?For which numbers ccc is it true that log(n)=O(nc)log\u2061(n)=O(nc)\\log(n)=O(n^c)?What does f(n)=O(1)f(n)=O(1)f(n)=O(1) mean? How would you summarize it in words?What does 1=O(f(n))1=O(f(n))1=O(f(n)) mean? How would you summarize it in words?If f(n)=O(g(n))f(n)=O(g(n))f(n)=O(g(n)) and g(n)=O(f(n))g(n)=O(f(n))g(n)=O(f(n)), does it follow that f(n)/g(n)→1f(n)/g(n)→1f(n)/g(n)\\to 1  as n→∞n→∞n\\to\\infty? If so, prove it. If not, find a counterexample.If f(n)=O(n2+ϵ)f(n)=O(n2+ϵ)f(n)=O(n^{2+\\epsilon}) for every ϵ>0ϵ>0\\epsilon>0, does it follow that f(n)=O(n2)f(n)=O(n2)f(n)=O(n^2)? If', 'result': {'fake': 0.0454, 'real': 0.9546}, 'status': 'success'}, {'text': 'so, prove it. If not, find a counterexample.Find a way to arrange the following functions in a sequence where every one is O()O()O() the next one. Indicate which pairs in your sequence can be flipped around, and which ones can’t: 2n,n2,n3,nlog(n),2n,n2,n3,nlog\u2061(n),2^n,n^2,n^3,n\\log(n), 4+5/n,log2(n),log(n)log(log(n)),4+5/n,log2\u2061(n),log\u2061(n)log\u2061(log\u2061(n)),4+5/n,\\log^2(n),\\log(n)\\log(\\log(n)), log(n!),n!,log\u2061(n!),n!,\\log(n!),n!, log∗log∗\\log^*(n),nlog∗(n),nlog(n),23log(n),5log(n)loglog(n)(n),nlog∗\u2061(n),nlog\u2061(n),23log\u2061(n),5log\u2061(n)log\u2061log\u2061(n)(n),n\\log^*(n),n^{\\log(n)},2^{3\\log(n)},5^{\\log(n)\\log\\log(n)}.If you’ve done all these and are completely comfortable with your work, you’re beginning to understand the idea of big O. You still don’t know all there is to know about it, of course, but that’s quite alright.', 'result': {'fake': 0.5956, 'real': 0.4044}, 'status': 'success'}], 'credits_used': 17, 'credits': 1986527, 'subscription': 0, 'content': 'This is a pretty terrible video. (For the record, it’s here. I won’t spend too much time tearing it apart but it’s shallow, misleading, and occasionally plain wrong. It doesn’t even provide the definition of big O!). How much you need to know about big O notation I can\'t tell – my mom doesn\'t know anything about it and she\'s a reasonably happy and accomplished person. However, if you want to understand how the growth of functions is being studied, including for the analysis of algorithms, then you should find other sources to learn this from, not this YouTube video. “Knowing” something is never about merely being able to recite the definition. I will give you the definition of big O in a moment, and it\'s fairly short and clear. In a formal sense, this is all you need to know: everything else can be derived from it. In reality, however, learning to use, apply and play with big O notation takes practice, patience and time. Never, ever, ever expect to know “everything you need to know” about a substantial topic from 5-minute videos on YouTube. Structure your learning around depth of understanding, not pathetic shortcuts. You’ll know all you need to know about big O notation when you can efficiently and consistently solve problems associated with it, not when you’ve watched a video or read an answer on Quora.Ok. Big O notation means this: we have two functions f(n)f(n)f(n) and g(n)g(n)g(n), taking a natural number nnn as input and returning values in real numbers (this can all be generalized further, but never mind now). We say that f(n)=O(g(n))f(n)=O(g(n))f(n)=O(g(n)) if the following conditions are met: there\'s some “threshold” value n0n0n_0, and some proportionality constant CCC, and |f(n)|≤C|f(n)|≤C|f(n)| \\leq C |g(n)|g(n)|g(n)| whenever n≥n0n≥n0n\\geq n_0. In words: f(n)f(n)f(n) is big O of g(n)g(n)g(n) if g(n)g(n)g(n), perhaps multiplied by something, is eventually larger than f(n)f(n)f(n), looking at absolute values if necessary. That\'s all. This is the cold, formal definition, and like I said in some sense this is all you need. But you may feel that the definition is opaque and confusing, and this is fine if you\'ve never seen it before. The hard work is coming to terms with what it means, why it\'s built that way, and how to use it.The usage of big O notation is extended to allow for O(g(n))O(g(n))O(g(n)) to show up more flexibly in expressions, equations and inequalities. For example, n2+O(log(n))n2+O(log\u2061(n))n^2+O(\\log(n)) denotes a function that has the form n2+f(n)n2+f(n)n^2+f(n) where f(n)=O(log(n))f(n)=O(log\u2061(n))f(n)=O(\\log(n)). We don’t specify f(n)f(n)f(n) and we don’t even bother giving it a name: all we care about is that it is O(log(n))O(log\u2061(n))O(\\log(n)). In this way you find, for example, statements like log(n!)=nlog(n)−n+O(log(n))log\u2061(n!)=nlog\u2061(n)−n+O(log\u2061(n))\\log(n!)=n\\log(n)-n+O(\\log(n)) which expresses the fact that log(n!)log\u2061(n!)\\log(n!) is dominated by the term nlog(n)nlog\u2061(n)n\\log(n), and the next most meaningful contribution is a −n−n-n term, and then there’s some leftovers that are less than log(n)log\u2061(n)\\log(n). This is a great way of understanding Stirling’s approximation.You may have noticed that the word “algorithm” is nowhere to be found in the definition. Big O notation is very useful in the analysis of algorithms, but it\'s also fantastically useful in a hundred of other contexts. It was invented long before anyone thought about algorithmic complexity, by people (Bachmann, Landau) who studied analytic number theory. We’re talking late 19th century here. Now, why this definition? The purpose of the big O notation is to help us study the growth of functions. When analyzing expressions in combinatorics, number theory, complexity theory, complex analysis and elsewhere it’s very often important to understand who’s going to win eventually, and by how much. For example, if you compare the functions 10n10n10^n and n!n!n!, you may find that initially, 10n10n10^n is way bigger. Check the values of those functions at n=1,2,3,4,5n=1,2,3,4,5n=1,2,3,4,5 and even n=10n=10n=10; what do you see? It seems that 10n10n10^n is winning handily.n=1: 10 vs 1\xa0n=2: 100 vs 2\xa0n=3: 1000 vs 6\xa0n=4: 10,000 vs 24\xa0n=5: 100,000 vs 120\xa0n=10: 10,000,000,000 vs 3,628,800\xa0However, this is misleading. As nnn continues to grow, n!n!n! catches up and eventually surpasses 10n10n10^n. When n=24n=24n=24, 10n10n10^n is about 60% larger than 24!24!24!, but at n=25n=25n=25 it is 36% smaller, and things quickly escalate from there. In fact, once n>24n>24n>24, 10n10n10^n never again wins over n!n!n!. To put it simply: 10n=O(n!)10n=O(n!)10^n = O(n!) This is just a short way of saying “n!n!n! eventually exceeds 10n10n10^n”. The role of n0n0n_0 in the definition is to let us ignore the haphazard behavior of small numbers; we don’t care what happens earlier than n=25n=25n=25, or n=100n=100n=100, or n=10100n=10100n=10^{100}. This may seem strange: for practical purposes, small values of nnn matter more than ridiculously large ones. Nevertheless it was found to be crucial to understand the eventual behavior. The role of the constant CCC in the definition is to let us stop worrying about simple multiplicative constants. As far as big O behavior is concerned, 5n2=O(10n2)5n2=O(10n2)5n^2 = O(10n^2) and also 10n2=O(5n2)10n2=O(5n2)10n^2 = O(5n^2) and both of these are O(n2)O(n2)O(n^2). It’s just convenient, in many contexts, not to have to keep carrying those coefficients around. However, this only goes for multiplicative constants! There’s definitely a difference between n1.8n1.8n^{1.8} and n2n2n^2, even though they only differ in “the constants”. WARNING: There’s a fairly common confusion with the way big O is used in practice. People tend to say “this or that is O(n3)O(n3)O(n^3)"" when they really mean to say that this or that is Θ(n3)Θ(n3)\\Theta(n^3), which means that it’s O(n3)O(n3)O(n^3) as well as Ω(n3)Ω(n3)\\Omega(n^3). This means that a lot of people give you a look when you say “n2+5=O(n4)n2+5=O(n4)n^2+5=O(n^4)"", even though that’s perfectly correct. Put simply, people really like specifying a more precise asymptotic behavior, but they mostly use the wrong term for that (big O instead of big ΘΘ\\Theta). Just be aware.To check your understanding, solve these problems:Is n2−100n−20=O(n1.9)n2−100n−20=O(n1.9)n^2-100n-20=O(n^{1.9})?Is n2+2n+2=O(n3)n2+2n+2=O(n3)n^2+2n+2=O(n^3)?Is n2+2n+2=O((n−1)2)n2+2n+2=O((n−1)2)n^2+2n+2=O((n-1)^2)?Is n2=O(n2−5n+1)n2=O(n2−5n+1)n^2=O(n^2-5n+1)?Is log(n)=O(n0.01)log\u2061(n)=O(n0.01)\\log(n)=O(n^{0.01})?For which numbers ccc is it true that log(n)=O(nc)log\u2061(n)=O(nc)\\log(n)=O(n^c)?What does f(n)=O(1)f(n)=O(1)f(n)=O(1) mean? How would you summarize it in words?What does 1=O(f(n))1=O(f(n))1=O(f(n)) mean? How would you summarize it in words?If f(n)=O(g(n))f(n)=O(g(n))f(n)=O(g(n)) and g(n)=O(f(n))g(n)=O(f(n))g(n)=O(f(n)), does it follow that f(n)/g(n)→1f(n)/g(n)→1f(n)/g(n)\\to 1  as n→∞n→∞n\\to\\infty? If so, prove it. If not, find a counterexample.If f(n)=O(n2+ϵ)f(n)=O(n2+ϵ)f(n)=O(n^{2+\\epsilon}) for every ϵ>0ϵ>0\\epsilon>0, does it follow that f(n)=O(n2)f(n)=O(n2)f(n)=O(n^2)? If so, prove it. If not, find a counterexample.Find a way to arrange the following functions in a sequence where every one is O()O()O() the next one. Indicate which pairs in your sequence can be flipped around, and which ones can’t: 2n,n2,n3,nlog(n),2n,n2,n3,nlog\u2061(n),2^n,n^2,n^3,n\\log(n), 4+5/n,log2(n),log(n)log(log(n)),4+5/n,log2\u2061(n),log\u2061(n)log\u2061(log\u2061(n)),4+5/n,\\log^2(n),\\log(n)\\log(\\log(n)), log(n!),n!,log\u2061(n!),n!,\\log(n!),n!, log∗log∗\\log^*(n),nlog∗(n),nlog(n),23log(n),5log(n)loglog(n)(n),nlog∗\u2061(n),nlog\u2061(n),23log\u2061(n),5log\u2061(n)log\u2061log\u2061(n)(n),n\\log^*(n),n^{\\log(n)},2^{3\\log(n)},5^{\\log(n)\\log\\log(n)}.If you’ve done all these and are completely comfortable with your work, you’re beginning to understand the idea of big O. You still don’t know all there is to know about it, of course, but that’s quite alright.', 'aiModelVersion': '1'}",0.73733333333333
Thomas Cormen,7y,"Is CLRS really an ""introduction""? If so, what's next?","Yes, Introduction to Algorithms really is an introductory text—on algorithms. It is not, and was never intended to be, an introductory text for computer science. We assume that the reader has some programming experience, including recursion, and knows how to read and write rigorous mathematical proofs. The discrete mathematics facts needed to analyze the algorithms in the book appear in the appendices.

As an algorithms text, it starts with insertion sort, one of the simplest of sorting algorithms. The algorithms and data structures covered in the first few sections are, for the most part, among the most basic. I think of the material in the first six parts of the book (except for the starred sections, which we consider graduate-level material) as part of the canon of computer science.

I understand that some people consider the book to be beyond introductory. We do go deeply into some material, and we pull no punches in the mathematics. From where the material starts, however, the book is most definitely an introduction.

What’s next? Don Knuth’s The Art of Computer Programming, which I consider the greatest books (it is a multi-volume set) computer science has ever had or ever will have.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/3pot8vr5if02xaew', 'title': 'Is CLRS really an ""introduction""? If so, what\'s next?', 'score': {'original': 0.9995, 'ai': 0.0005}, 'blocks': [{'text': 'Yes, Introduction to Algorithms really is an introductory text—on algorithms. It is not, and was never intended to be, an introductory text for computer science. We assume that the reader has some programming experience, including recursion, and knows how to read and write rigorous mathematical proofs. The discrete mathematics facts needed to analyze the algorithms in the book appear in the appendices.\n\nAs an algorithms text, it starts with insertion sort, one of the simplest of sorting algorithms. The algorithms and data structures covered in the first few sections are, for the most part, among the most basic. I think of the material in the first six parts of the book (except for the starred sections, which we consider graduate-level material) as part of the canon of computer science.\n\nI understand that some people consider the book to be beyond introductory. We do go deeply into some material, and we pull no punches in the mathematics. From where the material starts, however, the book is most definitely an introduction.\n\nWhat’s next? Don Knuth’s The Art of Computer Programming, which I consider the greatest books (it is a multi-volume set) computer science has ever had or ever will have.', 'result': {'fake': 0.0005, 'real': 0.9995}, 'status': 'success'}], 'credits_used': 3, 'credits': 1986524, 'subscription': 0, 'content': 'Yes, Introduction to Algorithms really is an introductory text—on algorithms. It is not, and was never intended to be, an introductory text for computer science. We assume that the reader has some programming experience, including recursion, and knows how to read and write rigorous mathematical proofs. The discrete mathematics facts needed to analyze the algorithms in the book appear in the appendices.\n\nAs an algorithms text, it starts with insertion sort, one of the simplest of sorting algorithms. The algorithms and data structures covered in the first few sections are, for the most part, among the most basic. I think of the material in the first six parts of the book (except for the starred sections, which we consider graduate-level material) as part of the canon of computer science.\n\nI understand that some people consider the book to be beyond introductory. We do go deeply into some material, and we pull no punches in the mathematics. From where the material starts, however, the book is most definitely an introduction.\n\nWhat’s next? Don Knuth’s The Art of Computer Programming, which I consider the greatest books (it is a multi-volume set) computer science has ever had or ever will have.', 'aiModelVersion': '1'}",0.9995
Alan Mellor,3y,"What would be my level at programming if I could solve all the problems of ""LeetCode""?","It would be of a kind I don’t really understand.

I’ve never written code as a puzzle. I’ve only ever written code as part of making a thing work. I’ve written games, embedded systems, software tools, half a word processor, banking and tax software, e-commerce.

Each thing brings its own set of challenges that need solving. Some I don’t know how to solve and have to figure it out.

I think the kinds of problems are different from those in coding katas and challenges.

So I wouldn’t know what to think.

Could you write a full application? I wouldn’t be able to know, I don’t think.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/sf5jo8xawk36plcv', 'title': 'What would be my level at programming if I could solve all the problems of ""LeetCode""?', 'score': {'original': 0.0835, 'ai': 0.9165}, 'blocks': [{'text': 'It would be of a kind I don’t really understand.\n\nI’ve never written code as a puzzle. I’ve only ever written code as part of making a thing work. I’ve written games, embedded systems, software tools, half a word processor, banking and tax software, e-commerce.\n\nEach thing brings its own set of challenges that need solving. Some I don’t know how to solve and have to figure it out.\n\nI think the kinds of problems are different from those in coding katas and challenges.\n\nSo I wouldn’t know what to think.\n\nCould you write a full application? I wouldn’t be able to know, I don’t think.', 'result': {'fake': 0.9165, 'real': 0.0835}, 'status': 'success'}], 'credits_used': 2, 'credits': 1986522, 'subscription': 0, 'content': 'It would be of a kind I don’t really understand.\n\nI’ve never written code as a puzzle. I’ve only ever written code as part of making a thing work. I’ve written games, embedded systems, software tools, half a word processor, banking and tax software, e-commerce.\n\nEach thing brings its own set of challenges that need solving. Some I don’t know how to solve and have to figure it out.\n\nI think the kinds of problems are different from those in coding katas and challenges.\n\nSo I wouldn’t know what to think.\n\nCould you write a full application? I wouldn’t be able to know, I don’t think.', 'aiModelVersion': '1'}",0.0835
Alon Amit,4y,If one had the product of all the prime numbers up to ,"There are several levels of wrong here. First, if you wish to keep stock of a bunch of prime numbers, “packing” them into their product is useless. It’s no more space-efficient than simply storing them individually, and for most purposes it’s substantially harder to extract them. Next, there are more primes up to 1050105010^{50} than you could store in any form in this measly universe of ours. Perhaps you think that 1051105110^{51} is just a bit more; it’s not: it’s ten times larger, so storing the primes up to 1051105110^{51} is wildly less reasonable than those up to 1050105010^{50}. And 1060106010^{60} is a billion times harder. What exactly do you think we can do with 1010000101000010^{10000}? Next, for the challenge of factoring large numbers, having a list of prime numbers is not useful in the least. If you wish to factor a 606060-digit number, which is quite feasible, the last thing you need is a list of all 303030-digit primes. And finally, cryptographic protocols based on the hardness of factorization rely on primes with far less than 1000 decimal digits, now and in the foreseeable future. There’s absolutely no need to go for 10,000 digits.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/ji94a75pel6d1snu', 'title': 'If one had the product of all the prime numbers up to', 'score': {'original': 0.9982, 'ai': 0.0018}, 'blocks': [{'text': 'There are several levels of wrong here. First, if you wish to keep stock of a bunch of prime numbers, “packing” them into their product is useless. It’s no more space-efficient than simply storing them individually, and for most purposes it’s substantially harder to extract them. Next, there are more primes up to 1050105010^{50} than you could store in any form in this measly universe of ours. Perhaps you think that 1051105110^{51} is just a bit more; it’s not: it’s ten times larger, so storing the primes up to 1051105110^{51} is wildly less reasonable than those up to 1050105010^{50}. And 1060106010^{60} is a billion times harder. What exactly do you think we can do with 1010000101000010^{10000}? Next, for the challenge of factoring large numbers, having a list of prime numbers is not useful in the least. If you wish to factor a 606060-digit number, which is quite feasible, the last thing you need is a list of all 303030-digit primes. And finally, cryptographic protocols based on the hardness of factorization rely on primes with far less than 1000 decimal digits, now and in the foreseeable future. There’s absolutely no need to go for 10,000 digits.', 'result': {'fake': 0.0018, 'real': 0.9982}, 'status': 'success'}], 'credits_used': 2, 'credits': 1986520, 'subscription': 0, 'content': 'There are several levels of wrong here. First, if you wish to keep stock of a bunch of prime numbers, “packing” them into their product is useless. It’s no more space-efficient than simply storing them individually, and for most purposes it’s substantially harder to extract them. Next, there are more primes up to 1050105010^{50} than you could store in any form in this measly universe of ours. Perhaps you think that 1051105110^{51} is just a bit more; it’s not: it’s ten times larger, so storing the primes up to 1051105110^{51} is wildly less reasonable than those up to 1050105010^{50}. And 1060106010^{60} is a billion times harder. What exactly do you think we can do with 1010000101000010^{10000}? Next, for the challenge of factoring large numbers, having a list of prime numbers is not useful in the least. If you wish to factor a 606060-digit number, which is quite feasible, the last thing you need is a list of all 303030-digit primes. And finally, cryptographic protocols based on the hardness of factorization rely on primes with far less than 1000 decimal digits, now and in the foreseeable future. There’s absolutely no need to go for 10,000 digits.', 'aiModelVersion': '1'}",0.9982
Alon Amit,Updated 2y,What common misunderstandings do people have about data structures and algorithms?,"Here are some more or less common misunderstandings and misconceptions:

The study of data structures and algorithms is only good for coding interviews and competitions. (In fact, while “Real world” coding has many aspects that aren’t data structures and algorithms, a deep understanding of data structures and algorithms is useful and practical in very real situations.)
“NP” means “non-polynomial”. (It doesn’t. It means “non-deterministic polynomial time”.)
NP problems are hard. (No, NP problems are easy. Problems not in NP are much harder.)
There’s a “best” algorithm for X. (There never is. There may be for particular instances of a problem, in particular circumstances, with clearly defined computational resources. This is never the case when such questions or assertions are made.)
Quantum computers are fast because they instantly check all possible combinations, like in parallel universes or something. (This is one of the most pervasive, consistent, utterly false misconceptions in the history of algorithms.)
Anything recursive is Dynamic Programming. (It’s not.)
My problem is NP-complete, so it’s hopeless. (it may be, but it may not. It depends on many things.)
SAT problems cannot be solved. (They sure can, and SAT solvers are incredibly useful in very practical, real-life situations.)
Sorting is 
O
(
n
log
n
)
O(nlog⁡n)
. (Sorting is an algorithmic task. Tasks aren’t 
O
O
 of anything. The time-complexity of a specific algorithm is a function of its input size 
n
n
, and we often approximate this function using big-Oh notation.)
Shorter programs are more efficient. (The correlation between performance and number of lines of code is very, very weak. A few lines of code can be horribly inefficient, or just mildly inefficient, compared with more lines that express a smarter algorithm.)
In machine learning, simpler models are better because Occam’s razor. (This may be true for two models that are otherwise equivalent, but if a more complex model is demonstrably more accurate, don’t automatically throw it away for a simpler and less accurate alternative. This is sometimes the right choice, but often it’s not.)
Governments are racing to build quantum computers because the first to succeed will be able to hack into any system it wants. (This was actually stated by several generally respectable news publications. It’s nonsense.)
Once we prove the Riemann Hypothesis, we’ll be able to factor numbers more efficiently, or find primes more efficiently, or break the internet. (No, No and No.)
I’m good at algorithms, but not so much at data structures. (No you’re not. The two are inexorably linked.)","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/neshgmuqvzd18p9c', 'title': 'What common misunderstandings do people have about data structures and algorithms?', 'score': {'original': 0.9992, 'ai': 0.0008}, 'blocks': [{'text': 'Here are some more or less common misunderstandings and misconceptions:\n\nThe study of data structures and algorithms is only good for coding interviews and competitions. (In fact, while “Real world” coding has many aspects that aren’t data structures and algorithms, a deep understanding of data structures and algorithms is useful and practical in very real situations.)\n“NP” means “non-polynomial”. (It doesn’t. It means “non-deterministic polynomial time”.)\nNP problems are hard. (No, NP problems are easy. Problems not in NP are much harder.)\nThere’s a “best” algorithm for X. (There never is. There may be for particular instances of a problem, in particular circumstances, with clearly defined computational resources. This is never the case when such questions or assertions are made.)\nQuantum computers are fast because they instantly check all possible combinations, like in parallel universes or something. (This is one of the most pervasive, consistent, utterly false misconceptions in the history of algorithms.)\nAnything recursive is Dynamic Programming. (It’s not.)\nMy problem is NP-complete, so it’s hopeless. (it may be, but it may not. It depends on many things.)\nSAT problems cannot be solved. (They sure can, and SAT solvers are incredibly useful in very practical, real-life situations.)\nSorting is \nO\n(\nn\nlog\nn\n)\nO(nlog\u2061n)\n. (Sorting is an algorithmic task. Tasks aren’t \nO\nO\n of anything. The time-complexity of a specific algorithm is a function of its input size \nn\nn\n, and we often approximate this function using big-Oh notation.)\nShorter programs are more efficient. (The correlation between performance and number of lines of code is very, very weak. A few lines of code can be horribly inefficient, or just mildly inefficient, compared with more lines that express a smarter algorithm.)\nIn machine learning, simpler models are better because Occam’s razor. (This may be true for two models that are otherwise equivalent, but if a more complex model is demonstrably more accurate, don’t automatically throw it away for a simpler and less accurate alternative. This is sometimes the right choice, but often it’s not.)\nGovernments are racing to build quantum computers because the first to succeed will be able to hack into any system it wants. (This was actually stated by several generally respectable news publications. It’s nonsense.)\nOnce we prove the Riemann Hypothesis, we’ll be able to factor numbers more efficiently, or find primes more efficiently, or break the internet. (No, No and No.)\nI’m good at algorithms, but not so much at data structures. (No you’re not. The two are inexorably linked.)', 'result': {'fake': 0.0008, 'real': 0.9992}, 'status': 'success'}], 'credits_used': 5, 'credits': 1986515, 'subscription': 0, 'content': 'Here are some more or less common misunderstandings and misconceptions:\n\nThe study of data structures and algorithms is only good for coding interviews and competitions. (In fact, while “Real world” coding has many aspects that aren’t data structures and algorithms, a deep understanding of data structures and algorithms is useful and practical in very real situations.)\n“NP” means “non-polynomial”. (It doesn’t. It means “non-deterministic polynomial time”.)\nNP problems are hard. (No, NP problems are easy. Problems not in NP are much harder.)\nThere’s a “best” algorithm for X. (There never is. There may be for particular instances of a problem, in particular circumstances, with clearly defined computational resources. This is never the case when such questions or assertions are made.)\nQuantum computers are fast because they instantly check all possible combinations, like in parallel universes or something. (This is one of the most pervasive, consistent, utterly false misconceptions in the history of algorithms.)\nAnything recursive is Dynamic Programming. (It’s not.)\nMy problem is NP-complete, so it’s hopeless. (it may be, but it may not. It depends on many things.)\nSAT problems cannot be solved. (They sure can, and SAT solvers are incredibly useful in very practical, real-life situations.)\nSorting is \nO\n(\nn\nlog\nn\n)\nO(nlog\u2061n)\n. (Sorting is an algorithmic task. Tasks aren’t \nO\nO\n of anything. The time-complexity of a specific algorithm is a function of its input size \nn\nn\n, and we often approximate this function using big-Oh notation.)\nShorter programs are more efficient. (The correlation between performance and number of lines of code is very, very weak. A few lines of code can be horribly inefficient, or just mildly inefficient, compared with more lines that express a smarter algorithm.)\nIn machine learning, simpler models are better because Occam’s razor. (This may be true for two models that are otherwise equivalent, but if a more complex model is demonstrably more accurate, don’t automatically throw it away for a simpler and less accurate alternative. This is sometimes the right choice, but often it’s not.)\nGovernments are racing to build quantum computers because the first to succeed will be able to hack into any system it wants. (This was actually stated by several generally respectable news publications. It’s nonsense.)\nOnce we prove the Riemann Hypothesis, we’ll be able to factor numbers more efficiently, or find primes more efficiently, or break the internet. (No, No and No.)\nI’m good at algorithms, but not so much at data structures. (No you’re not. The two are inexorably linked.)', 'aiModelVersion': '1'}",0.9992
Jan Christian Meyer,Updated 10y,How does 'grep' preprocess a text file for efficient regular expression matching?,"I don't think grep does any preprocessing of the input file; it certainly doesn't have to, regular expression matching is pretty efficient as it is.

Instead of sifting through all the world's different grep implementations looking for evidence of preprocessing that probably isn't there, though, I will argue this with a small experiment for illustration, because I think it's more fun than just saying that expression matching works in linear time.

We can try matching a regular expression without grep, so just grab a copy of the collected works of Shakespeare:


# I'm going to do everything in a somewhat UNIX-y way throughout 
% wget http://www.gutenberg.org/ebooks/100.txt.utf-8 

According to Words Shakespeare Invented
, The Bard came up with the words ""lonely"" and ""lower"", so let us match the regular expression 'lo(nely|wer)', and find out how often they occur in there.

Regular expressions have a correspondence with deterministic finite automata, so we can draw the expression as a graph of its automaton:

The idea is that you start in a numbered state (1), read a character, move to the next state if an arc is labelled with what you read, and repeat the procedure. Implicitly, there should be a bunch of arcs from states 2-8 going back to the start state (labelled with ""anything else""), but we can leave those out of the figure for the sake of clarity, and remember them. Similarly, let's quietly add a state 0 with an arc from 0 to 1 that is taken when there's a blank space, so that we actually make it the regular expression ' lo(nely|wer)'. The reason to do so is that 'lower' appears in 'flower', 'follower', and other places, so putting a space in is to narrow the search, and not drawing it in the figure is because I have a hard time making an obvious drawing of a space character. It's a slightly broken way to get space-separated words, but it's simple, and you can surely work out the changes in the graph to fix it up how you like anyway.

A nice thing about graphs is that they can be written as tables, so if we take all the 256 values a character can have as columns, and make a row for each of our 10 states, the arcs can be written as the destination state in table entry (state, character). The algorithm for matching text, then, becomes a matter of storing which state we're in, reading a character, and changing state according to the table. Here's our regular expression in C, I've hard-coded the table for the expression, since this is just an illustration:


#include <stdio.h> 
#include <string.h> 
 
char table[10][256]; 
 
void 
setup_table ( void ) 
{ 
    /* Start with everything has arcs to state 0 */ 
    memset ( table, 0, 10*256 ); 
    /* Add the arcs from our automaton */ 
    table[0][' '] = 1; 
    table[1]['l'] = 2; 
    table[2]['o'] = 3; 
    table[3]['n'] = 4; 
    table[3]['w'] = 7; 
    table[4]['e'] = 5; 
    table[5]['l'] = 6; 
    table[6]['y'] = 9; 
    table[7]['e'] = 8; 
    table[8]['r'] = 9; 
} 
 
int 
main ( ) 
{ 
    int state = 0, character; 
    setup_table(); 
    while ( !feof(stdin) ) 
    { 
        /* Match text */ 
        character = getchar(); 
        state = table[state][character]; 
 
        /* Recognize if we've reached a complete match */ 
        if ( state == 9 ) 
        { 
            printf ( ""Hooray, we found one!\n"" ); 
            state = 0; 
        } 
    } 
} 

Now, we run Shakespeare through that and count how many lines of hoorays we get:


% make mygrep 
cc     mygrep.c   -o mygrep 
% cat 100.txt.utf-8 | time ./mygrep | wc -l 
0.54user 0.01system 0:00.61elapsed 90%CPU (0avgtext+0avgdata 372maxresident)k 
0inputs+0outputs (0major+117minor)pagefaults 0swaps 
24 

So, that's 24 hits in around half a second for a 5.4MB file, at least on the puny netbook I'm writing this on. You can verify that 24 is correct using an ordinary grep with an expression in the appropriate syntax of choice.

Next, we can break this half-second down into how much trouble it is to read characters, and how much trouble it is to match expressions, by loading the entire text into memory in one sweep, and matching the expression in another:


#include <stdio.h> 
#include <string.h> 
 
/* We'll need clocks */ 
#include <sys/time.h> 
#define WALLTIME(t) ((double)(t).tv_sec + 1e-6 * (double)(t).tv_usec) 
 
/* The file is less than 6MB, so that will be more than enough for us */ 
int shakespeare[6*1024*1024]; 
 
char table[10][256]; 
 
/* The definition of setup_table is the same as before, so it's omitted, 
 * copy it from the previous source if you want to run this. 
 */ 
 
int 
main ( ) 
{ 
    int state = 0, character; 
    setup_table(); 
 
    size_t i = 0; 
    struct timeval t0, t1, t2; 
 
    /* Read the whole thing */ 
    gettimeofday ( &t0, NULL ); 
    while ( !feof(stdin) ) 
    { 
        shakespeare[i] = getchar(); 
        i = i + 1; 
    } 
    shakespeare[i] = EOF; 
    gettimeofday ( &t1, NULL ); 
    i = 0; 
 
    while ( shakespeare[i] != EOF ) 
    { 
        /* Match text against the loaded array */ 
        state = table[state][shakespeare[i]]; 
        i = i + 1; 
 
        /* Recognize if we've reached a complete match */ 
        if ( state == 9 ) 
        { 
            printf ( ""Hooray, we found one!\n"" ); 
            state = 0; 
        } 
    } 
    gettimeofday ( &t2, NULL ); 
    fprintf ( stderr, ""%lf seconds of reading, %lf seconds of matching\n"", 
        WALLTIME(t1)-WALLTIME(t0), WALLTIME(t2)-WALLTIME(t1) 
    ); 
} 

Running this on the same machine gets us


% make mygrep2 
cc     mygrep2.c   -o mygrep2 
% cat 100.txt.utf-8 | ./mygrep2 | wc -l 
0.597790 seconds of reading, 0.073611 seconds of matching 
24 

As you can see, even this completely unsophisticated little proto-grep could do a full-text match of more than 8 expressions in the time it takes just to get the characters in the text from disk. It has nothing to win from preprocessing, because any preprocessing would take as much time as doing the matching right away, the preprocessor would also have to read the file. All that really differentiates this tiny experiment from a full implementation, is that a proper grep constructs its table from the provided regular expression, and should probably use a more compressed format for the table, since this one grows as the number of states times the size of the possible input alphabet.

The procedure for finding matches is straightforward, and its performance is dominated by the cost of fetching all the text it searches through. There would be advantages to using preprocessing and a more elaborate data structure for a search tool that's expected to do a lot of searching in a large, slowly changing data set, but I don't think grep would be useful in the way it is if it relied on a periodically updated index database, or something.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/9vawe1uohijfzkd0', 'title': ""How does 'grep' preprocess a text file for efficient regular expression matching?"", 'score': {'original': 0.45723333333333, 'ai': 0.54276666666667}, 'blocks': [{'text': 'I don\'t think grep does any preprocessing of the input file; it certainly doesn\'t have to, regular expression matching is pretty efficient as it is.\n\nInstead of sifting through all the world\'s different grep implementations looking for evidence of preprocessing that probably isn\'t there, though, I will argue this with a small experiment for illustration, because I think it\'s more fun than just saying that expression matching works in linear time.\n\nWe can try matching a regular expression without grep, so just grab a copy of the collected works of Shakespeare:\n\n\n# I\'m going to do everything in a somewhat UNIX-y way throughout\xa0\n% wget http://www.gutenberg.org/ebooks/100.txt.utf-8\xa0\n\nAccording to Words Shakespeare Invented\n, The Bard came up with the words ""lonely"" and ""lower"", so let us match the regular expression \'lo(nely|wer)\', and find out how often they occur in there.\n\nRegular expressions have a correspondence with deterministic finite automata, so we can draw the expression as a graph of its automaton:\n\nThe idea is that you start in a numbered state (1), read a character, move to the next state if an arc is labelled with what you read, and repeat the procedure. Implicitly, there should be a bunch of arcs from states 2-8 going back to the start state (labelled with ""anything else""), but we can leave those out of the figure for the sake of clarity, and remember them. Similarly, let\'s quietly add a state 0 with an arc from 0 to 1 that is taken when there\'s a blank space, so that we actually make it the regular expression \' lo(nely|wer)\'. The reason to do so is that \'lower\' appears in \'flower\', \'follower\', and other places, so putting a space in is to narrow the search, and not drawing it in the figure is because I have a hard time making an obvious drawing of a space character. It\'s a slightly broken way to get space-separated words, but it\'s simple, and you can surely work out the changes in the graph to fix it up how you like anyway.\n\nA nice thing about graphs is that they can be written as tables, so if we take all the 256 values a character can have as columns, and make a row for each of our 10 states, the arcs can be written as the destination state in table entry (state, character). The algorithm for matching text, then, becomes a matter of storing which state we\'re in, reading a character, and changing state according to the table. Here\'s our regular expression in C, I\'ve hard-coded the table for the expression, since this is just an illustration:\n\n\n#include <stdio.h>\xa0\n#include <string.h>\xa0\n\xa0\nchar table[10][256];\xa0\n\xa0\nvoid\xa0\nsetup_table ( void )\xa0\n{\xa0\n    /* Start with everything has arcs to state 0 */\xa0\n    memset ( table, 0, 10*256 );\xa0\n    /* Add the arcs from our automaton */\xa0\n    table[0][\' \'] = 1;\xa0\n    table[1][\'l\'] = 2;\xa0\n    table[2][\'o\'] = 3;\xa0\n    table[3][\'n\'] = 4;\xa0\n    table[3][\'w\'] = 7;\xa0\n    table[4][\'e\'] = 5;\xa0\n    table[5][\'l\'] = 6;\xa0\n   ', 'result': {'fake': 0.0451, 'real': 0.9549}, 'status': 'success'}, {'text': 'table[6][\'y\'] = 9;\xa0\n    table[7][\'e\'] = 8;\xa0\n    table[8][\'r\'] = 9;\xa0\n}\xa0\n\xa0\nint\xa0\nmain ( )\xa0\n{\xa0\n    int state = 0, character;\xa0\n    setup_table();\xa0\n    while ( !feof(stdin) )\xa0\n    {\xa0\n        /* Match text */\xa0\n        character = getchar();\xa0\n        state = table[state][character];\xa0\n\xa0\n        /* Recognize if we\'ve reached a complete match */\xa0\n        if ( state == 9 )\xa0\n        {\xa0\n            printf ( ""Hooray, we found one!\\n"" );\xa0\n            state = 0;\xa0\n        }\xa0\n    }\xa0\n}\xa0\n\nNow, we run Shakespeare through that and count how many lines of hoorays we get:\n\n\n% make mygrep\xa0\ncc     mygrep.c   -o mygrep\xa0\n% cat 100.txt.utf-8 | time ./mygrep | wc -l\xa0\n0.54user 0.01system 0:00.61elapsed 90%CPU (0avgtext+0avgdata 372maxresident)k\xa0\n0inputs+0outputs (0major+117minor)pagefaults 0swaps\xa0\n24\xa0\n\nSo, that\'s 24 hits in around half a second for a 5.4MB file, at least on the puny netbook I\'m writing this on. You can verify that 24 is correct using an ordinary grep with an expression in the appropriate syntax of choice.\n\nNext, we can break this half-second down into how much trouble it is to read characters, and how much trouble it is to match expressions, by loading the entire text into memory in one sweep, and matching the expression in another:\n\n\n#include <stdio.h>\xa0\n#include <string.h>\xa0\n\xa0\n/* We\'ll need clocks */\xa0\n#include <sys/time.h>\xa0\n#define WALLTIME(t) ((double)(t).tv_sec + 1e-6 * (double)(t).tv_usec)\xa0\n\xa0\n/* The file is less than 6MB, so that will be more than enough for us */\xa0\nint shakespeare[6*1024*1024];\xa0\n\xa0\nchar table[10][256];\xa0\n\xa0\n/* The definition of setup_table is the same as before, so it\'s omitted,\xa0\n * copy it from the previous source if you want to run this.\xa0\n */\xa0\n\xa0\nint\xa0\nmain ( )\xa0\n{\xa0\n    int state = 0, character;\xa0\n    setup_table();\xa0\n\xa0\n    size_t i = 0;\xa0\n    struct timeval t0, t1, t2;\xa0\n\xa0\n    /* Read the whole thing */\xa0\n    gettimeofday ( &t0, NULL );\xa0\n    while ( !feof(stdin) )\xa0\n    {\xa0\n        shakespeare[i] = getchar();\xa0\n        i = i + 1;\xa0\n    }\xa0\n    shakespeare[i] = EOF;\xa0\n    gettimeofday ( &t1, NULL );\xa0\n    i = 0;\xa0\n\xa0\n    while ( shakespeare[i] != EOF )\xa0\n    {\xa0\n        /* Match text against the loaded array */\xa0\n        state = table[state][shakespeare[i]];\xa0\n        i = i + 1;\xa0\n\xa0\n        /* Recognize if we\'ve reached a complete match */\xa0\n        if ( state == 9', 'result': {'fake': 0.9908, 'real': 0.0092}, 'status': 'success'}, {'text': ')\xa0\n        {\xa0\n            printf ( ""Hooray, we found one!\\n"" );\xa0\n            state = 0;\xa0\n        }\xa0\n    }\xa0\n    gettimeofday ( &t2, NULL );\xa0\n    fprintf ( stderr, ""%lf seconds of reading, %lf seconds of matching\\n"",\xa0\n        WALLTIME(t1)-WALLTIME(t0), WALLTIME(t2)-WALLTIME(t1)\xa0\n    );\xa0\n}\xa0\n\nRunning this on the same machine gets us\n\n\n% make mygrep2\xa0\ncc     mygrep2.c   -o mygrep2\xa0\n% cat 100.txt.utf-8 | ./mygrep2 | wc -l\xa0\n0.597790 seconds of reading, 0.073611 seconds of matching\xa0\n24\xa0\n\nAs you can see, even this completely unsophisticated little proto-grep could do a full-text match of more than 8 expressions in the time it takes just to get the characters in the text from disk. It has nothing to win from preprocessing, because any preprocessing would take as much time as doing the matching right away, the preprocessor would also have to read the file. All that really differentiates this tiny experiment from a full implementation, is that a proper grep constructs its table from the provided regular expression, and should probably use a more compressed format for the table, since this one grows as the number of states times the size of the possible input alphabet.\n\nThe procedure for finding matches is straightforward, and its performance is dominated by the cost of fetching all the text it searches through. There would be advantages to using preprocessing and a more elaborate data structure for a search tool that\'s expected to do a lot of searching in a large, slowly changing data set, but I don\'t think grep would be useful in the way it is if it relied on a periodically updated index database, or something.', 'result': {'fake': 0.4827, 'real': 0.5173}, 'status': 'success'}], 'credits_used': 11, 'credits': 1986504, 'subscription': 0, 'content': 'I don\'t think grep does any preprocessing of the input file; it certainly doesn\'t have to, regular expression matching is pretty efficient as it is.\n\nInstead of sifting through all the world\'s different grep implementations looking for evidence of preprocessing that probably isn\'t there, though, I will argue this with a small experiment for illustration, because I think it\'s more fun than just saying that expression matching works in linear time.\n\nWe can try matching a regular expression without grep, so just grab a copy of the collected works of Shakespeare:\n\n\n# I\'m going to do everything in a somewhat UNIX-y way throughout\xa0\n% wget http://www.gutenberg.org/ebooks/100.txt.utf-8\xa0\n\nAccording to Words Shakespeare Invented\n, The Bard came up with the words ""lonely"" and ""lower"", so let us match the regular expression \'lo(nely|wer)\', and find out how often they occur in there.\n\nRegular expressions have a correspondence with deterministic finite automata, so we can draw the expression as a graph of its automaton:\n\nThe idea is that you start in a numbered state (1), read a character, move to the next state if an arc is labelled with what you read, and repeat the procedure. Implicitly, there should be a bunch of arcs from states 2-8 going back to the start state (labelled with ""anything else""), but we can leave those out of the figure for the sake of clarity, and remember them. Similarly, let\'s quietly add a state 0 with an arc from 0 to 1 that is taken when there\'s a blank space, so that we actually make it the regular expression \' lo(nely|wer)\'. The reason to do so is that \'lower\' appears in \'flower\', \'follower\', and other places, so putting a space in is to narrow the search, and not drawing it in the figure is because I have a hard time making an obvious drawing of a space character. It\'s a slightly broken way to get space-separated words, but it\'s simple, and you can surely work out the changes in the graph to fix it up how you like anyway.\n\nA nice thing about graphs is that they can be written as tables, so if we take all the 256 values a character can have as columns, and make a row for each of our 10 states, the arcs can be written as the destination state in table entry (state, character). The algorithm for matching text, then, becomes a matter of storing which state we\'re in, reading a character, and changing state according to the table. Here\'s our regular expression in C, I\'ve hard-coded the table for the expression, since this is just an illustration:\n\n\n#include <stdio.h>\xa0\n#include <string.h>\xa0\n\xa0\nchar table[10][256];\xa0\n\xa0\nvoid\xa0\nsetup_table ( void )\xa0\n{\xa0\n    /* Start with everything has arcs to state 0 */\xa0\n    memset ( table, 0, 10*256 );\xa0\n    /* Add the arcs from our automaton */\xa0\n    table[0][\' \'] = 1;\xa0\n    table[1][\'l\'] = 2;\xa0\n    table[2][\'o\'] = 3;\xa0\n    table[3][\'n\'] = 4;\xa0\n    table[3][\'w\'] = 7;\xa0\n    table[4][\'e\'] = 5;\xa0\n    table[5][\'l\'] = 6;\xa0\n    table[6][\'y\'] = 9;\xa0\n    table[7][\'e\'] = 8;\xa0\n    table[8][\'r\'] = 9;\xa0\n}\xa0\n\xa0\nint\xa0\nmain ( )\xa0\n{\xa0\n    int state = 0, character;\xa0\n    setup_table();\xa0\n    while ( !feof(stdin) )\xa0\n    {\xa0\n        /* Match text */\xa0\n        character = getchar();\xa0\n        state = table[state][character];\xa0\n\xa0\n        /* Recognize if we\'ve reached a complete match */\xa0\n        if ( state == 9 )\xa0\n        {\xa0\n            printf ( ""Hooray, we found one!\\n"" );\xa0\n            state = 0;\xa0\n        }\xa0\n    }\xa0\n}\xa0\n\nNow, we run Shakespeare through that and count how many lines of hoorays we get:\n\n\n% make mygrep\xa0\ncc     mygrep.c   -o mygrep\xa0\n% cat 100.txt.utf-8 | time ./mygrep | wc -l\xa0\n0.54user 0.01system 0:00.61elapsed 90%CPU (0avgtext+0avgdata 372maxresident)k\xa0\n0inputs+0outputs (0major+117minor)pagefaults 0swaps\xa0\n24\xa0\n\nSo, that\'s 24 hits in around half a second for a 5.4MB file, at least on the puny netbook I\'m writing this on. You can verify that 24 is correct using an ordinary grep with an expression in the appropriate syntax of choice.\n\nNext, we can break this half-second down into how much trouble it is to read characters, and how much trouble it is to match expressions, by loading the entire text into memory in one sweep, and matching the expression in another:\n\n\n#include <stdio.h>\xa0\n#include <string.h>\xa0\n\xa0\n/* We\'ll need clocks */\xa0\n#include <sys/time.h>\xa0\n#define WALLTIME(t) ((double)(t).tv_sec + 1e-6 * (double)(t).tv_usec)\xa0\n\xa0\n/* The file is less than 6MB, so that will be more than enough for us */\xa0\nint shakespeare[6*1024*1024];\xa0\n\xa0\nchar table[10][256];\xa0\n\xa0\n/* The definition of setup_table is the same as before, so it\'s omitted,\xa0\n * copy it from the previous source if you want to run this.\xa0\n */\xa0\n\xa0\nint\xa0\nmain ( )\xa0\n{\xa0\n    int state = 0, character;\xa0\n    setup_table();\xa0\n\xa0\n    size_t i = 0;\xa0\n    struct timeval t0, t1, t2;\xa0\n\xa0\n    /* Read the whole thing */\xa0\n    gettimeofday ( &t0, NULL );\xa0\n    while ( !feof(stdin) )\xa0\n    {\xa0\n        shakespeare[i] = getchar();\xa0\n        i = i + 1;\xa0\n    }\xa0\n    shakespeare[i] = EOF;\xa0\n    gettimeofday ( &t1, NULL );\xa0\n    i = 0;\xa0\n\xa0\n    while ( shakespeare[i] != EOF )\xa0\n    {\xa0\n        /* Match text against the loaded array */\xa0\n        state = table[state][shakespeare[i]];\xa0\n        i = i + 1;\xa0\n\xa0\n        /* Recognize if we\'ve reached a complete match */\xa0\n        if ( state == 9 )\xa0\n        {\xa0\n            printf ( ""Hooray, we found one!\\n"" );\xa0\n            state = 0;\xa0\n        }\xa0\n    }\xa0\n    gettimeofday ( &t2, NULL );\xa0\n    fprintf ( stderr, ""%lf seconds of reading, %lf seconds of matching\\n"",\xa0\n        WALLTIME(t1)-WALLTIME(t0), WALLTIME(t2)-WALLTIME(t1)\xa0\n    );\xa0\n}\xa0\n\nRunning this on the same machine gets us\n\n\n% make mygrep2\xa0\ncc     mygrep2.c   -o mygrep2\xa0\n% cat 100.txt.utf-8 | ./mygrep2 | wc -l\xa0\n0.597790 seconds of reading, 0.073611 seconds of matching\xa0\n24\xa0\n\nAs you can see, even this completely unsophisticated little proto-grep could do a full-text match of more than 8 expressions in the time it takes just to get the characters in the text from disk. It has nothing to win from preprocessing, because any preprocessing would take as much time as doing the matching right away, the preprocessor would also have to read the file. All that really differentiates this tiny experiment from a full implementation, is that a proper grep constructs its table from the provided regular expression, and should probably use a more compressed format for the table, since this one grows as the number of states times the size of the possible input alphabet.\n\nThe procedure for finding matches is straightforward, and its performance is dominated by the cost of fetching all the text it searches through. There would be advantages to using preprocessing and a more elaborate data structure for a search tool that\'s expected to do a lot of searching in a large, slowly changing data set, but I don\'t think grep would be useful in the way it is if it relied on a periodically updated index database, or something.', 'aiModelVersion': '1'}",0.45723333333333
Ashwini Chaudhary,Updated 11y,"When writing a ""for"" loop, why does everyone name the variable as ""i""?","Some amazing answers from : etymology - Why are variables ""i"" and ""j"" used for counters? - Stack Overflow


1:


It comes ultimately from mathematics: the summation notation traditionally uses i for the first index, j for the second, and so on. Example (from http://en.wikipedia.org/wiki/Summation):



It's also used that way for collections of things, like if you have a bunch of variables x1, x2, ... xn, then an arbitrary one will be known as xi.



2:


i stands for Index.
j comes after i.


3:


It dates back to Fortran. Variables starting with I through Q were integer by default, the others were real. This meant that I was the first integer variable, and J the second, etc., so they fell towards use in loops.


4:


Because of the name D*ijk*stra



5:


a seems an array
b seems another array
c seems a language name
d seems another language name
e seems exception
f looks bad in combination with ""for"" (for f, a pickup?)
g seems g force
h seems height
i seems an index
j seems i (another index)
k seems a constant k
l seems a number one (1)
m seems a matrix
n seems a node
o seems an output
p sounds like a pointer
q seems a queue
r seems a return value
s seems a string
t looks like time
u reserved for UVW mapping or electic phase
v reserved for UVW mapping or electic phase or a vector
w reserved for UVW mapping or electic phase or a weight
x seems an axis (or an unknown variable)
y seems an axis
z seems a third axis

6:


I found another possible answer that could be
that i, j, and k come from Hamilton's Quaternions.


Euler picked i for the imaginary unit.
Hamilton needed two more square roots of -1: ii = jj = kk = ijk = -1
Hamilton was really influential, and quaternions were the standard way to do 3D analysis before 1900. By then, mathematicians were used to thinking of (ijk) as a matched set. Vector calculus replaced quaternionic analysis in the 1890s because it was a better way to write Maxwell's equations. But people tended to write vector quantities as like this: (3i-2j+k) instead of (3,-2,1). So (ijk) became the standard basis vectors in R^3.
Finally, physicists started using group theory to describe symmetries in systems of differential equations. So (ijk) started to connote ""vectors that get swapped around by permutation groups,"" then drifted towards ""index-like things that take on all possible values in some specified set,"" which is basically what they mean in a for loop.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/mzv7u2t146h8c5s9', 'title': 'When writing a ""for"" loop, why does everyone name the variable as ""i""?', 'score': {'original': 0.9555, 'ai': 0.0445}, 'blocks': [{'text': 'Some amazing answers from : etymology - Why are variables ""i"" and ""j"" used for counters? - Stack Overflow\n\n\n1:\n\n\nIt comes ultimately from mathematics: the summation notation traditionally uses i for the first index, j for the second, and so on. Example (from http://en.wikipedia.org/wiki/Summation):\n\n\n\nIt\'s also used that way for collections of things, like if you have a bunch of variables x1, x2, ... xn, then an arbitrary one will be known as xi.\n\n\n\n2:\n\n\ni stands for Index.\nj comes after i.\n\n\n3:\n\n\nIt dates back to Fortran. Variables starting with I through Q were integer by default, the others were real. This meant that I was the first integer variable, and J the second, etc., so they fell towards use in loops.\n\n\n4:\n\n\nBecause of the name D*ijk*stra\n\n\n\n5:\n\n\na seems an array\nb seems another array\nc seems a language name\nd seems another language name\ne seems exception\nf looks bad in combination with ""for"" (for f, a pickup?)\ng seems g force\nh seems height\ni seems an index\nj seems i (another index)\nk seems a constant k\nl seems a number one (1)\nm seems a matrix\nn seems a node\no seems an output\np sounds like a pointer\nq seems a queue\nr seems a return value\ns seems a string\nt looks like time\nu reserved for UVW mapping or electic phase\nv reserved for UVW mapping or electic phase or a vector\nw reserved for UVW mapping or electic phase or a weight\nx seems an axis (or an unknown variable)\ny seems an axis\nz seems a third axis\n\n6:\n\n\nI found another possible answer that could be\nthat i, j, and k come from Hamilton\'s Quaternions.\n\n\nEuler picked i for the imaginary unit.\nHamilton needed two more square roots of -1: ii = jj = kk = ijk = -1\nHamilton was really influential, and quaternions were the standard way to do 3D analysis before 1900. By then, mathematicians were used to thinking of (ijk) as a matched set. Vector calculus replaced quaternionic analysis in the 1890s because it was a better way to write Maxwell\'s equations. But people tended to write vector quantities as like this: (3i-2j+k) instead of (3,-2,1). So (ijk) became the standard basis vectors in R^3.\nFinally, physicists started using group theory to describe symmetries in systems of differential equations. So (ijk) started to connote ""vectors that get swapped around by permutation groups,"" then drifted towards ""index-like things that take on all possible values in some specified set,"" which is basically what they mean in a for loop.', 'result': {'fake': 0.1729, 'real': 0.8271}, 'status': 'success'}], 'credits_used': 5, 'credits': 1986499, 'subscription': 0, 'content': 'Some amazing answers from : etymology - Why are variables ""i"" and ""j"" used for counters? - Stack Overflow\n\n\n1:\n\n\nIt comes ultimately from mathematics: the summation notation traditionally uses i for the first index, j for the second, and so on. Example (from http://en.wikipedia.org/wiki/Summation):\n\n\n\nIt\'s also used that way for collections of things, like if you have a bunch of variables x1, x2, ... xn, then an arbitrary one will be known as xi.\n\n\n\n2:\n\n\ni stands for Index.\nj comes after i.\n\n\n3:\n\n\nIt dates back to Fortran. Variables starting with I through Q were integer by default, the others were real. This meant that I was the first integer variable, and J the second, etc., so they fell towards use in loops.\n\n\n4:\n\n\nBecause of the name D*ijk*stra\n\n\n\n5:\n\n\na seems an array\nb seems another array\nc seems a language name\nd seems another language name\ne seems exception\nf looks bad in combination with ""for"" (for f, a pickup?)\ng seems g force\nh seems height\ni seems an index\nj seems i (another index)\nk seems a constant k\nl seems a number one (1)\nm seems a matrix\nn seems a node\no seems an output\np sounds like a pointer\nq seems a queue\nr seems a return value\ns seems a string\nt looks like time\nu reserved for UVW mapping or electic phase\nv reserved for UVW mapping or electic phase or a vector\nw reserved for UVW mapping or electic phase or a weight\nx seems an axis (or an unknown variable)\ny seems an axis\nz seems a third axis\n\n6:\n\n\nI found another possible answer that could be\nthat i, j, and k come from Hamilton\'s Quaternions.\n\n\nEuler picked i for the imaginary unit.\nHamilton needed two more square roots of -1: ii = jj = kk = ijk = -1\nHamilton was really influential, and quaternions were the standard way to do 3D analysis before 1900. By then, mathematicians were used to thinking of (ijk) as a matched set. Vector calculus replaced quaternionic analysis in the 1890s because it was a better way to write Maxwell\'s equations. But people tended to write vector quantities as like this: (3i-2j+k) instead of (3,-2,1). So (ijk) became the standard basis vectors in R^3.\nFinally, physicists started using group theory to describe symmetries in systems of differential equations. So (ijk) started to connote ""vectors that get swapped around by permutation groups,"" then drifted towards ""index-like things that take on all possible values in some specified set,"" which is basically what they mean in a for loop.', 'aiModelVersion': '1'}",0.9555
Brian Bi,11y,Have there been any new brilliant computer science algorithms in last 10 years?,"I believe just last year it was found that the maximum network flow problem can be solved in O(VE)O(VE)O(VE) time. This bound was first achieved for dense graphs, i.e., E∈Ω(V2)E∈Ω(V2)E \in \Omega(V^2), by the relabel-to-front algorithm, a particular version of the push-preflow method, which runs in O(V3)O(V3)O(V^3) time. This algorithm was published by Goldberg and Tarjan in 1986, and you can find it in CLRS. In 1994, King, Rao, and Tarjan gave an algorithm that runs in O(VElog(V)/log(EVlogV))O(VElog⁡(V)/log⁡(EVlog⁡V))O\left(VE \log(V)/\log\left(\frac{E}{V \log V}\right)\right) time. This reduces to O(VE)O(VE)O(VE) for all graphs that are not too sparse, i.e., E∈Ω(V1+ϵ)E∈Ω(V1+ϵ)E \in \Omega(V^{1+\epsilon}). (Graphs with constant or logarithmic average degree are still a bit too sparse.) Finally, in 2012, Orlin put the final piece in place, finding an algorithm that runs in O(VE+E31/16log2V)O(VE+E31/16log2⁡V)O(VE + E^{31/16} \log^2 V). For E∈O(V16/15−ϵ)E∈O(V16/15−ϵ)E \in O(V^{16/15-\epsilon}), that is, graphs that are sparse enough, this reduces to O(VE)O(VE)O(VE). By combining the algorithm of King, Rao, and Tarjan, and Orlin's algorithm, we see that maximum network flow can be solved in O(VE)O(VE)O(VE) time. I think that's pretty awesome.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/9ezsjnhcgt5284q1', 'title': 'Have there been any new brilliant computer science algorithms in last 10 years?', 'score': {'original': 0.0317, 'ai': 0.9683}, 'blocks': [{'text': ""I believe just last year it was found that the maximum network flow problem can be solved in O(VE)O(VE)O(VE) time. This bound was first achieved for dense graphs, i.e., E∈Ω(V2)E∈Ω(V2)E \\in \\Omega(V^2), by the relabel-to-front algorithm, a particular version of the push-preflow method, which runs in O(V3)O(V3)O(V^3) time. This algorithm was published by Goldberg and Tarjan in 1986, and you can find it in CLRS. In 1994, King, Rao, and Tarjan gave an algorithm that runs in O(VElog(V)/log(EVlogV))O(VElog\u2061(V)/log\u2061(EVlog\u2061V))O\\left(VE \\log(V)/\\log\\left(\\frac{E}{V \\log V}\\right)\\right) time. This reduces to O(VE)O(VE)O(VE) for all graphs that are not too sparse, i.e., E∈Ω(V1+ϵ)E∈Ω(V1+ϵ)E \\in \\Omega(V^{1+\\epsilon}). (Graphs with constant or logarithmic average degree are still a bit too sparse.) Finally, in 2012, Orlin put the final piece in place, finding an algorithm that runs in O(VE+E31/16log2V)O(VE+E31/16log2\u2061V)O(VE + E^{31/16} \\log^2 V). For E∈O(V16/15−ϵ)E∈O(V16/15−ϵ)E \\in O(V^{16/15-\\epsilon}), that is, graphs that are sparse enough, this reduces to O(VE)O(VE)O(VE). By combining the algorithm of King, Rao, and Tarjan, and Orlin's algorithm, we see that maximum network flow can be solved in O(VE)O(VE)O(VE) time. I think that's pretty awesome."", 'result': {'fake': 0.9683, 'real': 0.0317}, 'status': 'success'}], 'credits_used': 3, 'credits': 1986496, 'subscription': 0, 'content': ""I believe just last year it was found that the maximum network flow problem can be solved in O(VE)O(VE)O(VE) time. This bound was first achieved for dense graphs, i.e., E∈Ω(V2)E∈Ω(V2)E \\in \\Omega(V^2), by the relabel-to-front algorithm, a particular version of the push-preflow method, which runs in O(V3)O(V3)O(V^3) time. This algorithm was published by Goldberg and Tarjan in 1986, and you can find it in CLRS. In 1994, King, Rao, and Tarjan gave an algorithm that runs in O(VElog(V)/log(EVlogV))O(VElog\u2061(V)/log\u2061(EVlog\u2061V))O\\left(VE \\log(V)/\\log\\left(\\frac{E}{V \\log V}\\right)\\right) time. This reduces to O(VE)O(VE)O(VE) for all graphs that are not too sparse, i.e., E∈Ω(V1+ϵ)E∈Ω(V1+ϵ)E \\in \\Omega(V^{1+\\epsilon}). (Graphs with constant or logarithmic average degree are still a bit too sparse.) Finally, in 2012, Orlin put the final piece in place, finding an algorithm that runs in O(VE+E31/16log2V)O(VE+E31/16log2\u2061V)O(VE + E^{31/16} \\log^2 V). For E∈O(V16/15−ϵ)E∈O(V16/15−ϵ)E \\in O(V^{16/15-\\epsilon}), that is, graphs that are sparse enough, this reduces to O(VE)O(VE)O(VE). By combining the algorithm of King, Rao, and Tarjan, and Orlin's algorithm, we see that maximum network flow can be solved in O(VE)O(VE)O(VE) time. I think that's pretty awesome."", 'aiModelVersion': '1'}",0.0317
Alon Amit,Updated 3y,Is there a sorting algorithm with a time complexity of TREE(n) or worse?,"Sure there is. Here is one:

Input: an array of size 
n
n
.
Sort the array.
Compute TREE(
n
n
) by enumerating all appropriate sequences of trees.
Output the sorted array.

The complexity of this algorithm is far worse than TREE(
n
n
).

I understand that this isn’t what you meant. You want some kind of “genuine” sorting algorithm which takes an enormous amount of time to complete. But there’s no way to make this a sensible question.

Any algorithm which takes more than 
(
n
+
1
)
!
(n+1)!
 steps to sort an 
n
n
-item list is very deliberately doing something stupid in order to artificially slow itself down. The entire search space has size 
n
!
n!
, and the most naive algorithm wouldn’t take more than 
n
!
×
n
n!×n
 steps to scan it and verify each point (the name “bogosort
” is sometimes used for variants of this idea).

Of course you can make it as slow as you want by piling on additional useless or harmful steps, as in bogobogosort
. It’s not hard to invent such harmful steps and get to 
n
!
n
!
n!n!
 or the factorial of that or some such thing.

To get to TREE(
n
n
), you’ll need to introduce wildly complex idiocy, to the point where what you’re doing can only reasonably be regarded as counting to TREE(
n
n
) rather than sorting anything.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/3ts0b94wa2lcvfk5', 'title': 'Is there a sorting algorithm with a time complexity of TREE(n) or worse?', 'score': {'original': 0.9994, 'ai': 0.0006}, 'blocks': [{'text': 'Sure there is. Here is one:\n\nInput: an array of size \nn\nn\n.\nSort the array.\nCompute TREE(\nn\nn\n) by enumerating all appropriate sequences of trees.\nOutput the sorted array.\n\nThe complexity of this algorithm is far worse than TREE(\nn\nn\n).\n\nI understand that this isn’t what you meant. You want some kind of “genuine” sorting algorithm which takes an enormous amount of time to complete. But there’s no way to make this a sensible question.\n\nAny algorithm which takes more than \n(\nn\n+\n1\n)\n!\n(n+1)!\n steps to sort an \nn\nn\n-item list is very deliberately doing something stupid in order to artificially slow itself down. The entire search space has size \nn\n!\nn!\n, and the most naive algorithm wouldn’t take more than \nn\n!\n×\nn\nn!×n\n steps to scan it and verify each point (the name “bogosort\n” is sometimes used for variants of this idea).\n\nOf course you can make it as slow as you want by piling on additional useless or harmful steps, as in bogobogosort\n. It’s not hard to invent such harmful steps and get to \nn\n!\nn\n!\nn!n!\n or the factorial of that or some such thing.\n\nTo get to TREE(\nn\nn\n), you’ll need to introduce wildly complex idiocy, to the point where what you’re doing can only reasonably be regarded as counting to TREE(\nn\nn\n) rather than sorting anything.', 'result': {'fake': 0.0006, 'real': 0.9994}, 'status': 'success'}], 'credits_used': 3, 'credits': 1986493, 'subscription': 0, 'content': 'Sure there is. Here is one:\n\nInput: an array of size \nn\nn\n.\nSort the array.\nCompute TREE(\nn\nn\n) by enumerating all appropriate sequences of trees.\nOutput the sorted array.\n\nThe complexity of this algorithm is far worse than TREE(\nn\nn\n).\n\nI understand that this isn’t what you meant. You want some kind of “genuine” sorting algorithm which takes an enormous amount of time to complete. But there’s no way to make this a sensible question.\n\nAny algorithm which takes more than \n(\nn\n+\n1\n)\n!\n(n+1)!\n steps to sort an \nn\nn\n-item list is very deliberately doing something stupid in order to artificially slow itself down. The entire search space has size \nn\n!\nn!\n, and the most naive algorithm wouldn’t take more than \nn\n!\n×\nn\nn!×n\n steps to scan it and verify each point (the name “bogosort\n” is sometimes used for variants of this idea).\n\nOf course you can make it as slow as you want by piling on additional useless or harmful steps, as in bogobogosort\n. It’s not hard to invent such harmful steps and get to \nn\n!\nn\n!\nn!n!\n or the factorial of that or some such thing.\n\nTo get to TREE(\nn\nn\n), you’ll need to introduce wildly complex idiocy, to the point where what you’re doing can only reasonably be regarded as counting to TREE(\nn\nn\n) rather than sorting anything.', 'aiModelVersion': '1'}",0.9994
Alon Amit,Updated 3y,What are some programming problems that look hard at a first glance but are actually easy?,"Here’s a black and white image.

It is represented, as you’d expect, as an array of bits: 0 is white, 1 is black. Your programming challenge is to determine the number of connected components in such an image. In this example, there are three of them:

You’re not required to color them in! I’m just clarifying what I mean by “connected component”.

You can make the following assumptions. The black pixels of a component share an edge, not just a corner. Assume that this:

doesn’t happen. Connected components are strongly connected (their pixels share an edge), and different components don’t touch even in pixel corners. With a hi-res image like the example above those are very natural assumptions (Note: in an earlier version of this answer I was too lax here. Corrected now.)

Another simplifying assumption you can make is that there are no holes. The “blobs”, the connected components, are whole and filled in. Such blobs are called simply connected.

Finally, you may assume that the exterior border of the array is all white. If not, you can just zero-pad it.

So:

Input: array of bits, representing an image with simply connected components.
Output: an integer representing the number of components.
GO!

This is actually an important and useful algorithmic problem. Versions of it are needed, for example, in science and engineering to count objects in industrial, biological or medical images.

So, how would you go about this?

Almost anyone who attempts this does the most natural thing: Flood Fill
. Scan the image, find a black pixel, start crawling its neighbors and their neighbors and so on, marking the pixels you’ve found along the way. When you get stuck, backtrack to a previous black pixel which still has unprocessed neighbors, and continue until you’ve completed a blob. Add 
1
1
 to the count of blobs. Start over.

Here’s a quick animation (from the loc. cit. Wiki page) of a flood fill algorithm filling a white blob on a black background.

This is not a terribly difficult algorithm, but it’s not straightforward either. The Wikipedia article shows various versions, including a fairly optimized one with some 100 lines of pseudocode. See also Connected-component labeling
 for more on this approach.

(Naturally, the code golfers have addressed the problem
, but as you can see even they couldn’t get it down to their usual 9-byte Jelly programs. Except for the guy who cheated with Matlab’s imfill, the solutions are hundreds of bytes of dense code.)

But remember, I didn’t ask you to flood-fill anything, nor to label the blobs. We just want to count. Is there an easier way?

Yes, there is, a fantastically simple and easy way. It lets you count the number of connected components in the simply connected case, and in fact it works more generally: it counts the number of components minus the number of holes. If we assume no holes, as we did, then you simply get the number of blobs.

Here’s the complete algorithm.

Set a counter to 
0
0
. Scan the entire image, once, looking at 
2
×
2
2×2
 pixel windows anchored at each pixel. Add 1 to the counter every time you see this (a “dot”):

Subtract 1 every time you see that (a “T”):

Done. The counter has the number of connected components.

Yes, really. No queues, no stacks, no recursion, no backtracking, no forest fire fills, no labeling, nothing. Just a dead-simple, linear, one-time pass through the array, and counting two simple combinations of pixels.

If this is the input:

You’ll catch one 
+
1
+1
 and no subtractions. Output: 
1
1
. Check.

If this is the input:

You’ll count two 
+
1
+1
's and one 
−
1
−1
. Output: 
1
1
. Check.

Here’s a more complicated example:

There are 
4
4
 
+
1
+1
's here and 
3
3
 
−
1
−1
's. Output: 
1
1
. Check.

The local nature of the algorithm makes it quite clear that if it works for single blobs, it works for any number of blobs. Indeed, it is additive under superpositions. Overlay two disjoint blobs and the algorithm will simply accumulate the results from each independent one.

This algorithm is an instance of something truly deep and profound: the local-global behavior of the Euler characteristic
. In simple words, if you have local geometric data and you’re interested in global features, take an alternating sum. In our case, “dots minus T’s” is the same as “components minus holes”. The very same idea lies behind deep results like the Lefschetz fixed point theorem
 and the Gauss–Bonnet theorem
.

We’ll have to save a complete proof to another answer, but I would submit that this is an amazing instance of a seemingly challenging algorithmic problem which turns out to have a ridiculously simple solution.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/4qvlwjgh25ztkis8', 'title': 'What are some programming problems that look hard at a first glance but are actually easy?', 'score': {'original': 0.9801, 'ai': 0.0199}, 'blocks': [{'text': 'Here’s a black and white image.\n\nIt is represented, as you’d expect, as an array of bits: 0 is white, 1 is black. Your programming challenge is to determine the number of connected components in such an image. In this example, there are three of them:\n\nYou’re not required to color them in! I’m just clarifying what I mean by “connected component”.\n\nYou can make the following assumptions. The black pixels of a component share an edge, not just a corner. Assume that this:\n\ndoesn’t happen. Connected components are strongly connected (their pixels share an edge), and different components don’t touch even in pixel corners. With a hi-res image like the example above those are very natural assumptions (Note: in an earlier version of this answer I was too lax here. Corrected now.)\n\nAnother simplifying assumption you can make is that there are no holes. The “blobs”, the connected components, are whole and filled in. Such blobs are called simply connected.\n\nFinally, you may assume that the exterior border of the array is all white. If not, you can just zero-pad it.\n\nSo:\n\nInput: array of bits, representing an image with simply connected components.\nOutput: an integer representing the number of components.\nGO!\n\nThis is actually an important and useful algorithmic problem. Versions of it are needed, for example, in science and engineering to count objects in industrial, biological or medical images.\n\nSo, how would you go about this?\n\nAlmost anyone who attempts this does the most natural thing: Flood Fill\n. Scan the image, find a black pixel, start crawling its neighbors and their neighbors and so on, marking the pixels you’ve found along the way. When you get stuck, backtrack to a previous black pixel which still has unprocessed neighbors, and continue until you’ve completed a blob. Add \n1\n1\n to the count of blobs. Start over.\n\nHere’s a quick animation (from the loc. cit. Wiki page) of a flood fill algorithm filling a white blob on a black background.\n\nThis is not a terribly difficult algorithm, but it’s not straightforward either. The Wikipedia article shows various versions, including a fairly optimized one with some 100 lines of pseudocode. See also Connected-component labeling\n for more on this approach.\n\n(Naturally, the code golfers have addressed the problem\n, but as you can see even they couldn’t get it down to their usual 9-byte Jelly programs. Except for the guy who cheated with Matlab’s imfill, the solutions are hundreds of bytes of dense code.)\n\nBut remember, I didn’t ask you to flood-fill anything, nor to label the blobs. We just want to count. Is there an easier way?\n\nYes, there is, a fantastically simple and easy way. It lets you count the number of connected components in the simply connected case, and in fact it works more generally: it counts the number of components minus the number of holes. If we assume no holes, as we did, then you simply get the number of blobs.\n\nHere’s the complete algorithm.\n\nSet a counter to \n0\n0\n. Scan the entire image, once, looking at \n2\n×\n2\n2×2\n pixel windows anchored at each pixel. Add 1 to the counter every time you see this (a “dot”):\n\nSubtract 1 every time you see', 'result': {'fake': 0.009, 'real': 0.991}, 'status': 'success'}, {'text': ""that (a “T”):\n\nDone. The counter has the number of connected components.\n\nYes, really. No queues, no stacks, no recursion, no backtracking, no forest fire fills, no labeling, nothing. Just a dead-simple, linear, one-time pass through the array, and counting two simple combinations of pixels.\n\nIf this is the input:\n\nYou’ll catch one \n+\n1\n+1\n and no subtractions. Output: \n1\n1\n. Check.\n\nIf this is the input:\n\nYou’ll count two \n+\n1\n+1\n's and one \n−\n1\n−1\n. Output: \n1\n1\n. Check.\n\nHere’s a more complicated example:\n\nThere are \n4\n4\n \n+\n1\n+1\n's here and \n3\n3\n \n−\n1\n−1\n's. Output: \n1\n1\n. Check.\n\nThe local nature of the algorithm makes it quite clear that if it works for single blobs, it works for any number of blobs. Indeed, it is additive under superpositions. Overlay two disjoint blobs and the algorithm will simply accumulate the results from each independent one.\n\nThis algorithm is an instance of something truly deep and profound: the local-global behavior of the Euler characteristic\n. In simple words, if you have local geometric data and you’re interested in global features, take an alternating sum. In our case, “dots minus T’s” is the same as “components minus holes”. The very same idea lies behind deep results like the Lefschetz fixed point theorem\n and the Gauss–Bonnet theorem\n.\n\nWe’ll have to save a complete proof to another answer, but I would submit that this is an amazing instance of a seemingly challenging algorithmic problem which turns out to have a ridiculously simple solution."", 'result': {'fake': 0.1562, 'real': 0.8438}, 'status': 'success'}], 'credits_used': 8, 'credits': 1986485, 'subscription': 0, 'content': ""Here’s a black and white image.\n\nIt is represented, as you’d expect, as an array of bits: 0 is white, 1 is black. Your programming challenge is to determine the number of connected components in such an image. In this example, there are three of them:\n\nYou’re not required to color them in! I’m just clarifying what I mean by “connected component”.\n\nYou can make the following assumptions. The black pixels of a component share an edge, not just a corner. Assume that this:\n\ndoesn’t happen. Connected components are strongly connected (their pixels share an edge), and different components don’t touch even in pixel corners. With a hi-res image like the example above those are very natural assumptions (Note: in an earlier version of this answer I was too lax here. Corrected now.)\n\nAnother simplifying assumption you can make is that there are no holes. The “blobs”, the connected components, are whole and filled in. Such blobs are called simply connected.\n\nFinally, you may assume that the exterior border of the array is all white. If not, you can just zero-pad it.\n\nSo:\n\nInput: array of bits, representing an image with simply connected components.\nOutput: an integer representing the number of components.\nGO!\n\nThis is actually an important and useful algorithmic problem. Versions of it are needed, for example, in science and engineering to count objects in industrial, biological or medical images.\n\nSo, how would you go about this?\n\nAlmost anyone who attempts this does the most natural thing: Flood Fill\n. Scan the image, find a black pixel, start crawling its neighbors and their neighbors and so on, marking the pixels you’ve found along the way. When you get stuck, backtrack to a previous black pixel which still has unprocessed neighbors, and continue until you’ve completed a blob. Add \n1\n1\n to the count of blobs. Start over.\n\nHere’s a quick animation (from the loc. cit. Wiki page) of a flood fill algorithm filling a white blob on a black background.\n\nThis is not a terribly difficult algorithm, but it’s not straightforward either. The Wikipedia article shows various versions, including a fairly optimized one with some 100 lines of pseudocode. See also Connected-component labeling\n for more on this approach.\n\n(Naturally, the code golfers have addressed the problem\n, but as you can see even they couldn’t get it down to their usual 9-byte Jelly programs. Except for the guy who cheated with Matlab’s imfill, the solutions are hundreds of bytes of dense code.)\n\nBut remember, I didn’t ask you to flood-fill anything, nor to label the blobs. We just want to count. Is there an easier way?\n\nYes, there is, a fantastically simple and easy way. It lets you count the number of connected components in the simply connected case, and in fact it works more generally: it counts the number of components minus the number of holes. If we assume no holes, as we did, then you simply get the number of blobs.\n\nHere’s the complete algorithm.\n\nSet a counter to \n0\n0\n. Scan the entire image, once, looking at \n2\n×\n2\n2×2\n pixel windows anchored at each pixel. Add 1 to the counter every time you see this (a “dot”):\n\nSubtract 1 every time you see that (a “T”):\n\nDone. The counter has the number of connected components.\n\nYes, really. No queues, no stacks, no recursion, no backtracking, no forest fire fills, no labeling, nothing. Just a dead-simple, linear, one-time pass through the array, and counting two simple combinations of pixels.\n\nIf this is the input:\n\nYou’ll catch one \n+\n1\n+1\n and no subtractions. Output: \n1\n1\n. Check.\n\nIf this is the input:\n\nYou’ll count two \n+\n1\n+1\n's and one \n−\n1\n−1\n. Output: \n1\n1\n. Check.\n\nHere’s a more complicated example:\n\nThere are \n4\n4\n \n+\n1\n+1\n's here and \n3\n3\n \n−\n1\n−1\n's. Output: \n1\n1\n. Check.\n\nThe local nature of the algorithm makes it quite clear that if it works for single blobs, it works for any number of blobs. Indeed, it is additive under superpositions. Overlay two disjoint blobs and the algorithm will simply accumulate the results from each independent one.\n\nThis algorithm is an instance of something truly deep and profound: the local-global behavior of the Euler characteristic\n. In simple words, if you have local geometric data and you’re interested in global features, take an alternating sum. In our case, “dots minus T’s” is the same as “components minus holes”. The very same idea lies behind deep results like the Lefschetz fixed point theorem\n and the Gauss–Bonnet theorem\n.\n\nWe’ll have to save a complete proof to another answer, but I would submit that this is an amazing instance of a seemingly challenging algorithmic problem which turns out to have a ridiculously simple solution."", 'aiModelVersion': '1'}",0.9801
Alon Amit,2y,Can all NP problems be solved in exponential time?,"Yes. This is formally expressed as NP ⊆⊆\subseteq EXPTIME and the reason it’s so is because instances in NP have polynomial-length certificates that can be checked in polynomial time, so one may simply enumerate over all possible certificates and see if any of them checks out. In fact, it is also known that NP ⊆⊆\subseteq PSPACE ⊆⊆\subseteq EXPTIME. As is often the case in complexity theory, those containments aren’t known to be strict. For all we know, it is possible that NP=EXPTIME, though I don’t think many people expect that to be true.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/gr0wqm7di42zevb1', 'title': 'Can all NP problems be solved in exponential time?', 'score': {'original': 0.9856, 'ai': 0.0144}, 'blocks': [{'text': 'Yes. This is formally expressed as NP ⊆⊆\\subseteq EXPTIME and the reason it’s so is because instances in NP have polynomial-length certificates that can be checked in polynomial time, so one may simply enumerate over all possible certificates and see if any of them checks out. In fact, it is also known that NP ⊆⊆\\subseteq PSPACE ⊆⊆\\subseteq EXPTIME. As is often the case in complexity theory, those containments aren’t known to be strict. For all we know, it is possible that NP=EXPTIME, though I don’t think many people expect that to be true.', 'result': {'fake': 0.0144, 'real': 0.9856}, 'status': 'success'}], 'credits_used': 1, 'credits': 1986484, 'subscription': 0, 'content': 'Yes. This is formally expressed as NP ⊆⊆\\subseteq EXPTIME and the reason it’s so is because instances in NP have polynomial-length certificates that can be checked in polynomial time, so one may simply enumerate over all possible certificates and see if any of them checks out. In fact, it is also known that NP ⊆⊆\\subseteq PSPACE ⊆⊆\\subseteq EXPTIME. As is often the case in complexity theory, those containments aren’t known to be strict. For all we know, it is possible that NP=EXPTIME, though I don’t think many people expect that to be true.', 'aiModelVersion': '1'}",0.9856
Paul Pacheco,Updated 7y,What are some algorithms that are easy to understand but are extremely powerful?,"My favorite is Finite State Machines (aka Automata).

Suppose you want to search for a string in a larger string. For example I want to search for “hola” in a large file. You could start going through the large string looking for an “h”, followed by “o”, etc.

An alternative algorithm is to build an automaton from the substring. An automaton is just a directed graph. Every character will trigger a transition between states. For “hola” the automaton would look like this:

The initial state is 1. Start feeding characters from your input string to the automaton. If you are in state 1 and you see an ‘h’, move to state 2. If you are in state 2 and you see an ‘o’ move to state 3. If you are in a state and you get an unexpected character, you go to state 1. Every time you reach state 5, you have found the word “hola”.

For every character you receive, you just determine which transition to take from the current state. This can be done in O(1) per letter. So the total performance of searching through a file is O(n) where n is the size of the file.

Now what is interesting about automata is that they can be used for regular expressions as well and still preserve the O(n) performance. For example consider the regular expression “ab*cd?”. It means the letter ‘a’ followed by zero or more ‘b’, followed by a ‘c’ optionally followed by a ‘d’. The automaton would be:

Every time you reach 3 or 4, you have found a match. For every character, all you do is move to a new state which is constant time, so the performance remains O(n).

What if I want to search for more than one regular expression? For example, I want to search for the strings “bar” and “baz”, I want to know when either one of them is found. No problem, I can write a single FSM for both:

Every time you reach state 4, you have found the string “bar”, every time you reach state 5 you have found the string “baz”. I can have any arbitrary number of regular expressions and search for all of them at the same time with no performance impact at all by combining them into a single FSM.

Non deterministic automata can have multiple transitions for the same character and state. That would affect performance because you can have more than one active state at the same time. However all non deterministic automata can be transformed to deterministic ones without loss of functionality. Generating an FSM from a regular expression is a well understood process. It’s a bit too complex for this post but it consists of producing a non deterministic FSM and then transforming it to a deterministic one.

Automata can run on a stream. For example a socket, pipe or serial port. They don’t require to backtrack or jump ahead. Just process 1 character at a time for as long as the input is coming. They work fine on multi line search strings. They consume the same amount of memory regardless of the size of the file to be searched, they work fine even if the input file is terabytes long.

FSM have more applications than just regular expression matching. You can use them to model game AI (thanks Vladislav Zorov), workflows, tracking of transactions, documentation, traffic lights, the circuit for a keyboard, etc.. They are not Turing complete, but definitely useful for many applications.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/wv6icf3kqgztnyr7', 'title': 'What are some algorithms that are easy to understand but are extremely powerful?', 'score': {'original': 0.8342, 'ai': 0.1658}, 'blocks': [{'text': 'My favorite is Finite State Machines (aka Automata).\n\nSuppose you want to search for a string in a larger string. For example I want to search for “hola” in a large file. You could start going through the large string looking for an “h”, followed by “o”, etc.\n\nAn alternative algorithm is to build an automaton from the substring. An automaton is just a directed graph. Every character will trigger a transition between states. For “hola” the automaton would look like this:\n\nThe initial state is 1. Start feeding characters from your input string to the automaton. If you are in state 1 and you see an ‘h’, move to state 2. If you are in state 2 and you see an ‘o’ move to state 3. If you are in a state and you get an unexpected character, you go to state 1. Every time you reach state 5, you have found the word “hola”.\n\nFor every character you receive, you just determine which transition to take from the current state. This can be done in O(1) per letter. So the total performance of searching through a file is O(n) where n is the size of the file.\n\nNow what is interesting about automata is that they can be used for regular expressions as well and still preserve the O(n) performance. For example consider the regular expression “ab*cd?”. It means the letter ‘a’ followed by zero or more ‘b’, followed by a ‘c’ optionally followed by a ‘d’. The automaton would be:\n\nEvery time you reach 3 or 4, you have found a match. For every character, all you do is move to a new state which is constant time, so the performance remains O(n).\n\nWhat if I want to search for more than one regular expression? For example, I want to search for the strings “bar” and “baz”, I want to know when either one of them is found. No problem, I can write a single FSM for both:\n\nEvery time you reach state 4, you have found the string “bar”, every time you reach state 5 you have found the string “baz”. I can have any arbitrary number of regular expressions and search for all of them at the same time with no performance impact at all by combining them into a single FSM.\n\nNon deterministic automata can have multiple transitions for the same character and state. That would affect performance because you can have more than one active state at the same time. However all non deterministic automata can be transformed to deterministic ones without loss of functionality. Generating an FSM from a regular expression is a well understood process. It’s a bit too complex for this post but it consists of producing a non deterministic FSM and then transforming it to a deterministic one.\n\nAutomata can run on a stream. For example a socket, pipe or serial port. They don’t require to backtrack or jump ahead. Just process 1 character at a time for as long as the input is coming. They work fine on multi line search strings. They consume the same amount of memory regardless', 'result': {'fake': 0.1038, 'real': 0.8962}, 'status': 'success'}, {'text': 'of the size of the file to be searched, they work fine even if the input file is terabytes long.\n\nFSM have more applications than just regular expression matching. You can use them to model game AI (thanks Vladislav Zorov), workflows, tracking of transactions, documentation, traffic lights, the circuit for a keyboard, etc.. They are not Turing complete, but definitely useful for many applications.', 'result': {'fake': 0.3293, 'real': 0.6707}, 'status': 'success'}], 'credits_used': 6, 'credits': 1986478, 'subscription': 0, 'content': 'My favorite is Finite State Machines (aka Automata).\n\nSuppose you want to search for a string in a larger string. For example I want to search for “hola” in a large file. You could start going through the large string looking for an “h”, followed by “o”, etc.\n\nAn alternative algorithm is to build an automaton from the substring. An automaton is just a directed graph. Every character will trigger a transition between states. For “hola” the automaton would look like this:\n\nThe initial state is 1. Start feeding characters from your input string to the automaton. If you are in state 1 and you see an ‘h’, move to state 2. If you are in state 2 and you see an ‘o’ move to state 3. If you are in a state and you get an unexpected character, you go to state 1. Every time you reach state 5, you have found the word “hola”.\n\nFor every character you receive, you just determine which transition to take from the current state. This can be done in O(1) per letter. So the total performance of searching through a file is O(n) where n is the size of the file.\n\nNow what is interesting about automata is that they can be used for regular expressions as well and still preserve the O(n) performance. For example consider the regular expression “ab*cd?”. It means the letter ‘a’ followed by zero or more ‘b’, followed by a ‘c’ optionally followed by a ‘d’. The automaton would be:\n\nEvery time you reach 3 or 4, you have found a match. For every character, all you do is move to a new state which is constant time, so the performance remains O(n).\n\nWhat if I want to search for more than one regular expression? For example, I want to search for the strings “bar” and “baz”, I want to know when either one of them is found. No problem, I can write a single FSM for both:\n\nEvery time you reach state 4, you have found the string “bar”, every time you reach state 5 you have found the string “baz”. I can have any arbitrary number of regular expressions and search for all of them at the same time with no performance impact at all by combining them into a single FSM.\n\nNon deterministic automata can have multiple transitions for the same character and state. That would affect performance because you can have more than one active state at the same time. However all non deterministic automata can be transformed to deterministic ones without loss of functionality. Generating an FSM from a regular expression is a well understood process. It’s a bit too complex for this post but it consists of producing a non deterministic FSM and then transforming it to a deterministic one.\n\nAutomata can run on a stream. For example a socket, pipe or serial port. They don’t require to backtrack or jump ahead. Just process 1 character at a time for as long as the input is coming. They work fine on multi line search strings. They consume the same amount of memory regardless of the size of the file to be searched, they work fine even if the input file is terabytes long.\n\nFSM have more applications than just regular expression matching. You can use them to model game AI (thanks Vladislav Zorov), workflows, tracking of transactions, documentation, traffic lights, the circuit for a keyboard, etc.. They are not Turing complete, but definitely useful for many applications.', 'aiModelVersion': '1'}",0.8342
Li Pi,Updated 12y,How does garbage collection work in the JVM?,"This actually varies depending on the JVM implementation, but I'm assuming you're talking about Oracle (Sun) Version 6. Java itself does not specify a particular method of garbage collection.

The JVM uses a form of garbage collector called a tracing collector, which essentially operates by first stopping the world, marking all root objects, or objects that are referenced directly by running threads, and following references, marking each object it hits along the way.

Java 6 implements something called a generational garbage collector—based upon the generational hypothesis assumption, which states that the majority of objects that are created are quickly discarded, and that objects that are not quickly collected are likely to be around for some time.

Based upon these assumptions, Java therefore partitions objects into two different generations, and then operates differently upon them.

Visually, the generations look like this:



(Not quite to scale)

Young Generation: This is where objects start out. It has two subgenerations:


Eden - Objects start out here.
Survivor - Objects that survive Eden end up here. There are two of these, and only one is in use at any given time. One is designated as empty, and the other as live. This switched every GC cycle.


Tenured Generation: Older objects with longer lifetimes end up here.

Java is smart enough to apply different garbage collection methods to each generation. The young generation is handled using a tracing, copying collector called the Parallel New Collector. This collector stops the world, but because the young generation is generally small, the pause is short.

For the young generation:

When Eden fills up, the garbage collector stops the world, then traces through the objects in the young generation, starting with those referenced immediately by a running thread.

Those that are marked or ""alive"" are copied over to the empty survivor space. This survivor space is then marked as ""live"", and Eden, along with the other survivor space, is marked as empty. This has the side effect of compacting all the objects into a single survivor space, allowing for rather efficient memory usage. If an object has been copied between the two survivor places a certain amount of times, its designated as tenured, and moved to the tenured section.

Eden will now be overwritten by new objects, and the next garbage collection cycle will proceed to use the other survivor space.

This usage of a copying collector for the young generation is fast because the vast majority of objects are very quickly destroyed, and generally, very few objects must be moved around.

For the tenured generation:

I'm going to steal this section from this blog post by Todd Lipcon, http://www.cloudera.com/blog/2011/02/avoiding-full-gcs-in-hbase-with-memstore-local-allocation-buffers-part-1/

Tenured Generation – Concurrent Mark-Sweep

Every time the parallel new collector runs, it will tenure some objects into the tenured generation. So, of course, the old generation will eventually fill up, and we need a strategy for collecting it as well. The Concurrent-Mark-Sweep collector (CMS) is responsible for clearing dead objects in this generation.

The CMS collector operates in a series of phases. Some phases stop the world, and others run concurrently with the Java application. The major phases are:

initial-mark (stops the world). In this phase, the CMS collector places a mark on the rootobjects. A root object is something directly referenced from a live Thread – for example, the local variables in use by that thread. This phase is short because the number of roots is very small.
concurrent-mark (concurrent). The collector now follows every pointer starting from the root objects until it has marked all live objects in the system.
remark (stops the world). Since objects might have had references changed, and new objects might have been created during concurrent-mark, we need to go back and take those into account in this phase. This is short because a special data structure allows us to only inspect those objects that were modified during the prior phase.
concurrent-sweep (concurrent). Now, we proceed through all objects in the heap. Any object without a mark is collected and considered free space. New objects allocated during this time are marked as they are created so that they aren’t accidentally collected.


The important things to note here are:

The stop-the-world phases are made to be very short. The long work of scanning the whole heap and sweeping up the dead objects happens concurrently.
This collector does not relocate the live objects, so free space can be spread in different chunks throughout the heap. We’ll come back to this later!","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/xm1h2zbcvqp5kdly', 'title': 'How does garbage collection work in the JVM?', 'score': {'original': 0.7865, 'ai': 0.2135}, 'blocks': [{'text': 'This actually varies depending on the JVM implementation, but I\'m assuming you\'re talking about Oracle (Sun) Version 6. Java itself does not specify a particular method of garbage collection.\n\nThe JVM uses a form of garbage collector called a tracing collector, which essentially operates by first stopping the world, marking all root objects, or objects that are referenced directly by running threads, and following references, marking each object it hits along the way.\n\nJava 6 implements something called a generational garbage collector—based upon the generational hypothesis assumption, which states that the majority of objects that are created are quickly discarded, and that objects that are not quickly collected are likely to be around for some time.\n\nBased upon these assumptions, Java therefore partitions objects into two different generations, and then operates differently upon them.\n\nVisually, the generations look like this:\n\n\n\n(Not quite to scale)\n\nYoung Generation: This is where objects start out. It has two subgenerations:\n\n\nEden - Objects start out here.\nSurvivor - Objects that survive Eden end up here. There are two of these, and only one is in use at any given time. One is designated as empty, and the other as live. This switched every GC cycle.\n\n\nTenured Generation: Older objects with longer lifetimes end up here.\n\nJava is smart enough to apply different garbage collection methods to each generation. The young generation is handled using a tracing, copying collector called the Parallel New Collector. This collector stops the world, but because the young generation is generally small, the pause is short.\n\nFor the young generation:\n\nWhen Eden fills up, the garbage collector stops the world, then traces through the objects in the young generation, starting with those referenced immediately by a running thread.\n\nThose that are marked or ""alive"" are copied over to the empty survivor space. This survivor space is then marked as ""live"", and Eden, along with the other survivor space, is marked as empty. This has the side effect of compacting all the objects into a single survivor space, allowing for rather efficient memory usage. If an object has been copied between the two survivor places a certain amount of times, its designated as tenured, and moved to the tenured section.\n\nEden will now be overwritten by new objects, and the next garbage collection cycle will proceed to use the other survivor space.\n\nThis usage of a copying collector for the young generation is fast because the vast majority of objects are very quickly destroyed, and generally, very few objects must be moved around.\n\nFor the tenured generation:\n\nI\'m going to steal this section from this blog post by Todd Lipcon, http://www.cloudera.com/blog/2011/02/avoiding-full-gcs-in-hbase-with-memstore-local-allocation-buffers-part-1/\n\nTenured Generation – Concurrent Mark-Sweep\n\nEvery time the parallel new collector runs, it will tenure some objects into the tenured generation. So, of course, the old generation will eventually fill up, and we need a strategy for collecting it as well. The Concurrent-Mark-Sweep collector (CMS) is responsible for clearing dead objects in this generation.\n\nThe CMS collector operates in a series of phases. Some phases stop the world, and others run concurrently with the Java application. The major phases are:\n\ninitial-mark (stops the world). In this phase, the CMS collector places a mark', 'result': {'fake': 0.007, 'real': 0.993}, 'status': 'success'}, {'text': 'on the rootobjects. A root object is something directly referenced from a live Thread – for example, the local variables in use by that thread. This phase is short because the number of roots is very small.\nconcurrent-mark (concurrent). The collector now follows every pointer starting from the root objects until it has marked all live objects in the system.\nremark (stops the world). Since objects might have had references changed, and new objects might have been created during concurrent-mark, we need to go back and take those into account in this phase. This is short because a special data structure allows us to only inspect those objects that were modified during the prior phase.\nconcurrent-sweep (concurrent). Now, we proceed through all objects in the heap. Any object without a mark is collected and considered free space. New objects allocated during this time are marked as they are created so that they aren’t accidentally collected.\n\n\nThe important things to note here are:\n\nThe stop-the-world phases are made to be very short. The long work of scanning the whole heap and sweeping up the dead objects happens concurrently.\nThis collector does not relocate the live objects, so free space can be spread in different chunks throughout the heap. We’ll come back to this later!', 'result': {'fake': 0.7234, 'real': 0.2766}, 'status': 'success'}], 'credits_used': 8, 'credits': 1986470, 'subscription': 0, 'content': 'This actually varies depending on the JVM implementation, but I\'m assuming you\'re talking about Oracle (Sun) Version 6. Java itself does not specify a particular method of garbage collection.\n\nThe JVM uses a form of garbage collector called a tracing collector, which essentially operates by first stopping the world, marking all root objects, or objects that are referenced directly by running threads, and following references, marking each object it hits along the way.\n\nJava 6 implements something called a generational garbage collector—based upon the generational hypothesis assumption, which states that the majority of objects that are created are quickly discarded, and that objects that are not quickly collected are likely to be around for some time.\n\nBased upon these assumptions, Java therefore partitions objects into two different generations, and then operates differently upon them.\n\nVisually, the generations look like this:\n\n\n\n(Not quite to scale)\n\nYoung Generation: This is where objects start out. It has two subgenerations:\n\n\nEden - Objects start out here.\nSurvivor - Objects that survive Eden end up here. There are two of these, and only one is in use at any given time. One is designated as empty, and the other as live. This switched every GC cycle.\n\n\nTenured Generation: Older objects with longer lifetimes end up here.\n\nJava is smart enough to apply different garbage collection methods to each generation. The young generation is handled using a tracing, copying collector called the Parallel New Collector. This collector stops the world, but because the young generation is generally small, the pause is short.\n\nFor the young generation:\n\nWhen Eden fills up, the garbage collector stops the world, then traces through the objects in the young generation, starting with those referenced immediately by a running thread.\n\nThose that are marked or ""alive"" are copied over to the empty survivor space. This survivor space is then marked as ""live"", and Eden, along with the other survivor space, is marked as empty. This has the side effect of compacting all the objects into a single survivor space, allowing for rather efficient memory usage. If an object has been copied between the two survivor places a certain amount of times, its designated as tenured, and moved to the tenured section.\n\nEden will now be overwritten by new objects, and the next garbage collection cycle will proceed to use the other survivor space.\n\nThis usage of a copying collector for the young generation is fast because the vast majority of objects are very quickly destroyed, and generally, very few objects must be moved around.\n\nFor the tenured generation:\n\nI\'m going to steal this section from this blog post by Todd Lipcon, http://www.cloudera.com/blog/2011/02/avoiding-full-gcs-in-hbase-with-memstore-local-allocation-buffers-part-1/\n\nTenured Generation – Concurrent Mark-Sweep\n\nEvery time the parallel new collector runs, it will tenure some objects into the tenured generation. So, of course, the old generation will eventually fill up, and we need a strategy for collecting it as well. The Concurrent-Mark-Sweep collector (CMS) is responsible for clearing dead objects in this generation.\n\nThe CMS collector operates in a series of phases. Some phases stop the world, and others run concurrently with the Java application. The major phases are:\n\ninitial-mark (stops the world). In this phase, the CMS collector places a mark on the rootobjects. A root object is something directly referenced from a live Thread – for example, the local variables in use by that thread. This phase is short because the number of roots is very small.\nconcurrent-mark (concurrent). The collector now follows every pointer starting from the root objects until it has marked all live objects in the system.\nremark (stops the world). Since objects might have had references changed, and new objects might have been created during concurrent-mark, we need to go back and take those into account in this phase. This is short because a special data structure allows us to only inspect those objects that were modified during the prior phase.\nconcurrent-sweep (concurrent). Now, we proceed through all objects in the heap. Any object without a mark is collected and considered free space. New objects allocated during this time are marked as they are created so that they aren’t accidentally collected.\n\n\nThe important things to note here are:\n\nThe stop-the-world phases are made to be very short. The long work of scanning the whole heap and sweeping up the dead objects happens concurrently.\nThis collector does not relocate the live objects, so free space can be spread in different chunks throughout the heap. We’ll come back to this later!', 'aiModelVersion': '1'}",0.7865
Franklin Veaux,8mo,How do Democrats explain the peer-reviewed paper on the 4 hidden algorithms found in the NY voter rolls using multiple obfuscation techniques built into the system?,"Greetings, Max Girth!

I wondered what you were yapping about, so I looked up this “peer-reviewed paper” of yours. Turns out it’s not accessible without paying $240 to see it:

Which means you haven’t read it, I’m betting.

In fact, I’d put good money that you haven’t read it and you’re just repeating what other people have told you to think, because your question completely gets the article wrong.

You see, while you have to pay $240 to read the article, the “researcher” who wrote it also put up an article in the (totally) credible and (totally) scholarly Red Voice Media,
 and whoa, did you (totally) get the details wrong. Oh my God.

It’s not a paper about “4 hidden algorithms found in the NY voter rolls,” it’s a paper that claims—and having read his article, with, I must say, the sort of earnest garwharbl that sounds so scientific and such to people who are technically illiterate, but to people who know even a little about infosec is the security equivalent of “gravity isn’t real, it’s just quasicrystal supersolid spacetime displacing matter”—that anonymous voter IDs actually contain hidden information that allows someone who knows the ID to reveal the identity of the voter.

He claims other stuff too, which…well, I’ll let anyone who’s interested read the article. It’s a grind, but the overall takeaway is “I don’t know how it works” (although he phrases it as “There is no way to discover the boundaries of these bands without exhaustive manual effort,” with an implied “that I am too lazy or too incompetent to do”) but totally there’s totally some totally hidden information in there, but I won’t give you any examples nor explain exactly how I came to this conclusion except through the same sort of numerology that people who make Bible ‘predictions’ use.

Psychologists have a name for this, by the way. It’s called “promiscuous pattern recognition.” If you stare at a big enough list of numbers for long enough, you can see all sorts of things that aren’t there.

But Democrats don’t need to explain it. Infosec people are too busy laughing at it.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/fzskt2gcl86vuaj7', 'title': 'How do Democrats explain the peer-reviewed paper on the 4 hidden algorithms found in the NY voter rolls using multiple obfuscation techniques built into the system?', 'score': {'original': 0.999, 'ai': 0.001}, 'blocks': [{'text': 'Greetings, Max Girth!\n\nI wondered what you were yapping about, so I looked up this “peer-reviewed paper” of yours. Turns out it’s not accessible without paying $240 to see it:\n\nWhich means you haven’t read it, I’m betting.\n\nIn fact, I’d put good money that you haven’t read it and you’re just repeating what other people have told you to think, because your question completely gets the article wrong.\n\nYou see, while you have to pay $240 to read the article, the “researcher” who wrote it also put up an article in the (totally) credible and (totally) scholarly Red Voice Media,\n and whoa, did you (totally) get the details wrong. Oh my God.\n\nIt’s not a paper about “4 hidden algorithms found in the NY voter rolls,” it’s a paper that claims—and having read his article, with, I must say, the sort of earnest garwharbl that sounds so scientific and such to people who are technically illiterate, but to people who know even a little about infosec is the security equivalent of “gravity isn’t real, it’s just quasicrystal supersolid spacetime displacing matter”—that anonymous voter IDs actually contain hidden information that allows someone who knows the ID to reveal the identity of the voter.\n\nHe claims other stuff too, which…well, I’ll let anyone who’s interested read the article. It’s a grind, but the overall takeaway is “I don’t know how it works” (although he phrases it as “There is no way to discover the boundaries of these bands without exhaustive manual effort,” with an implied “that I am too lazy or too incompetent to do”) but totally there’s totally some totally hidden information in there, but I won’t give you any examples nor explain exactly how I came to this conclusion except through the same sort of numerology that people who make Bible ‘predictions’ use.\n\nPsychologists have a name for this, by the way. It’s called “promiscuous pattern recognition.” If you stare at a big enough list of numbers for long enough, you can see all sorts of things that aren’t there.\n\nBut Democrats don’t need to explain it. Infosec people are too busy laughing at it.', 'result': {'fake': 0.001, 'real': 0.999}, 'status': 'success'}], 'credits_used': 4, 'credits': 1986466, 'subscription': 0, 'content': 'Greetings, Max Girth!\n\nI wondered what you were yapping about, so I looked up this “peer-reviewed paper” of yours. Turns out it’s not accessible without paying $240 to see it:\n\nWhich means you haven’t read it, I’m betting.\n\nIn fact, I’d put good money that you haven’t read it and you’re just repeating what other people have told you to think, because your question completely gets the article wrong.\n\nYou see, while you have to pay $240 to read the article, the “researcher” who wrote it also put up an article in the (totally) credible and (totally) scholarly Red Voice Media,\n and whoa, did you (totally) get the details wrong. Oh my God.\n\nIt’s not a paper about “4 hidden algorithms found in the NY voter rolls,” it’s a paper that claims—and having read his article, with, I must say, the sort of earnest garwharbl that sounds so scientific and such to people who are technically illiterate, but to people who know even a little about infosec is the security equivalent of “gravity isn’t real, it’s just quasicrystal supersolid spacetime displacing matter”—that anonymous voter IDs actually contain hidden information that allows someone who knows the ID to reveal the identity of the voter.\n\nHe claims other stuff too, which…well, I’ll let anyone who’s interested read the article. It’s a grind, but the overall takeaway is “I don’t know how it works” (although he phrases it as “There is no way to discover the boundaries of these bands without exhaustive manual effort,” with an implied “that I am too lazy or too incompetent to do”) but totally there’s totally some totally hidden information in there, but I won’t give you any examples nor explain exactly how I came to this conclusion except through the same sort of numerology that people who make Bible ‘predictions’ use.\n\nPsychologists have a name for this, by the way. It’s called “promiscuous pattern recognition.” If you stare at a big enough list of numbers for long enough, you can see all sorts of things that aren’t there.\n\nBut Democrats don’t need to explain it. Infosec people are too busy laughing at it.', 'aiModelVersion': '1'}",0.999
Andrew Bromage,7mo,"As we all know, DeepMind has discovered faster sorting algorithms, so is the algorithm I learned in computer science at university still useful, and can I not learn it?","First off, DeepMind has not discovered a new sorting algorithm. What it discovered was a superoptimisation
: a code-to-code transformation that was previously unknown and improves performance.

This is extremely valuable, and the technique of discovering new transformation templates by deep learning (and then testing them using automated theorem provers, of course) could revolutionise compilers. It won’t revolutionise sorting, though.

Second, and most importantly, you don’t study sort algorithms because you need to know a lot of sort algorithms. You study them to learn algorithmic thinking.

Sorting is a model problem that a young child can understand, but it has both trivial and nontrivial solutions with varying tradeoffs. You learn sort algorithms to learn how to understand, analyse, and evaluate these tradeoffs.

In the real world, knowing how to implement some sort algorithm off the top of your head isn’t that useful. But knowing that there are options and analysing possible solutions is invaluable.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/islk4bx7u8qa56mc', 'title': 'As we all know, DeepMind has discovered faster sorting algorithms, so is the algorithm I learned in computer science at university still useful, and can I not learn it?', 'score': {'original': 0.9989, 'ai': 0.0011}, 'blocks': [{'text': 'First off, DeepMind has not discovered a new sorting algorithm. What it discovered was a superoptimisation\n: a code-to-code transformation that was previously unknown and improves performance.\n\nThis is extremely valuable, and the technique of discovering new transformation templates by deep learning (and then testing them using automated theorem provers, of course) could revolutionise compilers. It won’t revolutionise sorting, though.\n\nSecond, and most importantly, you don’t study sort algorithms because you need to know a lot of sort algorithms. You study them to learn algorithmic thinking.\n\nSorting is a model problem that a young child can understand, but it has both trivial and nontrivial solutions with varying tradeoffs. You learn sort algorithms to learn how to understand, analyse, and evaluate these tradeoffs.\n\nIn the real world, knowing how to implement some sort algorithm off the top of your head isn’t that useful. But knowing that there are options and analysing possible solutions is invaluable.', 'result': {'fake': 0.0011, 'real': 0.9989}, 'status': 'success'}], 'credits_used': 2, 'credits': 1986464, 'subscription': 0, 'content': 'First off, DeepMind has not discovered a new sorting algorithm. What it discovered was a superoptimisation\n: a code-to-code transformation that was previously unknown and improves performance.\n\nThis is extremely valuable, and the technique of discovering new transformation templates by deep learning (and then testing them using automated theorem provers, of course) could revolutionise compilers. It won’t revolutionise sorting, though.\n\nSecond, and most importantly, you don’t study sort algorithms because you need to know a lot of sort algorithms. You study them to learn algorithmic thinking.\n\nSorting is a model problem that a young child can understand, but it has both trivial and nontrivial solutions with varying tradeoffs. You learn sort algorithms to learn how to understand, analyse, and evaluate these tradeoffs.\n\nIn the real world, knowing how to implement some sort algorithm off the top of your head isn’t that useful. But knowing that there are options and analysing possible solutions is invaluable.', 'aiModelVersion': '1'}",0.9989
Prabha Prakash,1y,What is your review of Learnbay's Data Structure and Algorithms Course?,"Learnbay is the only educational institution that both satisfies the demands of working professionals and prepares them to become industry experts. Learnbay provides all students with live lessons on weekdays and weekends, one-on-one question-and-answer sessions, personal mentorship and coaching, small class sizes, high-quality study tools, and outstanding placement support.

Learnbay offers the best data structures and algorithms training in Bangalore, both in the classroom and online.

DSA and System Design

Weekday Batches: 5 Months & Weekend Batches: 6 Months
Duration: 200+ hours of learning

Full Stack Software Development Program

Weekday Batches: 8 Months & Weekend Batches: 9 Months
Duration: 300+ hours of learning

Learnbay has a lot of features that can help you decide if Learnbay fits well with your career needs.

You don't even have to be a coder to benefit from their assistance. It has interactive graphics that are significantly more user-friendly than any other existing teaching approach. The interactive tasks will help you rapidly grasp the essential ideas. This platform is particularly built for non-programmers who wish to understand data structures quickly.
Students will study DSA and system design foundations, as well as software development, algorithm analysis, and spatial and temporal complexity. To help you succeed in MAANG interviews, there are extra courses on Real-time Projects & Use Cases, and Interview Preparation. There are additional Elite Domains for Full Stack, Product Management, Web 3.0 Developer, and DevOps & Clouds in the Full Stack Software Development Program where you may specialize and master domain-specific industrial projects. Because of this, you will be able to stand out from the crowd and perform well in interviews.
They deliver meaningful material; they don't only focus on data structures; instead, they dive deeper into what we often refer to as algorithms that help us solve problems. They provide you with real-world solutions to problems so you can learn about them and how to apply them.
Several real-time projects are included in the Full-Stack Software Development Course. Learnbay provides project-based learning, which requires students to create an actual web application as part of the course. Learning becomes more intriguing and engaging as a result. Some of the projects include:
k-d tree research project.
Non-C system languages have fast data structures.
Using doubly-linked lists in a phone directory application.
Sessions for Job Assistance: In addition to resume preparation, mock interview rounds, and job proposals to top employers, Learnbay provides career assistance sessions. The sessions assist students immensely since they boost their chances of finding a job with a reputed organization.

It is quite evident that Learnbay is one of the best options out there. But before joining any course, you must be aware of the career and the job prospects.

Let’s look at why data structures and algorithms are important for jobs:

Data structures and algorithms exhibit a candidate's problem-solving skills. There is no place for complex tales, which implies that either the applicant can or cannot handle the problem.
Data structures and algorithms Questions can be adjusted up or down depending on the candidate's knowledge level. As a result, a wide range of candidates may be assessed using essentially the same issues.
Data structures and algorithms are used to assess applicants' analytical skills since they are helpful tools for identifying the underlying algorithms in real-world situations and solving them quickly.
The basics of software development are data structures and algorithms. They stay the same regardless of the new technology utilized, and this focuses the interview process on the problem rather than the technology.

It is very clear that you must have proper knowledge of data structures and algorithms. Learnbay offers one of the most in-depth and convenient courses available today.

Either way, I’ll list a few more DSA courses for you to compare and decide what works best for you:

Udemy

Udemy is a well-known online learning site and one of the most famous suppliers of data structure training courses online. It contains great teaching resources for data structures, replete with images and explanations. However, there are no live sessions. Instead, it offers pre-recorded videos.

Final thought

There are many courses that are easily available today. But in my opinion, Learnbay provides the best data structures and algorithms courses that can help you get the right job. They will train you in-depth and will help you find the best job out there. You always need good credentials when it comes to a job. So, choose wisely.

I hope my answer helped you.

Best wishes!","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/ftma68gslpxzwr3u', 'title': ""What is your review of Learnbay's Data Structure and Algorithms Course?"", 'score': {'original': 0, 'ai': 1}, 'blocks': [{'text': ""Learnbay is the only educational institution that both satisfies the demands of working professionals and prepares them to become industry experts. Learnbay provides all students with live lessons on weekdays and weekends, one-on-one question-and-answer sessions, personal mentorship and coaching, small class sizes, high-quality study tools, and outstanding placement support.\n\nLearnbay offers the best data structures and algorithms training in Bangalore, both in the classroom and online.\n\nDSA and System Design\n\nWeekday Batches: 5 Months & Weekend Batches: 6 Months\nDuration: 200+ hours of learning\n\nFull Stack Software Development Program\n\nWeekday Batches: 8 Months & Weekend Batches: 9 Months\nDuration: 300+ hours of learning\n\nLearnbay has a lot of features that can help you decide if Learnbay fits well with your career needs.\n\nYou don't even have to be a coder to benefit from their assistance. It has interactive graphics that are significantly more user-friendly than any other existing teaching approach. The interactive tasks will help you rapidly grasp the essential ideas. This platform is particularly built for non-programmers who wish to understand data structures quickly.\nStudents will study DSA and system design foundations, as well as software development, algorithm analysis, and spatial and temporal complexity. To help you succeed in MAANG interviews, there are extra courses on Real-time Projects & Use Cases, and Interview Preparation. There are additional Elite Domains for Full Stack, Product Management, Web 3.0 Developer, and DevOps & Clouds in the Full Stack Software Development Program where you may specialize and master domain-specific industrial projects. Because of this, you will be able to stand out from the crowd and perform well in interviews.\nThey deliver meaningful material; they don't only focus on data structures; instead, they dive deeper into what we often refer to as algorithms that help us solve problems. They provide you with real-world solutions to problems so you can learn about them and how to apply them.\nSeveral real-time projects are included in the Full-Stack Software Development Course. Learnbay provides project-based learning, which requires students to create an actual web application as part of the course. Learning becomes more intriguing and engaging as a result. Some of the projects include:\nk-d tree research project.\nNon-C system languages have fast data structures.\nUsing doubly-linked lists in a phone directory application.\nSessions for Job Assistance: In addition to resume preparation, mock interview rounds, and job proposals to top employers, Learnbay provides career assistance sessions. The sessions assist students immensely since they boost their chances of finding a job with a reputed organization.\n\nIt is quite evident that Learnbay is one of the best options out there. But before joining any course, you must be aware of the career and the job prospects.\n\nLet’s look at why data structures and algorithms are important for jobs:\n\nData structures and algorithms exhibit a candidate's problem-solving skills. There is no place for complex tales, which implies that either the applicant can or cannot handle the problem.\nData structures and algorithms Questions can be adjusted up or down depending on the candidate's knowledge level. As a result, a wide range of candidates may be assessed using essentially the same issues.\nData structures and algorithms are used to assess applicants' analytical skills since they are"", 'result': {'fake': 1, 'real': 0}, 'status': 'success'}, {'text': 'helpful tools for identifying the underlying algorithms in real-world situations and solving them quickly.\nThe basics of software development are data structures and algorithms. They stay the same regardless of the new technology utilized, and this focuses the interview process on the problem rather than the technology.\n\nIt is very clear that you must have proper knowledge of data structures and algorithms. Learnbay offers one of the most in-depth and convenient courses available today.\n\nEither way, I’ll list a few more DSA courses for you to compare and decide what works best for you:\n\nUdemy\n\nUdemy is a well-known online learning site and one of the most famous suppliers of data structure training courses online. It contains great teaching resources for data structures, replete with images and explanations. However, there are no live sessions. Instead, it offers pre-recorded videos.\n\nFinal thought\n\nThere are many courses that are easily available today. But in my opinion, Learnbay provides the best data structures and algorithms courses that can help you get the right job. They will train you in-depth and will help you find the best job out there. You always need good credentials when it comes to a job. So, choose wisely.\n\nI hope my answer helped you.\n\nBest wishes!', 'result': {'fake': 1, 'real': 0}, 'status': 'success'}], 'credits_used': 8, 'credits': 1986456, 'subscription': 0, 'content': ""Learnbay is the only educational institution that both satisfies the demands of working professionals and prepares them to become industry experts. Learnbay provides all students with live lessons on weekdays and weekends, one-on-one question-and-answer sessions, personal mentorship and coaching, small class sizes, high-quality study tools, and outstanding placement support.\n\nLearnbay offers the best data structures and algorithms training in Bangalore, both in the classroom and online.\n\nDSA and System Design\n\nWeekday Batches: 5 Months & Weekend Batches: 6 Months\nDuration: 200+ hours of learning\n\nFull Stack Software Development Program\n\nWeekday Batches: 8 Months & Weekend Batches: 9 Months\nDuration: 300+ hours of learning\n\nLearnbay has a lot of features that can help you decide if Learnbay fits well with your career needs.\n\nYou don't even have to be a coder to benefit from their assistance. It has interactive graphics that are significantly more user-friendly than any other existing teaching approach. The interactive tasks will help you rapidly grasp the essential ideas. This platform is particularly built for non-programmers who wish to understand data structures quickly.\nStudents will study DSA and system design foundations, as well as software development, algorithm analysis, and spatial and temporal complexity. To help you succeed in MAANG interviews, there are extra courses on Real-time Projects & Use Cases, and Interview Preparation. There are additional Elite Domains for Full Stack, Product Management, Web 3.0 Developer, and DevOps & Clouds in the Full Stack Software Development Program where you may specialize and master domain-specific industrial projects. Because of this, you will be able to stand out from the crowd and perform well in interviews.\nThey deliver meaningful material; they don't only focus on data structures; instead, they dive deeper into what we often refer to as algorithms that help us solve problems. They provide you with real-world solutions to problems so you can learn about them and how to apply them.\nSeveral real-time projects are included in the Full-Stack Software Development Course. Learnbay provides project-based learning, which requires students to create an actual web application as part of the course. Learning becomes more intriguing and engaging as a result. Some of the projects include:\nk-d tree research project.\nNon-C system languages have fast data structures.\nUsing doubly-linked lists in a phone directory application.\nSessions for Job Assistance: In addition to resume preparation, mock interview rounds, and job proposals to top employers, Learnbay provides career assistance sessions. The sessions assist students immensely since they boost their chances of finding a job with a reputed organization.\n\nIt is quite evident that Learnbay is one of the best options out there. But before joining any course, you must be aware of the career and the job prospects.\n\nLet’s look at why data structures and algorithms are important for jobs:\n\nData structures and algorithms exhibit a candidate's problem-solving skills. There is no place for complex tales, which implies that either the applicant can or cannot handle the problem.\nData structures and algorithms Questions can be adjusted up or down depending on the candidate's knowledge level. As a result, a wide range of candidates may be assessed using essentially the same issues.\nData structures and algorithms are used to assess applicants' analytical skills since they are helpful tools for identifying the underlying algorithms in real-world situations and solving them quickly.\nThe basics of software development are data structures and algorithms. They stay the same regardless of the new technology utilized, and this focuses the interview process on the problem rather than the technology.\n\nIt is very clear that you must have proper knowledge of data structures and algorithms. Learnbay offers one of the most in-depth and convenient courses available today.\n\nEither way, I’ll list a few more DSA courses for you to compare and decide what works best for you:\n\nUdemy\n\nUdemy is a well-known online learning site and one of the most famous suppliers of data structure training courses online. It contains great teaching resources for data structures, replete with images and explanations. However, there are no live sessions. Instead, it offers pre-recorded videos.\n\nFinal thought\n\nThere are many courses that are easily available today. But in my opinion, Learnbay provides the best data structures and algorithms courses that can help you get the right job. They will train you in-depth and will help you find the best job out there. You always need good credentials when it comes to a job. So, choose wisely.\n\nI hope my answer helped you.\n\nBest wishes!"", 'aiModelVersion': '1'}",0.0
Joe Zbiciak,4y,Why should we use recursion in programming languages if we could just use for and while loops instead?,"You could always use loops instead of recursion.

Try writing a binary tree traversal as a loop sometime. It's not difficult, although you may be surprised by some of the corner conditions you encounter. Then compare it to the recursive function implementation. Which one is clearer and easier to follow?

With the loop-based version, it turns out that you still have recursion. It's just data recursion. You have to build a stack manually. With code recursion, the compiler does it for you.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/oeghku692ymsni3c', 'title': 'Why should we use recursion in programming languages if we could just use for and while loops instead?', 'score': {'original': 0.9594, 'ai': 0.0406}, 'blocks': [{'text': ""You could always use loops instead of recursion.\n\nTry writing a binary tree traversal as a loop sometime. It's not difficult, although you may be surprised by some of the corner conditions you encounter. Then compare it to the recursive function implementation. Which one is clearer and easier to follow?\n\nWith the loop-based version, it turns out that you still have recursion. It's just data recursion. You have to build a stack manually. With code recursion, the compiler does it for you."", 'result': {'fake': 0.0406, 'real': 0.9594}, 'status': 'success'}], 'credits_used': 1, 'credits': 1986455, 'subscription': 0, 'content': ""You could always use loops instead of recursion.\n\nTry writing a binary tree traversal as a loop sometime. It's not difficult, although you may be surprised by some of the corner conditions you encounter. Then compare it to the recursive function implementation. Which one is clearer and easier to follow?\n\nWith the loop-based version, it turns out that you still have recursion. It's just data recursion. You have to build a stack manually. With code recursion, the compiler does it for you."", 'aiModelVersion': '1'}",0.9594
Jeff Erickson,Updated 10mo,"Why can’t I come up with a solution of algorithm design, but when I see the code I can understand everything? Are there any techniques I should work on?","Because P≠NP.

You’re basically asking “Why do I have trouble solving Sudoku puzzles, even though I can verify that a solution is correct?” or “Why do I have trouble taking integrals is my calculus test, even though I have no trouble understanding the exam solutions?” or “Why can’t I perform the cups-and-balls trick, when I know exactly how it works?” Solving problems is always harder than checking solutions.

In fact you don’t understand everything. You understand the solution, but you don’t understand the process of deriving the solution, and the design process is what you’re supposed to be learning in your algorithms class.

More strongly: Understanding is a seductive lie. That comfortable feeling of “Oh, I get it.” when you see the work someone else has done is your brain’s defense mechanism against having to do the work itself. You goal should not be understanding, but mastery. Not knowing the thing, but actually doing the thing.

So how do you get better at the thing? Practice and feedback. The only way to get better at writing is to write. Grass is green. The only way to get better at cooking is to cook. The sky is blue. The only way to get better at designing algorithms is to design algorithms. Water is wet.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/7hmqnd4fetz6cwj9', 'title': 'Why can’t I come up with a solution of algorithm design, but when I see the code I can understand everything? Are there any techniques I should work on?', 'score': {'original': 0.9996, 'ai': 0.0004}, 'blocks': [{'text': 'Because P≠NP.\n\nYou’re basically asking “Why do I have trouble solving Sudoku puzzles, even though I can verify that a solution is correct?” or “Why do I have trouble taking integrals is my calculus test, even though I have no trouble understanding the exam solutions?” or “Why can’t I perform the cups-and-balls trick, when I know exactly how it works?” Solving problems is always harder than checking solutions.\n\nIn fact you don’t understand everything. You understand the solution, but you don’t understand the process of deriving the solution, and the design process is what you’re supposed to be learning in your algorithms class.\n\nMore strongly: Understanding is a seductive lie. That comfortable feeling of “Oh, I get it.” when you see the work someone else has done is your brain’s defense mechanism against having to do the work itself. You goal should not be understanding, but mastery. Not knowing the thing, but actually doing the thing.\n\nSo how do you get better at the thing? Practice and feedback. The only way to get better at writing is to write. Grass is green. The only way to get better at cooking is to cook. The sky is blue. The only way to get better at designing algorithms is to design algorithms. Water is wet.', 'result': {'fake': 0.0004, 'real': 0.9996}, 'status': 'success'}], 'credits_used': 3, 'credits': 1986452, 'subscription': 0, 'content': 'Because P≠NP.\n\nYou’re basically asking “Why do I have trouble solving Sudoku puzzles, even though I can verify that a solution is correct?” or “Why do I have trouble taking integrals is my calculus test, even though I have no trouble understanding the exam solutions?” or “Why can’t I perform the cups-and-balls trick, when I know exactly how it works?” Solving problems is always harder than checking solutions.\n\nIn fact you don’t understand everything. You understand the solution, but you don’t understand the process of deriving the solution, and the design process is what you’re supposed to be learning in your algorithms class.\n\nMore strongly: Understanding is a seductive lie. That comfortable feeling of “Oh, I get it.” when you see the work someone else has done is your brain’s defense mechanism against having to do the work itself. You goal should not be understanding, but mastery. Not knowing the thing, but actually doing the thing.\n\nSo how do you get better at the thing? Practice and feedback. The only way to get better at writing is to write. Grass is green. The only way to get better at cooking is to cook. The sky is blue. The only way to get better at designing algorithms is to design algorithms. Water is wet.', 'aiModelVersion': '1'}",0.9996
Y. Wang,6y,What is the strangest sorting algorithm?,"I didn't invent this. I saw it somewhere.

A student went to a copy shop to print some materials. He wanted to print 2 copies. Somehow, instead of printing out 2 copies, he printed every pages twice. Let me illustrate.

Pages he wanted : 1 2 3 4 … N; 1 2 3 4 … N

Pages he got: 1 1 2 2 3 3 4 4 …. N N

So when he was trying to sort the pages by picking up one and putting on the left pile and then picking another and putting on the right pile, the owner of the shop took over.

He first put the first page on left and then picked 2 pages and put on the right, then 2 left, 2 right ……

Sorting speed doubled……","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/4r8iup7b0ajvmzfo', 'title': 'What is the strangest sorting algorithm?', 'score': {'original': 0.9994, 'ai': 0.0006}, 'blocks': [{'text': ""I didn't invent this. I saw it somewhere.\n\nA student went to a copy shop to print some materials. He wanted to print 2 copies. Somehow, instead of printing out 2 copies, he printed every pages twice. Let me illustrate.\n\nPages he wanted : 1 2 3 4 … N; 1 2 3 4 … N\n\nPages he got: 1 1 2 2 3 3 4 4 …. N N\n\nSo when he was trying to sort the pages by picking up one and putting on the left pile and then picking another and putting on the right pile, the owner of the shop took over.\n\nHe first put the first page on left and then picked 2 pages and put on the right, then 2 left, 2 right ……\n\nSorting speed doubled……"", 'result': {'fake': 0.0006, 'real': 0.9994}, 'status': 'success'}], 'credits_used': 2, 'credits': 1986450, 'subscription': 0, 'content': ""I didn't invent this. I saw it somewhere.\n\nA student went to a copy shop to print some materials. He wanted to print 2 copies. Somehow, instead of printing out 2 copies, he printed every pages twice. Let me illustrate.\n\nPages he wanted : 1 2 3 4 … N; 1 2 3 4 … N\n\nPages he got: 1 1 2 2 3 3 4 4 …. N N\n\nSo when he was trying to sort the pages by picking up one and putting on the left pile and then picking another and putting on the right pile, the owner of the shop took over.\n\nHe first put the first page on left and then picked 2 pages and put on the right, then 2 left, 2 right ……\n\nSorting speed doubled……"", 'aiModelVersion': '1'}",0.9994
Kaushal Hooda,Updated 10y,How exactly does a chess computer work?,"BY THE POWER OF MATHEMATICS!

A chess computer works exactly as any other computer works - by reducing the problem to a bunch of dumb calculations. Because that's what computers are good at. Of course, modern chess algorithms are pretty complicated, but the essence is not that hard to grasp.

Step 1 : Constructing a Tree

Let's say you've got a chessboard set up, with each player having 16 pieces. And it is the computer's turn. Now, the computer can make 1 of 20 possible moves (2 each for the 8 pawns, plus 2 each for the knights). And, in response to any of those moves, the opponent can make 20 possible moves. So, two moves into the game, we have 20*20 = 400 possible scenarios.
Now the computer has around 20 or so ways to respond to each of these 400 scenarios.


And so this tree keeps growing. In theory, the perfect computer would be able to get to the very bottom of this tree, and look at all possible configurations of the board, approximately 10^120. Then it would see which are the paths down this tree that lead to its victory, and choose accordingly.

Step 2 : Evaluating the outcomes

But there's a problem. 10^120 is a very friggin' huge number. Contrast the total estimated atoms in the universe - 10^75, and you get an idea how large. We'd be sitting around waiting for the damn thing to make its move till the universe ended.

So what real computers do is build up this tree to the best of their hardware capabilities - 5, or 10, or 20 or whatever moves into the future. Once they have this limited tree, they evaluate each position using an evaluation function.

For a really simple example, an evaluation function could be the
number of pieces the computer has - number of pieces opponent has.
For example, the computer has 10 pieces left on the board, the opponent has only 8. Then the computer would evaluate such a board to 10 - 8 = 2.
Of course, that's not a very good evaluation function, but you get the idea. This can be made more and more complicated - taking into account the value of individual pieces, board position, control of the centre, vulnerability of the king to check, vulnerability of the opponent's queen, and tons of other parameters.
Whatever the function, it allows a computer to compare board positions, to see which are the desirable outcomes.

Step 3 : Making a move

The analysis done, it's time to make a decision. Let's make up a simplified tree.


The computer, playing as white, has to decide it's move. It constructs the tree above and applies what is called the Minimax
 Algorithm.

It starts from the bottom (3rd) level, and chooses the one with the maximum score. Consider the left-most square in the 2nd level. It has two possible outcomes - 2 and 8. Since it will be the computer's turn at that stage, it chooses the best outcome, ie., the one with MAX score, which is 8, and so it assigns 8 to that node. Similarly for all the nodes in the 2nd level.


Now, for the second level, the outcome is decided by the opponent - since at that time, it will be black's turn. The computer assumes that black will make the move which is best for black, and so the worst for white, hence it chooses the setups with MIN score. For example, for the centre node on the first level, there are three possibilities - 9, 5, and 9. The computer assumes black will take the one that leaves the computer weakest, and that is 5. So, the first level nodes are all given values.


Finally, the first level is the computer's turn, so it makes the choice with MAX score, ie, 7.

Thus the computer climbs the tree, alternatively choosing minimum and maximum scores (Thus the name MINIMAX), and makes the choice that leaves it best off in the end. The better the hardware, the deeper the depth of the tree it can analyse, and so the better its chances of winning. Which is why computers couldn't usually beat humans in the 1950-60s, but now are regularly able to wallop Grandmasters. (Human–computer chess matches
)


Bonus Step : But there's more!

The procedure I've described is an extremely simplified version of what really happens. In practice, the computer nowadays uses a lot of trick to reduce its efforts, tries to avoid going down paths that are clearly hopeless. Alpha–beta pruning
, Endgame tablebase
, Killer heuristic
 etc etc... It's pretty complicated stuff. Seriously, you could do a PhD in CS studying this stuff.


But I hope my answer at least gives you a general picture of what's going on in the computer's silicon neurons.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/lhkwc83t0pz5fjg4', 'title': 'How exactly does a chess computer work?', 'score': {'original': 0.3618, 'ai': 0.6382}, 'blocks': [{'text': ""BY THE POWER OF MATHEMATICS!\n\nA chess computer works exactly as any other computer works - by reducing the problem to a bunch of dumb calculations. Because that's what computers are good at. Of course, modern chess algorithms are pretty complicated, but the essence is not that hard to grasp.\n\nStep 1 : Constructing a Tree\n\nLet's say you've got a chessboard set up, with each player having 16 pieces. And it is the computer's turn. Now, the computer can make 1 of 20 possible moves (2 each for the 8 pawns, plus 2 each for the knights). And, in response to any of those moves, the opponent can make 20 possible moves. So, two moves into the game, we have 20*20 = 400 possible scenarios.\nNow the computer has around 20 or so ways to respond to each of these 400 scenarios.\n\n\nAnd so this tree keeps growing. In theory, the perfect computer would be able to get to the very bottom of this tree, and look at all possible configurations of the board, approximately 10^120. Then it would see which are the paths down this tree that lead to its victory, and choose accordingly.\n\nStep 2 : Evaluating the outcomes\n\nBut there's a problem. 10^120 is a very friggin' huge number. Contrast the total estimated atoms in the universe - 10^75, and you get an idea how large. We'd be sitting around waiting for the damn thing to make its move till the universe ended.\n\nSo what real computers do is build up this tree to the best of their hardware capabilities - 5, or 10, or 20 or whatever moves into the future. Once they have this limited tree, they evaluate each position using an evaluation function.\n\nFor a really simple example, an evaluation function could be the\nnumber of pieces the computer has - number of pieces opponent has.\nFor example, the computer has 10 pieces left on the board, the opponent has only 8. Then the computer would evaluate such a board to 10 - 8 = 2.\nOf course, that's not a very good evaluation function, but you get the idea. This can be made more and more complicated - taking into account the value of individual pieces, board position, control of the centre, vulnerability of the king to check, vulnerability of the opponent's queen, and tons of other parameters.\nWhatever the function, it allows a computer to compare board positions, to see which are the desirable outcomes.\n\nStep 3 : Making a move\n\nThe analysis done, it's time to make a decision. Let's make up a simplified tree.\n\n\nThe computer, playing as white, has to decide it's move. It constructs the tree above and applies what is called the Minimax\n Algorithm.\n\nIt starts from the bottom (3rd) level, and chooses the one with the maximum score. Consider the left-most square in the 2nd level. It has two possible outcomes - 2 and 8. Since it will be the computer's turn at that stage, it chooses the best outcome, ie., the one with MAX score, which is 8, and so it assigns 8 to that node. Similarly for all the nodes in the"", 'result': {'fake': 0.7453, 'real': 0.2547}, 'status': 'success'}, {'text': ""2nd level.\n\n\nNow, for the second level, the outcome is decided by the opponent - since at that time, it will be black's turn. The computer assumes that black will make the move which is best for black, and so the worst for white, hence it chooses the setups with MIN score. For example, for the centre node on the first level, there are three possibilities - 9, 5, and 9. The computer assumes black will take the one that leaves the computer weakest, and that is 5. So, the first level nodes are all given values.\n\n\nFinally, the first level is the computer's turn, so it makes the choice with MAX score, ie, 7.\n\nThus the computer climbs the tree, alternatively choosing minimum and maximum scores (Thus the name MINIMAX), and makes the choice that leaves it best off in the end. The better the hardware, the deeper the depth of the tree it can analyse, and so the better its chances of winning. Which is why computers couldn't usually beat humans in the 1950-60s, but now are regularly able to wallop Grandmasters. (Human–computer chess matches\n)\n\n\nBonus Step : But there's more!\n\nThe procedure I've described is an extremely simplified version of what really happens. In practice, the computer nowadays uses a lot of trick to reduce its efforts, tries to avoid going down paths that are clearly hopeless. Alpha–beta pruning\n, Endgame tablebase\n, Killer heuristic\n etc etc... It's pretty complicated stuff. Seriously, you could do a PhD in CS studying this stuff.\n\n\nBut I hope my answer at least gives you a general picture of what's going on in the computer's silicon neurons."", 'result': {'fake': 0.339, 'real': 0.661}, 'status': 'success'}], 'credits_used': 8, 'credits': 1986442, 'subscription': 0, 'content': ""BY THE POWER OF MATHEMATICS!\n\nA chess computer works exactly as any other computer works - by reducing the problem to a bunch of dumb calculations. Because that's what computers are good at. Of course, modern chess algorithms are pretty complicated, but the essence is not that hard to grasp.\n\nStep 1 : Constructing a Tree\n\nLet's say you've got a chessboard set up, with each player having 16 pieces. And it is the computer's turn. Now, the computer can make 1 of 20 possible moves (2 each for the 8 pawns, plus 2 each for the knights). And, in response to any of those moves, the opponent can make 20 possible moves. So, two moves into the game, we have 20*20 = 400 possible scenarios.\nNow the computer has around 20 or so ways to respond to each of these 400 scenarios.\n\n\nAnd so this tree keeps growing. In theory, the perfect computer would be able to get to the very bottom of this tree, and look at all possible configurations of the board, approximately 10^120. Then it would see which are the paths down this tree that lead to its victory, and choose accordingly.\n\nStep 2 : Evaluating the outcomes\n\nBut there's a problem. 10^120 is a very friggin' huge number. Contrast the total estimated atoms in the universe - 10^75, and you get an idea how large. We'd be sitting around waiting for the damn thing to make its move till the universe ended.\n\nSo what real computers do is build up this tree to the best of their hardware capabilities - 5, or 10, or 20 or whatever moves into the future. Once they have this limited tree, they evaluate each position using an evaluation function.\n\nFor a really simple example, an evaluation function could be the\nnumber of pieces the computer has - number of pieces opponent has.\nFor example, the computer has 10 pieces left on the board, the opponent has only 8. Then the computer would evaluate such a board to 10 - 8 = 2.\nOf course, that's not a very good evaluation function, but you get the idea. This can be made more and more complicated - taking into account the value of individual pieces, board position, control of the centre, vulnerability of the king to check, vulnerability of the opponent's queen, and tons of other parameters.\nWhatever the function, it allows a computer to compare board positions, to see which are the desirable outcomes.\n\nStep 3 : Making a move\n\nThe analysis done, it's time to make a decision. Let's make up a simplified tree.\n\n\nThe computer, playing as white, has to decide it's move. It constructs the tree above and applies what is called the Minimax\n Algorithm.\n\nIt starts from the bottom (3rd) level, and chooses the one with the maximum score. Consider the left-most square in the 2nd level. It has two possible outcomes - 2 and 8. Since it will be the computer's turn at that stage, it chooses the best outcome, ie., the one with MAX score, which is 8, and so it assigns 8 to that node. Similarly for all the nodes in the 2nd level.\n\n\nNow, for the second level, the outcome is decided by the opponent - since at that time, it will be black's turn. The computer assumes that black will make the move which is best for black, and so the worst for white, hence it chooses the setups with MIN score. For example, for the centre node on the first level, there are three possibilities - 9, 5, and 9. The computer assumes black will take the one that leaves the computer weakest, and that is 5. So, the first level nodes are all given values.\n\n\nFinally, the first level is the computer's turn, so it makes the choice with MAX score, ie, 7.\n\nThus the computer climbs the tree, alternatively choosing minimum and maximum scores (Thus the name MINIMAX), and makes the choice that leaves it best off in the end. The better the hardware, the deeper the depth of the tree it can analyse, and so the better its chances of winning. Which is why computers couldn't usually beat humans in the 1950-60s, but now are regularly able to wallop Grandmasters. (Human–computer chess matches\n)\n\n\nBonus Step : But there's more!\n\nThe procedure I've described is an extremely simplified version of what really happens. In practice, the computer nowadays uses a lot of trick to reduce its efforts, tries to avoid going down paths that are clearly hopeless. Alpha–beta pruning\n, Endgame tablebase\n, Killer heuristic\n etc etc... It's pretty complicated stuff. Seriously, you could do a PhD in CS studying this stuff.\n\n\nBut I hope my answer at least gives you a general picture of what's going on in the computer's silicon neurons."", 'aiModelVersion': '1'}",0.3618
Jerry Coffin,4y,What is the most inefficient sort in computer science?,"Bogobogosort

I had previously believed this “honor” probably belonged to the bogobogosort (note the extra “bogo” there—this is not your garden variety bogosort. Nonetheless, as you can probably guess from the name, bogobogosort is based on and fairly similar to the bogosort.

To understand bogobogosort, we first have to outline the basic idea of bogosort, which is:

randomize the order of the elements
check of they’re in order
if not, repeat from step 1

So, for N elements, there are N! possible arrangements, and checking if the elements are in order is linear, so overall complexity is O(N * N!) (which is sometimes represented as O((N+1)!)—which is technically accurate, but unnecessarily pessimistic, though not by a large factor).

The general idea of bogobogosort is similar, but in step 2, it specifies a somewhat more complex method of finding whether the elements are in order. In the vanilla bogosort, you do the obvious: walk though the collection and check whether each item is larger than its predecessor.

Bogobogosort is clearly superior, because it uses recursion. To test whether N elements are in order, you first copy the collection, then do a bogobogosort on the first N-1 elements, then check whether element N is greater than element N-1, then check whether this sorted-sub-list is in the same order as the original one.

At least according to an analysis by Nathan Collins, this has an overall complexity of 
O
(
n
!
n
−
k
)
O(n!n−k)
—dramatically worse than the basic bogosort.

For what it’s worth, the inventor did test bogobogosort. Its complexity is high enough that he only ever sorted up to 6 elements. 5 elements sorted in less than a second. Six elements took 450 seconds. He tried to sort 7 elements, but gave up after it ran overnight without finishing.

Beating Bogobogosort

To provide a proper answer to this question, however, I did a little research, and found something named Worst Sort. The notion of worst sort is similar to that of the bogobogosort: start with a terrible algorithm, then use recursion to make it arbitrarily worse. Worst sort, however, is more of a generalized meta-algorithm though, so it doesn’t specify all the parameters to be used. In particular, it specifies use of a function to determine the recursion depth, but doesn’t specify the exact function to be used. One common suggestion is apparently the Ackerman function (known for extremely fast growth itself).

Depending on the function you use, its complexity can be arbitrarily high.

My own entry

I’ve invented an algorithm that’s a bit difficult to compare to the others. The basic idea is fairly simple:

Check whether the elements are in order
If not, repeat from step 1

This may not seem like it’s going any sorting at all, and that’s sort of true. What it’s doing is waiting for cosmic rays to flip bits in the elements of the collection so they happen to come out in order.

This adds another element to the equation: its speed depends on how well protected you are from cosmic rays. For example, the higher your altitude, the faster it’s likely to complete.

Its complexity also depends on the number of *bits* involved in the out or order condition. For example, sorting two 8-bit bytes may be faster than sorting two 64-bit words.

For the moment, however, let’s consider sorting two 64-bit words with the values 0xAAAAAAAAAAAAAAAA and 0x5555555555555555. This is a reasonable approximation of a worst case—it requires that every bit in each word be flipped simultaneously for the result to be equal to the original values, but in their proper order. As noted, the exact speed will depend on altitude (and other factors controlling cosmic rays), but a quick computation indicates that at the current level of cosmic radiation on earth at sea level, just getting those two elements in order is unlikely to happen before the heat death of the universe.

This is sort of cheating though, since it doesn’t (itself) take any action that contributes toward the elements getting into order.

Reference

DM's Esoteric Programming Languages","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/c8rye9ij3n5qaslh', 'title': 'What is the most inefficient sort in computer science?', 'score': {'original': 0.8973, 'ai': 0.1027}, 'blocks': [{'text': 'Bogobogosort\n\nI had previously believed this “honor” probably belonged to the bogobogosort (note the extra “bogo” there—this is not your garden variety bogosort. Nonetheless, as you can probably guess from the name, bogobogosort is based on and fairly similar to the bogosort.\n\nTo understand bogobogosort, we first have to outline the basic idea of bogosort, which is:\n\nrandomize the order of the elements\ncheck of they’re in order\nif not, repeat from step 1\n\nSo, for N elements, there are N! possible arrangements, and checking if the elements are in order is linear, so overall complexity is O(N * N!) (which is sometimes represented as O((N+1)!)—which is technically accurate, but unnecessarily pessimistic, though not by a large factor).\n\nThe general idea of bogobogosort is similar, but in step 2, it specifies a somewhat more complex method of finding whether the elements are in order. In the vanilla bogosort, you do the obvious: walk though the collection and check whether each item is larger than its predecessor.\n\nBogobogosort is clearly superior, because it uses recursion. To test whether N elements are in order, you first copy the collection, then do a bogobogosort on the first N-1 elements, then check whether element N is greater than element N-1, then check whether this sorted-sub-list is in the same order as the original one.\n\nAt least according to an analysis by Nathan Collins, this has an overall complexity of \nO\n(\nn\n!\nn\n−\nk\n)\nO(n!n−k)\n—dramatically worse than the basic bogosort.\n\nFor what it’s worth, the inventor did test bogobogosort. Its complexity is high enough that he only ever sorted up to 6 elements. 5 elements sorted in less than a second. Six elements took 450 seconds. He tried to sort 7 elements, but gave up after it ran overnight without finishing.\n\nBeating Bogobogosort\n\nTo provide a proper answer to this question, however, I did a little research, and found something named Worst Sort. The notion of worst sort is similar to that of the bogobogosort: start with a terrible algorithm, then use recursion to make it arbitrarily worse. Worst sort, however, is more of a generalized meta-algorithm though, so it doesn’t specify all the parameters to be used. In particular, it specifies use of a function to determine the recursion depth, but doesn’t specify the exact function to be used. One common suggestion is apparently the Ackerman function (known for extremely fast growth itself).\n\nDepending on the function you use, its complexity can be arbitrarily high.\n\nMy own entry\n\nI’ve invented an algorithm that’s a bit difficult to compare to the others. The basic idea is fairly simple:\n\nCheck whether the elements are in order\nIf not, repeat from step 1\n\nThis may not seem like it’s going any sorting at all, and that’s sort of true. What it’s doing is waiting for cosmic rays to flip bits in the elements of the collection so they happen to come out in order.\n\nThis adds another element to the equation: its speed depends on how well protected you are from cosmic rays. For example, the higher your altitude, the faster it’s likely to complete.\n\nIts complexity also depends on the number of *bits* involved in the out or order condition. For example,', 'result': {'fake': 0.0006, 'real': 0.9994}, 'status': 'success'}, {'text': ""sorting two 8-bit bytes may be faster than sorting two 64-bit words.\n\nFor the moment, however, let’s consider sorting two 64-bit words with the values 0xAAAAAAAAAAAAAAAA and 0x5555555555555555. This is a reasonable approximation of a worst case—it requires that every bit in each word be flipped simultaneously for the result to be equal to the original values, but in their proper order. As noted, the exact speed will depend on altitude (and other factors controlling cosmic rays), but a quick computation indicates that at the current level of cosmic radiation on earth at sea level, just getting those two elements in order is unlikely to happen before the heat death of the universe.\n\nThis is sort of cheating though, since it doesn’t (itself) take any action that contributes toward the elements getting into order.\n\nReference\n\nDM's Esoteric Programming Languages"", 'result': {'fake': 0.1327, 'real': 0.8673}, 'status': 'success'}], 'credits_used': 7, 'credits': 1986435, 'subscription': 0, 'content': ""Bogobogosort\n\nI had previously believed this “honor” probably belonged to the bogobogosort (note the extra “bogo” there—this is not your garden variety bogosort. Nonetheless, as you can probably guess from the name, bogobogosort is based on and fairly similar to the bogosort.\n\nTo understand bogobogosort, we first have to outline the basic idea of bogosort, which is:\n\nrandomize the order of the elements\ncheck of they’re in order\nif not, repeat from step 1\n\nSo, for N elements, there are N! possible arrangements, and checking if the elements are in order is linear, so overall complexity is O(N * N!) (which is sometimes represented as O((N+1)!)—which is technically accurate, but unnecessarily pessimistic, though not by a large factor).\n\nThe general idea of bogobogosort is similar, but in step 2, it specifies a somewhat more complex method of finding whether the elements are in order. In the vanilla bogosort, you do the obvious: walk though the collection and check whether each item is larger than its predecessor.\n\nBogobogosort is clearly superior, because it uses recursion. To test whether N elements are in order, you first copy the collection, then do a bogobogosort on the first N-1 elements, then check whether element N is greater than element N-1, then check whether this sorted-sub-list is in the same order as the original one.\n\nAt least according to an analysis by Nathan Collins, this has an overall complexity of \nO\n(\nn\n!\nn\n−\nk\n)\nO(n!n−k)\n—dramatically worse than the basic bogosort.\n\nFor what it’s worth, the inventor did test bogobogosort. Its complexity is high enough that he only ever sorted up to 6 elements. 5 elements sorted in less than a second. Six elements took 450 seconds. He tried to sort 7 elements, but gave up after it ran overnight without finishing.\n\nBeating Bogobogosort\n\nTo provide a proper answer to this question, however, I did a little research, and found something named Worst Sort. The notion of worst sort is similar to that of the bogobogosort: start with a terrible algorithm, then use recursion to make it arbitrarily worse. Worst sort, however, is more of a generalized meta-algorithm though, so it doesn’t specify all the parameters to be used. In particular, it specifies use of a function to determine the recursion depth, but doesn’t specify the exact function to be used. One common suggestion is apparently the Ackerman function (known for extremely fast growth itself).\n\nDepending on the function you use, its complexity can be arbitrarily high.\n\nMy own entry\n\nI’ve invented an algorithm that’s a bit difficult to compare to the others. The basic idea is fairly simple:\n\nCheck whether the elements are in order\nIf not, repeat from step 1\n\nThis may not seem like it’s going any sorting at all, and that’s sort of true. What it’s doing is waiting for cosmic rays to flip bits in the elements of the collection so they happen to come out in order.\n\nThis adds another element to the equation: its speed depends on how well protected you are from cosmic rays. For example, the higher your altitude, the faster it’s likely to complete.\n\nIts complexity also depends on the number of *bits* involved in the out or order condition. For example, sorting two 8-bit bytes may be faster than sorting two 64-bit words.\n\nFor the moment, however, let’s consider sorting two 64-bit words with the values 0xAAAAAAAAAAAAAAAA and 0x5555555555555555. This is a reasonable approximation of a worst case—it requires that every bit in each word be flipped simultaneously for the result to be equal to the original values, but in their proper order. As noted, the exact speed will depend on altitude (and other factors controlling cosmic rays), but a quick computation indicates that at the current level of cosmic radiation on earth at sea level, just getting those two elements in order is unlikely to happen before the heat death of the universe.\n\nThis is sort of cheating though, since it doesn’t (itself) take any action that contributes toward the elements getting into order.\n\nReference\n\nDM's Esoteric Programming Languages"", 'aiModelVersion': '1'}",0.8973
Alon Amit,Updated 8y,What are some proofs in mathematics that prove certain tasks are impossible?,"You cannot tile a chessboard with 1x3 domino tiles since 64 is not divisible by 3.
You cannot tile a chessboard with opposite corners removed with 1x2 domino tiles since opposite corners have the same color and each domino must cover one black and one white square.
You can't write 10000000000007 as the sum of three squares of whole numbers.
Given a circle, you cannot construct a square of the same area using a straightedge and a compass.
You cannot hear the shape of a drum (i.e. you cannot infer the shape of a 2d surface with boundary from the spectrum of its Laplacian).[1]
You cannot devise a compression scheme that is guaranteed to shrink every input file.
Better, you cannot compress more efficiently than the source entropy allows.[2]
You cannot write a computer program that will print out all the true statements in the first order language of arithmetic, and only those statements. (this is one of many forms of Gödel's incompleteness theorem).
You cannot write a computer program that accepts a polynomial equation with integer coefficients and correctly determines if that equation has a solution in integers. [3]
You cannot write a computer program that examines the code of any given program and determines if that other program ever halts. [4]
You cannot cut a cube into finitely many polyhedra and reassemble them to make a pyramid with a larger volume.
You cannot cut a cube into finitely many polyhedra and reassemble them to make a pyramid with the *same* volume. [5]

[1] http://en.wikipedia.org/wiki/Hearing_the_shape_of_a_drum

[2] http://en.wikipedia.org/wiki/Shannon%27s_source_coding_theorem

[3] http://en.wikipedia.org/wiki/Hilbert%27s_tenth_problem

[4] http://en.wikipedia.org/wiki/Halting_problem

[5] http://en.wikipedia.org/wiki/Dehn_invariant","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/fmt7w9yidkxposvr', 'title': 'What are some proofs in mathematics that prove certain tasks are impossible?', 'score': {'original': 0.9992, 'ai': 0.0008}, 'blocks': [{'text': ""You cannot tile a chessboard with 1x3 domino tiles since 64 is not divisible by 3.\nYou cannot tile a chessboard with opposite corners removed with 1x2 domino tiles since opposite corners have the same color and each domino must cover one black and one white square.\nYou can't write 10000000000007 as the sum of three squares of whole numbers.\nGiven a circle, you cannot construct a square of the same area using a straightedge and a compass.\nYou cannot hear the shape of a drum (i.e. you cannot infer the shape of a 2d surface with boundary from the spectrum of its Laplacian).[1]\nYou cannot devise a compression scheme that is guaranteed to shrink every input file.\nBetter, you cannot compress more efficiently than the source entropy allows.[2]\nYou cannot write a computer program that will print out all the true statements in the first order language of arithmetic, and only those statements. (this is one of many forms of Gödel's incompleteness theorem).\nYou cannot write a computer program that accepts a polynomial equation with integer coefficients and correctly determines if that equation has a solution in integers. [3]\nYou cannot write a computer program that examines the code of any given program and determines if that other program ever halts. [4]\nYou cannot cut a cube into finitely many polyhedra and reassemble them to make a pyramid with a larger volume.\nYou cannot cut a cube into finitely many polyhedra and reassemble them to make a pyramid with the *same* volume. [5]\n\n[1] http://en.wikipedia.org/wiki/Hearing_the_shape_of_a_drum\n\n[2] http://en.wikipedia.org/wiki/Shannon%27s_source_coding_theorem\n\n[3] http://en.wikipedia.org/wiki/Hilbert%27s_tenth_problem\n\n[4] http://en.wikipedia.org/wiki/Halting_problem\n\n[5] http://en.wikipedia.org/wiki/Dehn_invariant"", 'result': {'fake': 0.0008, 'real': 0.9992}, 'status': 'success'}], 'credits_used': 3, 'credits': 1986432, 'subscription': 0, 'content': ""You cannot tile a chessboard with 1x3 domino tiles since 64 is not divisible by 3.\nYou cannot tile a chessboard with opposite corners removed with 1x2 domino tiles since opposite corners have the same color and each domino must cover one black and one white square.\nYou can't write 10000000000007 as the sum of three squares of whole numbers.\nGiven a circle, you cannot construct a square of the same area using a straightedge and a compass.\nYou cannot hear the shape of a drum (i.e. you cannot infer the shape of a 2d surface with boundary from the spectrum of its Laplacian).[1]\nYou cannot devise a compression scheme that is guaranteed to shrink every input file.\nBetter, you cannot compress more efficiently than the source entropy allows.[2]\nYou cannot write a computer program that will print out all the true statements in the first order language of arithmetic, and only those statements. (this is one of many forms of Gödel's incompleteness theorem).\nYou cannot write a computer program that accepts a polynomial equation with integer coefficients and correctly determines if that equation has a solution in integers. [3]\nYou cannot write a computer program that examines the code of any given program and determines if that other program ever halts. [4]\nYou cannot cut a cube into finitely many polyhedra and reassemble them to make a pyramid with a larger volume.\nYou cannot cut a cube into finitely many polyhedra and reassemble them to make a pyramid with the *same* volume. [5]\n\n[1] http://en.wikipedia.org/wiki/Hearing_the_shape_of_a_drum\n\n[2] http://en.wikipedia.org/wiki/Shannon%27s_source_coding_theorem\n\n[3] http://en.wikipedia.org/wiki/Hilbert%27s_tenth_problem\n\n[4] http://en.wikipedia.org/wiki/Halting_problem\n\n[5] http://en.wikipedia.org/wiki/Dehn_invariant"", 'aiModelVersion': '1'}",0.9992
Greg Kemnitz,8y,Why do we need so many sorting algorithms?,"We have many different ones because they satisfy different sorting use-cases. Some examples:


Merge sort 
is useful for sorting linked lists.

Polyphase merge sort 
is useful if the sort set can't fit into RAM.
Heapsort 
is very good for sorting arrays (and is used by many relational db engines for in-memory sorting, or for the memory part of polyphase merge sort). It uses little extra RAM and is very predictable, which is the sort of behavior you want in a db engine.

Quicksort
 has excellent average-case behavior - and poor worst-case behavior - and is the default sort for most sorting library implementations. Its bad worst-case behavior is why it isn't used for db engines.
Insertion sort 
is good if you have a set that is almost sorted; it's good if you have a sorted list that has a couple items added to it occasionally but then needs to be resorted.

Even the much-ridiculed (including by me) Bubble sort
 algorithm has its use case: if you have a very small sort set so you can stand its O(n^2) average case and don't want a lot of code - as it's by far the shortest sort algorithm by simple count of code - it can be used.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/9c3jouwgfdt1bm6x', 'title': 'Why do we need so many sorting algorithms?', 'score': {'original': 0.9984, 'ai': 0.0016}, 'blocks': [{'text': ""We have many different ones because they satisfy different sorting use-cases. Some examples:\n\n\nMerge sort \nis useful for sorting linked lists.\n\nPolyphase merge sort \nis useful if the sort set can't fit into RAM.\nHeapsort \nis very good for sorting arrays (and is used by many relational db engines for in-memory sorting, or for the memory part of polyphase merge sort). It uses little extra RAM and is very predictable, which is the sort of behavior you want in a db engine.\n\nQuicksort\n has excellent average-case behavior - and poor worst-case behavior - and is the default sort for most sorting library implementations. Its bad worst-case behavior is why it isn't used for db engines.\nInsertion sort \nis good if you have a set that is almost sorted; it's good if you have a sorted list that has a couple items added to it occasionally but then needs to be resorted.\n\nEven the much-ridiculed (including by me) Bubble sort\n algorithm has its use case: if you have a very small sort set so you can stand its O(n^2) average case and don't want a lot of code - as it's by far the shortest sort algorithm by simple count of code - it can be used."", 'result': {'fake': 0.0016, 'real': 0.9984}, 'status': 'success'}], 'credits_used': 3, 'credits': 1986429, 'subscription': 0, 'content': ""We have many different ones because they satisfy different sorting use-cases. Some examples:\n\n\nMerge sort \nis useful for sorting linked lists.\n\nPolyphase merge sort \nis useful if the sort set can't fit into RAM.\nHeapsort \nis very good for sorting arrays (and is used by many relational db engines for in-memory sorting, or for the memory part of polyphase merge sort). It uses little extra RAM and is very predictable, which is the sort of behavior you want in a db engine.\n\nQuicksort\n has excellent average-case behavior - and poor worst-case behavior - and is the default sort for most sorting library implementations. Its bad worst-case behavior is why it isn't used for db engines.\nInsertion sort \nis good if you have a set that is almost sorted; it's good if you have a sorted list that has a couple items added to it occasionally but then needs to be resorted.\n\nEven the much-ridiculed (including by me) Bubble sort\n algorithm has its use case: if you have a very small sort set so you can stand its O(n^2) average case and don't want a lot of code - as it's by far the shortest sort algorithm by simple count of code - it can be used."", 'aiModelVersion': '1'}",0.9984
Thomas Cormen,Updated 7y,"How do I plan and complete reading ""Introduction to Algorithms"" and implement a decent number of algorithms within a period of one month?","Do you realize what you are asking? The book has over 1300 pages, and it's highly technical. Just reading and understanding it in one month--never mind implementing a single algorithm--would be a tremendous accomplishment.

If, however, you are determined to read and understand Introduction to Algorithms in one month, then clear your calendar of everything else, except--maybe--for necessary bodily functions. Make sure that your coffee maker is in good working order!","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/01glfx7edmc6sr52', 'title': 'How do I plan and complete reading ""Introduction to Algorithms"" and implement a decent number of algorithms within a period of one month?', 'score': {'original': 0.6598, 'ai': 0.3402}, 'blocks': [{'text': ""Do you realize what you are asking? The book has over 1300 pages, and it's highly technical. Just reading and understanding it in one month--never mind implementing a single algorithm--would be a tremendous accomplishment.\n\nIf, however, you are determined to read and understand Introduction to Algorithms in one month, then clear your calendar of everything else, except--maybe--for necessary bodily functions. Make sure that your coffee maker is in good working order!"", 'result': {'fake': 0.3402, 'real': 0.6598}, 'status': 'success'}], 'credits_used': 1, 'credits': 1986428, 'subscription': 0, 'content': ""Do you realize what you are asking? The book has over 1300 pages, and it's highly technical. Just reading and understanding it in one month--never mind implementing a single algorithm--would be a tremendous accomplishment.\n\nIf, however, you are determined to read and understand Introduction to Algorithms in one month, then clear your calendar of everything else, except--maybe--for necessary bodily functions. Make sure that your coffee maker is in good working order!"", 'aiModelVersion': '1'}",0.6598
Håkon Hapnes Strand,4y,Are complex algorithms and data structure used in day to day programming?,"Well, yes. But it’s probably not like what you think.

Today, I used an algorithm called gradient boosted decision trees. Schematically, it works like this:

It’s a machine learning algorithm that constructs an ensemble of decision trees based on multi-dimensional input data.

Typically, there are hundreds of trees with hundreds of nodes each and the dataset contains millions of data points. I’d say it passes the bar as a complex algorithm.

Here’s the kicker, though: Using this algorithm required one line of code on my part, and it took one second to run. So much for complexity.

That’s the reality of programming. Most of the time, we use implementations of algorithms that are readily available in libraries or even built in to the programming language itself. The algorithms may be very complex, but most of that complexity is already abstracted away.

It can happen that we truly need to implement a complex algorithm from scratch, but it’s not an everyday occurence. The more experienced you become at programming, the less this tends to happen, because you become an expert at exploiting the work of others.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/ej3g9p4vruy65fqn', 'title': 'Are complex algorithms and data structure used in day to day programming?', 'score': {'original': 0.9992, 'ai': 0.0008}, 'blocks': [{'text': 'Well, yes. But it’s probably not like what you think.\n\nToday, I used an algorithm called gradient boosted decision trees. Schematically, it works like this:\n\nIt’s a machine learning algorithm that constructs an ensemble of decision trees based on multi-dimensional input data.\n\nTypically, there are hundreds of trees with hundreds of nodes each and the dataset contains millions of data points. I’d say it passes the bar as a complex algorithm.\n\nHere’s the kicker, though: Using this algorithm required one line of code on my part, and it took one second to run. So much for complexity.\n\nThat’s the reality of programming. Most of the time, we use implementations of algorithms that are readily available in libraries or even built in to the programming language itself. The algorithms may be very complex, but most of that complexity is already abstracted away.\n\nIt can happen that we truly need to implement a complex algorithm from scratch, but it’s not an everyday occurence. The more experienced you become at programming, the less this tends to happen, because you become an expert at exploiting the work of others.', 'result': {'fake': 0.0008, 'real': 0.9992}, 'status': 'success'}], 'credits_used': 2, 'credits': 1986426, 'subscription': 0, 'content': 'Well, yes. But it’s probably not like what you think.\n\nToday, I used an algorithm called gradient boosted decision trees. Schematically, it works like this:\n\nIt’s a machine learning algorithm that constructs an ensemble of decision trees based on multi-dimensional input data.\n\nTypically, there are hundreds of trees with hundreds of nodes each and the dataset contains millions of data points. I’d say it passes the bar as a complex algorithm.\n\nHere’s the kicker, though: Using this algorithm required one line of code on my part, and it took one second to run. So much for complexity.\n\nThat’s the reality of programming. Most of the time, we use implementations of algorithms that are readily available in libraries or even built in to the programming language itself. The algorithms may be very complex, but most of that complexity is already abstracted away.\n\nIt can happen that we truly need to implement a complex algorithm from scratch, but it’s not an everyday occurence. The more experienced you become at programming, the less this tends to happen, because you become an expert at exploiting the work of others.', 'aiModelVersion': '1'}",0.9992
Mark Gritter,1y,How can I write a C++ program for the Tower of Hanoi without recursive functions?,"Many of the answers provide a straightforward solution that converts a recursive algorithm into one using a stack.

But, there are algorithms available that are stack-free, and can handle either solving the problem from the initial state, or an intermediate state.

In the book “The Tower of Hanoi — Myths and Maths” by Andreas Hinz et al, in Chapter 2, the authors introduce “Algorithm 3: Idle Peg algorithm” which operates based on the following idea:

Introduce a thimble starting on the source peg. Each turn, take the thimble in your left hand and move it around the pegs in order, forming a cycle.
Then, with your right hand, make the only legal move avoiding the peg that is blocked by the thimble.

No recursion necessary and no back-tracking stack is required. It’s just a simple loop. But, you do need to track which discs are on which peg in order to do the “legal move” part. You can do this with an array (a location for each disc) or with three stacks, one for each peg.

Algorithm 3 in pseudocode, from the book:

Parameter n: number of disks  
Parameter i: source peg 
Parameter j: goal peg 
 
idle <- i 
dir <- (-1)^n (j-i) 
while not all discs are on peg j: 
  idle <- (idle + dir) mod 3 
  make legal move between pegs different from idle 
end while 

To translate this into C++, I’ll simplify by assuming the source peg is 0 and the destination peg is 1 to get rid of the direction variable. (That means my implementation will only work correctly for even n!) We’ll use stack for each of the pegs so that finding the top disc is constant-time (and so I don’t have to write an extra loop.)

void tower_of_hanoi( int n ) { 
  int idle = 0; 
  std::stack<int> pegs[3]; 
 
  // Number disc 1 through n, n is largest 
  for (int i = 0; i < n; i++ ) { 
     pegs[0].push( n - i ); 
  } 
 
  while ( pegs[1].size() < n ) { 
     idle = (idle + 1) % 3; 
     int from, to; 
     switch (idle) { 
        case 0: from = 1; to = 2; break; 
        case 1: from = 0; to = 2; break; 
        case 2: from = 0; to = 1; break; 
     } 
     // Must move smaller disc to larger disc 
     if ( pegs[from].empty() ||  
          (!pegs[to].empty() && pegs[from].top() > pegs[to].top()) ) { 
         std::swap( from, to ); 
     } 
     int disc = pegs[from].top(); 
     std::cout << ""Move disc "" << disc << "" from "" << from << "" to "" << to <<  ""\n""; 
     pegs[from].pop(); 
     pegs[to].push( disc ); 
  } 
} 

You can see it live at Compiler Explorer - C++ (x86-64 gcc (trunk))

The book contains many other algorithms. For example, here is one that finds the best move to a perfect state, given any arbitrary regular (i.e., legal) state. It’s algorithm 10 in the same chapter:

Parameter n: number of disks 
Parameter s[1..n]: regular state, given as an array 
Parameter j: goal peg 
 
mu <- 0             // length of path 
delta <- n+1        // active disc 
k <- j              // ""state of the P1-automaton"",  
for d = n down to 1 
  if s[d] <> k then 
     mu <- mu + 2^(d-1) 
     delta <- d 
     k <- 3 - k - s[d] 
  end if 
end for 

No stack or recursion necessary! The algorithm gives both the disc to move, and the length of the path to the goal state.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/7w1msn9ic4rz65og', 'title': 'How can I write a C++ program for the Tower of Hanoi without recursive functions?', 'score': {'original': 0.53225, 'ai': 0.46775}, 'blocks': [{'text': 'Many of the answers provide a straightforward solution that converts a recursive algorithm into one using a stack.\n\nBut, there are algorithms available that are stack-free, and can handle either solving the problem from the initial state, or an intermediate state.\n\nIn the book “The Tower of Hanoi — Myths and Maths” by Andreas Hinz et al, in Chapter 2, the authors introduce “Algorithm 3: Idle Peg algorithm” which operates based on the following idea:\n\nIntroduce a thimble starting on the source peg. Each turn, take the thimble in your left hand and move it around the pegs in order, forming a cycle.\nThen, with your right hand, make the only legal move avoiding the peg that is blocked by the thimble.\n\nNo recursion necessary and no back-tracking stack is required. It’s just a simple loop. But, you do need to track which discs are on which peg in order to do the “legal move” part. You can do this with an array (a location for each disc) or with three stacks, one for each peg.\n\nAlgorithm 3 in pseudocode, from the book:\n\nParameter n: number of disks \xa0\nParameter i: source peg\xa0\nParameter j: goal peg\xa0\n\xa0\nidle <- i\xa0\ndir <- (-1)^n (j-i)\xa0\nwhile not all discs are on peg j:\xa0\n  idle <- (idle + dir) mod 3\xa0\n  make legal move between pegs different from idle\xa0\nend while\xa0\n\nTo translate this into C++, I’ll simplify by assuming the source peg is 0 and the destination peg is 1 to get rid of the direction variable. (That means my implementation will only work correctly for even n!) We’ll use stack for each of the pegs so that finding the top disc is constant-time (and so I don’t have to write an extra loop.)\n\nvoid tower_of_hanoi( int n ) {\xa0\n  int idle = 0;\xa0\n  std::stack<int> pegs[3];\xa0\n\xa0\n  // Number disc 1 through n, n is largest\xa0\n  for (int i = 0; i < n; i++ ) {\xa0\n     pegs[0].push( n - i );\xa0\n  }\xa0\n\xa0\n  while ( pegs[1].size() < n ) {\xa0\n     idle = (idle + 1) % 3;\xa0\n     int from, to;\xa0\n     switch (idle) {\xa0\n        case 0: from = 1; to = 2; break;\xa0\n        case 1: from = 0; to = 2; break;\xa0\n        case 2: from = 0; to = 1; break;\xa0\n     }\xa0\n     // Must move smaller disc to larger disc\xa0\n     if ( pegs[from].empty() || \xa0\n          (!pegs[to].empty() && pegs[from].top() > pegs[to].top()) ) {\xa0\n         std::swap( from, to );\xa0\n     }\xa0\n     int disc = pegs[from].top();\xa0\n     std::cout << ""Move disc "" << disc << "" from "" << from << "" to "" << to <<  ""\\n"";\xa0\n     pegs[from].pop();\xa0\n     pegs[to].push( disc', 'result': {'fake': 0.0126, 'real': 0.9874}, 'status': 'success'}, {'text': ');\xa0\n  }\xa0\n}\xa0\n\nYou can see it live at Compiler Explorer - C++ (x86-64 gcc (trunk))\n\nThe book contains many other algorithms. For example, here is one that finds the best move to a perfect state, given any arbitrary regular (i.e., legal) state. It’s algorithm 10 in the same chapter:\n\nParameter n: number of disks\xa0\nParameter s[1..n]: regular state, given as an array\xa0\nParameter j: goal peg\xa0\n\xa0\nmu <- 0             // length of path\xa0\ndelta <- n+1        // active disc\xa0\nk <- j              // ""state of the P1-automaton"", \xa0\nfor d = n down to 1\xa0\n  if s[d] <> k then\xa0\n     mu <- mu + 2^(d-1)\xa0\n     delta <- d\xa0\n     k <- 3 - k - s[d]\xa0\n  end if\xa0\nend for\xa0\n\nNo stack or recursion necessary! The algorithm gives both the disc to move, and the length of the path to the goal state.', 'result': {'fake': 0.5332, 'real': 0.4668}, 'status': 'success'}], 'credits_used': 6, 'credits': 1986420, 'subscription': 0, 'content': 'Many of the answers provide a straightforward solution that converts a recursive algorithm into one using a stack.\n\nBut, there are algorithms available that are stack-free, and can handle either solving the problem from the initial state, or an intermediate state.\n\nIn the book “The Tower of Hanoi — Myths and Maths” by Andreas Hinz et al, in Chapter 2, the authors introduce “Algorithm 3: Idle Peg algorithm” which operates based on the following idea:\n\nIntroduce a thimble starting on the source peg. Each turn, take the thimble in your left hand and move it around the pegs in order, forming a cycle.\nThen, with your right hand, make the only legal move avoiding the peg that is blocked by the thimble.\n\nNo recursion necessary and no back-tracking stack is required. It’s just a simple loop. But, you do need to track which discs are on which peg in order to do the “legal move” part. You can do this with an array (a location for each disc) or with three stacks, one for each peg.\n\nAlgorithm 3 in pseudocode, from the book:\n\nParameter n: number of disks \xa0\nParameter i: source peg\xa0\nParameter j: goal peg\xa0\n\xa0\nidle <- i\xa0\ndir <- (-1)^n (j-i)\xa0\nwhile not all discs are on peg j:\xa0\n  idle <- (idle + dir) mod 3\xa0\n  make legal move between pegs different from idle\xa0\nend while\xa0\n\nTo translate this into C++, I’ll simplify by assuming the source peg is 0 and the destination peg is 1 to get rid of the direction variable. (That means my implementation will only work correctly for even n!) We’ll use stack for each of the pegs so that finding the top disc is constant-time (and so I don’t have to write an extra loop.)\n\nvoid tower_of_hanoi( int n ) {\xa0\n  int idle = 0;\xa0\n  std::stack<int> pegs[3];\xa0\n\xa0\n  // Number disc 1 through n, n is largest\xa0\n  for (int i = 0; i < n; i++ ) {\xa0\n     pegs[0].push( n - i );\xa0\n  }\xa0\n\xa0\n  while ( pegs[1].size() < n ) {\xa0\n     idle = (idle + 1) % 3;\xa0\n     int from, to;\xa0\n     switch (idle) {\xa0\n        case 0: from = 1; to = 2; break;\xa0\n        case 1: from = 0; to = 2; break;\xa0\n        case 2: from = 0; to = 1; break;\xa0\n     }\xa0\n     // Must move smaller disc to larger disc\xa0\n     if ( pegs[from].empty() || \xa0\n          (!pegs[to].empty() && pegs[from].top() > pegs[to].top()) ) {\xa0\n         std::swap( from, to );\xa0\n     }\xa0\n     int disc = pegs[from].top();\xa0\n     std::cout << ""Move disc "" << disc << "" from "" << from << "" to "" << to <<  ""\\n"";\xa0\n     pegs[from].pop();\xa0\n     pegs[to].push( disc );\xa0\n  }\xa0\n}\xa0\n\nYou can see it live at Compiler Explorer - C++ (x86-64 gcc (trunk))\n\nThe book contains many other algorithms. For example, here is one that finds the best move to a perfect state, given any arbitrary regular (i.e., legal) state. It’s algorithm 10 in the same chapter:\n\nParameter n: number of disks\xa0\nParameter s[1..n]: regular state, given as an array\xa0\nParameter j: goal peg\xa0\n\xa0\nmu <- 0             // length of path\xa0\ndelta <- n+1        // active disc\xa0\nk <- j              // ""state of the P1-automaton"", \xa0\nfor d = n down to 1\xa0\n  if s[d] <> k then\xa0\n     mu <- mu + 2^(d-1)\xa0\n     delta <- d\xa0\n     k <- 3 - k - s[d]\xa0\n  end if\xa0\nend for\xa0\n\nNo stack or recursion necessary! The algorithm gives both the disc to move, and the length of the path to the goal state.', 'aiModelVersion': '1'}",0.53225
Tarun Chitra,9y,Have there been any new brilliant computer science algorithms in last 10 years?,"Fully Homomorphic Encryption (FHE)Imagine if you were a hospital that needed to process/analyze data on EC2, but were worried about privacy. In an ideal world, one would like:To encrypt his or her dataSend the encrypted data to the cloud and have the cloud servers operate on the encypted data (yes, I mean that)Sending you back the encrypted results, that you can easily decryptThis probably seems like magic — after all, how can someone operate on garbled data, creating more garbled data and then send me back some junk that is guaranteed to decrypt to the correct answer? It turns out that since most cryptosystems inherit symmetries/operations from the mathematical objects that they are based on (groups, rings, lattices, algebraic number fields), we can sometimes use these operations without breaking our encryption.  Before giving some details about FHE, let's look at an example. Suppose that I give you an RSA public key (N,e)(N,e)(N,e)  and suppose that the secret key is d≡e−1 mod ϕ(N)d≡e−1 mod ϕ(N) d \equiv e^{-1} \text{ mod } \phi(N). Then two plaintexts π1,π2∈Zπ1,π2∈Z\pi_1, \pi_2 \in \Z would become ciphertexts ψ1,ψ2ψ1,ψ2\psi_1, \psi_2, where ψ1=πe1 mod N,ψ2=πe2 mod Nψ1=π1e mod N,ψ2=π2e mod N \psi_1 = \pi_1^e \text{ mod } N, \psi_2 = \pi_2^e \text{ mod } N Note that, π1π2 mod N=(ψd1 mod N)(ψd2 mod N)=π1π2 mod N=(ψ1d mod N)(ψ2d mod N)= \pi_1 \pi_2 \text{ mod } N = (\psi_1^d \text{ mod } N) (\psi_2^d \text{ mod } N) = (ψ1ψ2)d mod N(ψ1ψ2)d mod N (\psi_1 \psi_2)^d  \text{ mod } Nso that the decryption of the product of two ciphertexts is equivalent (mod N) to the product of the two plaintexts. Our goal is to make a system that is both multiplicatively homomorphic (like RSA) as well as additively homomorphic (which RSA is not, as you can see from the binomial formula). Note that in this about process, the cloud servers never see your raw data. Fully homomorphic encrypytion makes this happen. The landmark paper/thesis [0] of Gentry (2009) led to some astonishing revelations about simple encryption schemes:As long as a scheme can evaluate its own decryption circuit as well as a single NAND gate, one can bootstrap this scheme to a fully homomorphic schemeTechniques used to prove guarantees of post-quantum security turn out to be useful for proving that a bootstrappable homomorphic encryption scheme existsEven very simple integer schemes can workIn particular, van Dijk, Gentry, Halevi and Vaikunthan (DGHV) proved in [1] that a cryptography scheme that is simpler than RSA (!!!) isHomomorphic for virtually unlimited number of additive gates, homomorphic for small numbers of multiplicative gatesBootstrappableSo simple and clean (relative to other cryptosystems, e.g. NTRU) that it was casually proposed on a message board in 2000 by Bram CohenLater, Vaikunthan and Brakerski proved that one can construct non-bootstrappable homomorphic encryption schemes [2] that base their security on stronger, post-quantum problems (e.g. Learning with Errors). This scheme appears to be more practical than the original bootstrapping schemes (although it still uses bootstrapping as 'an optimization').  A nice non-technical summary can be found on the MIT tech review [3] [0] Craig Gentry's PhD Thesis[1] Page on microsoft.com[2] Page on iacr.org[3] Homomorphic Encryption - MIT Technology Review","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/peh1b6f4qylrw3jo', 'title': 'Have there been any new brilliant computer science algorithms in last 10 years?', 'score': {'original': 0.9986, 'ai': 0.0014}, 'blocks': [{'text': ""Fully Homomorphic Encryption (FHE)Imagine if you were a hospital that needed to process/analyze data on EC2, but were worried about privacy. In an ideal world, one would like:To encrypt his or her dataSend the encrypted data to the cloud and have the cloud servers operate on the encypted data (yes, I mean that)Sending you back the encrypted results, that you can easily decryptThis probably seems like magic — after all, how can someone operate on garbled data, creating more garbled data and then send me back some junk that is guaranteed to decrypt to the correct answer? It turns out that since most cryptosystems inherit symmetries/operations from the mathematical objects that they are based on (groups, rings, lattices, algebraic number fields), we can sometimes use these operations without breaking our encryption.  Before giving some details about FHE, let's look at an example. Suppose that I give you an RSA public key (N,e)(N,e)(N,e)  and suppose that the secret key is d≡e−1\xa0mod\xa0ϕ(N)d≡e−1\xa0mod\xa0ϕ(N) d \\equiv e^{-1} \\text{ mod } \\phi(N). Then two plaintexts π1,π2∈Zπ1,π2∈Z\\pi_1, \\pi_2 \\in \\Z would become ciphertexts ψ1,ψ2ψ1,ψ2\\psi_1, \\psi_2, where ψ1=πe1\xa0mod\xa0N,ψ2=πe2\xa0mod\xa0Nψ1=π1e\xa0mod\xa0N,ψ2=π2e\xa0mod\xa0N \\psi_1 = \\pi_1^e \\text{ mod } N, \\psi_2 = \\pi_2^e \\text{ mod } N Note that, π1π2\xa0mod\xa0N=(ψd1\xa0mod\xa0N)(ψd2\xa0mod\xa0N)=π1π2\xa0mod\xa0N=(ψ1d\xa0mod\xa0N)(ψ2d\xa0mod\xa0N)= \\pi_1 \\pi_2 \\text{ mod } N = (\\psi_1^d \\text{ mod } N) (\\psi_2^d \\text{ mod } N) = (ψ1ψ2)d\xa0mod\xa0N(ψ1ψ2)d\xa0mod\xa0N (\\psi_1 \\psi_2)^d  \\text{ mod } Nso that the decryption of the product of two ciphertexts is equivalent (mod N) to the product of the two plaintexts. Our goal is to make a system that is both multiplicatively homomorphic (like RSA) as well as additively homomorphic (which RSA is not, as you can see from the binomial formula). Note that in this about process, the cloud servers never see your raw data. Fully homomorphic encrypytion makes this happen. The landmark paper/thesis [0] of Gentry (2009) led to some astonishing revelations about simple encryption schemes:As long as a scheme can evaluate its own decryption circuit as well as a single NAND gate, one can bootstrap this scheme to a fully homomorphic schemeTechniques used to prove guarantees of post-quantum security turn out to be useful for proving that a bootstrappable homomorphic encryption scheme existsEven very simple integer schemes can workIn particular, van Dijk, Gentry, Halevi and Vaikunthan (DGHV) proved in [1] that a cryptography scheme that is simpler than RSA (!!!) isHomomorphic for virtually unlimited number of additive gates, homomorphic for small numbers of multiplicative gatesBootstrappableSo simple and clean (relative to other cryptosystems, e.g. NTRU) that it was casually proposed on a message board in 2000 by Bram CohenLater, Vaikunthan and Brakerski proved that one can construct non-bootstrappable homomorphic encryption schemes [2] that base their security on stronger, post-quantum problems (e.g. Learning with Errors). This scheme appears to be more practical than the original bootstrapping schemes (although it still uses bootstrapping as 'an optimization').  A nice non-technical summary can be found on the MIT tech review [3] [0] Craig Gentry's PhD Thesis[1] Page on microsoft.com[2] Page on iacr.org[3] Homomorphic Encryption - MIT Technology Review"", 'result': {'fake': 0.0014, 'real': 0.9986}, 'status': 'success'}], 'credits_used': 6, 'credits': 1986414, 'subscription': 0, 'content': ""Fully Homomorphic Encryption (FHE)Imagine if you were a hospital that needed to process/analyze data on EC2, but were worried about privacy. In an ideal world, one would like:To encrypt his or her dataSend the encrypted data to the cloud and have the cloud servers operate on the encypted data (yes, I mean that)Sending you back the encrypted results, that you can easily decryptThis probably seems like magic — after all, how can someone operate on garbled data, creating more garbled data and then send me back some junk that is guaranteed to decrypt to the correct answer? It turns out that since most cryptosystems inherit symmetries/operations from the mathematical objects that they are based on (groups, rings, lattices, algebraic number fields), we can sometimes use these operations without breaking our encryption.  Before giving some details about FHE, let's look at an example. Suppose that I give you an RSA public key (N,e)(N,e)(N,e)  and suppose that the secret key is d≡e−1\xa0mod\xa0ϕ(N)d≡e−1\xa0mod\xa0ϕ(N) d \\equiv e^{-1} \\text{ mod } \\phi(N). Then two plaintexts π1,π2∈Zπ1,π2∈Z\\pi_1, \\pi_2 \\in \\Z would become ciphertexts ψ1,ψ2ψ1,ψ2\\psi_1, \\psi_2, where ψ1=πe1\xa0mod\xa0N,ψ2=πe2\xa0mod\xa0Nψ1=π1e\xa0mod\xa0N,ψ2=π2e\xa0mod\xa0N \\psi_1 = \\pi_1^e \\text{ mod } N, \\psi_2 = \\pi_2^e \\text{ mod } N Note that, π1π2\xa0mod\xa0N=(ψd1\xa0mod\xa0N)(ψd2\xa0mod\xa0N)=π1π2\xa0mod\xa0N=(ψ1d\xa0mod\xa0N)(ψ2d\xa0mod\xa0N)= \\pi_1 \\pi_2 \\text{ mod } N = (\\psi_1^d \\text{ mod } N) (\\psi_2^d \\text{ mod } N) = (ψ1ψ2)d\xa0mod\xa0N(ψ1ψ2)d\xa0mod\xa0N (\\psi_1 \\psi_2)^d  \\text{ mod } Nso that the decryption of the product of two ciphertexts is equivalent (mod N) to the product of the two plaintexts. Our goal is to make a system that is both multiplicatively homomorphic (like RSA) as well as additively homomorphic (which RSA is not, as you can see from the binomial formula). Note that in this about process, the cloud servers never see your raw data. Fully homomorphic encrypytion makes this happen. The landmark paper/thesis [0] of Gentry (2009) led to some astonishing revelations about simple encryption schemes:As long as a scheme can evaluate its own decryption circuit as well as a single NAND gate, one can bootstrap this scheme to a fully homomorphic schemeTechniques used to prove guarantees of post-quantum security turn out to be useful for proving that a bootstrappable homomorphic encryption scheme existsEven very simple integer schemes can workIn particular, van Dijk, Gentry, Halevi and Vaikunthan (DGHV) proved in [1] that a cryptography scheme that is simpler than RSA (!!!) isHomomorphic for virtually unlimited number of additive gates, homomorphic for small numbers of multiplicative gatesBootstrappableSo simple and clean (relative to other cryptosystems, e.g. NTRU) that it was casually proposed on a message board in 2000 by Bram CohenLater, Vaikunthan and Brakerski proved that one can construct non-bootstrappable homomorphic encryption schemes [2] that base their security on stronger, post-quantum problems (e.g. Learning with Errors). This scheme appears to be more practical than the original bootstrapping schemes (although it still uses bootstrapping as 'an optimization').  A nice non-technical summary can be found on the MIT tech review [3] [0] Craig Gentry's PhD Thesis[1] Page on microsoft.com[2] Page on iacr.org[3] Homomorphic Encryption - MIT Technology Review"", 'aiModelVersion': '1'}",0.9986
Bruce Zu,8y,We have n bottles of wine and one of them is poisoned. How can we determine which one of the bottles is poisoned in one month while hiring only O(log n) tasters?,"Label each bottle from 1 to n , and consider each as a binary number.

e.g. 11 bottles

00000001 
00000010 
00000011 
00000100 
00000101 
00000110 
00000111 
00001000 
00001001 
00001010 
00001011 

Now, from the right to left , firstly take a drop from each of the bottles whose rightest bit is set to '1' and deposit in the first cup.

Secondly take a drop from each bottle whose 2nd bit is set '1' and deposit in the second cup.

Continue in similar fashion through the highest bit. So in total we need 4 cups and 4 tasters.

taster4 taster3 taster2 tester1 
cup4     cup3    cup2     cup1 

we now map the tasters to cups and map the cups to bits, so map tasters to bits

command tasters to drink. In a month, some of your tasters will become dead.

e.g. taster3 and taster1 become dead

then set the corresponding bits to 1, and all other bits to 0. The resulting binary number

00000101 will identify the poisoned bottle.

the number of tasters f(n) = (int)(logn)+1 , so f(n) is O(logn)","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/w7gt6j45c0ozasxk', 'title': 'We have n bottles of wine and one of them is poisoned. How can we determine which one of the bottles is poisoned in one month while hiring only O(log n) tasters?', 'score': {'original': 0.9097, 'ai': 0.0903}, 'blocks': [{'text': ""Label each bottle from 1 to n , and consider each as a binary number.\n\ne.g. 11 bottles\n\n00000001\xa0\n00000010\xa0\n00000011\xa0\n00000100\xa0\n00000101\xa0\n00000110\xa0\n00000111\xa0\n00001000\xa0\n00001001\xa0\n00001010\xa0\n00001011\xa0\n\nNow, from the right to left , firstly take a drop from each of the bottles whose rightest bit is set to '1' and deposit in the first cup.\n\nSecondly take a drop from each bottle whose 2nd bit is set '1' and deposit in the second cup.\n\nContinue in similar fashion through the highest bit. So in total we need 4 cups and 4 tasters.\n\ntaster4 taster3 taster2 tester1\xa0\ncup4     cup3    cup2     cup1\xa0\n\nwe now map the tasters to cups and map the cups to bits, so map tasters to bits\n\ncommand tasters to drink. In a month, some of your tasters will become dead.\n\ne.g. taster3 and taster1 become dead\n\nthen set the corresponding bits to 1, and all other bits to 0. The resulting binary number\n\n00000101 will identify the poisoned bottle.\n\nthe number of tasters f(n) = (int)(logn)+1 , so f(n) is O(logn)"", 'result': {'fake': 0.0903, 'real': 0.9097}, 'status': 'success'}], 'credits_used': 2, 'credits': 1986412, 'subscription': 0, 'content': ""Label each bottle from 1 to n , and consider each as a binary number.\n\ne.g. 11 bottles\n\n00000001\xa0\n00000010\xa0\n00000011\xa0\n00000100\xa0\n00000101\xa0\n00000110\xa0\n00000111\xa0\n00001000\xa0\n00001001\xa0\n00001010\xa0\n00001011\xa0\n\nNow, from the right to left , firstly take a drop from each of the bottles whose rightest bit is set to '1' and deposit in the first cup.\n\nSecondly take a drop from each bottle whose 2nd bit is set '1' and deposit in the second cup.\n\nContinue in similar fashion through the highest bit. So in total we need 4 cups and 4 tasters.\n\ntaster4 taster3 taster2 tester1\xa0\ncup4     cup3    cup2     cup1\xa0\n\nwe now map the tasters to cups and map the cups to bits, so map tasters to bits\n\ncommand tasters to drink. In a month, some of your tasters will become dead.\n\ne.g. taster3 and taster1 become dead\n\nthen set the corresponding bits to 1, and all other bits to 0. The resulting binary number\n\n00000101 will identify the poisoned bottle.\n\nthe number of tasters f(n) = (int)(logn)+1 , so f(n) is O(logn)"", 'aiModelVersion': '1'}",0.9097
Gerry Rzeppa,2y,What is the most interesting Python algorithm in less than ten lines of code?,"Well, it’s Plain English rather than Python (but easily translated) and it’s exactly ten lines (rather than less than ten), but I think this little Lindenmayer interpreter…

To interpret some times:
If the times are 0, exit.
Put ""A+FA-FA-F++"" into a string.
Loop. If the string is blank, break.
Get a letter from the string.
If the letter is ""-"", turn right 1/4 of the way around; repeat.
If the letter is ""+"", turn left 1/4 of the way around; repeat.
If the letter is ""A"", interpret the times minus 1; repeat.
If the letter is ""F"", draw a line 1/8 inch long; repeat.
Repeat.

…is interesting because small changes produce such significantly different results. With the code shown above, for example, the output looks like this:

But if we turn 1/3 of the way around (instead of 1/4) we get this:

And if we turn 1/6 of way around, we get:

And if we go back to 1/4 turns and change the characters in the string to something like this…

Put ""FA+FA-FA-FAFA+FA+FA-FA++"" into a string.

…we get a significantly different result, like this:

And we can get a brain-like pattern if we use that same string with 1/8 turns:

Fun stuff. I could play with it all day. And if you allow yourself just a few more characters and lines, you can grow bushes like these…

…and curious curves like this…

…and this:

Et voila!","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/b9k3h65wdgx4sq2f', 'title': 'What is the most interesting Python algorithm in less than ten lines of code?', 'score': {'original': 0.9988, 'ai': 0.0012}, 'blocks': [{'text': 'Well, it’s Plain English rather than Python (but easily translated) and it’s exactly ten lines (rather than less than ten), but I think this little Lindenmayer interpreter…\n\nTo interpret some times:\nIf the times are 0, exit.\nPut ""A+FA-FA-F++"" into a string.\nLoop. If the string is blank, break.\nGet a letter from the string.\nIf the letter is ""-"", turn right 1/4 of the way around; repeat.\nIf the letter is ""+"", turn left 1/4 of the way around; repeat.\nIf the letter is ""A"", interpret the times minus 1; repeat.\nIf the letter is ""F"", draw a line 1/8 inch long; repeat.\nRepeat.\n\n…is interesting because small changes produce such significantly different results. With the code shown above, for example, the output looks like this:\n\nBut if we turn 1/3 of the way around (instead of 1/4) we get this:\n\nAnd if we turn 1/6 of way around, we get:\n\nAnd if we go back to 1/4 turns and change the characters in the string to something like this…\n\nPut ""FA+FA-FA-FAFA+FA+FA-FA++"" into a string.\n\n…we get a significantly different result, like this:\n\nAnd we can get a brain-like pattern if we use that same string with 1/8 turns:\n\nFun stuff. I could play with it all day. And if you allow yourself just a few more characters and lines, you can grow bushes like these…\n\n…and curious curves like this…\n\n…and this:\n\nEt voila!', 'result': {'fake': 0.0014, 'real': 0.9986}, 'status': 'success'}], 'credits_used': 3, 'credits': 1986409, 'subscription': 0, 'content': 'Well, it’s Plain English rather than Python (but easily translated) and it’s exactly ten lines (rather than less than ten), but I think this little Lindenmayer interpreter…\n\nTo interpret some times:\nIf the times are 0, exit.\nPut ""A+FA-FA-F++"" into a string.\nLoop. If the string is blank, break.\nGet a letter from the string.\nIf the letter is ""-"", turn right 1/4 of the way around; repeat.\nIf the letter is ""+"", turn left 1/4 of the way around; repeat.\nIf the letter is ""A"", interpret the times minus 1; repeat.\nIf the letter is ""F"", draw a line 1/8 inch long; repeat.\nRepeat.\n\n…is interesting because small changes produce such significantly different results. With the code shown above, for example, the output looks like this:\n\nBut if we turn 1/3 of the way around (instead of 1/4) we get this:\n\nAnd if we turn 1/6 of way around, we get:\n\nAnd if we go back to 1/4 turns and change the characters in the string to something like this…\n\nPut ""FA+FA-FA-FAFA+FA+FA-FA++"" into a string.\n\n…we get a significantly different result, like this:\n\nAnd we can get a brain-like pattern if we use that same string with 1/8 turns:\n\nFun stuff. I could play with it all day. And if you allow yourself just a few more characters and lines, you can grow bushes like these…\n\n…and curious curves like this…\n\n…and this:\n\nEt voila!', 'aiModelVersion': '1'}",0.9988
Mubeen Fathima,Jan 16,How do I master data structures and algorithms (DSA) to improve my problem solving skills which will eventually be helpful in interviews?,"Data structure and algorithms are the two most important aspects of computer science. Data structures allow us to organize and store data, whereas algorithms allow us to process that data meaningfully. Learning data structures and algorithms will help you become a better programmer. The ability to code is the most important skill that any engineer must learn. Coding has become a fundamental requirement for all fields and specializations as technology has expanded and adapted in many spheres of life.

Tips to improve data structures and algorithms:

A data structure is a way that you group values or items of information.
A data structure is important because it determines how you physically arrange your data (where it lives, and how many items it holds) and what will happen to that data if there is a problem.
The most common reason for trying to figure out common data structures is to improve the performance of algorithms/algorithms.
Data structures are the building blocks of algorithms.
Practice with algorithms and data structures so that you can improve your performance during interviews. Practice is extremely important when it comes to interview preparation as well as actual interviews themselves, as you will be in a situation where time is at an absolute minimum and you are expected to perform.

Online courses:

This is the first place to start when it comes to learning more about data structures and algorithms. The courses are packed with information but in a conversational and non-intimidating way. If you have taken an engineering class or are familiar with basic programming concepts, these courses will be a great place for you to start when it comes to learning or reviewing these concepts.

Coursera

This platform offers excellent education in a variety of subjects, including data science and data structures, among others. They are experts at assisting students in understanding concepts by providing relevant examples. The course content is good, and the tasks and instructions are simple to follow.

Learnbay

Course:

Software Development Program (including DSA Training)

Features

The Software Development Program at this institute is appropriate for students of all skill levels, from beginners to specialists. Throughout the semester, students will engage in important software development projects. You may experience what it is like to work in the real world. Students will also receive an IBM and Microsoft course completion certificate.

Final Thought:

Data structures and algorithms are important topics to be familiar with if you are in the engineering/computer science field. They are also important for interviews to help you demonstrate a depth of knowledge that will help you stand out. Data structures and algorithms have a deep impact on how your job gets done, as well as computer science in general. It is a complex topic but learning about them will help you understand your job better, and prepare for interviews. The aforementioned courses address this issue by providing more affordable courses to a larger audience. It's a great place to learn DSA at a low cost because the curriculum is up-to-date and includes the most recent industry algorithms.

All the best","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/v2njqhfwdykouzic', 'title': 'How do I master data structures and algorithms (DSA) to improve my problem solving skills which will eventually be helpful in interviews?', 'score': {'original': 0.0001, 'ai': 0.9999}, 'blocks': [{'text': ""Data structure and algorithms are the two most important aspects of computer science. Data structures allow us to organize and store data, whereas algorithms allow us to process that data meaningfully. Learning data structures and algorithms will help you become a better programmer. The ability to code is the most important skill that any engineer must learn. Coding has become a fundamental requirement for all fields and specializations as technology has expanded and adapted in many spheres of life.\n\nTips to improve data structures and algorithms:\n\nA data structure is a way that you group values or items of information.\nA data structure is important because it determines how you physically arrange your data (where it lives, and how many items it holds) and what will happen to that data if there is a problem.\nThe most common reason for trying to figure out common data structures is to improve the performance of algorithms/algorithms.\nData structures are the building blocks of algorithms.\nPractice with algorithms and data structures so that you can improve your performance during interviews. Practice is extremely important when it comes to interview preparation as well as actual interviews themselves, as you will be in a situation where time is at an absolute minimum and you are expected to perform.\n\nOnline courses:\n\nThis is the first place to start when it comes to learning more about data structures and algorithms. The courses are packed with information but in a conversational and non-intimidating way. If you have taken an engineering class or are familiar with basic programming concepts, these courses will be a great place for you to start when it comes to learning or reviewing these concepts.\n\nCoursera\n\nThis platform offers excellent education in a variety of subjects, including data science and data structures, among others. They are experts at assisting students in understanding concepts by providing relevant examples. The course content is good, and the tasks and instructions are simple to follow.\n\nLearnbay\n\nCourse:\n\nSoftware Development Program (including DSA Training)\n\nFeatures\n\nThe Software Development Program at this institute is appropriate for students of all skill levels, from beginners to specialists. Throughout the semester, students will engage in important software development projects. You may experience what it is like to work in the real world. Students will also receive an IBM and Microsoft course completion certificate.\n\nFinal Thought:\n\nData structures and algorithms are important topics to be familiar with if you are in the engineering/computer science field. They are also important for interviews to help you demonstrate a depth of knowledge that will help you stand out. Data structures and algorithms have a deep impact on how your job gets done, as well as computer science in general. It is a complex topic but learning about them will help you understand your job better, and prepare for interviews. The aforementioned courses address this issue by providing more affordable courses to a larger audience. It's a great place to learn DSA at a low cost because the curriculum is up-to-date and includes the most recent industry algorithms.\n\nAll the best"", 'result': {'fake': 0.9999, 'real': 0.0001}, 'status': 'success'}], 'credits_used': 6, 'credits': 1986403, 'subscription': 0, 'content': ""Data structure and algorithms are the two most important aspects of computer science. Data structures allow us to organize and store data, whereas algorithms allow us to process that data meaningfully. Learning data structures and algorithms will help you become a better programmer. The ability to code is the most important skill that any engineer must learn. Coding has become a fundamental requirement for all fields and specializations as technology has expanded and adapted in many spheres of life.\n\nTips to improve data structures and algorithms:\n\nA data structure is a way that you group values or items of information.\nA data structure is important because it determines how you physically arrange your data (where it lives, and how many items it holds) and what will happen to that data if there is a problem.\nThe most common reason for trying to figure out common data structures is to improve the performance of algorithms/algorithms.\nData structures are the building blocks of algorithms.\nPractice with algorithms and data structures so that you can improve your performance during interviews. Practice is extremely important when it comes to interview preparation as well as actual interviews themselves, as you will be in a situation where time is at an absolute minimum and you are expected to perform.\n\nOnline courses:\n\nThis is the first place to start when it comes to learning more about data structures and algorithms. The courses are packed with information but in a conversational and non-intimidating way. If you have taken an engineering class or are familiar with basic programming concepts, these courses will be a great place for you to start when it comes to learning or reviewing these concepts.\n\nCoursera\n\nThis platform offers excellent education in a variety of subjects, including data science and data structures, among others. They are experts at assisting students in understanding concepts by providing relevant examples. The course content is good, and the tasks and instructions are simple to follow.\n\nLearnbay\n\nCourse:\n\nSoftware Development Program (including DSA Training)\n\nFeatures\n\nThe Software Development Program at this institute is appropriate for students of all skill levels, from beginners to specialists. Throughout the semester, students will engage in important software development projects. You may experience what it is like to work in the real world. Students will also receive an IBM and Microsoft course completion certificate.\n\nFinal Thought:\n\nData structures and algorithms are important topics to be familiar with if you are in the engineering/computer science field. They are also important for interviews to help you demonstrate a depth of knowledge that will help you stand out. Data structures and algorithms have a deep impact on how your job gets done, as well as computer science in general. It is a complex topic but learning about them will help you understand your job better, and prepare for interviews. The aforementioned courses address this issue by providing more affordable courses to a larger audience. It's a great place to learn DSA at a low cost because the curriculum is up-to-date and includes the most recent industry algorithms.\n\nAll the best"", 'aiModelVersion': '1'}",0.0001
DJ Rich,Updated 5y,What is the most interesting algorithm?,"Strassen’s AlgorithmThe most mind-blowing fact of this algorithm is that someone attempted it. Let me show you what I mean. First, we need to know about matrix multiplication. Let's write down two 3-by-3 matrices:Let's call the left matrix AA\mathbf{A} and the right BB\mathbf{B}. We define matrix multiplication between these two as a calculation which results in another matrix with the same numbers of rows as AA\mathbf{A} and the same number of columns as BB\mathbf{B}. The definition dictates we calculate each element of the result as:Let's call the resulting matrix CC\mathbf{C}. So if you'd like to calculate an element of CC\mathbf{C} that's in the second row and first column, you first select out the second row from AA\mathbf{A} and first column of BB\mathbf{B}. Then you multiply each element of these together and sum them up. This is similarly defined for all other elements of CC\mathbf{C}. The result is:To understand why Strassen's Algorithm is interesting, we need to count how many simple add/multiply calculations are involved in producing CC\mathbf{C}. Well, that's not hard. To produce that number 48, we had 3 multiplications and 2 additions, for a total of 5 simple calcs. Since there are 9 elements in CC\mathbf{C}, we have a total of 9×5=459×5=459\times 5=45 calculations. To make progress, we need to get more general. Let's say AA\mathbf{A} and BB\mathbf{B} are nnn-by-nnn matrices[1]. Then the formula for the total number of calculations is: T(n)=n2(n+(n−1))=2n3−n2T(n)=n2(n+(n−1))=2n3−n2T(n) = n^2(n + (n-1)) = 2n^3 - n^2 Now, when some mathy people look at this, they want to drop the specifics and consider only the dominate behavior as nnn gets large. In other words, they care about the generic speed with which this function grows. For this case, they would say T(n)T(n)T(n) grows in proportion to n3n3n^3. More technically, they say:T(n) is in the set O(n3)O(n3)\mathcal{O}(n^3)which means you could choose a constant ccc such that T(n)<c⋅n3T(n)<c⋅n3T(n)<c\cdot n^3 for all nnn beyond a certain point. Just think of this as a rigorous way of pointing out the highest exponent term in T(n)T(n)T(n). So let's think about that statement: T(n)T(n)T(n) grows in proportion to n3n3n^3. It has to, right? The result, CC\mathbf{C}, has n2n2n^2 elements and we have to calculate each in turn. For each turn, we have some near-multiple of nnn calculations to do. Therefore, this must amount in something on the order of n3n3n^3 calculations... right? No. Strassen's algorithm was the first strike to chip away at the n3n3n^3 shell, showing us that we could get the cost of matrix multiplication to grow at a rate less than n3n3n^3. That is absolutely wild. How the hell are we avoiding the work of matrix multiplication that seems baked into its definition? I have no clue and no one suspected it was worth an attempt until Volker Strassen came along. His algorithm showed it could be done with a cost near O(n2.8)O(n2.8)\mathcal{O}(n^{2.8}). This sparked a flurry of research, and we've since made significant progress:I’ll say it again, that is absolutely wild. Footnotes [1] Strassen’s algorithm isn’t specific to nnn-by-nnn matrices. It just simplifies my explanation. Sources [1] I first came across this in Introduction to Algorithms (often called ‘CLRS’). It caught my attention with this line:Strassen’s method is not at all obvious. (This might be the biggest understatement in this book.)","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/fldinykswt6ouzev', 'title': 'What is the most interesting algorithm?', 'score': {'original': 0.99, 'ai': 0.01}, 'blocks': [{'text': ""Strassen’s AlgorithmThe most mind-blowing fact of this algorithm is that someone attempted it. Let me show you what I mean. First, we need to know about matrix multiplication. Let's write down two 3-by-3 matrices:Let's call the left matrix AA\\mathbf{A} and the right BB\\mathbf{B}. We define matrix multiplication between these two as a calculation which results in another matrix with the same numbers of rows as AA\\mathbf{A} and the same number of columns as BB\\mathbf{B}. The definition dictates we calculate each element of the result as:Let's call the resulting matrix CC\\mathbf{C}. So if you'd like to calculate an element of CC\\mathbf{C} that's in the second row and first column, you first select out the second row from AA\\mathbf{A} and first column of BB\\mathbf{B}. Then you multiply each element of these together and sum them up. This is similarly defined for all other elements of CC\\mathbf{C}. The result is:To understand why Strassen's Algorithm is interesting, we need to count how many simple add/multiply calculations are involved in producing CC\\mathbf{C}. Well, that's not hard. To produce that number 48, we had 3 multiplications and 2 additions, for a total of 5 simple calcs. Since there are 9 elements in CC\\mathbf{C}, we have a total of 9×5=459×5=459\\times 5=45 calculations. To make progress, we need to get more general. Let's say AA\\mathbf{A} and BB\\mathbf{B} are nnn-by-nnn matrices[1]. Then the formula for the total number of calculations is: T(n)=n2(n+(n−1))=2n3−n2T(n)=n2(n+(n−1))=2n3−n2T(n) = n^2(n + (n-1)) = 2n^3 - n^2 Now, when some mathy people look at this, they want to drop the specifics and consider only the dominate behavior as nnn gets large. In other words, they care about the generic speed with which this function grows. For this case, they would say T(n)T(n)T(n) grows in proportion to n3n3n^3. More technically, they say:T(n) is in the set O(n3)O(n3)\\mathcal{O}(n^3)which means you could choose a constant ccc such that T(n)<c⋅n3T(n)<c⋅n3T(n)<c\\cdot n^3 for all nnn beyond a certain point. Just think of this as a rigorous way of pointing out the highest exponent term in T(n)T(n)T(n). So let's think about that statement: T(n)T(n)T(n) grows in proportion to n3n3n^3. It has to, right? The result, CC\\mathbf{C}, has n2n2n^2 elements and we have to calculate each in turn. For each turn, we have some near-multiple of nnn calculations to do. Therefore, this must amount in something on the order of n3n3n^3 calculations... right? No. Strassen's algorithm was the first strike to chip away at the n3n3n^3 shell, showing us that we could get the cost of matrix multiplication to grow at a rate less than n3n3n^3. That is absolutely wild. How the hell are we avoiding the work of matrix multiplication that seems baked into its definition? I have no clue and no one suspected it was worth an attempt until Volker Strassen came along. His algorithm showed it could be done with a cost near O(n2.8)O(n2.8)\\mathcal{O}(n^{2.8}). This sparked a flurry of research, and we've since made significant progress:I’ll say it again, that is absolutely wild. Footnotes [1] Strassen’s algorithm isn’t specific to nnn-by-nnn matrices. It just simplifies my explanation. Sources [1] I first came"", 'result': {'fake': 0.0089, 'real': 0.9911}, 'status': 'success'}, {'text': 'across this in Introduction to Algorithms (often called ‘CLRS’). It caught my attention with this line:Strassen’s method is not at all obvious. (This might be the biggest understatement in this book.)', 'result': {'fake': 0.0076, 'real': 0.9924}, 'status': 'success'}], 'credits_used': 7, 'credits': 1986396, 'subscription': 0, 'content': ""Strassen’s AlgorithmThe most mind-blowing fact of this algorithm is that someone attempted it. Let me show you what I mean. First, we need to know about matrix multiplication. Let's write down two 3-by-3 matrices:Let's call the left matrix AA\\mathbf{A} and the right BB\\mathbf{B}. We define matrix multiplication between these two as a calculation which results in another matrix with the same numbers of rows as AA\\mathbf{A} and the same number of columns as BB\\mathbf{B}. The definition dictates we calculate each element of the result as:Let's call the resulting matrix CC\\mathbf{C}. So if you'd like to calculate an element of CC\\mathbf{C} that's in the second row and first column, you first select out the second row from AA\\mathbf{A} and first column of BB\\mathbf{B}. Then you multiply each element of these together and sum them up. This is similarly defined for all other elements of CC\\mathbf{C}. The result is:To understand why Strassen's Algorithm is interesting, we need to count how many simple add/multiply calculations are involved in producing CC\\mathbf{C}. Well, that's not hard. To produce that number 48, we had 3 multiplications and 2 additions, for a total of 5 simple calcs. Since there are 9 elements in CC\\mathbf{C}, we have a total of 9×5=459×5=459\\times 5=45 calculations. To make progress, we need to get more general. Let's say AA\\mathbf{A} and BB\\mathbf{B} are nnn-by-nnn matrices[1]. Then the formula for the total number of calculations is: T(n)=n2(n+(n−1))=2n3−n2T(n)=n2(n+(n−1))=2n3−n2T(n) = n^2(n + (n-1)) = 2n^3 - n^2 Now, when some mathy people look at this, they want to drop the specifics and consider only the dominate behavior as nnn gets large. In other words, they care about the generic speed with which this function grows. For this case, they would say T(n)T(n)T(n) grows in proportion to n3n3n^3. More technically, they say:T(n) is in the set O(n3)O(n3)\\mathcal{O}(n^3)which means you could choose a constant ccc such that T(n)<c⋅n3T(n)<c⋅n3T(n)<c\\cdot n^3 for all nnn beyond a certain point. Just think of this as a rigorous way of pointing out the highest exponent term in T(n)T(n)T(n). So let's think about that statement: T(n)T(n)T(n) grows in proportion to n3n3n^3. It has to, right? The result, CC\\mathbf{C}, has n2n2n^2 elements and we have to calculate each in turn. For each turn, we have some near-multiple of nnn calculations to do. Therefore, this must amount in something on the order of n3n3n^3 calculations... right? No. Strassen's algorithm was the first strike to chip away at the n3n3n^3 shell, showing us that we could get the cost of matrix multiplication to grow at a rate less than n3n3n^3. That is absolutely wild. How the hell are we avoiding the work of matrix multiplication that seems baked into its definition? I have no clue and no one suspected it was worth an attempt until Volker Strassen came along. His algorithm showed it could be done with a cost near O(n2.8)O(n2.8)\\mathcal{O}(n^{2.8}). This sparked a flurry of research, and we've since made significant progress:I’ll say it again, that is absolutely wild. Footnotes [1] Strassen’s algorithm isn’t specific to nnn-by-nnn matrices. It just simplifies my explanation. Sources [1] I first came across this in Introduction to Algorithms (often called ‘CLRS’). It caught my attention with this line:Strassen’s method is not at all obvious. (This might be the biggest understatement in this book.)"", 'aiModelVersion': '1'}",0.99
Paul K. Young,7y,"Googlers, have you ever touched or seen the code of the Google Search Algorithm?","I work on search and have never seen the search ranking algorithm. That’s the bit that takes all the various signals like PageRank, keywords, etc. (there are over 200 of them [ https://www.google.com/insidesearch/howsearchworks/algorithms.html ]) and determines the order of the search results.

That piece of code is particularly sensitive. It is a significant component of Google’s competitive edge in search and if the details were released we’d likely see a big increase in people attempting to game the system. (This is already a problem without the details of the algorithm being published.)

Most of Google’s code is viewable by any developer. However some code has more restrictive access. I’m not sure if the ranking algorithm falls under this category but wouldn’t be surprised if it were only accessible on a need-to-know basis.

The search ranking algorithm is only a small part of the search stack. Most of the search stack (e.g. the crawler, indexing system, serve-time services) is accessible to the entire company. This can be quite useful when working across systems or teams.

For instance when I worked on indexing I occasionally needed to trigger a manual crawl. The status codes for the crawler are documented in the source code so it was handy to be able to open up the source to figure out what was going on. On a few occasions I ...

Access this answer and support the author as a Quora+ subscriber
Access all answers reserved by 
Paul K. Young
 for Quora+ subscribers
Access exclusive answers from thousands more participating creators in Quora+
Browse ad‑free and support creators
Start free trial
Learn more","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/16i5yv8q2hnt4zsx', 'title': 'Googlers, have you ever touched or seen the code of the Google Search Algorithm?', 'score': {'original': 0.9995, 'ai': 0.0005}, 'blocks': [{'text': 'I work on search and have never seen the search ranking algorithm. That’s the bit that takes all the various signals like PageRank, keywords, etc. (there are over 200 of them [ https://www.google.com/insidesearch/howsearchworks/algorithms.html ]) and determines the order of the search results.\n\nThat piece of code is particularly sensitive. It is a significant component of Google’s competitive edge in search and if the details were released we’d likely see a big increase in people attempting to game the system. (This is already a problem without the details of the algorithm being published.)\n\nMost of Google’s code is viewable by any developer. However some code has more restrictive access. I’m not sure if the ranking algorithm falls under this category but wouldn’t be surprised if it were only accessible on a need-to-know basis.\n\nThe search ranking algorithm is only a small part of the search stack. Most of the search stack (e.g. the crawler, indexing system, serve-time services) is accessible to the entire company. This can be quite useful when working across systems or teams.\n\nFor instance when I worked on indexing I occasionally needed to trigger a manual crawl. The status codes for the crawler are documented in the source code so it was handy to be able to open up the source to figure out what was going on. On a few occasions I ...\n\nAccess this answer and support the author as a Quora+ subscriber\nAccess all answers reserved by \nPaul K. Young\n for Quora+ subscribers\nAccess exclusive answers from thousands more participating creators in Quora+\nBrowse ad‑free and support creators\nStart free trial\nLearn more', 'result': {'fake': 0.0005, 'real': 0.9995}, 'status': 'success'}], 'credits_used': 3, 'credits': 1986393, 'subscription': 0, 'content': 'I work on search and have never seen the search ranking algorithm. That’s the bit that takes all the various signals like PageRank, keywords, etc. (there are over 200 of them [ https://www.google.com/insidesearch/howsearchworks/algorithms.html ]) and determines the order of the search results.\n\nThat piece of code is particularly sensitive. It is a significant component of Google’s competitive edge in search and if the details were released we’d likely see a big increase in people attempting to game the system. (This is already a problem without the details of the algorithm being published.)\n\nMost of Google’s code is viewable by any developer. However some code has more restrictive access. I’m not sure if the ranking algorithm falls under this category but wouldn’t be surprised if it were only accessible on a need-to-know basis.\n\nThe search ranking algorithm is only a small part of the search stack. Most of the search stack (e.g. the crawler, indexing system, serve-time services) is accessible to the entire company. This can be quite useful when working across systems or teams.\n\nFor instance when I worked on indexing I occasionally needed to trigger a manual crawl. The status codes for the crawler are documented in the source code so it was handy to be able to open up the source to figure out what was going on. On a few occasions I ...\n\nAccess this answer and support the author as a Quora+ subscriber\nAccess all answers reserved by \nPaul K. Young\n for Quora+ subscribers\nAccess exclusive answers from thousands more participating creators in Quora+\nBrowse ad‑free and support creators\nStart free trial\nLearn more', 'aiModelVersion': '1'}",0.9995
Thomas Cormen,Updated 1y,What does Thomas Cormen do now?,"I don’t know why you are interested in what I do now, but here is what I do now.

I am Emeritus Professor of Computer Science at Dartmouth College. I maintain my connection to Dartmouth, but any responsibilities I take on regarding Dartmouth are entirely by choice. For example, I might supervise a senior thesis student.

I have become heavily involved with COVER Home Repair of White River Junction, Vermont. COVER Home Repair, Inc.
 I have worked on few roof and ramp projects, I joined the Development Committee as a community member in the fall of 2021, I became the pro bono grant writer in December 2021, and as of July 2022, I am on the Board of Directors.

And now, as of June 2022, I am a candidate for the New Hampshire House of Representatives, hoping to represent Grafton District 15, which is Ward 3 of Lebanon, NH. I am running as a Democrat.

All that and trying to get exercise.

Update August 2, 2022: I now have a campaign website: Tom Cormen for NH House Lebanon Ward 3","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/bzljgwhs0fv84kxt', 'title': 'What does Thomas Cormen do now?', 'score': {'original': 0.9987, 'ai': 0.0013}, 'blocks': [{'text': 'I don’t know why you are interested in what I do now, but here is what I do now.\n\nI am Emeritus Professor of Computer Science at Dartmouth College. I maintain my connection to Dartmouth, but any responsibilities I take on regarding Dartmouth are entirely by choice. For example, I might supervise a senior thesis student.\n\nI have become heavily involved with COVER Home Repair of White River Junction, Vermont. COVER Home Repair, Inc.\n I have worked on few roof and ramp projects, I joined the Development Committee as a community member in the fall of 2021, I became the pro bono grant writer in December 2021, and as of July 2022, I am on the Board of Directors.\n\nAnd now, as of June 2022, I am a candidate for the New Hampshire House of Representatives, hoping to represent Grafton District 15, which is Ward 3 of Lebanon, NH. I am running as a Democrat.\n\nAll that and trying to get exercise.\n\nUpdate August 2, 2022: I now have a campaign website: Tom Cormen for NH House Lebanon Ward 3', 'result': {'fake': 0.0013, 'real': 0.9987}, 'status': 'success'}], 'credits_used': 2, 'credits': 1986391, 'subscription': 0, 'content': 'I don’t know why you are interested in what I do now, but here is what I do now.\n\nI am Emeritus Professor of Computer Science at Dartmouth College. I maintain my connection to Dartmouth, but any responsibilities I take on regarding Dartmouth are entirely by choice. For example, I might supervise a senior thesis student.\n\nI have become heavily involved with COVER Home Repair of White River Junction, Vermont. COVER Home Repair, Inc.\n I have worked on few roof and ramp projects, I joined the Development Committee as a community member in the fall of 2021, I became the pro bono grant writer in December 2021, and as of July 2022, I am on the Board of Directors.\n\nAnd now, as of June 2022, I am a candidate for the New Hampshire House of Representatives, hoping to represent Grafton District 15, which is Ward 3 of Lebanon, NH. I am running as a Democrat.\n\nAll that and trying to get exercise.\n\nUpdate August 2, 2022: I now have a campaign website: Tom Cormen for NH House Lebanon Ward 3', 'aiModelVersion': '1'}",0.9987
Akash Deep,1y,How can a person learn algorithms by himself?,"Algorithms existed before computers were created. Algorithms are now widespread because computers are! The core of computing is an algorithm. If we look around us, we can see several algorithms at work, addressing the issues we face every day: Algorithms power a variety of applications, including Netflix recommendation systems, social media networks, GPS applications, Google search, and e-commerce platforms. Coding interviews are frequently used to land high-paying positions in the software industry. Consequently, one of the essential career skills for programmers is understanding algorithms.

ALGORITHM

A well-defined step-by-step process known as an algorithm is used to convert a given input into the desired output in order to solve a computational problem. To put it another way, an algorithm is a method for resolving a specific computational issue. The computational problem consists of a set of inquiries that computers might be able to answer. A computational problem is, for instance, the sorting problem: ""Given a sequence of n integers, arrange them in increasing order.""

THE BASIC ELEMENTS OF ALGORITHMS

There are inputs and outputs for each algorithm. The output is what you typically see and is the outcome of the algorithm. That could be Netflix suggesting a show, TurboTax calculating your refund, or Google Maps determining your route home. Likewise, algorithms have inputs. The input could be straightforward, such as a number, or it could be much bigger than it appears. In order to find a route from point A to point B, for instance, an algorithm uses the points you provide as inputs in addition to a large database of roads, other drivers' routes, etc. Consider all of the potential inputs when thinking about how to solve the problem.

Algorithms go through a series of actions after receiving inputs to produce outputs. Most algorithms are derived from straightforward processes. In fact, a tiny device that reads ones and zeros off a strip of paper, looks up information in a table, and modifies the digit could perform every complex task you perform on a computer. (This is the Turing Machine, which is the cornerstone of computer science.) List sorting, list searching, and mathematical manipulation are all frequent processes that support numerous larger algorithms.

HOW TO LEARN ALGORITHMS?

Choose a programming language, get familiar with it, and stick with it. Avoid speaking too many languages at once. If you have some programming basics, we'll move on to learning about algorithms and data structures.

There are several great resources available online to learn data structures and algorithm.

Books - Introduction to Algorithms and Cracking the Coding Interview.

I know that many of you don’t like learning from books. Hence, I’ll also recommend some online resources that you can follow.

One great course I found on algorithms and data structures is on the Logicmojo. They have Data Structures and Algorithms courses in Python, Java, and C++. If you’re using one of these languages, you can get the corresponding course, and it is pretty cheap as well.

Two more great courses on Algorithms that I found are the “Algorithms Specialization Course” offered by Stanford at Coursera and the Udacity course “Intro to Data Structures and Algorithms” offered by Google.

However, the best way to improve your skills in algorithms and problem solving is by taking part in coding challenges. There are several online platforms where you can do coding challenges, and that will help you a lot. Some of the best online websites offering programming challenges are: LeetCode, Codeforces, CodeChef, HackerRank, etc.

You can select one of these platforms and participate in coding challenges. I used HackerRank a lot for improving my skills and participating in competitive programming challenges. These kinds of challenges are fun and competitive, and they will help you sharpen your skills.

FINAL THOUGHTS

Most algorithms you run into in everyday life are extremely complex, but that doesn’t mean you can’t develop a basic literacy to help understand them. Analyze the inputs and try to understand all the data an algorithm might have to work with. Learn the building blocks of algorithms, like searching and sorting, which get combined with some math to make up a lot of the algorithms you see. Recognize common algorithmic problems that show up around you all the time. And, finally, practice making some. Though you won’t become a professional, you will learn to appreciate and critique these processes that influence so much of our daily lives.

I hope you got some value out of this article. If you have any doubts or anything to add to this article, feel free to drop a comment. I’ll be happy to respond.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/ti4x0f7639vw2hae', 'title': 'How can a person learn algorithms by himself?', 'score': {'original': 0.0001, 'ai': 0.9999}, 'blocks': [{'text': 'Algorithms existed before computers were created. Algorithms are now widespread because computers are! The core of computing is an algorithm. If we look around us, we can see several algorithms at work, addressing the issues we face every day: Algorithms power a variety of applications, including Netflix recommendation systems, social media networks, GPS applications, Google search, and e-commerce platforms. Coding interviews are frequently used to land high-paying positions in the software industry. Consequently, one of the essential career skills for programmers is understanding algorithms.\n\nALGORITHM\n\nA well-defined step-by-step process known as an algorithm is used to convert a given input into the desired output in order to solve a computational problem. To put it another way, an algorithm is a method for resolving a specific computational issue. The computational problem consists of a set of inquiries that computers might be able to answer. A computational problem is, for instance, the sorting problem: ""Given a sequence of n integers, arrange them in increasing order.""\n\nTHE BASIC ELEMENTS OF ALGORITHMS\n\nThere are inputs and outputs for each algorithm. The output is what you typically see and is the outcome of the algorithm. That could be Netflix suggesting a show, TurboTax calculating your refund, or Google Maps determining your route home. Likewise, algorithms have inputs. The input could be straightforward, such as a number, or it could be much bigger than it appears. In order to find a route from point A to point B, for instance, an algorithm uses the points you provide as inputs in addition to a large database of roads, other drivers\' routes, etc. Consider all of the potential inputs when thinking about how to solve the problem.\n\nAlgorithms go through a series of actions after receiving inputs to produce outputs. Most algorithms are derived from straightforward processes. In fact, a tiny device that reads ones and zeros off a strip of paper, looks up information in a table, and modifies the digit could perform every complex task you perform on a computer. (This is the Turing Machine, which is the cornerstone of computer science.) List sorting, list searching, and mathematical manipulation are all frequent processes that support numerous larger algorithms.\n\nHOW TO LEARN ALGORITHMS?\n\nChoose a programming language, get familiar with it, and stick with it. Avoid speaking too many languages at once. If you have some programming basics, we\'ll move on to learning about algorithms and data structures.\n\nThere are several great resources available online to learn data structures and algorithm.\n\nBooks - Introduction to Algorithms and Cracking the Coding Interview.\n\nI know that many of you don’t like learning from books. Hence, I’ll also recommend some online resources that you can follow.\n\nOne great course I found on algorithms and data structures is on the Logicmojo. They have Data Structures and Algorithms courses in Python, Java, and C++. If you’re using one of these languages, you can get the corresponding course, and it is pretty cheap as well.\n\nTwo more great courses on Algorithms that I found are the “Algorithms Specialization Course” offered by Stanford at Coursera and the Udacity course “Intro to Data Structures and Algorithms” offered by Google.\n\nHowever,', 'result': {'fake': 0.9999, 'real': 0.0001}, 'status': 'success'}, {'text': 'the best way to improve your skills in algorithms and problem solving is by taking part in coding challenges. There are several online platforms where you can do coding challenges, and that will help you a lot. Some of the best online websites offering programming challenges are: LeetCode, Codeforces, CodeChef, HackerRank, etc.\n\nYou can select one of these platforms and participate in coding challenges. I used HackerRank a lot for improving my skills and participating in competitive programming challenges. These kinds of challenges are fun and competitive, and they will help you sharpen your skills.\n\nFINAL THOUGHTS\n\nMost algorithms you run into in everyday life are extremely complex, but that doesn’t mean you can’t develop a basic literacy to help understand them. Analyze the inputs and try to understand all the data an algorithm might have to work with. Learn the building blocks of algorithms, like searching and sorting, which get combined with some math to make up a lot of the algorithms you see. Recognize common algorithmic problems that show up around you all the time. And, finally, practice making some. Though you won’t become a professional, you will learn to appreciate and critique these processes that influence so much of our daily lives.\n\nI hope you got some value out of this article. If you have any doubts or anything to add to this article, feel free to drop a comment. I’ll be happy to respond.', 'result': {'fake': 1, 'real': 0}, 'status': 'success'}], 'credits_used': 8, 'credits': 1986383, 'subscription': 0, 'content': 'Algorithms existed before computers were created. Algorithms are now widespread because computers are! The core of computing is an algorithm. If we look around us, we can see several algorithms at work, addressing the issues we face every day: Algorithms power a variety of applications, including Netflix recommendation systems, social media networks, GPS applications, Google search, and e-commerce platforms. Coding interviews are frequently used to land high-paying positions in the software industry. Consequently, one of the essential career skills for programmers is understanding algorithms.\n\nALGORITHM\n\nA well-defined step-by-step process known as an algorithm is used to convert a given input into the desired output in order to solve a computational problem. To put it another way, an algorithm is a method for resolving a specific computational issue. The computational problem consists of a set of inquiries that computers might be able to answer. A computational problem is, for instance, the sorting problem: ""Given a sequence of n integers, arrange them in increasing order.""\n\nTHE BASIC ELEMENTS OF ALGORITHMS\n\nThere are inputs and outputs for each algorithm. The output is what you typically see and is the outcome of the algorithm. That could be Netflix suggesting a show, TurboTax calculating your refund, or Google Maps determining your route home. Likewise, algorithms have inputs. The input could be straightforward, such as a number, or it could be much bigger than it appears. In order to find a route from point A to point B, for instance, an algorithm uses the points you provide as inputs in addition to a large database of roads, other drivers\' routes, etc. Consider all of the potential inputs when thinking about how to solve the problem.\n\nAlgorithms go through a series of actions after receiving inputs to produce outputs. Most algorithms are derived from straightforward processes. In fact, a tiny device that reads ones and zeros off a strip of paper, looks up information in a table, and modifies the digit could perform every complex task you perform on a computer. (This is the Turing Machine, which is the cornerstone of computer science.) List sorting, list searching, and mathematical manipulation are all frequent processes that support numerous larger algorithms.\n\nHOW TO LEARN ALGORITHMS?\n\nChoose a programming language, get familiar with it, and stick with it. Avoid speaking too many languages at once. If you have some programming basics, we\'ll move on to learning about algorithms and data structures.\n\nThere are several great resources available online to learn data structures and algorithm.\n\nBooks - Introduction to Algorithms and Cracking the Coding Interview.\n\nI know that many of you don’t like learning from books. Hence, I’ll also recommend some online resources that you can follow.\n\nOne great course I found on algorithms and data structures is on the Logicmojo. They have Data Structures and Algorithms courses in Python, Java, and C++. If you’re using one of these languages, you can get the corresponding course, and it is pretty cheap as well.\n\nTwo more great courses on Algorithms that I found are the “Algorithms Specialization Course” offered by Stanford at Coursera and the Udacity course “Intro to Data Structures and Algorithms” offered by Google.\n\nHowever, the best way to improve your skills in algorithms and problem solving is by taking part in coding challenges. There are several online platforms where you can do coding challenges, and that will help you a lot. Some of the best online websites offering programming challenges are: LeetCode, Codeforces, CodeChef, HackerRank, etc.\n\nYou can select one of these platforms and participate in coding challenges. I used HackerRank a lot for improving my skills and participating in competitive programming challenges. These kinds of challenges are fun and competitive, and they will help you sharpen your skills.\n\nFINAL THOUGHTS\n\nMost algorithms you run into in everyday life are extremely complex, but that doesn’t mean you can’t develop a basic literacy to help understand them. Analyze the inputs and try to understand all the data an algorithm might have to work with. Learn the building blocks of algorithms, like searching and sorting, which get combined with some math to make up a lot of the algorithms you see. Recognize common algorithmic problems that show up around you all the time. And, finally, practice making some. Though you won’t become a professional, you will learn to appreciate and critique these processes that influence so much of our daily lives.\n\nI hope you got some value out of this article. If you have any doubts or anything to add to this article, feel free to drop a comment. I’ll be happy to respond.', 'aiModelVersion': '1'}",0.0001
Mark McCartin-Lim,7y,What are the top 10 algorithms every software engineer should know by heart?,"None.

Rather than memorizing algorithms, you should understand algorithmic principles, and know those algorithmic principles by heart. The goal in understanding algorithms is to be able to analyze algorithms you haven’t seen before, to be able to apply existing algorithms to new problems, and to be able to create new algorithms from scratch.

Of course, in order to gain a good understanding of those algorithmic principles, you will need to study a lot of algorithms (way more than 10). It may be useful to keep to these algorithms you learn in your mind as canonical examples of the principles they deploy.

For instance, Mergesort is a good canonical example of the Divide-and-Conquer principle. It is not the only canonical example, and I would expect that someone who understands Divide-and-Conquer well would have a few examples in their mind. But someone who knows the Divide-and-Conquer principle behind Mergesort would probably be able to write pseudocode for it or code up an implementation without references. Although if they haven’t done so in a long time, it might take them a little while to produce the correct implementation, and their first attempt might be buggy.

In that sense, yes they do know Mergesort because they understand the principle behind it. However, it’s not like they “know by heart” the actual code. And they should not be expected to code it up without thinking. Quite the opposite, they should code it up by consciously referring in their mind to the principle that it uses. The end result may or may not look like the code they originally saw when they first learned Mergesort but it will use the same principle. Someone who understands algorithms well should never feel the need to memorize how to code any algorithm!!!

Here are 10 algorithmic principles I think that every software engineer should know, roughly in the order of how important I think it is to know them:

How to analyze the running time of non-recursive code (nested for loops, while loops, etc.)
How to create and traverse dynamic linked data structures using pointers, and understanding when those data structures can be implemented as implicit/succinct data structures without using pointers (a good example is the binary heap, which could be implemented with pointers but is usually implemented implicitly for efficiency reasons)
Graph traversal (BFS and DFS) and the various graph properties you might be interested in (connectivity, shortest path, cycle detection, etc.)
How to analyze the running time of recursive code (formulating recurrences, using Master Theorem, recognizing common recursive structures)
The divide and conquer principle (e.g. merge sort, binary search, fast exponentiation, majority algorithm, select/median-finding algorithm, Karatsuba/Toom-Cook multiplication, fast fourier transform, Strassen matrix multiplication, Preparata-Hong convex hull, closest point pair, etc.)
Dynamic programming and memoization (e.g. knapsack, shortest path, CYK parsing algorithm, longest common subsequence, edit distance, Knuth word wrap, solving games, etc.)
Iterative methods and how to analyze their convergence, error-bounding and numerical stability properties. In particular, you should at least be familiar with gradient descent/ascent and some common optimizations like Newton’s method. Should know common applications like root finding and solving linear systems.
Branch-and-bound search strategies and their derivatives used in AI like A*, IDA, alpha-beta pruning, etc.
The general principle of reductions, i.e. taking one problem and modelling it as another. In particular, it is useful to be able to model problems you want to solve as constraint satisfaction problems or linear programs, and use general purpose solvers to get the solution. Furthermore, sometimes you realize the constraints of your problem allow it to be modeled as a problem that can be solved with a specialized algorithm, e.g. modelling as a flow problem or a shortest path problem. The idea of reductions is also used a lot in computational complexity, for instance to prove that a problem is NP-hard, which is useful to a practitioner who does not know the complexity of a particular problem.
Various math tricks from number theory, linear algebra, trigonometry, computational geometry, etc. which pop up frequently in computer science.

Depending upon the kind of work you do, you might re-order the importance of the second half of this list. However, I think it is most important for a good computer scientist or software engineer to have a mastery of all these principles before they try to memorize a single algorithm. Just my 2 cents.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/pxnlb7e45iu32vfy', 'title': 'What are the top 10 algorithms every software engineer should know by heart?', 'score': {'original': 0.98115, 'ai': 0.01885}, 'blocks': [{'text': 'None.\n\nRather than memorizing algorithms, you should understand algorithmic principles, and know those algorithmic principles by heart. The goal in understanding algorithms is to be able to analyze algorithms you haven’t seen before, to be able to apply existing algorithms to new problems, and to be able to create new algorithms from scratch.\n\nOf course, in order to gain a good understanding of those algorithmic principles, you will need to study a lot of algorithms (way more than 10). It may be useful to keep to these algorithms you learn in your mind as canonical examples of the principles they deploy.\n\nFor instance, Mergesort is a good canonical example of the Divide-and-Conquer principle. It is not the only canonical example, and I would expect that someone who understands Divide-and-Conquer well would have a few examples in their mind. But someone who knows the Divide-and-Conquer principle behind Mergesort would probably be able to write pseudocode for it or code up an implementation without references. Although if they haven’t done so in a long time, it might take them a little while to produce the correct implementation, and their first attempt might be buggy.\n\nIn that sense, yes they do know Mergesort because they understand the principle behind it. However, it’s not like they “know by heart” the actual code. And they should not be expected to code it up without thinking. Quite the opposite, they should code it up by consciously referring in their mind to the principle that it uses. The end result may or may not look like the code they originally saw when they first learned Mergesort but it will use the same principle. Someone who understands algorithms well should never feel the need to memorize how to code any algorithm!!!\n\nHere are 10 algorithmic principles I think that every software engineer should know, roughly in the order of how important I think it is to know them:\n\nHow to analyze the running time of non-recursive code (nested for loops, while loops, etc.)\nHow to create and traverse dynamic linked data structures using pointers, and understanding when those data structures can be implemented as implicit/succinct data structures without using pointers (a good example is the binary heap, which could be implemented with pointers but is usually implemented implicitly for efficiency reasons)\nGraph traversal (BFS and DFS) and the various graph properties you might be interested in (connectivity, shortest path, cycle detection, etc.)\nHow to analyze the running time of recursive code (formulating recurrences, using Master Theorem, recognizing common recursive structures)\nThe divide and conquer principle (e.g. merge sort, binary search, fast exponentiation, majority algorithm, select/median-finding algorithm, Karatsuba/Toom-Cook multiplication, fast fourier transform, Strassen matrix multiplication, Preparata-Hong convex hull, closest point pair, etc.)\nDynamic programming and memoization (e.g. knapsack, shortest path, CYK parsing algorithm, longest common subsequence, edit distance, Knuth word wrap, solving games, etc.)\nIterative methods and how to analyze their convergence, error-bounding and numerical stability properties. In particular, you should at least be familiar with gradient descent/ascent and some common optimizations like Newton’s method. Should know common applications like root finding and solving linear systems.\nBranch-and-bound search strategies and their derivatives used in', 'result': {'fake': 0.0116, 'real': 0.9884}, 'status': 'success'}, {'text': 'AI like A*, IDA, alpha-beta pruning, etc.\nThe general principle of reductions, i.e. taking one problem and modelling it as another. In particular, it is useful to be able to model problems you want to solve as constraint satisfaction problems or linear programs, and use general purpose solvers to get the solution. Furthermore, sometimes you realize the constraints of your problem allow it to be modeled as a problem that can be solved with a specialized algorithm, e.g. modelling as a flow problem or a shortest path problem. The idea of reductions is also used a lot in computational complexity, for instance to prove that a problem is NP-hard, which is useful to a practitioner who does not know the complexity of a particular problem.\nVarious math tricks from number theory, linear algebra, trigonometry, computational geometry, etc. which pop up frequently in computer science.\n\nDepending upon the kind of work you do, you might re-order the importance of the second half of this list. However, I think it is most important for a good computer scientist or software engineer to have a mastery of all these principles before they try to memorize a single algorithm. Just my 2 cents.', 'result': {'fake': 0.1182, 'real': 0.8818}, 'status': 'success'}], 'credits_used': 8, 'credits': 1986375, 'subscription': 0, 'content': 'None.\n\nRather than memorizing algorithms, you should understand algorithmic principles, and know those algorithmic principles by heart. The goal in understanding algorithms is to be able to analyze algorithms you haven’t seen before, to be able to apply existing algorithms to new problems, and to be able to create new algorithms from scratch.\n\nOf course, in order to gain a good understanding of those algorithmic principles, you will need to study a lot of algorithms (way more than 10). It may be useful to keep to these algorithms you learn in your mind as canonical examples of the principles they deploy.\n\nFor instance, Mergesort is a good canonical example of the Divide-and-Conquer principle. It is not the only canonical example, and I would expect that someone who understands Divide-and-Conquer well would have a few examples in their mind. But someone who knows the Divide-and-Conquer principle behind Mergesort would probably be able to write pseudocode for it or code up an implementation without references. Although if they haven’t done so in a long time, it might take them a little while to produce the correct implementation, and their first attempt might be buggy.\n\nIn that sense, yes they do know Mergesort because they understand the principle behind it. However, it’s not like they “know by heart” the actual code. And they should not be expected to code it up without thinking. Quite the opposite, they should code it up by consciously referring in their mind to the principle that it uses. The end result may or may not look like the code they originally saw when they first learned Mergesort but it will use the same principle. Someone who understands algorithms well should never feel the need to memorize how to code any algorithm!!!\n\nHere are 10 algorithmic principles I think that every software engineer should know, roughly in the order of how important I think it is to know them:\n\nHow to analyze the running time of non-recursive code (nested for loops, while loops, etc.)\nHow to create and traverse dynamic linked data structures using pointers, and understanding when those data structures can be implemented as implicit/succinct data structures without using pointers (a good example is the binary heap, which could be implemented with pointers but is usually implemented implicitly for efficiency reasons)\nGraph traversal (BFS and DFS) and the various graph properties you might be interested in (connectivity, shortest path, cycle detection, etc.)\nHow to analyze the running time of recursive code (formulating recurrences, using Master Theorem, recognizing common recursive structures)\nThe divide and conquer principle (e.g. merge sort, binary search, fast exponentiation, majority algorithm, select/median-finding algorithm, Karatsuba/Toom-Cook multiplication, fast fourier transform, Strassen matrix multiplication, Preparata-Hong convex hull, closest point pair, etc.)\nDynamic programming and memoization (e.g. knapsack, shortest path, CYK parsing algorithm, longest common subsequence, edit distance, Knuth word wrap, solving games, etc.)\nIterative methods and how to analyze their convergence, error-bounding and numerical stability properties. In particular, you should at least be familiar with gradient descent/ascent and some common optimizations like Newton’s method. Should know common applications like root finding and solving linear systems.\nBranch-and-bound search strategies and their derivatives used in AI like A*, IDA, alpha-beta pruning, etc.\nThe general principle of reductions, i.e. taking one problem and modelling it as another. In particular, it is useful to be able to model problems you want to solve as constraint satisfaction problems or linear programs, and use general purpose solvers to get the solution. Furthermore, sometimes you realize the constraints of your problem allow it to be modeled as a problem that can be solved with a specialized algorithm, e.g. modelling as a flow problem or a shortest path problem. The idea of reductions is also used a lot in computational complexity, for instance to prove that a problem is NP-hard, which is useful to a practitioner who does not know the complexity of a particular problem.\nVarious math tricks from number theory, linear algebra, trigonometry, computational geometry, etc. which pop up frequently in computer science.\n\nDepending upon the kind of work you do, you might re-order the importance of the second half of this list. However, I think it is most important for a good computer scientist or software engineer to have a mastery of all these principles before they try to memorize a single algorithm. Just my 2 cents.', 'aiModelVersion': '1'}",0.98115
Robin Thomas,7y,"What is the difference between an array, a list, and a linked list?","Take out your wallet. All your credit cards filled in neatly (contiguous memory locations of same type). That’s an Array. You can take any credit card from the wallet in constant time.

Put a new credit card in the wallet? Find an empty slot, and insert the card. What if the wallet is full? You cannot add anymore. Need a bigger wallet. Move your credit cards into the new wallet. Same principle with the arrays.

You know how to play Treasure Hunt? You first find Clue 1, then Clue 2 .. and so on until say, Clue 10 leading you to the treasure. Clues are spread throughout your house (non-contiguous memory locations). The game is simply a chain of clues. Or in other words a Linked List.

You start with Clue 1. You cannot find Clue 3 without finding Clue 2. So the order within the chain of clues is important.

Add a new Clue? Add Clue 11 to the chain leading to the treasure. Clue 10 now simply leads to Clue 11 (instead of the treasure). Remove a Clue? Same principle. That’s adding/deleting nodes in a linked list.

Ignore the term list. Its just a generic term.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/h5eavlcxpogu1dkq', 'title': 'What is the difference between an array, a list, and a linked list?', 'score': {'original': 0.9998, 'ai': 0.0002}, 'blocks': [{'text': 'Take out your wallet. All your credit cards filled in neatly (contiguous memory locations of same type). That’s an Array. You can take any credit card from the wallet in constant time.\n\nPut a new credit card in the wallet? Find an empty slot, and insert the card. What if the wallet is full? You cannot add anymore. Need a bigger wallet. Move your credit cards into the new wallet. Same principle with the arrays.\n\nYou know how to play Treasure Hunt? You first find Clue 1, then Clue 2 .. and so on until say, Clue 10 leading you to the treasure. Clues are spread throughout your house (non-contiguous memory locations). The game is simply a chain of clues. Or in other words a Linked List.\n\nYou start with Clue 1. You cannot find Clue 3 without finding Clue 2. So the order within the chain of clues is important.\n\nAdd a new Clue? Add Clue 11 to the chain leading to the treasure. Clue 10 now simply leads to Clue 11 (instead of the treasure). Remove a Clue? Same principle. That’s adding/deleting nodes in a linked list.\n\nIgnore the term list. Its just a generic term.', 'result': {'fake': 0.0002, 'real': 0.9998}, 'status': 'success'}], 'credits_used': 2, 'credits': 1986373, 'subscription': 0, 'content': 'Take out your wallet. All your credit cards filled in neatly (contiguous memory locations of same type). That’s an Array. You can take any credit card from the wallet in constant time.\n\nPut a new credit card in the wallet? Find an empty slot, and insert the card. What if the wallet is full? You cannot add anymore. Need a bigger wallet. Move your credit cards into the new wallet. Same principle with the arrays.\n\nYou know how to play Treasure Hunt? You first find Clue 1, then Clue 2 .. and so on until say, Clue 10 leading you to the treasure. Clues are spread throughout your house (non-contiguous memory locations). The game is simply a chain of clues. Or in other words a Linked List.\n\nYou start with Clue 1. You cannot find Clue 3 without finding Clue 2. So the order within the chain of clues is important.\n\nAdd a new Clue? Add Clue 11 to the chain leading to the treasure. Clue 10 now simply leads to Clue 11 (instead of the treasure). Remove a Clue? Same principle. That’s adding/deleting nodes in a linked list.\n\nIgnore the term list. Its just a generic term.', 'aiModelVersion': '1'}",0.9998
Anders Kaseorg,Updated 6y,How does Git merge work?,"Recall that a Git repository is structured as a directed acyclic graph: every Git commit is a snapshot of the tree along with references to its parent commits (usually one parent, but the initial commit has no parents, while a merge commit has two or more parents). So each commit recursively references some set of ancestor commits. It’s usually more helpful to think of a commit as representing a patch, by taking the diff between the commit’s parent tree(s) and the commit’s tree. In this way, one thinks of a commit’s tree as the result of applying all of its ancestor’s patches. The tree of a merge commit between two branches, therefore, can be thought of as the result of applying all of the patches in the union of the two branches’ sets of ancestors.

But that is not how git merge is actually implemented, both because it would be terribly slow, and because it would require re-resolving all the merge conflicts that ever happened along the way. So what’s actually going on?

I like to think about this mathematically: given commits 
A
A
 and 
B
B
, the merge commit 
A
∨
B
A∨B
 is represented by 
[
A
∨
B
]
=
[
A
]
+
[
B
]
−
[
C
]
[A∨B]=[A]+[B]−[C]
, where 
C
C
 is the merge base
 (most recent common ancestor) of 
A
A
 and 
B
B
. We have to “subtract out” 
[
C
]
[C]
 because otherwise that content would be double-counted by 
[
A
]
[A]
 and 
[
B
]
[B]
. This operation 
x
+
y
−
w
x+y−w
 is called a three-way merge. You can think of this as applying the patch 
y
−
w
y−w
 to 
x
x
, or as applying the patch 
x
−
w
x−w
 to 
y
y
.

In fact this operation is not literally implemented with diff and patch, but with the algorithm used to build them: the longest common subsequence
 algorithm. The diff 
x
−
w
x−w
 between two sequences 
x
,
w
x,w
 of lines is just what we get when we align them along their longest common subsequence (and perhaps throw out the long spans that are common to both sequences). To construct the three-way merge 
x
+
y
−
w
x+y−w
, we align 
x
x
 and 
w
w
 along their longest common subsequence, align 
y
y
 and 
w
w
 along their longest common subsequence, and then output each line that’s either

common to all three sequences, or
present in 
x
x
 but absent in 
y
y
 and 
w
w
, or
present in 
y
y
 but absent in 
x
x
 and 
w
w
,

while we delete the lines that are either

present in 
y
y
 and 
w
w
 but absent in 
x
x
, or
present in 
x
x
 and 
w
w
 but absent in 
y
y
.

Here’s an example:

x:      w:      y:      ↦ merged: 
milk    milk    milk      milk 
juice                     juice 
flour   flour   flour     flour 
                sausage   sausage 
eggs    eggs    eggs      eggs 
        butter  butter 

The order of the lines of 
x
x
, 
y
y
, and 
w
w
 may only impose a partial order on the output lines of the three-way merge. If so, it’s because the same block of 
w
w
 was edited in two different ways between 
x
x
 and 
y
y
—so we declare that block to be a merge conflict and present it to the user to resolve manually.

When git shows you a merge conflict, by default you will only see x and y blocks of the conflict:

<<<<<<< x 
I had one egg and three sausages for breakfast. 
======= 
I had two eggs and two sausages for breakfast. 
>>>>>>> y 

However, merge conflicts become much easier to resolve when you can see the merge base 
w
w
. I recommend turning this on in ~/.gitconfig by running git config --global merge.conflictstyle diff3
.

<<<<<<< x 
I had one egg and three sausages for breakfast. 
||||||| w 
I had one egg and two sausages for breakfast. 
======= 
I had two eggs and two sausages for breakfast. 
>>>>>>> y 

Now you can see that this resolves to:

I had two eggs and three sausages for breakfast. 

(Note that this operation is symmetric w.r.t exchanging 
w
w
 with the result, so you really do need to see 
w
w
.)

There are two other cases to consider: there may be lines that are

present in 
x
x
 and 
y
y
 but absent in 
w
w
, or
present in 
w
w
 but absent in 
x
x
 and 
y
y
.

Some three-way merge algorithms will always tag such lines as merge conflicts. Git, however, will instead happily output or delete such lines, respectively, provided that the surrounding lines didn’t change. This effect is called an accidental clean merge. It is occasionally convenient in practice, especially when the user screwed up and merged two different versions of the same patch with each other. But I think it’s generally not a good idea to cover up such mistakes and wish this behavior could be turned off. Try to avoid taking advantage of it.

If you’ve been paying careful attention, you might have spotted a small hole in my description above: since the commits 
A
A
 and 
B
B
 may themselves contain merge commits, their most recent common ancestor might not be unique! In general, there may be many most recent common ancestors 
C
1
,
…
,
C
k
C1,…,Ck
. In this case, git merge proceeds recursively: it first constructs the merge 
C
=
C
1
∨
…
∨
C
k
C=C1∨…∨Ck
, and uses that as the merge base for the three way merge 
[
A
]
+
[
B
]
−
[
C
]
[A]+[B]−[C]
. This is why Git’s default merge strategy is named recursive.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/w54a6e9sbi2qgn0j', 'title': 'How does Git merge work?', 'score': {'original': 0.9842, 'ai': 0.0158}, 'blocks': [{'text': 'Recall that a Git repository is structured as a directed acyclic graph: every Git commit is a snapshot of the tree along with references to its parent commits (usually one parent, but the initial commit has no parents, while a merge commit has two or more parents). So each commit recursively references some set of ancestor commits. It’s usually more helpful to think of a commit as representing a patch, by taking the diff between the commit’s parent tree(s) and the commit’s tree. In this way, one thinks of a commit’s tree as the result of applying all of its ancestor’s patches. The tree of a merge commit between two branches, therefore, can be thought of as the result of applying all of the patches in the union of the two branches’ sets of ancestors.\n\nBut that is not how git merge is actually implemented, both because it would be terribly slow, and because it would require re-resolving all the merge conflicts that ever happened along the way. So what’s actually going on?\n\nI like to think about this mathematically: given commits \nA\nA\n and \nB\nB\n, the merge commit \nA\n∨\nB\nA∨B\n is represented by \n[\nA\n∨\nB\n]\n=\n[\nA\n]\n+\n[\nB\n]\n−\n[\nC\n]\n[A∨B]=[A]+[B]−[C]\n, where \nC\nC\n is the merge base\n (most recent common ancestor) of \nA\nA\n and \nB\nB\n. We have to “subtract out” \n[\nC\n]\n[C]\n because otherwise that content would be double-counted by \n[\nA\n]\n[A]\n and \n[\nB\n]\n[B]\n. This operation \nx\n+\ny\n−\nw\nx+y−w\n is called a three-way merge. You can think of this as applying the patch \ny\n−\nw\ny−w\n to \nx\nx\n, or as applying the patch \nx\n−\nw\nx−w\n to \ny\ny\n.\n\nIn fact this operation is not literally implemented with diff and patch, but with the algorithm used to build them: the longest common subsequence\n algorithm. The diff \nx\n−\nw\nx−w\n between two sequences \nx\n,\nw\nx,w\n of lines is just what we get when we align them along their longest common subsequence (and perhaps throw out the long spans that are common to both sequences). To construct the three-way merge \nx\n+\ny\n−\nw\nx+y−w\n, we align \nx\nx\n and \nw\nw\n along their longest common subsequence, align \ny\ny\n and \nw\nw\n along their longest common subsequence, and then output each line that’s either\n\ncommon to all three sequences, or\npresent in \nx\nx\n but absent in \ny\ny\n and \nw\nw\n, or\npresent in \ny\ny\n but absent in \nx\nx\n and \nw\nw\n,\n\nwhile we delete the lines that are either\n\npresent in \ny\ny\n and \nw\nw\n but absent in \nx\nx\n, or\npresent in \nx\nx\n and \nw\nw\n but absent in \ny\ny\n.\n\nHere’s an example:\n\nx:      w:      y:      ↦ merged:\xa0\nmilk    milk    milk      milk\xa0\njuice                     juice\xa0\nflour   flour   flour     flour\xa0\n                sausage   sausage\xa0\neggs    eggs    eggs      eggs\xa0\n        butter  butter\xa0\n\nThe order of the lines of \nx\nx\n, \ny\ny\n, and \nw\nw\n may only impose a partial', 'result': {'fake': 0.0423, 'real': 0.9577}, 'status': 'success'}, {'text': 'order on the output lines of the three-way merge. If so, it’s because the same block of \nw\nw\n was edited in two different ways between \nx\nx\n and \ny\ny\n—so we declare that block to be a merge conflict and present it to the user to resolve manually.\n\nWhen git shows you a merge conflict, by default you will only see x and y blocks of the conflict:\n\n<<<<<<< x\xa0\nI had one egg and three sausages for breakfast.\xa0\n=======\xa0\nI had two eggs and two sausages for breakfast.\xa0\n>>>>>>> y\xa0\n\nHowever, merge conflicts become much easier to resolve when you can see the merge base \nw\nw\n. I recommend turning this on in ~/.gitconfig by running git config --global merge.conflictstyle diff3\n.\n\n<<<<<<< x\xa0\nI had one egg and three sausages for breakfast.\xa0\n||||||| w\xa0\nI had one egg and two sausages for breakfast.\xa0\n=======\xa0\nI had two eggs and two sausages for breakfast.\xa0\n>>>>>>> y\xa0\n\nNow you can see that this resolves to:\n\nI had two eggs and three sausages for breakfast.\xa0\n\n(Note that this operation is symmetric w.r.t exchanging \nw\nw\n with the result, so you really do need to see \nw\nw\n.)\n\nThere are two other cases to consider: there may be lines that are\n\npresent in \nx\nx\n and \ny\ny\n but absent in \nw\nw\n, or\npresent in \nw\nw\n but absent in \nx\nx\n and \ny\ny\n.\n\nSome three-way merge algorithms will always tag such lines as merge conflicts. Git, however, will instead happily output or delete such lines, respectively, provided that the surrounding lines didn’t change. This effect is called an accidental clean merge. It is occasionally convenient in practice, especially when the user screwed up and merged two different versions of the same patch with each other. But I think it’s generally not a good idea to cover up such mistakes and wish this behavior could be turned off. Try to avoid taking advantage of it.\n\nIf you’ve been paying careful attention, you might have spotted a small hole in my description above: since the commits \nA\nA\n and \nB\nB\n may themselves contain merge commits, their most recent common ancestor might not be unique! In general, there may be many most recent common ancestors \nC\n1\n,\n…\n,\nC\nk\nC1,…,Ck\n. In this case, git merge proceeds recursively: it first constructs the merge \nC\n=\nC\n1\n∨\n…\n∨\nC\nk\nC=C1∨…∨Ck\n, and uses that as the merge base for the three way merge \n[\nA\n]\n+\n[\nB\n]\n−\n[\nC\n]\n[A]+[B]−[C]\n. This is why Git’s default merge strategy is named recursive.', 'result': {'fake': 0.5359, 'real': 0.4641}, 'status': 'success'}], 'credits_used': 10, 'credits': 1986363, 'subscription': 0, 'content': 'Recall that a Git repository is structured as a directed acyclic graph: every Git commit is a snapshot of the tree along with references to its parent commits (usually one parent, but the initial commit has no parents, while a merge commit has two or more parents). So each commit recursively references some set of ancestor commits. It’s usually more helpful to think of a commit as representing a patch, by taking the diff between the commit’s parent tree(s) and the commit’s tree. In this way, one thinks of a commit’s tree as the result of applying all of its ancestor’s patches. The tree of a merge commit between two branches, therefore, can be thought of as the result of applying all of the patches in the union of the two branches’ sets of ancestors.\n\nBut that is not how git merge is actually implemented, both because it would be terribly slow, and because it would require re-resolving all the merge conflicts that ever happened along the way. So what’s actually going on?\n\nI like to think about this mathematically: given commits \nA\nA\n and \nB\nB\n, the merge commit \nA\n∨\nB\nA∨B\n is represented by \n[\nA\n∨\nB\n]\n=\n[\nA\n]\n+\n[\nB\n]\n−\n[\nC\n]\n[A∨B]=[A]+[B]−[C]\n, where \nC\nC\n is the merge base\n (most recent common ancestor) of \nA\nA\n and \nB\nB\n. We have to “subtract out” \n[\nC\n]\n[C]\n because otherwise that content would be double-counted by \n[\nA\n]\n[A]\n and \n[\nB\n]\n[B]\n. This operation \nx\n+\ny\n−\nw\nx+y−w\n is called a three-way merge. You can think of this as applying the patch \ny\n−\nw\ny−w\n to \nx\nx\n, or as applying the patch \nx\n−\nw\nx−w\n to \ny\ny\n.\n\nIn fact this operation is not literally implemented with diff and patch, but with the algorithm used to build them: the longest common subsequence\n algorithm. The diff \nx\n−\nw\nx−w\n between two sequences \nx\n,\nw\nx,w\n of lines is just what we get when we align them along their longest common subsequence (and perhaps throw out the long spans that are common to both sequences). To construct the three-way merge \nx\n+\ny\n−\nw\nx+y−w\n, we align \nx\nx\n and \nw\nw\n along their longest common subsequence, align \ny\ny\n and \nw\nw\n along their longest common subsequence, and then output each line that’s either\n\ncommon to all three sequences, or\npresent in \nx\nx\n but absent in \ny\ny\n and \nw\nw\n, or\npresent in \ny\ny\n but absent in \nx\nx\n and \nw\nw\n,\n\nwhile we delete the lines that are either\n\npresent in \ny\ny\n and \nw\nw\n but absent in \nx\nx\n, or\npresent in \nx\nx\n and \nw\nw\n but absent in \ny\ny\n.\n\nHere’s an example:\n\nx:      w:      y:      ↦ merged:\xa0\nmilk    milk    milk      milk\xa0\njuice                     juice\xa0\nflour   flour   flour     flour\xa0\n                sausage   sausage\xa0\neggs    eggs    eggs      eggs\xa0\n        butter  butter\xa0\n\nThe order of the lines of \nx\nx\n, \ny\ny\n, and \nw\nw\n may only impose a partial order on the output lines of the three-way merge. If so, it’s because the same block of \nw\nw\n was edited in two different ways between \nx\nx\n and \ny\ny\n—so we declare that block to be a merge conflict and present it to the user to resolve manually.\n\nWhen git shows you a merge conflict, by default you will only see x and y blocks of the conflict:\n\n<<<<<<< x\xa0\nI had one egg and three sausages for breakfast.\xa0\n=======\xa0\nI had two eggs and two sausages for breakfast.\xa0\n>>>>>>> y\xa0\n\nHowever, merge conflicts become much easier to resolve when you can see the merge base \nw\nw\n. I recommend turning this on in ~/.gitconfig by running git config --global merge.conflictstyle diff3\n.\n\n<<<<<<< x\xa0\nI had one egg and three sausages for breakfast.\xa0\n||||||| w\xa0\nI had one egg and two sausages for breakfast.\xa0\n=======\xa0\nI had two eggs and two sausages for breakfast.\xa0\n>>>>>>> y\xa0\n\nNow you can see that this resolves to:\n\nI had two eggs and three sausages for breakfast.\xa0\n\n(Note that this operation is symmetric w.r.t exchanging \nw\nw\n with the result, so you really do need to see \nw\nw\n.)\n\nThere are two other cases to consider: there may be lines that are\n\npresent in \nx\nx\n and \ny\ny\n but absent in \nw\nw\n, or\npresent in \nw\nw\n but absent in \nx\nx\n and \ny\ny\n.\n\nSome three-way merge algorithms will always tag such lines as merge conflicts. Git, however, will instead happily output or delete such lines, respectively, provided that the surrounding lines didn’t change. This effect is called an accidental clean merge. It is occasionally convenient in practice, especially when the user screwed up and merged two different versions of the same patch with each other. But I think it’s generally not a good idea to cover up such mistakes and wish this behavior could be turned off. Try to avoid taking advantage of it.\n\nIf you’ve been paying careful attention, you might have spotted a small hole in my description above: since the commits \nA\nA\n and \nB\nB\n may themselves contain merge commits, their most recent common ancestor might not be unique! In general, there may be many most recent common ancestors \nC\n1\n,\n…\n,\nC\nk\nC1,…,Ck\n. In this case, git merge proceeds recursively: it first constructs the merge \nC\n=\nC\n1\n∨\n…\n∨\nC\nk\nC=C1∨…∨Ck\n, and uses that as the merge base for the three way merge \n[\nA\n]\n+\n[\nB\n]\n−\n[\nC\n]\n[A]+[B]−[C]\n. This is why Git’s default merge strategy is named recursive.', 'aiModelVersion': '1'}",0.9842
Thomas Cormen,3y,What textbook did the CLRS authors use before CLRS?,"A2A

I recall answering this question elsewhere. I cannot speak for my coauthors, but I used The Design and Analysis of Computer Algorithms by Aho, Hopcroft, and Ullman. I bought the book when it was first published, back in 1975, and it was the textbook used when I took the undergraduate algorithms course at Princeton, EECS 423, from Ken Steiglitz in 1976. I learned the algorithms material much better by TAing the MIT undergraduate algorithms course, 6.046, taught by Charles Leiserson. That’s what led to Introduction to Algorithms.

As I like to point out, I did not get an A in algorithms as an undergraduate. I got A-. All told, my best grades were in Civil Engineering courses (four A+, one A, and of the four A+, two of them were in graduate-level courses)","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/exsqotkd36yhr1vz', 'title': 'What textbook did the CLRS authors use before CLRS?', 'score': {'original': 0.9985, 'ai': 0.0015}, 'blocks': [{'text': 'A2A\n\nI recall answering this question elsewhere. I cannot speak for my coauthors, but I used The Design and Analysis of Computer Algorithms by Aho, Hopcroft, and Ullman. I bought the book when it was first published, back in 1975, and it was the textbook used when I took the undergraduate algorithms course at Princeton, EECS 423, from Ken Steiglitz in 1976. I learned the algorithms material much better by TAing the MIT undergraduate algorithms course, 6.046, taught by Charles Leiserson. That’s what led to Introduction to Algorithms.\n\nAs I like to point out, I did not get an A in algorithms as an undergraduate. I got A-. All told, my best grades were in Civil Engineering courses (four A+, one A, and of the four A+, two of them were in graduate-level courses)', 'result': {'fake': 0.0015, 'real': 0.9985}, 'status': 'success'}], 'credits_used': 2, 'credits': 1986361, 'subscription': 0, 'content': 'A2A\n\nI recall answering this question elsewhere. I cannot speak for my coauthors, but I used The Design and Analysis of Computer Algorithms by Aho, Hopcroft, and Ullman. I bought the book when it was first published, back in 1975, and it was the textbook used when I took the undergraduate algorithms course at Princeton, EECS 423, from Ken Steiglitz in 1976. I learned the algorithms material much better by TAing the MIT undergraduate algorithms course, 6.046, taught by Charles Leiserson. That’s what led to Introduction to Algorithms.\n\nAs I like to point out, I did not get an A in algorithms as an undergraduate. I got A-. All told, my best grades were in Civil Engineering courses (four A+, one A, and of the four A+, two of them were in graduate-level courses)', 'aiModelVersion': '1'}",0.9985
Pranav Gokhale,Updated 7y,What is the coolest data structure? What makes it so cool?,"My vote for coolest data structure goes to the Merkle Tree. To understand the Merkle Tree, we first need to understand the hash pointer, a concept upon which it is built. (Related answer: Pranav Gokhale's answer to What are some practical applications of hashing? [ https://www.quora.com/What-are-some-practical-applications-of-hashing/answer/Pranav-Gokhale ])




A hash pointer is just a pair of values:

hash_pointer = (pointer, hash_value) 

The pointer a plain-old pointer that specifies a memory address. This is no different from a pointer in a linked list or a tree.

The interesting part is the hash_value field which stores the hash of whatever content is being pointed to.

Here is a picture: [1]

The red arrow represents the pointer that stores a memory address and the H( ) indicates the storage of the hash of (data).




The power of hash pointers becomes apparent when we take regular data structures and replace the pointers with hash pointers. For example, when you take a linked list but use hash pointers instead of regular pointers, you get a data structure called a block chain: [2]

The magic of a block chain is that it offers tamper-detection. If someone tries to change some data in one of the nodes, then the hash value changes too and is no longer consistent with the hash_value reported in the hash pointer.

The best known application of block chain is Bitcoin, a cryptocurrency in which new transactions are collected into blocks every ten minutes. Because block chain offers tamper-detection, an end user who stores just the most recent hash pointer (the top right most H( ) in the diagram above), can verify the entire history of transactions ever made in Bitcoin!




This brings us to the final act, the Merkle Tree. The Merkle Tree is a binary tree with hash pointers instead of regular pointers and data stor...

Access this answer and support the author as a Quora+ subscriber
Access all answers reserved by 
Pranav Gokhale
 for Quora+ subscribers
Access exclusive answers from thousands more participating creators in Quora+
Browse ad‑free and support creators
Start free trial
Learn more","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/4dytnkm58ix19bej', 'title': 'What is the coolest data structure? What makes it so cool?', 'score': {'original': 0.9997, 'ai': 0.0003}, 'blocks': [{'text': ""My vote for coolest data structure goes to the Merkle Tree. To understand the Merkle Tree, we first need to understand the hash pointer, a concept upon which it is built. (Related answer: Pranav Gokhale's answer to What are some practical applications of hashing? [ https://www.quora.com/What-are-some-practical-applications-of-hashing/answer/Pranav-Gokhale ])\n\n\n\n\nA hash pointer is just a pair of values:\n\nhash_pointer = (pointer, hash_value)\xa0\n\nThe pointer a plain-old pointer that specifies a memory address. This is no different from a pointer in a linked list or a tree.\n\nThe interesting part is the hash_value field which stores the hash of whatever content is being pointed to.\n\nHere is a picture: [1]\n\nThe red arrow represents the pointer that stores a memory address and the H( ) indicates the storage of the hash of (data).\n\n\n\n\nThe power of hash pointers becomes apparent when we take regular data structures and replace the pointers with hash pointers. For example, when you take a linked list but use hash pointers instead of regular pointers, you get a data structure called a block chain: [2]\n\nThe magic of a block chain is that it offers tamper-detection. If someone tries to change some data in one of the nodes, then the hash value changes too and is no longer consistent with the hash_value reported in the hash pointer.\n\nThe best known application of block chain is Bitcoin, a cryptocurrency in which new transactions are collected into blocks every ten minutes. Because block chain offers tamper-detection, an end user who stores just the most recent hash pointer (the top right most H( ) in the diagram above), can verify the entire history of transactions ever made in Bitcoin!\n\n\n\n\nThis brings us to the final act, the Merkle Tree. The Merkle Tree is a binary tree with hash pointers instead of regular pointers and data stor...\n\nAccess this answer and support the author as a Quora+ subscriber\nAccess all answers reserved by \nPranav Gokhale\n for Quora+ subscribers\nAccess exclusive answers from thousands more participating creators in Quora+\nBrowse ad‑free and support creators\nStart free trial\nLearn more"", 'result': {'fake': 0.0003, 'real': 0.9997}, 'status': 'success'}], 'credits_used': 4, 'credits': 1986357, 'subscription': 0, 'content': ""My vote for coolest data structure goes to the Merkle Tree. To understand the Merkle Tree, we first need to understand the hash pointer, a concept upon which it is built. (Related answer: Pranav Gokhale's answer to What are some practical applications of hashing? [ https://www.quora.com/What-are-some-practical-applications-of-hashing/answer/Pranav-Gokhale ])\n\n\n\n\nA hash pointer is just a pair of values:\n\nhash_pointer = (pointer, hash_value)\xa0\n\nThe pointer a plain-old pointer that specifies a memory address. This is no different from a pointer in a linked list or a tree.\n\nThe interesting part is the hash_value field which stores the hash of whatever content is being pointed to.\n\nHere is a picture: [1]\n\nThe red arrow represents the pointer that stores a memory address and the H( ) indicates the storage of the hash of (data).\n\n\n\n\nThe power of hash pointers becomes apparent when we take regular data structures and replace the pointers with hash pointers. For example, when you take a linked list but use hash pointers instead of regular pointers, you get a data structure called a block chain: [2]\n\nThe magic of a block chain is that it offers tamper-detection. If someone tries to change some data in one of the nodes, then the hash value changes too and is no longer consistent with the hash_value reported in the hash pointer.\n\nThe best known application of block chain is Bitcoin, a cryptocurrency in which new transactions are collected into blocks every ten minutes. Because block chain offers tamper-detection, an end user who stores just the most recent hash pointer (the top right most H( ) in the diagram above), can verify the entire history of transactions ever made in Bitcoin!\n\n\n\n\nThis brings us to the final act, the Merkle Tree. The Merkle Tree is a binary tree with hash pointers instead of regular pointers and data stor...\n\nAccess this answer and support the author as a Quora+ subscriber\nAccess all answers reserved by \nPranav Gokhale\n for Quora+ subscribers\nAccess exclusive answers from thousands more participating creators in Quora+\nBrowse ad‑free and support creators\nStart free trial\nLearn more"", 'aiModelVersion': '1'}",0.9997
Alex Eustis,2y,Is it possible to have a sorting algorithm with worst case O(1) time complexity?,"No. A correct sorting algorithm has to at least read the input and write the output, which is a 
Ω
(
n
)
Ω(n)
 operation. You can't even reverse a list in O(1) time. You can't even count the number of 0’s in a list in O(1) time. You can't do anything involving a list in O(1) time, because that would mean the algorithm doesn't even read the list, which is absurd.

Just about the only thing you can do in O(1) time is this:

function wishSort(list) { 
   // Wish that the list is already sorted, then return it. 
   return list 
} ","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/48svpnkyqhgeif3j', 'title': 'Is it possible to have a sorting algorithm with worst case O(1) time complexity?', 'score': {'original': 0.0346, 'ai': 0.9654}, 'blocks': [{'text': ""No. A correct sorting algorithm has to at least read the input and write the output, which is a \nΩ\n(\nn\n)\nΩ(n)\n operation. You can't even reverse a list in O(1) time. You can't even count the number of 0’s in a list in O(1) time. You can't do anything involving a list in O(1) time, because that would mean the algorithm doesn't even read the list, which is absurd.\n\nJust about the only thing you can do in O(1) time is this:\n\nfunction wishSort(list) {\xa0\n   // Wish that the list is already sorted, then return it.\xa0\n   return list\xa0\n}\xa0"", 'result': {'fake': 0.9654, 'real': 0.0346}, 'status': 'success'}], 'credits_used': 1, 'credits': 1986356, 'subscription': 0, 'content': ""No. A correct sorting algorithm has to at least read the input and write the output, which is a \nΩ\n(\nn\n)\nΩ(n)\n operation. You can't even reverse a list in O(1) time. You can't even count the number of 0’s in a list in O(1) time. You can't do anything involving a list in O(1) time, because that would mean the algorithm doesn't even read the list, which is absurd.\n\nJust about the only thing you can do in O(1) time is this:\n\nfunction wishSort(list) {\xa0\n   // Wish that the list is already sorted, then return it.\xa0\n   return list\xa0\n}\xa0"", 'aiModelVersion': '1'}",0.0346
Alan Kay,2y,I searched YouTube for Alan Kay with Donald Knuth and found nothing. How does Alan Kay understand the essence of literate programming? Is it to design code like you would have to teach it?,"Don and I have been friends for more than 50 years now. The simple summary of “literate programming” is that “Don is amazing”, both in “many ways” and in how he goes about programming, and what he thinks a program *is*.

He wrote a nice short paper and example for a book about programming by Doug McElroy, that got many prominent programmers to write a program for a problem — I think it was text justification or some such — and also comment about it.

A much longer, and very illuminating example, is the “B” book for TEX.

Don thinks of the form of a program as kind of essay that has to be as comprehensible as possible to both humans and computers. The burden of this is on the human programmer, who has a set of tools to help create the composite document — this includes an “extractor” that extracts and stitches together the programming language text in a number of ways.

He has generally not been terribly interested in VHLLs, in part — I think — because a well explained MHLL is pretty darn understandable in considerable detail (at some point the “wealth” of detail starts to become a tax).

Don started programming in the late 50s (when many of us old timers did), and the algorithms and data structures styles of those days produced programs that were somewhat “narrative” in structure, and Don’s “Web” tools for “literate programming” facilitate narratives.

As one moves from procedures and data structures to systems, especially at scale, the narrative structure quickly loses much of its benefits (you can tell the story of a few people in an apartment building in New York City, but trying the describe the city requires a very different kind of approach).

There have been experiments with organizing “narrative threads” through system descriptions, none of which I’m aware of quite delivered enough value. Since we humans are organized around stories and narrative, finding ways to bridge this gap for systems would not only “be nice”, but I think it has to be a critical part of making further progress,","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/a9z2m3dw7ufc0koy', 'title': 'I searched YouTube for Alan Kay with Donald Knuth and found nothing. How does Alan Kay understand the essence of literate programming? Is it to design code like you would have to teach it?', 'score': {'original': 0.6981, 'ai': 0.3019}, 'blocks': [{'text': 'Don and I have been friends for more than 50 years now. The simple summary of “literate programming” is that “Don is amazing”, both in “many ways” and in how he goes about programming, and what he thinks a program *is*.\n\nHe wrote a nice short paper and example for a book about programming by Doug McElroy, that got many prominent programmers to write a program for a problem — I think it was text justification or some such — and also comment about it.\n\nA much longer, and very illuminating example, is the “B” book for TEX.\n\nDon thinks of the form of a program as kind of essay that has to be as comprehensible as possible to both humans and computers. The burden of this is on the human programmer, who has a set of tools to help create the composite document — this includes an “extractor” that extracts and stitches together the programming language text in a number of ways.\n\nHe has generally not been terribly interested in VHLLs, in part — I think — because a well explained MHLL is pretty darn understandable in considerable detail (at some point the “wealth” of detail starts to become a tax).\n\nDon started programming in the late 50s (when many of us old timers did), and the algorithms and data structures styles of those days produced programs that were somewhat “narrative” in structure, and Don’s “Web” tools for “literate programming” facilitate narratives.\n\nAs one moves from procedures and data structures to systems, especially at scale, the narrative structure quickly loses much of its benefits (you can tell the story of a few people in an apartment building in New York City, but trying the describe the city requires a very different kind of approach).\n\nThere have been experiments with organizing “narrative threads” through system descriptions, none of which I’m aware of quite delivered enough value. Since we humans are organized around stories and narrative, finding ways to bridge this gap for systems would not only “be nice”, but I think it has to be a critical part of making further progress,', 'result': {'fake': 0.3019, 'real': 0.6981}, 'status': 'success'}], 'credits_used': 4, 'credits': 1986352, 'subscription': 0, 'content': 'Don and I have been friends for more than 50 years now. The simple summary of “literate programming” is that “Don is amazing”, both in “many ways” and in how he goes about programming, and what he thinks a program *is*.\n\nHe wrote a nice short paper and example for a book about programming by Doug McElroy, that got many prominent programmers to write a program for a problem — I think it was text justification or some such — and also comment about it.\n\nA much longer, and very illuminating example, is the “B” book for TEX.\n\nDon thinks of the form of a program as kind of essay that has to be as comprehensible as possible to both humans and computers. The burden of this is on the human programmer, who has a set of tools to help create the composite document — this includes an “extractor” that extracts and stitches together the programming language text in a number of ways.\n\nHe has generally not been terribly interested in VHLLs, in part — I think — because a well explained MHLL is pretty darn understandable in considerable detail (at some point the “wealth” of detail starts to become a tax).\n\nDon started programming in the late 50s (when many of us old timers did), and the algorithms and data structures styles of those days produced programs that were somewhat “narrative” in structure, and Don’s “Web” tools for “literate programming” facilitate narratives.\n\nAs one moves from procedures and data structures to systems, especially at scale, the narrative structure quickly loses much of its benefits (you can tell the story of a few people in an apartment building in New York City, but trying the describe the city requires a very different kind of approach).\n\nThere have been experiments with organizing “narrative threads” through system descriptions, none of which I’m aware of quite delivered enough value. Since we humans are organized around stories and narrative, finding ways to bridge this gap for systems would not only “be nice”, but I think it has to be a critical part of making further progress,', 'aiModelVersion': '1'}",0.6981
Alon Amit,Updated 9mo,Are there missing prime numbers in between already discovered primes? There are various algorithms for discovering ever larger primes. Is it possible that these algorithms miss primes that are in between them?,"It’s not just possible, it’s guaranteed. The algorithms for finding the largest known primes are only useful for finding primes of a VERY special type, known as Mersenne primes, which are numbers of the form 2N−12N−12^N-1. We have no way, not even remotely, of checking primality of very large numbers which aren’t of this very special form. For example, as of right now the largest known prime is 282,589,933−1282,589,933−12^{82,589,933}-1. The previous record was 277,232,917−1277,232,917−12^{77,232,917}-1. In between these two numbers there are over 1010,000,0001010,000,00010^{10,000,000} prime numbers. That’s ten to the power of ten million. That’s how many primes there are between the current record and the previous record, and we don’t know any of those primes, and very likely never will. Here’s my attempt at portraying the various regions of prime numbers. There’s a region in which we can test any number for primality (it may take months or years at the top end), and there’s a region in which we couldn’t possibly do that but we can still check Mersenne prime candidates (which still takes months or years). These two regions are so far removed from each other it’s not even funny.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/r6a8qugksebpvfz0', 'title': 'Are there missing prime numbers in between already discovered primes? There are various algorithms for discovering ever larger primes. Is it possible that these algorithms miss primes that are in between them?', 'score': {'original': 0.999, 'ai': 0.001}, 'blocks': [{'text': 'It’s not just possible, it’s guaranteed. The algorithms for finding the largest known primes are only useful for finding primes of a VERY special type, known as Mersenne primes, which are numbers of the form 2N−12N−12^N-1. We have no way, not even remotely, of checking primality of very large numbers which aren’t of this very special form. For example, as of right now the largest known prime is 282,589,933−1282,589,933−12^{82,589,933}-1. The previous record was 277,232,917−1277,232,917−12^{77,232,917}-1. In between these two numbers there are over 1010,000,0001010,000,00010^{10,000,000} prime numbers. That’s ten to the power of ten million. That’s how many primes there are between the current record and the previous record, and we don’t know any of those primes, and very likely never will. Here’s my attempt at portraying the various regions of prime numbers. There’s a region in which we can test any number for primality (it may take months or years at the top end), and there’s a region in which we couldn’t possibly do that but we can still check Mersenne prime candidates (which still takes months or years). These two regions are so far removed from each other it’s not even funny.', 'result': {'fake': 0.001, 'real': 0.999}, 'status': 'success'}], 'credits_used': 3, 'credits': 1986349, 'subscription': 0, 'content': 'It’s not just possible, it’s guaranteed. The algorithms for finding the largest known primes are only useful for finding primes of a VERY special type, known as Mersenne primes, which are numbers of the form 2N−12N−12^N-1. We have no way, not even remotely, of checking primality of very large numbers which aren’t of this very special form. For example, as of right now the largest known prime is 282,589,933−1282,589,933−12^{82,589,933}-1. The previous record was 277,232,917−1277,232,917−12^{77,232,917}-1. In between these two numbers there are over 1010,000,0001010,000,00010^{10,000,000} prime numbers. That’s ten to the power of ten million. That’s how many primes there are between the current record and the previous record, and we don’t know any of those primes, and very likely never will. Here’s my attempt at portraying the various regions of prime numbers. There’s a region in which we can test any number for primality (it may take months or years at the top end), and there’s a region in which we couldn’t possibly do that but we can still check Mersenne prime candidates (which still takes months or years). These two regions are so far removed from each other it’s not even funny.', 'aiModelVersion': '1'}",0.999
Joe Zbiciak,4y,Is it possible to write a sorting algorithm with a time complexity below O(n * log(n))?,"The likely origin of your question arises from the fact that most generic sorting algorithms we encounter are based on comparisons. The sort you get with std::sort in C++ falls into this category, as the only property it relies on for the data itself is that it has a strict weak ordering. A comparison sort requires an average-case Ω(nlgn)Ω(nlg⁡n)\Omega(n \lg n) comparisons. (Note: Ω()Ω()\Omega() means bounded below, in contrast to O()O()O(), which means bounded above.) Quoting Wikipedia:There are fundamental limits on the performance of comparison sorts. A comparison sort must have an average-case lower bound of Ω(nlogn)Ω(nlog⁡n)\Omega(n \log n) comparison operations, which is known as linearithmic time. This is a consequence of the limited information available through comparisons alone — or, to put it differently, of the vague algebraic structure of totally ordered sets.Sorts such as Heap Sort, Merge Sort, and Intro Sort hit this theoretical complexity bound, and so they are both Ω(nlgn)Ω(nlg⁡n)\Omega(n \lg n) and O(nlgn)O(nlg⁡n)O(n \lg n), making them Θ(nlgn)Θ(nlg⁡n)\Theta(n \lg n) and asymptotically optimal. Now, some comparison sorts can provide better guarantees if you restrict the properties of the input. For example, Bubble Sort and Insertion Sort are O(n)O(n)O(n) if you put a strict upper bound on the number of out-of-sequence elements. If you don’t place those restrictions, they’re both O(n2)O(n2)O(n^2). There are other types of sort that don’t rely on comparisons. Their time complexity may break through the Ω(nlgn)Ω(nlg⁡n)\Omega(n \lg n) floor. Their time complexity may also be less than O(nlgn)O(nlg⁡n)O(n \lg n). Counting sort, which counts the number of instances of each key, is effectively O(n)O(n)O(n), provided you have O(1)O(1)O(1) mechanisms for looking up each key and providing a sorted set of keys. This latter constraint usually limits a counting sort to operating on a bounded range of integers, or something that could be trivially mapped onto a bounded range of integers. (Think: strings in a fixed, sorted string table that’s established a priori, combined with a perfect hash for mapping strings to indices.) Radix sort can break below Ω(nlgn)Ω(nlg⁡n)\Omega(n \lg n). Its actual complexity is O(wn)O(wn)O(wn) where www is the number of digits. If www is strictly bounded—implying that you will have repeated keys for sufficiently large nnn—then you could say O(wn)=O(n)O(wn)=O(n)O(wn) = O(n). Otherwise, if you disallow repeated keys, but have a reasonably dense key distribution,* then w=O(lgn)w=O(lg⁡n)w = O(\lg n) and so radix sort is effectively O(nlgn)O(nlg⁡n)O(n \lg n). (I think. Paging Jonas to check my work here.) EDIT: And, thanks to Greg Young's answer, today I learned about FlashSort, which relies on the intuitive notion that if you know approximately where an item should land in the sorted result, you can move it toward that eventual location. This works only if you know the expected distribution of your inputs. If you do know that, you can be O(n)O(n)O(n).* You could have a totally unreasonable key distribution. If I’m not mistaken, if you make all of your keys different lengths, for example, you end up with w=O(n)w=O(n)w = O(n) and radix sort becomes O(n2)O(n2)O(n^2).","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/w1r0ohz7bfimkxc3', 'title': 'Is it possible to write a sorting algorithm with a time complexity below O(n * log(n))?', 'score': {'original': 0.9956, 'ai': 0.0044}, 'blocks': [{'text': ""The likely origin of your question arises from the fact that most generic sorting algorithms we encounter are based on comparisons. The sort you get with std::sort in C++ falls into this category, as the only property it relies on for the data itself is that it has a strict weak ordering. A comparison sort requires an average-case Ω(nlgn)Ω(nlg\u2061n)\\Omega(n \\lg n) comparisons. (Note: Ω()Ω()\\Omega() means bounded below, in contrast to O()O()O(), which means bounded above.) Quoting Wikipedia:There are fundamental limits on the performance of comparison sorts. A comparison sort must have an average-case lower bound of Ω(nlogn)Ω(nlog\u2061n)\\Omega(n \\log n) comparison operations, which is known as linearithmic time. This is a consequence of the limited information available through comparisons alone — or, to put it differently, of the vague algebraic structure of totally ordered sets.Sorts such as Heap Sort, Merge Sort, and Intro Sort hit this theoretical complexity bound, and so they are both Ω(nlgn)Ω(nlg\u2061n)\\Omega(n \\lg n) and O(nlgn)O(nlg\u2061n)O(n \\lg n), making them Θ(nlgn)Θ(nlg\u2061n)\\Theta(n \\lg n) and asymptotically optimal. Now, some comparison sorts can provide better guarantees if you restrict the properties of the input. For example, Bubble Sort and Insertion Sort are O(n)O(n)O(n) if you put a strict upper bound on the number of out-of-sequence elements. If you don’t place those restrictions, they’re both O(n2)O(n2)O(n^2). There are other types of sort that don’t rely on comparisons. Their time complexity may break through the Ω(nlgn)Ω(nlg\u2061n)\\Omega(n \\lg n) floor. Their time complexity may also be less than O(nlgn)O(nlg\u2061n)O(n \\lg n). Counting sort, which counts the number of instances of each key, is effectively O(n)O(n)O(n), provided you have O(1)O(1)O(1) mechanisms for looking up each key and providing a sorted set of keys. This latter constraint usually limits a counting sort to operating on a bounded range of integers, or something that could be trivially mapped onto a bounded range of integers. (Think: strings in a fixed, sorted string table that’s established a priori, combined with a perfect hash for mapping strings to indices.) Radix sort can break below Ω(nlgn)Ω(nlg\u2061n)\\Omega(n \\lg n). Its actual complexity is O(wn)O(wn)O(wn) where www is the number of digits. If www is strictly bounded—implying that you will have repeated keys for sufficiently large nnn—then you could say O(wn)=O(n)O(wn)=O(n)O(wn) = O(n). Otherwise, if you disallow repeated keys, but have a reasonably dense key distribution,* then w=O(lgn)w=O(lg\u2061n)w = O(\\lg n) and so radix sort is effectively O(nlgn)O(nlg\u2061n)O(n \\lg n). (I think. Paging Jonas to check my work here.) EDIT: And, thanks to Greg Young's answer, today I learned about FlashSort, which relies on the intuitive notion that if you know approximately where an item should land in the sorted result, you can move it toward that eventual location. This works only if you know the expected distribution of your inputs. If you do know that, you can be O(n)O(n)O(n).* You could have a totally unreasonable key distribution. If I’m not mistaken, if you make all of your keys different lengths, for example, you end up with w=O(n)w=O(n)w = O(n) and radix sort becomes O(n2)O(n2)O(n^2)."", 'result': {'fake': 0.0044, 'real': 0.9956}, 'status': 'success'}], 'credits_used': 7, 'credits': 1986342, 'subscription': 0, 'content': ""The likely origin of your question arises from the fact that most generic sorting algorithms we encounter are based on comparisons. The sort you get with std::sort in C++ falls into this category, as the only property it relies on for the data itself is that it has a strict weak ordering. A comparison sort requires an average-case Ω(nlgn)Ω(nlg\u2061n)\\Omega(n \\lg n) comparisons. (Note: Ω()Ω()\\Omega() means bounded below, in contrast to O()O()O(), which means bounded above.) Quoting Wikipedia:There are fundamental limits on the performance of comparison sorts. A comparison sort must have an average-case lower bound of Ω(nlogn)Ω(nlog\u2061n)\\Omega(n \\log n) comparison operations, which is known as linearithmic time. This is a consequence of the limited information available through comparisons alone — or, to put it differently, of the vague algebraic structure of totally ordered sets.Sorts such as Heap Sort, Merge Sort, and Intro Sort hit this theoretical complexity bound, and so they are both Ω(nlgn)Ω(nlg\u2061n)\\Omega(n \\lg n) and O(nlgn)O(nlg\u2061n)O(n \\lg n), making them Θ(nlgn)Θ(nlg\u2061n)\\Theta(n \\lg n) and asymptotically optimal. Now, some comparison sorts can provide better guarantees if you restrict the properties of the input. For example, Bubble Sort and Insertion Sort are O(n)O(n)O(n) if you put a strict upper bound on the number of out-of-sequence elements. If you don’t place those restrictions, they’re both O(n2)O(n2)O(n^2). There are other types of sort that don’t rely on comparisons. Their time complexity may break through the Ω(nlgn)Ω(nlg\u2061n)\\Omega(n \\lg n) floor. Their time complexity may also be less than O(nlgn)O(nlg\u2061n)O(n \\lg n). Counting sort, which counts the number of instances of each key, is effectively O(n)O(n)O(n), provided you have O(1)O(1)O(1) mechanisms for looking up each key and providing a sorted set of keys. This latter constraint usually limits a counting sort to operating on a bounded range of integers, or something that could be trivially mapped onto a bounded range of integers. (Think: strings in a fixed, sorted string table that’s established a priori, combined with a perfect hash for mapping strings to indices.) Radix sort can break below Ω(nlgn)Ω(nlg\u2061n)\\Omega(n \\lg n). Its actual complexity is O(wn)O(wn)O(wn) where www is the number of digits. If www is strictly bounded—implying that you will have repeated keys for sufficiently large nnn—then you could say O(wn)=O(n)O(wn)=O(n)O(wn) = O(n). Otherwise, if you disallow repeated keys, but have a reasonably dense key distribution,* then w=O(lgn)w=O(lg\u2061n)w = O(\\lg n) and so radix sort is effectively O(nlgn)O(nlg\u2061n)O(n \\lg n). (I think. Paging Jonas to check my work here.) EDIT: And, thanks to Greg Young's answer, today I learned about FlashSort, which relies on the intuitive notion that if you know approximately where an item should land in the sorted result, you can move it toward that eventual location. This works only if you know the expected distribution of your inputs. If you do know that, you can be O(n)O(n)O(n).* You could have a totally unreasonable key distribution. If I’m not mistaken, if you make all of your keys different lengths, for example, you end up with w=O(n)w=O(n)w = O(n) and radix sort becomes O(n2)O(n2)O(n^2)."", 'aiModelVersion': '1'}",0.9956
Tyler Schroeder,6y,What is the strangest sorting algorithm?,"I'm quite a fan of quantum bogosort, myself:

Randomly shuffle the elements of the list.
If the list is not sorted, destroy the universe (this step is left as an activity for the reader).
Any surviving universes will then have the sorted version of the list.

Works in O(N) time!*

*note: this figure relies on the accuracy of the many worlds theory of quantum mechanics. if the many worlds theory of quantum mechanics is not accurate, your algorithm is unlikely to work in O(N) time.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/cykfz6287jmh4an0', 'title': 'What is the strangest sorting algorithm?', 'score': {'original': 0.8956, 'ai': 0.1044}, 'blocks': [{'text': ""I'm quite a fan of quantum bogosort, myself:\n\nRandomly shuffle the elements of the list.\nIf the list is not sorted, destroy the universe (this step is left as an activity for the reader).\nAny surviving universes will then have the sorted version of the list.\n\nWorks in O(N) time!*\n\n*note: this figure relies on the accuracy of the many worlds theory of quantum mechanics. if the many worlds theory of quantum mechanics is not accurate, your algorithm is unlikely to work in O(N) time."", 'result': {'fake': 0.1044, 'real': 0.8956}, 'status': 'success'}], 'credits_used': 1, 'credits': 1986341, 'subscription': 0, 'content': ""I'm quite a fan of quantum bogosort, myself:\n\nRandomly shuffle the elements of the list.\nIf the list is not sorted, destroy the universe (this step is left as an activity for the reader).\nAny surviving universes will then have the sorted version of the list.\n\nWorks in O(N) time!*\n\n*note: this figure relies on the accuracy of the many worlds theory of quantum mechanics. if the many worlds theory of quantum mechanics is not accurate, your algorithm is unlikely to work in O(N) time."", 'aiModelVersion': '1'}",0.8956
Vedant Misra,Updated 12y,Is there any public elevator scheduling algorithm standard?,"There is no standard. Manufacturers tend to use slightly different algorithms and treat them as trade secrets. But in practice, their algorithms are similar, because the theoretical optimization criteria are roughly the same:


provide even service to each floor
minimize how long passengers wait for an elevator to arrive
minimize how long passengers spend to get to their destination floor
serve as many passengers as possible


The single elevator case is not very interesting, nor is the case when the passenger can't specify his direction of travel when making the call (one button per floor), so I'll instead discuss only the case where there are multiple elevators, and two buttons on each floor.

There are several criteria to consider in elevator scheduling. For example, people have predictable behavioral patterns that must be addressed, including the uppeak and downpeak---respectively 9AM and 5PM, in many office buildings---which are when elevator efficiency matters the most. There is often a 1-2 hour two-way peak (lunchtime) to address as well. Algorithms should consider whether an elevator is full before assigning it to an elevator call. Sometimes, some blocks of floors have predictably higher interblock or intrablock traffic than other blocks. Often, calls on some floors (executive floors, for example) are given higher priority than others (basements). All of these factors increase the algorithm sophistication.

Still, they tend to be based on the four classic group traffic control algorithms.


Nearest Car (NC): Elevator calls are assigned to the elevator best placed to answer that call according to three criteria that are used to compute a figure of suitability (FS) for each elevator. (1) If an elevator is moving towards a call, and the call is in the same direction, FS = (N + 2) - d, where N is one less than the number of floors in the building, and d is the distance in floors between the elevator and the passenger call. (2) If the elevator is moving towards the call, but the call is in the opposite direction, FS = (N + 1) - d. (3) If the elevator is moving away from the point of call, FS = 1. The elevator with the highest FS for each call is sent to answer it. The search for the ""nearest car"" is performed continuously until each call is serviced.
Fixed Sectoring Common Sector System (FSO): The building is divided into as many sectors as there are elevators. Elevators in each sector prefer calls in that sector.
Fixed Sectoring Priority Timed System (FS4): The building is divided into up sectors and down sectors, and elevators only ever treat down calls in down sectors and up calls in up sectors. Each sector has a priority level, which increases the longer the passengers wait. The rate of increase can vary from sector to sector and over time.
Dynamic Sectoring System (DS): Floors are grouped into dynamic sectors. Each elevator is allocated to a sector in the sector definition, and the sectors change size and location based on the position of moving and idle elevators.


Modern control systems do even more than this. Some of them dynamically compute cost functions for passengers waiting on an elevator. Stochastic traffic control systems empirically compute the distribution of response times and try to make it as Gaussian as possible (wait times should be consistent; there shouldn't be some times when elevators respond instantly and others where they take a while). Some advanced techniques use fuzzy logic schedulers (Ho and Robertson 1994), genetic algorithms (Siikonen 2001, Miravete 1999), and neural networks (Barney and Imrak 2001).

Most of this information is paraphrased from UK-based lift consultant Gina Barney's book ""Elevator Traffic Handbook: Theory and Practice."" A most uplifting read.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/wfkjy9pgt57mnozd', 'title': 'Is there any public elevator scheduling algorithm standard?', 'score': {'original': 0.98605, 'ai': 0.01395}, 'blocks': [{'text': 'There is no standard. Manufacturers tend to use slightly different algorithms and treat them as trade secrets. But in practice, their algorithms are similar, because the theoretical optimization criteria are roughly the same:\n\n\nprovide even service to each floor\nminimize how long passengers wait for an elevator to arrive\nminimize how long passengers spend to get to their destination floor\nserve as many passengers as possible\n\n\nThe single elevator case is not very interesting, nor is the case when the passenger can\'t specify his direction of travel when making the call (one button per floor), so I\'ll instead discuss only the case where there are multiple elevators, and two buttons on each floor.\n\nThere are several criteria to consider in elevator scheduling. For example, people have predictable behavioral patterns that must be addressed, including the uppeak and downpeak---respectively 9AM and 5PM, in many office buildings---which are when elevator efficiency matters the most. There is often a 1-2 hour two-way peak (lunchtime) to address as well. Algorithms should consider whether an elevator is full before assigning it to an elevator call. Sometimes, some blocks of floors have predictably higher interblock or intrablock traffic than other blocks. Often, calls on some floors (executive floors, for example) are given higher priority than others (basements). All of these factors increase the algorithm sophistication.\n\nStill, they tend to be based on the four classic group traffic control algorithms.\n\n\nNearest Car (NC): Elevator calls are assigned to the elevator best placed to answer that call according to three criteria that are used to compute a figure of suitability (FS) for each elevator. (1) If an elevator is moving towards a call, and the call is in the same direction, FS = (N + 2) - d, where N is one less than the number of floors in the building, and d is the distance in floors between the elevator and the passenger call. (2) If the elevator is moving towards the call, but the call is in the opposite direction, FS = (N + 1) - d. (3) If the elevator is moving away from the point of call, FS = 1. The elevator with the highest FS for each call is sent to answer it. The search for the ""nearest car"" is performed continuously until each call is serviced.\nFixed Sectoring Common Sector System (FSO): The building is divided into as many sectors as there are elevators. Elevators in each sector prefer calls in that sector.\nFixed Sectoring Priority Timed System (FS4): The building is divided into up sectors and down sectors, and elevators only ever treat down calls in down sectors and up calls in up sectors. Each sector has a priority level, which increases the longer the passengers wait. The rate of increase can vary from sector to sector and over time.\nDynamic Sectoring System (DS): Floors are grouped into dynamic sectors. Each elevator is allocated to a sector in the sector definition, and the sectors change size and location based on the position of moving and idle elevators.\n\n\nModern control systems do even more than this. Some of them dynamically compute cost functions for passengers waiting', 'result': {'fake': 0.0282, 'real': 0.9718}, 'status': 'success'}, {'text': 'on an elevator. Stochastic traffic control systems empirically compute the distribution of response times and try to make it as Gaussian as possible (wait times should be consistent; there shouldn\'t be some times when elevators respond instantly and others where they take a while). Some advanced techniques use fuzzy logic schedulers (Ho and Robertson 1994), genetic algorithms (Siikonen 2001, Miravete 1999), and neural networks (Barney and Imrak 2001).\n\nMost of this information is paraphrased from UK-based lift consultant Gina Barney\'s book ""Elevator Traffic Handbook: Theory and Practice."" A most uplifting read.', 'result': {'fake': 0.6355, 'real': 0.3645}, 'status': 'success'}], 'credits_used': 6, 'credits': 1986335, 'subscription': 0, 'content': 'There is no standard. Manufacturers tend to use slightly different algorithms and treat them as trade secrets. But in practice, their algorithms are similar, because the theoretical optimization criteria are roughly the same:\n\n\nprovide even service to each floor\nminimize how long passengers wait for an elevator to arrive\nminimize how long passengers spend to get to their destination floor\nserve as many passengers as possible\n\n\nThe single elevator case is not very interesting, nor is the case when the passenger can\'t specify his direction of travel when making the call (one button per floor), so I\'ll instead discuss only the case where there are multiple elevators, and two buttons on each floor.\n\nThere are several criteria to consider in elevator scheduling. For example, people have predictable behavioral patterns that must be addressed, including the uppeak and downpeak---respectively 9AM and 5PM, in many office buildings---which are when elevator efficiency matters the most. There is often a 1-2 hour two-way peak (lunchtime) to address as well. Algorithms should consider whether an elevator is full before assigning it to an elevator call. Sometimes, some blocks of floors have predictably higher interblock or intrablock traffic than other blocks. Often, calls on some floors (executive floors, for example) are given higher priority than others (basements). All of these factors increase the algorithm sophistication.\n\nStill, they tend to be based on the four classic group traffic control algorithms.\n\n\nNearest Car (NC): Elevator calls are assigned to the elevator best placed to answer that call according to three criteria that are used to compute a figure of suitability (FS) for each elevator. (1) If an elevator is moving towards a call, and the call is in the same direction, FS = (N + 2) - d, where N is one less than the number of floors in the building, and d is the distance in floors between the elevator and the passenger call. (2) If the elevator is moving towards the call, but the call is in the opposite direction, FS = (N + 1) - d. (3) If the elevator is moving away from the point of call, FS = 1. The elevator with the highest FS for each call is sent to answer it. The search for the ""nearest car"" is performed continuously until each call is serviced.\nFixed Sectoring Common Sector System (FSO): The building is divided into as many sectors as there are elevators. Elevators in each sector prefer calls in that sector.\nFixed Sectoring Priority Timed System (FS4): The building is divided into up sectors and down sectors, and elevators only ever treat down calls in down sectors and up calls in up sectors. Each sector has a priority level, which increases the longer the passengers wait. The rate of increase can vary from sector to sector and over time.\nDynamic Sectoring System (DS): Floors are grouped into dynamic sectors. Each elevator is allocated to a sector in the sector definition, and the sectors change size and location based on the position of moving and idle elevators.\n\n\nModern control systems do even more than this. Some of them dynamically compute cost functions for passengers waiting on an elevator. Stochastic traffic control systems empirically compute the distribution of response times and try to make it as Gaussian as possible (wait times should be consistent; there shouldn\'t be some times when elevators respond instantly and others where they take a while). Some advanced techniques use fuzzy logic schedulers (Ho and Robertson 1994), genetic algorithms (Siikonen 2001, Miravete 1999), and neural networks (Barney and Imrak 2001).\n\nMost of this information is paraphrased from UK-based lift consultant Gina Barney\'s book ""Elevator Traffic Handbook: Theory and Practice."" A most uplifting read.', 'aiModelVersion': '1'}",0.98605
Avanish Yadav,7mo,How do you deal with problems in life?,"I had been in a depression phase for almost 1.5 years. I still have anxiety issue which has no cure.

My health was ruined. I lost more than 15 kgs to be underweight and weighed 41 kgs. Physical appearance and shape both faded.

My mental traumas had a bad effects on my social relationships. I lost contact with my most of the friends with whom I was closed.

I had arguments and fights over small and big issues for more than 6 months with the people whom I loved.

This year, I met with accidents thrice. My legs and shoulder were injured. It took months to heal.

I performed too poor in every aspect of my life whether it was my career or personal life.

I turned out to be a toxic person not to others only but to myself too.

I cried almost every day, why there's no solutions to my problems.

Later, I realised thare every person has problems. I'm not the only one who have problems.

So,

How do I deal with problems in life?

It's a life. Optimistic thoughts of future don’t work always.

There are times when a queue of unending problems enter in your life.

All your plans, strategies and ideas just go in vein when these incidents appear before you unexpectedly.

And you really don't have an idea how to deal with these problems. All you can do, is just blindly go through those tough phases.

You fight and fail and you try again to face your problems in your life.

You don't stop yourself living if problems are big or worse. You don't stop trying if things are going out of your hands.

There's no way to be back. If you quit, you will never know whether the next moment is beautiful or more worse.

“Keep going through your problems until you reach the next side.”

This the only way to deal with problems in life.

You will not have a solution of everything but if you a purpose to see next day, you would sail every problem.

Aura:)","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/4adbj8ctumefv96i', 'title': 'How do you deal with problems in life?', 'score': {'original': 0.9997, 'ai': 0.0003}, 'blocks': [{'text': ""I had been in a depression phase for almost 1.5 years. I still have anxiety issue which has no cure.\n\nMy health was ruined. I lost more than 15 kgs to be underweight and weighed 41 kgs. Physical appearance and shape both faded.\n\nMy mental traumas had a bad effects on my social relationships. I lost contact with my most of the friends with whom I was closed.\n\nI had arguments and fights over small and big issues for more than 6 months with the people whom I loved.\n\nThis year, I met with accidents thrice. My legs and shoulder were injured. It took months to heal.\n\nI performed too poor in every aspect of my life whether it was my career or personal life.\n\nI turned out to be a toxic person not to others only but to myself too.\n\nI cried almost every day, why there's no solutions to my problems.\n\nLater, I realised thare every person has problems. I'm not the only one who have problems.\n\nSo,\n\nHow do I deal with problems in life?\n\nIt's a life. Optimistic thoughts of future don’t work always.\n\nThere are times when a queue of unending problems enter in your life.\n\nAll your plans, strategies and ideas just go in vein when these incidents appear before you unexpectedly.\n\nAnd you really don't have an idea how to deal with these problems. All you can do, is just blindly go through those tough phases.\n\nYou fight and fail and you try again to face your problems in your life.\n\nYou don't stop yourself living if problems are big or worse. You don't stop trying if things are going out of your hands.\n\nThere's no way to be back. If you quit, you will never know whether the next moment is beautiful or more worse.\n\n“Keep going through your problems until you reach the next side.”\n\nThis the only way to deal with problems in life.\n\nYou will not have a solution of everything but if you a purpose to see next day, you would sail every problem.\n\nAura:)"", 'result': {'fake': 0.0003, 'real': 0.9997}, 'status': 'success'}], 'credits_used': 4, 'credits': 1986331, 'subscription': 0, 'content': ""I had been in a depression phase for almost 1.5 years. I still have anxiety issue which has no cure.\n\nMy health was ruined. I lost more than 15 kgs to be underweight and weighed 41 kgs. Physical appearance and shape both faded.\n\nMy mental traumas had a bad effects on my social relationships. I lost contact with my most of the friends with whom I was closed.\n\nI had arguments and fights over small and big issues for more than 6 months with the people whom I loved.\n\nThis year, I met with accidents thrice. My legs and shoulder were injured. It took months to heal.\n\nI performed too poor in every aspect of my life whether it was my career or personal life.\n\nI turned out to be a toxic person not to others only but to myself too.\n\nI cried almost every day, why there's no solutions to my problems.\n\nLater, I realised thare every person has problems. I'm not the only one who have problems.\n\nSo,\n\nHow do I deal with problems in life?\n\nIt's a life. Optimistic thoughts of future don’t work always.\n\nThere are times when a queue of unending problems enter in your life.\n\nAll your plans, strategies and ideas just go in vein when these incidents appear before you unexpectedly.\n\nAnd you really don't have an idea how to deal with these problems. All you can do, is just blindly go through those tough phases.\n\nYou fight and fail and you try again to face your problems in your life.\n\nYou don't stop yourself living if problems are big or worse. You don't stop trying if things are going out of your hands.\n\nThere's no way to be back. If you quit, you will never know whether the next moment is beautiful or more worse.\n\n“Keep going through your problems until you reach the next side.”\n\nThis the only way to deal with problems in life.\n\nYou will not have a solution of everything but if you a purpose to see next day, you would sail every problem.\n\nAura:)"", 'aiModelVersion': '1'}",0.9997
Mark Gritter,Updated 2y,"In order to solve a 2D maze, one just has to stick to the left wall and will find the exit. This however  doesn't work for 3D mazes. Is there a similar algorithm for 3D mazes?","The rule only works for 2-D mazes that are simply connected. For example, here is a 2-D maze for which the wall-following algorithm fails, because it goes around the inner loop without ever trying the “outside” wall:

The same applies to mazes embedded in more than 2 dimensions. If they are simply-connected then a wall-following type algorithm can work, when the decision points in the maze can be converted into a deterministic sequence.

For example, if there is only one “floor” to the maze, and it is simply connected, then a 3-D maze is equivalent to a 2-D maze.

Or, if the orientation of the maze can be kept fixed, then “up” or “down” can be assigned a notional direction that determines the order in which they are visited. Say, treat “up” as northwest and “down” as southeast. Then when you come in from the west, the left-hand rule says to take “up” next.

But, it is much easier to make a maze that is not simply connected in more than 2 dimensions, in which case a stateless depth-first search (like wall-following) will fail.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/pcwbv6di5smt4zg3', 'title': ""In order to solve a 2D maze, one just has to stick to the left wall and will find the exit. This however  doesn't work for 3D mazes. Is there a similar algorithm for 3D mazes?"", 'score': {'original': 0.999, 'ai': 0.001}, 'blocks': [{'text': 'The rule only works for 2-D mazes that are simply connected. For example, here is a 2-D maze for which the wall-following algorithm fails, because it goes around the inner loop without ever trying the “outside” wall:\n\nThe same applies to mazes embedded in more than 2 dimensions. If they are simply-connected then a wall-following type algorithm can work, when the decision points in the maze can be converted into a deterministic sequence.\n\nFor example, if there is only one “floor” to the maze, and it is simply connected, then a 3-D maze is equivalent to a 2-D maze.\n\nOr, if the orientation of the maze can be kept fixed, then “up” or “down” can be assigned a notional direction that determines the order in which they are visited. Say, treat “up” as northwest and “down” as southeast. Then when you come in from the west, the left-hand rule says to take “up” next.\n\nBut, it is much easier to make a maze that is not simply connected in more than 2 dimensions, in which case a stateless depth-first search (like wall-following) will fail.', 'result': {'fake': 0.001, 'real': 0.999}, 'status': 'success'}], 'credits_used': 2, 'credits': 1986329, 'subscription': 0, 'content': 'The rule only works for 2-D mazes that are simply connected. For example, here is a 2-D maze for which the wall-following algorithm fails, because it goes around the inner loop without ever trying the “outside” wall:\n\nThe same applies to mazes embedded in more than 2 dimensions. If they are simply-connected then a wall-following type algorithm can work, when the decision points in the maze can be converted into a deterministic sequence.\n\nFor example, if there is only one “floor” to the maze, and it is simply connected, then a 3-D maze is equivalent to a 2-D maze.\n\nOr, if the orientation of the maze can be kept fixed, then “up” or “down” can be assigned a notional direction that determines the order in which they are visited. Say, treat “up” as northwest and “down” as southeast. Then when you come in from the west, the left-hand rule says to take “up” next.\n\nBut, it is much easier to make a maze that is not simply connected in more than 2 dimensions, in which case a stateless depth-first search (like wall-following) will fail.', 'aiModelVersion': '1'}",0.999
Kiran Kumar,Updated 5y,What is the strangest sorting algorithm?,"This is something called chaata(Telugu)

Usually found in South Indian homes.

This thing is used to clean the rice before cooking and it's a standard Indian way to husk the rice.

This is how they do it

After every wave, the husk separates from the rice. It works on the weight of grains.

At one point of time you'll find every grain sorted in ascending order so perfectly.

If I loosely translate this into pseudo code then it will be some what close to Bogo sort.

For every Wave the chaata//assumed chat as matrix. 
 For every row 
   For every sub row 
      Compare(x1,x2)//x1,x2 are adjacent grains 
      If x1 >x2 : forward (x1)// moving          x1forward 
      else forward (x2) ","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/ke53myisnugj6xpq', 'title': 'What is the strangest sorting algorithm?', 'score': {'original': 0.9993, 'ai': 0.0007}, 'blocks': [{'text': ""This is something called chaata(Telugu)\n\nUsually found in South Indian homes.\n\nThis thing is used to clean the rice before cooking and it's a standard Indian way to husk the rice.\n\nThis is how they do it\n\nAfter every wave, the husk separates from the rice. It works on the weight of grains.\n\nAt one point of time you'll find every grain sorted in ascending order so perfectly.\n\nIf I loosely translate this into pseudo code then it will be some what close to Bogo sort.\n\nFor every Wave the chaata//assumed chat as matrix.\xa0\n For every row\xa0\n   For every sub row\xa0\n      Compare(x1,x2)//x1,x2 are adjacent grains\xa0\n      If x1 >x2 : forward (x1)// moving          x1forward\xa0\n      else forward (x2)\xa0"", 'result': {'fake': 0.0009, 'real': 0.9991}, 'status': 'success'}], 'credits_used': 2, 'credits': 1986327, 'subscription': 0, 'content': ""This is something called chaata(Telugu)\n\nUsually found in South Indian homes.\n\nThis thing is used to clean the rice before cooking and it's a standard Indian way to husk the rice.\n\nThis is how they do it\n\nAfter every wave, the husk separates from the rice. It works on the weight of grains.\n\nAt one point of time you'll find every grain sorted in ascending order so perfectly.\n\nIf I loosely translate this into pseudo code then it will be some what close to Bogo sort.\n\nFor every Wave the chaata//assumed chat as matrix.\xa0\n For every row\xa0\n   For every sub row\xa0\n      Compare(x1,x2)//x1,x2 are adjacent grains\xa0\n      If x1 >x2 : forward (x1)// moving          x1forward\xa0\n      else forward (x2)\xa0"", 'aiModelVersion': '1'}",0.9993
Thomas Cormen,9y,What was the hardest chapter to write in the Introduction to Algorithms book by CLRS?,"That's easy for me to answer, though I don't know whether my coauthors would agree.  It was the chapter on dynamic programming. When we were writing the first edition, back in the late 1980s, by the time we got to the dynamic programming chapter, we knew that we had to plan it out carefully before writing it.  So that's exactly what we did.  We planned it out very carefully.  I wrote the first draft, exactly according to the specification that we had agreed upon.  I was happy with it. But Charles Leiserson and Ron Rivest were not.  They agreed that I had written the chapter to spec.  But they felt that it just did not work. We asked a graduate student in the Theory Group at MIT to read the draft and tell us what he thought.  He agreed with Charles and Ron. So I rewrote the chapter and, as with all our chapters, Charles and Ron edited it.  The result is what appeared in the first edition of Introduction to Algorithms.  It was OK, but it started with matrix-chain multiplication, a two-dimensional problem, and it did not have any simpler, one-dimensional problems. For the second edition, we decided that we'd start off with a one-dimensional problem.  We used the assembly-line scheduling problem.  (It was our recasting of the fly-vs.-drive problem.)  Indeed, it can be solved with dynamic programming, but that's not really the best way to solve this problem, because it's really just finding the shortest path in a directed acyclic graph. For the third edition, Ron Rivest worked on the chapter.  He changed the opening problem to the rod-cutting problem, which is one-dimensional and lends itself to dynamic programming better than the assembly-line scheduling problem does.  Ron also increased the emphasis on memoization in the chapter.  I think we finally have a good chapter.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/f32zeh7ubdpgyt46', 'title': 'What was the hardest chapter to write in the Introduction to Algorithms book by CLRS?', 'score': {'original': 0.9982, 'ai': 0.0018}, 'blocks': [{'text': ""That's easy for me to answer, though I don't know whether my coauthors would agree.  It was the chapter on dynamic programming. When we were writing the first edition, back in the late 1980s, by the time we got to the dynamic programming chapter, we knew that we had to plan it out carefully before writing it.  So that's exactly what we did.  We planned it out very carefully.  I wrote the first draft, exactly according to the specification that we had agreed upon.  I was happy with it. But Charles Leiserson and Ron Rivest were not.  They agreed that I had written the chapter to spec.  But they felt that it just did not work. We asked a graduate student in the Theory Group at MIT to read the draft and tell us what he thought.  He agreed with Charles and Ron. So I rewrote the chapter and, as with all our chapters, Charles and Ron edited it.  The result is what appeared in the first edition of Introduction to Algorithms.  It was OK, but it started with matrix-chain multiplication, a two-dimensional problem, and it did not have any simpler, one-dimensional problems. For the second edition, we decided that we'd start off with a one-dimensional problem.  We used the assembly-line scheduling problem.  (It was our recasting of the fly-vs.-drive problem.)  Indeed, it can be solved with dynamic programming, but that's not really the best way to solve this problem, because it's really just finding the shortest path in a directed acyclic graph. For the third edition, Ron Rivest worked on the chapter.  He changed the opening problem to the rod-cutting problem, which is one-dimensional and lends itself to dynamic programming better than the assembly-line scheduling problem does.  Ron also increased the emphasis on memoization in the chapter.  I think we finally have a good chapter."", 'result': {'fake': 0.0018, 'real': 0.9982}, 'status': 'success'}], 'credits_used': 4, 'credits': 1986323, 'subscription': 0, 'content': ""That's easy for me to answer, though I don't know whether my coauthors would agree.  It was the chapter on dynamic programming. When we were writing the first edition, back in the late 1980s, by the time we got to the dynamic programming chapter, we knew that we had to plan it out carefully before writing it.  So that's exactly what we did.  We planned it out very carefully.  I wrote the first draft, exactly according to the specification that we had agreed upon.  I was happy with it. But Charles Leiserson and Ron Rivest were not.  They agreed that I had written the chapter to spec.  But they felt that it just did not work. We asked a graduate student in the Theory Group at MIT to read the draft and tell us what he thought.  He agreed with Charles and Ron. So I rewrote the chapter and, as with all our chapters, Charles and Ron edited it.  The result is what appeared in the first edition of Introduction to Algorithms.  It was OK, but it started with matrix-chain multiplication, a two-dimensional problem, and it did not have any simpler, one-dimensional problems. For the second edition, we decided that we'd start off with a one-dimensional problem.  We used the assembly-line scheduling problem.  (It was our recasting of the fly-vs.-drive problem.)  Indeed, it can be solved with dynamic programming, but that's not really the best way to solve this problem, because it's really just finding the shortest path in a directed acyclic graph. For the third edition, Ron Rivest worked on the chapter.  He changed the opening problem to the rod-cutting problem, which is one-dimensional and lends itself to dynamic programming better than the assembly-line scheduling problem does.  Ron also increased the emphasis on memoization in the chapter.  I think we finally have a good chapter."", 'aiModelVersion': '1'}",0.9982
Alon Amit,3y,What is the difference between a big O and a tight big O?,"n+17=O(2n)n+17=O(2n)n+17 = O(2^n). True, not tight. n+17=O(n2)n+17=O(n2)n+17 = O(n^2). True, tighter, still not tight. n+17=O(n)n+17=O(n)n+17 = O(n). True and tight. n+17=Θ(n)n+17=Θ(n)n+17 = \Theta(n). True, and expresses the tightness by asserting that nnn is both an upper bound and a lower bound for n+17n+17n+17, with suitable multiplicative constants.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/vexdugsyab5t4k78', 'title': 'What is the difference between a big O and a tight big O?', 'score': {'original': 0.9589, 'ai': 0.0411}, 'blocks': [{'text': 'n+17=O(2n)n+17=O(2n)n+17 = O(2^n). True, not tight. n+17=O(n2)n+17=O(n2)n+17 = O(n^2). True, tighter, still not tight. n+17=O(n)n+17=O(n)n+17 = O(n). True and tight. n+17=Θ(n)n+17=Θ(n)n+17 = \\Theta(n). True, and expresses the tightness by asserting that nnn is both an upper bound and a lower bound for n+17n+17n+17, with suitable multiplicative constants.', 'result': {'fake': 0.0411, 'real': 0.9589}, 'status': 'success'}], 'credits_used': 1, 'credits': 1986322, 'subscription': 0, 'content': 'n+17=O(2n)n+17=O(2n)n+17 = O(2^n). True, not tight. n+17=O(n2)n+17=O(n2)n+17 = O(n^2). True, tighter, still not tight. n+17=O(n)n+17=O(n)n+17 = O(n). True and tight. n+17=Θ(n)n+17=Θ(n)n+17 = \\Theta(n). True, and expresses the tightness by asserting that nnn is both an upper bound and a lower bound for n+17n+17n+17, with suitable multiplicative constants.', 'aiModelVersion': '1'}",0.9589
Joe Zbiciak,1y,Will the algorithm design be no longer an issue for coders knowing that ChatGPT can easily create any algorithm? Can a use of ChatGPT have any bad consequences for a programmer?,"ChatGPT can easily regurgitate modified boilerplate that's occasionally wrong in subtle (or sometimes not so subtle) ways.

I asked ChatGPT how to read an arbitrarily long line from a stream in C. This is what it came up with:

#include <stdio.h> 
#include <stdlib.h> 
 
char *read_line(FILE *stream) { 
    char *line = NULL; 
    int line_size = 0; 
    int line_capacity = 0; 
    int c; 
 
    while ((c = fgetc(stream)) != EOF && c != '\n') { 
        if (line_size >= line_capacity) { 
            line_capacity = line_capacity == 0 ? 64 : line_capacity * 2; 
            char *new_line = realloc(line, line_capacity); 
            if (new_line == NULL) { 
                free(line); 
                return NULL; 
            } 
            line = new_line; 
        } 
        line[line_size++] = (char)c; 
    } 
 
    if (line_size > 0 || c == '\n') { 
        if (line_size >= line_capacity) { 
            line_capacity = line_capacity == 0 ? 64 : line_capacity * 2; 
            char *new_line = realloc(line, line_capacity); 
            if (new_line == NULL) { 
                free(line); 
                return NULL; 
            } 
            line = new_line; 
        } 
        line[line_size++] = '\0'; 
    } 
 
    return line; 
}: 

Here's how the code works:

line is a pointer to the dynamically allocated memory that will store the line.
line_size is the current number of characters in the line.
line_capacity is the current size of the allocated memory.
The loop reads each character from the stream until the end of the stream or a newline character is encountered.
If the current line size is greater than or equal to the allocated memory capacity, the memory is reallocated to double its size.
The character is appended to the line, and the line size is incremented.
If the end of the line or stream is reached and there are characters in the line, the null terminator is added to the end of the line.
The function returns a pointer to the line or NULL if an error occurs.

To use this function, you can pass a pointer to the stream you want to read from as an argument:

int main() { 
    char *line = read_line(stdin); 
    if (line == NULL) { 
        fprintf(stderr, ""Error: could not read line\n""); 
        exit(EXIT_FAILURE); 
    } 
    printf(""Read line: %s\n"", line); 
    free(line); 
    return 0; 
} 

In this example, the function read_line is called with stdin as the argument to read a line from the standard input stream. The line is printed to the console, and the dynamically allocated memory is freed using free when it is no longer needed.

That looks fairly reasonable. Not great, but not terrible.

You have a potential signed integer overflow in the geometric growth code. And of course, character at a time isn't really the pinnacle of efficiency, now is it?

I asked it it could write a more efficient version with fgets(), and it obliged. However, it's one step forward and two steps back:

#include <stdio.h> 
#include <stdlib.h> 
#include <string.h> 
 
char *read_line(FILE *stream) { 
    char *line = NULL; 
    size_t line_capacity = 0; 
    ssize_t line_size = 0; 
 
    do { 
        line_capacity += BUFSIZ; 
        char *new_line = realloc(line, line_capacity); 
        if (new_line == NULL) { 
            free(line); 
            return NULL; 
        } 
        line = new_line; 
 
        if (fgets(line + line_size, (int)(line_capacity - line_size), stream) == NULL) { 
            break; 
        } 
 
        line_size = strlen(line); 
    } while (line[line_size - 1] != '\n'); 
 
    if (line_size == 0) { 
        free(line); 
        return NULL; 
    } 
 
    line[line_size - 1] = '\0'; 
    char *new_line = realloc(line, line_size); 
    if (new_line == NULL) { 
        free(line); 
        return NULL; 
    } 
    line = new_line; 
 
    return line; 
} 

Some flaws:

Our nice geometric growth allocation is gone. We now have linear growth, which is 
O
(
n
2
)
.
O(n2).
But, we’ve upgraded to size_t, so any overflow there will be unsigned rather than UB inducing signed overflow.
When detecting how much text fgets() read in, it remeasures the entire string. Again, that's 
O
(
n
2
)
.
O(n2).
It weirdly keeps the string length in the non-standard ssize_t. strlen() returns size_t.
Why are we realloc’ing again at the end after we’ve successfully read the string? Just return it with a bit of extra pad at the end and avoid an extra trip through the memory allocator, an additional opportunity to fail allocation, and an extra potential memcpy().

Now, we are dividing n by BUFSIZ, so in practice it won't be noticeable until some bozo puts something like a megabyte-sized line in your file.

But isn't that exactly what DoS attackers live for?

Both of these have you free() the buffer when you're done. That's potentially going to fragment your heap unnecessarily over time. More commonly, you want to reuse an input buffer. You don't need to keep a copy. Instead of fresh allocations for each line, you can just reuse the previous buffer.

You can ask ChatGPT to do that, and it obliges:

#include <stdio.h> 
#include <stdlib.h> 
#include <string.h> 
 
#define INITIAL_LINE_CAPACITY 128 
 
char *read_line(FILE *stream, char *line, size_t *line_capacity) { 
    ssize_t line_size = 0; 
 
    do { 
        if (fgets(line + line_size, (int)(*line_capacity - line_size), stream) == NULL) { 
            break; 
        } 
 
        line_size = strlen(line); 
        if (line[line_size - 1] == '\n') { 
            break; 
        } 
 
        *line_capacity *= 2; 
        char *new_line = realloc(line, *line_capacity); 
        if (new_line == NULL) { 
            free(line); 
            return NULL; 
        } 
        line = new_line; 
    } while (1); 
 
    if (line_size == 0) { 
        return NULL; 
    } 
 
    line[line_size - 1] = '\0'; 
    char *new_line = realloc(line, line_size); 
    if (new_line == NULL) { 
        free(line); 
        return NULL; 
    } 
    line = new_line; 
 
    return line; 
} 

And it provides this demo code:

int main() { 
    char *line = malloc(INITIAL_LINE_CAPACITY); 
    size_t line_capacity = INITIAL_LINE_CAPACITY; 
 
    while (read_line(stdin, line, &line_capacity) != NULL) { 
        printf(""Read line: %s\n"", line); 
    } 
 
    free(line); 
    return 0; 
} 

Again, this feels like one step forward, two steps back.

We're back to geometric growth, which is a positive. But, that now puts this expression at risk of integer overflow: (int)(*line_capacity - line_size)
The argument line is passed by value while its companion line_size is passed by pointer.
That requires the user to reassign line on return because realloc() can move the buffer.
This introduces a significant opportunity to “hold it wrong”
 and fail to update line.
In fact, ChatGPT itself “holds it wrong” in its own demo code.
while (read_line(stdin, line, &line_capacity) != NULL) { 
If realloc() fails, ChatGPT frees the buffer, but fails to zero out the line_capacity.
*line_capacity *= 2; 
char *new_line = realloc(line, *line_capacity); 
if (new_line == NULL) { 
    free(line); 
    return NULL; 
} 
Previous versions would bootstrap themselves from an empty allocation and zero capacity.
This one doesn't, requiring the caller to do that, introducing another opportunity to “hold it wrong.”
ChatGPT “holds it wrong” subtly, failing to check that the initial malloc() succeeded
The read_line() code itself does not check whether the incoming buffer has any room or even a non-NULL pointer. That would come naturally, though, if it could bootstrap from a NULL pointer.

This honestly feels like getting a new college grad through their first industrial code review. That's the kind of code review that takes a week or two of back-and-forth, because each new version fixes one thing but breaks another. Or, a mentor goes and spends an hour or two pair programming with the new guy.

I pointed out a number of flaws in ChatGPT’s code. How many of those would you have caught?

How many of those would lazy programmers who lean on ChatGPT and other code generators catch?

As I said in another answer about ChatGPT, I feel a bit like Sideshow Bob here.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/pbsda2uq1h9xrtw3', 'title': 'Will the algorithm design be no longer an issue for coders knowing that ChatGPT can easily create any algorithm? Can a use of ChatGPT have any bad consequences for a programmer?', 'score': {'original': 0.83463333333333, 'ai': 0.16536666666667}, 'blocks': [{'text': ""ChatGPT can easily regurgitate modified boilerplate that's occasionally wrong in subtle (or sometimes not so subtle) ways.\n\nI asked ChatGPT how to read an arbitrarily long line from a stream in C. This is what it came up with:\n\n#include <stdio.h>\xa0\n#include <stdlib.h>\xa0\n\xa0\nchar *read_line(FILE *stream) {\xa0\n    char *line = NULL;\xa0\n    int line_size = 0;\xa0\n    int line_capacity = 0;\xa0\n    int c;\xa0\n\xa0\n    while ((c = fgetc(stream)) != EOF && c != '\\n') {\xa0\n        if (line_size >= line_capacity) {\xa0\n            line_capacity = line_capacity == 0 ? 64 : line_capacity * 2;\xa0\n            char *new_line = realloc(line, line_capacity);\xa0\n            if (new_line == NULL) {\xa0\n                free(line);\xa0\n                return NULL;\xa0\n            }\xa0\n            line = new_line;\xa0\n        }\xa0\n        line[line_size++] = (char)c;\xa0\n    }\xa0\n\xa0\n    if (line_size > 0 || c == '\\n') {\xa0\n        if (line_size >= line_capacity) {\xa0\n            line_capacity = line_capacity == 0 ? 64 : line_capacity * 2;\xa0\n            char *new_line = realloc(line, line_capacity);\xa0\n            if (new_line == NULL) {\xa0\n                free(line);\xa0\n                return NULL;\xa0\n            }\xa0\n            line = new_line;\xa0\n        }\xa0\n        line[line_size++] = '\\0';\xa0\n    }\xa0\n\xa0\n    return line;\xa0\n}:\xa0\n\nHere's how the code works:\n\nline is a pointer to the dynamically allocated memory that will store the line.\nline_size is the current number of characters in the line.\nline_capacity is the current size of the allocated memory.\nThe loop reads each character from the stream until the end of the stream or a newline character is encountered.\nIf the current line size is greater than or equal to the allocated memory capacity, the memory is reallocated to double its size.\nThe character is appended to the line, and the line size is incremented.\nIf the end of the line or stream is reached and there are characters in the line, the null terminator is added to the end of the line.\nThe function returns a pointer"", 'result': {'fake': 1, 'real': 0}, 'status': 'success'}, {'text': 'to the line or NULL if an error occurs.\n\nTo use this function, you can pass a pointer to the stream you want to read from as an argument:\n\nint main() {\xa0\n    char *line = read_line(stdin);\xa0\n    if (line == NULL) {\xa0\n        fprintf(stderr, ""Error: could not read line\\n"");\xa0\n        exit(EXIT_FAILURE);\xa0\n    }\xa0\n    printf(""Read line: %s\\n"", line);\xa0\n    free(line);\xa0\n    return 0;\xa0\n}\xa0\n\nIn this example, the function read_line is called with stdin as the argument to read a line from the standard input stream. The line is printed to the console, and the dynamically allocated memory is freed using free when it is no longer needed.\n\nThat looks fairly reasonable. Not great, but not terrible.\n\nYou have a potential signed integer overflow in the geometric growth code. And of course, character at a time isn\'t really the pinnacle of efficiency, now is it?\n\nI asked it it could write a more efficient version with fgets(), and it obliged. However, it\'s one step forward and two steps back:\n\n#include <stdio.h>\xa0\n#include <stdlib.h>\xa0\n#include <string.h>\xa0\n\xa0\nchar *read_line(FILE *stream) {\xa0\n    char *line = NULL;\xa0\n    size_t line_capacity = 0;\xa0\n    ssize_t line_size = 0;\xa0\n\xa0\n    do {\xa0\n        line_capacity += BUFSIZ;\xa0\n        char *new_line = realloc(line, line_capacity);\xa0\n        if (new_line == NULL) {\xa0\n            free(line);\xa0\n            return NULL;\xa0\n        }\xa0\n        line = new_line;\xa0\n\xa0\n        if (fgets(line + line_size, (int)(line_capacity - line_size), stream) == NULL) {\xa0\n            break;\xa0\n        }\xa0\n\xa0\n        line_size = strlen(line);\xa0\n    } while (line[line_size - 1] != \'\\n\');\xa0\n\xa0\n    if (line_size == 0) {\xa0\n        free(line);\xa0\n        return NULL;\xa0\n    }\xa0\n\xa0\n    line[line_size - 1] = \'\\0\';\xa0\n    char *new_line = realloc(line, line_size);\xa0\n    if (new_line == NULL) {\xa0\n        free(line);\xa0\n        return NULL;\xa0\n    }\xa0\n    line = new_line;\xa0\n\xa0\n    return line;\xa0\n}\xa0\n\nSome flaws:\n\nOur nice geometric growth allocation is gone. We now have linear growth, which is \nO\n(\nn\n2\n)\n.\nO(n2).\nBut, we’ve upgraded to size_t, so any overflow there will be unsigned rather than UB inducing signed overflow.\nWhen detecting how much text fgets() read in, it remeasures the entire string. Again, that\'s \nO\n(\nn\n2\n)\n.\nO(n2).\nIt weirdly keeps the string length in the non-standard ssize_t. strlen() returns size_t.\nWhy are we realloc’ing again at the end after we’ve successfully read the string? Just', 'result': {'fake': 0.5291, 'real': 0.4709}, 'status': 'success'}, {'text': 'return it with a bit of extra pad at the end and avoid an extra trip through the memory allocator, an additional opportunity to fail allocation, and an extra potential memcpy().\n\nNow, we are dividing n by BUFSIZ, so in practice it won\'t be noticeable until some bozo puts something like a megabyte-sized line in your file.\n\nBut isn\'t that exactly what DoS attackers live for?\n\nBoth of these have you free() the buffer when you\'re done. That\'s potentially going to fragment your heap unnecessarily over time. More commonly, you want to reuse an input buffer. You don\'t need to keep a copy. Instead of fresh allocations for each line, you can just reuse the previous buffer.\n\nYou can ask ChatGPT to do that, and it obliges:\n\n#include <stdio.h>\xa0\n#include <stdlib.h>\xa0\n#include <string.h>\xa0\n\xa0\n#define INITIAL_LINE_CAPACITY 128\xa0\n\xa0\nchar *read_line(FILE *stream, char *line, size_t *line_capacity) {\xa0\n    ssize_t line_size = 0;\xa0\n\xa0\n    do {\xa0\n        if (fgets(line + line_size, (int)(*line_capacity - line_size), stream) == NULL) {\xa0\n            break;\xa0\n        }\xa0\n\xa0\n        line_size = strlen(line);\xa0\n        if (line[line_size - 1] == \'\\n\') {\xa0\n            break;\xa0\n        }\xa0\n\xa0\n        *line_capacity *= 2;\xa0\n        char *new_line = realloc(line, *line_capacity);\xa0\n        if (new_line == NULL) {\xa0\n            free(line);\xa0\n            return NULL;\xa0\n        }\xa0\n        line = new_line;\xa0\n    } while (1);\xa0\n\xa0\n    if (line_size == 0) {\xa0\n        return NULL;\xa0\n    }\xa0\n\xa0\n    line[line_size - 1] = \'\\0\';\xa0\n    char *new_line = realloc(line, line_size);\xa0\n    if (new_line == NULL) {\xa0\n        free(line);\xa0\n        return NULL;\xa0\n    }\xa0\n    line = new_line;\xa0\n\xa0\n    return line;\xa0\n}\xa0\n\nAnd it provides this demo code:\n\nint main() {\xa0\n    char *line = malloc(INITIAL_LINE_CAPACITY);\xa0\n    size_t line_capacity = INITIAL_LINE_CAPACITY;\xa0\n\xa0\n    while (read_line(stdin, line, &line_capacity) != NULL) {\xa0\n        printf(""Read line: %s\\n"", line);\xa0\n    }\xa0\n\xa0\n    free(line);\xa0\n    return 0;\xa0\n}\xa0\n\nAgain, this feels like one step forward, two steps back.\n\nWe\'re back to geometric growth, which is a positive. But, that now puts this expression at risk of integer overflow: (int)(*line_capacity - line_size)\nThe argument line is passed by value while its companion line_size is passed by pointer.\nThat requires the user to reassign line on return because realloc() can move the buffer.\nThis introduces a significant opportunity to “hold it wrong”\n and', 'result': {'fake': 0.7139, 'real': 0.2861}, 'status': 'success'}, {'text': ""fail to update line.\nIn fact, ChatGPT itself “holds it wrong” in its own demo code.\nwhile (read_line(stdin, line, &line_capacity) != NULL) {\xa0\nIf realloc() fails, ChatGPT frees the buffer, but fails to zero out the line_capacity.\n*line_capacity *= 2;\xa0\nchar *new_line = realloc(line, *line_capacity);\xa0\nif (new_line == NULL) {\xa0\n    free(line);\xa0\n    return NULL;\xa0\n}\xa0\nPrevious versions would bootstrap themselves from an empty allocation and zero capacity.\nThis one doesn't, requiring the caller to do that, introducing another opportunity to “hold it wrong.”\nChatGPT “holds it wrong” subtly, failing to check that the initial malloc() succeeded\nThe read_line() code itself does not check whether the incoming buffer has any room or even a non-NULL pointer. That would come naturally, though, if it could bootstrap from a NULL pointer.\n\nThis honestly feels like getting a new college grad through their first industrial code review. That's the kind of code review that takes a week or two of back-and-forth, because each new version fixes one thing but breaks another. Or, a mentor goes and spends an hour or two pair programming with the new guy.\n\nI pointed out a number of flaws in ChatGPT’s code. How many of those would you have caught?\n\nHow many of those would lazy programmers who lean on ChatGPT and other code generators catch?\n\nAs I said in another answer about ChatGPT, I feel a bit like Sideshow Bob here."", 'result': {'fake': 0.5223, 'real': 0.4777}, 'status': 'success'}], 'credits_used': 13, 'credits': 1986309, 'subscription': 0, 'content': 'ChatGPT can easily regurgitate modified boilerplate that\'s occasionally wrong in subtle (or sometimes not so subtle) ways.\n\nI asked ChatGPT how to read an arbitrarily long line from a stream in C. This is what it came up with:\n\n#include <stdio.h>\xa0\n#include <stdlib.h>\xa0\n\xa0\nchar *read_line(FILE *stream) {\xa0\n    char *line = NULL;\xa0\n    int line_size = 0;\xa0\n    int line_capacity = 0;\xa0\n    int c;\xa0\n\xa0\n    while ((c = fgetc(stream)) != EOF && c != \'\\n\') {\xa0\n        if (line_size >= line_capacity) {\xa0\n            line_capacity = line_capacity == 0 ? 64 : line_capacity * 2;\xa0\n            char *new_line = realloc(line, line_capacity);\xa0\n            if (new_line == NULL) {\xa0\n                free(line);\xa0\n                return NULL;\xa0\n            }\xa0\n            line = new_line;\xa0\n        }\xa0\n        line[line_size++] = (char)c;\xa0\n    }\xa0\n\xa0\n    if (line_size > 0 || c == \'\\n\') {\xa0\n        if (line_size >= line_capacity) {\xa0\n            line_capacity = line_capacity == 0 ? 64 : line_capacity * 2;\xa0\n            char *new_line = realloc(line, line_capacity);\xa0\n            if (new_line == NULL) {\xa0\n                free(line);\xa0\n                return NULL;\xa0\n            }\xa0\n            line = new_line;\xa0\n        }\xa0\n        line[line_size++] = \'\\0\';\xa0\n    }\xa0\n\xa0\n    return line;\xa0\n}:\xa0\n\nHere\'s how the code works:\n\nline is a pointer to the dynamically allocated memory that will store the line.\nline_size is the current number of characters in the line.\nline_capacity is the current size of the allocated memory.\nThe loop reads each character from the stream until the end of the stream or a newline character is encountered.\nIf the current line size is greater than or equal to the allocated memory capacity, the memory is reallocated to double its size.\nThe character is appended to the line, and the line size is incremented.\nIf the end of the line or stream is reached and there are characters in the line, the null terminator is added to the end of the line.\nThe function returns a pointer to the line or NULL if an error occurs.\n\nTo use this function, you can pass a pointer to the stream you want to read from as an argument:\n\nint main() {\xa0\n    char *line = read_line(stdin);\xa0\n    if (line == NULL) {\xa0\n        fprintf(stderr, ""Error: could not read line\\n"");\xa0\n        exit(EXIT_FAILURE);\xa0\n    }\xa0\n    printf(""Read line: %s\\n"", line);\xa0\n    free(line);\xa0\n    return 0;\xa0\n}\xa0\n\nIn this example, the function read_line is called with stdin as the argument to read a line from the standard input stream. The line is printed to the console, and the dynamically allocated memory is freed using free when it is no longer needed.\n\nThat looks fairly reasonable. Not great, but not terrible.\n\nYou have a potential signed integer overflow in the geometric growth code. And of course, character at a time isn\'t really the pinnacle of efficiency, now is it?\n\nI asked it it could write a more efficient version with fgets(), and it obliged. However, it\'s one step forward and two steps back:\n\n#include <stdio.h>\xa0\n#include <stdlib.h>\xa0\n#include <string.h>\xa0\n\xa0\nchar *read_line(FILE *stream) {\xa0\n    char *line = NULL;\xa0\n    size_t line_capacity = 0;\xa0\n    ssize_t line_size = 0;\xa0\n\xa0\n    do {\xa0\n        line_capacity += BUFSIZ;\xa0\n        char *new_line = realloc(line, line_capacity);\xa0\n        if (new_line == NULL) {\xa0\n            free(line);\xa0\n            return NULL;\xa0\n        }\xa0\n        line = new_line;\xa0\n\xa0\n        if (fgets(line + line_size, (int)(line_capacity - line_size), stream) == NULL) {\xa0\n            break;\xa0\n        }\xa0\n\xa0\n        line_size = strlen(line);\xa0\n    } while (line[line_size - 1] != \'\\n\');\xa0\n\xa0\n    if (line_size == 0) {\xa0\n        free(line);\xa0\n        return NULL;\xa0\n    }\xa0\n\xa0\n    line[line_size - 1] = \'\\0\';\xa0\n    char *new_line = realloc(line, line_size);\xa0\n    if (new_line == NULL) {\xa0\n        free(line);\xa0\n        return NULL;\xa0\n    }\xa0\n    line = new_line;\xa0\n\xa0\n    return line;\xa0\n}\xa0\n\nSome flaws:\n\nOur nice geometric growth allocation is gone. We now have linear growth, which is \nO\n(\nn\n2\n)\n.\nO(n2).\nBut, we’ve upgraded to size_t, so any overflow there will be unsigned rather than UB inducing signed overflow.\nWhen detecting how much text fgets() read in, it remeasures the entire string. Again, that\'s \nO\n(\nn\n2\n)\n.\nO(n2).\nIt weirdly keeps the string length in the non-standard ssize_t. strlen() returns size_t.\nWhy are we realloc’ing again at the end after we’ve successfully read the string? Just return it with a bit of extra pad at the end and avoid an extra trip through the memory allocator, an additional opportunity to fail allocation, and an extra potential memcpy().\n\nNow, we are dividing n by BUFSIZ, so in practice it won\'t be noticeable until some bozo puts something like a megabyte-sized line in your file.\n\nBut isn\'t that exactly what DoS attackers live for?\n\nBoth of these have you free() the buffer when you\'re done. That\'s potentially going to fragment your heap unnecessarily over time. More commonly, you want to reuse an input buffer. You don\'t need to keep a copy. Instead of fresh allocations for each line, you can just reuse the previous buffer.\n\nYou can ask ChatGPT to do that, and it obliges:\n\n#include <stdio.h>\xa0\n#include <stdlib.h>\xa0\n#include <string.h>\xa0\n\xa0\n#define INITIAL_LINE_CAPACITY 128\xa0\n\xa0\nchar *read_line(FILE *stream, char *line, size_t *line_capacity) {\xa0\n    ssize_t line_size = 0;\xa0\n\xa0\n    do {\xa0\n        if (fgets(line + line_size, (int)(*line_capacity - line_size), stream) == NULL) {\xa0\n            break;\xa0\n        }\xa0\n\xa0\n        line_size = strlen(line);\xa0\n        if (line[line_size - 1] == \'\\n\') {\xa0\n            break;\xa0\n        }\xa0\n\xa0\n        *line_capacity *= 2;\xa0\n        char *new_line = realloc(line, *line_capacity);\xa0\n        if (new_line == NULL) {\xa0\n            free(line);\xa0\n            return NULL;\xa0\n        }\xa0\n        line = new_line;\xa0\n    } while (1);\xa0\n\xa0\n    if (line_size == 0) {\xa0\n        return NULL;\xa0\n    }\xa0\n\xa0\n    line[line_size - 1] = \'\\0\';\xa0\n    char *new_line = realloc(line, line_size);\xa0\n    if (new_line == NULL) {\xa0\n        free(line);\xa0\n        return NULL;\xa0\n    }\xa0\n    line = new_line;\xa0\n\xa0\n    return line;\xa0\n}\xa0\n\nAnd it provides this demo code:\n\nint main() {\xa0\n    char *line = malloc(INITIAL_LINE_CAPACITY);\xa0\n    size_t line_capacity = INITIAL_LINE_CAPACITY;\xa0\n\xa0\n    while (read_line(stdin, line, &line_capacity) != NULL) {\xa0\n        printf(""Read line: %s\\n"", line);\xa0\n    }\xa0\n\xa0\n    free(line);\xa0\n    return 0;\xa0\n}\xa0\n\nAgain, this feels like one step forward, two steps back.\n\nWe\'re back to geometric growth, which is a positive. But, that now puts this expression at risk of integer overflow: (int)(*line_capacity - line_size)\nThe argument line is passed by value while its companion line_size is passed by pointer.\nThat requires the user to reassign line on return because realloc() can move the buffer.\nThis introduces a significant opportunity to “hold it wrong”\n and fail to update line.\nIn fact, ChatGPT itself “holds it wrong” in its own demo code.\nwhile (read_line(stdin, line, &line_capacity) != NULL) {\xa0\nIf realloc() fails, ChatGPT frees the buffer, but fails to zero out the line_capacity.\n*line_capacity *= 2;\xa0\nchar *new_line = realloc(line, *line_capacity);\xa0\nif (new_line == NULL) {\xa0\n    free(line);\xa0\n    return NULL;\xa0\n}\xa0\nPrevious versions would bootstrap themselves from an empty allocation and zero capacity.\nThis one doesn\'t, requiring the caller to do that, introducing another opportunity to “hold it wrong.”\nChatGPT “holds it wrong” subtly, failing to check that the initial malloc() succeeded\nThe read_line() code itself does not check whether the incoming buffer has any room or even a non-NULL pointer. That would come naturally, though, if it could bootstrap from a NULL pointer.\n\nThis honestly feels like getting a new college grad through their first industrial code review. That\'s the kind of code review that takes a week or two of back-and-forth, because each new version fixes one thing but breaks another. Or, a mentor goes and spends an hour or two pair programming with the new guy.\n\nI pointed out a number of flaws in ChatGPT’s code. How many of those would you have caught?\n\nHow many of those would lazy programmers who lean on ChatGPT and other code generators catch?\n\nAs I said in another answer about ChatGPT, I feel a bit like Sideshow Bob here.', 'aiModelVersion': '1'}",0.83463333333333
Rita Singh,1y,"What is the best online data structure and algorithm MOOC, or course in C or C++?","For Data structure and algorithms, C and C++ are some of the popular programs around the world. This is because it involves the active usage of skills and software that is necessary for the IT industry. However, it is recommended to opt for an entire course instead of just learning one particular programming language. This will help you to gain various career opportunities comparatively.

Where can you learn more about DSA?

You can learn through self-learning from different YouTube videos, which are free of cost. Many popular channels like Gaurav Sen, Abdul Bari, Tushar Roy, Rachit Jain, GeeksforGeeks, etc. They will teach you basic programming and data structures from basics. If you go to their website, you will find many subscribers who are learning these programs from their videos for free.
You can opt for online institutes, which will give you hand-holding experience in the field of Data structures and algorithms by industry experts. These institutes are designed to educate you on different topics with real-life projects and assignments. Some of these institutes also offer teamwork where they place you in a team so that you can have hands-on experience in your chosen domain.

Having proper domain knowledge is always a plus point for any candidate aiming to grow in their career. Because most companies worldwide look for individuals who have strong knowledge about their domain or have a topic understanding.

Hence, it is recommended to always look for institutes or channels that offer domain-specialized education and not in general. However, there are very rare channels online that offer domain-specialized courses in Full-Stack.

Moving on, let’s discuss some of the popular institutes that will offer domain-based knowledge in the Full-Stack development course that includes training for DSA. Some of the institutes that are found after evaluation are Simplilearn, and Learnbay.

The features of these institutes are discussed below:

This institute has different courses that will help you to develop skills and knowledge in the field of software development that has training for DSA. Furthermore, their experts are well-trained and have industry experience, which will help you to gain various insights about the chosen specialization.

However, the eligibility criteria for the Full-Stack development course require individuals to have a mandatory background in Computer Science and prior experience in the IT industry which is not provided by Simplilearn.

They offer domain-specialized courses and they even train individuals who are looking for career transition but belong to a non-IT background. The institute is located in different cities where they provide offline training to the students through projects and assignments.

Full-Stack Software development includes Data Structure and Algorithms.

Course details-

Weekend batch: 9 months (Saturday-Sunday)
Weekday batch: 8 months (Monday-Friday)
The duration of the Full-Stack Software development course is 300+ hours.

Course highlights-

Real-time projects: Various real-time projects are offered to students as per their domain such as workout applications, food delivery applications, chatting or messaging applications, etc. Students are placed in a team where they are required to complete these projects independently or through teamwork. During interviews, these projects will work as brownie points in your CV.
Elite domain: Domain specialization is a crucial factor as it allows better topic understanding and positive skill enhancement. Some of the domains offered by Learnbay are Project management, Web 3.0, Web development, and DevOps & Clouds. With the right knowledge about the domain, you will be able to crack tough interviews and be placed in top MNCs.
Job Assistance: Their job assistance feature includes mock interviews, guaranteed interview calls, career guidance, resume optimization, and more.
IBM Certification: Learnbay offers IBM certification to its students. Students receive course completion certificates from IBM.

In conclusion, you can learn the DSA from an online institute and improve your knowledge in the specific domain. Comparing the two above-mentioned institutes, it is recommended to opt for Learnbay because it will help you to crack MAANG and increase your chances of being placed in a top MNC.

Thank you for reading!","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/3yr2q6z19xjge8ao', 'title': 'What is the best online data structure and algorithm MOOC, or course in C or C++?', 'score': {'original': 0.47775, 'ai': 0.52225}, 'blocks': [{'text': 'For Data structure and algorithms, C and C++ are some of the popular programs around the world. This is because it involves the active usage of skills and software that is necessary for the IT industry. However, it is recommended to opt for an entire course instead of just learning one particular programming language. This will help you to gain various career opportunities comparatively.\n\nWhere can you learn more about DSA?\n\nYou can learn through self-learning from different YouTube videos, which are free of cost. Many popular channels like Gaurav Sen, Abdul Bari, Tushar Roy, Rachit Jain, GeeksforGeeks, etc. They will teach you basic programming and data structures from basics. If you go to their website, you will find many subscribers who are learning these programs from their videos for free.\nYou can opt for online institutes, which will give you hand-holding experience in the field of Data structures and algorithms by industry experts. These institutes are designed to educate you on different topics with real-life projects and assignments. Some of these institutes also offer teamwork where they place you in a team so that you can have hands-on experience in your chosen domain.\n\nHaving proper domain knowledge is always a plus point for any candidate aiming to grow in their career. Because most companies worldwide look for individuals who have strong knowledge about their domain or have a topic understanding.\n\nHence, it is recommended to always look for institutes or channels that offer domain-specialized education and not in general. However, there are very rare channels online that offer domain-specialized courses in Full-Stack.\n\nMoving on, let’s discuss some of the popular institutes that will offer domain-based knowledge in the Full-Stack development course that includes training for DSA. Some of the institutes that are found after evaluation are Simplilearn, and Learnbay.\n\nThe features of these institutes are discussed below:\n\nThis institute has different courses that will help you to develop skills and knowledge in the field of software development that has training for DSA. Furthermore, their experts are well-trained and have industry experience, which will help you to gain various insights about the chosen specialization.\n\nHowever, the eligibility criteria for the Full-Stack development course require individuals to have a mandatory background in Computer Science and prior experience in the IT industry which is not provided by Simplilearn.\n\nThey offer domain-specialized courses and they even train individuals who are looking for career transition but belong to a non-IT background. The institute is located in different cities where they provide offline training to the students through projects and assignments.\n\nFull-Stack Software development includes Data Structure and Algorithms.\n\nCourse details-\n\nWeekend batch: 9 months (Saturday-Sunday)\nWeekday batch: 8 months (Monday-Friday)\nThe duration of the Full-Stack Software development course is 300+ hours.\n\nCourse highlights-\n\nReal-time projects: Various real-time projects are offered to students as per their domain such as workout applications, food delivery applications, chatting or messaging applications, etc. Students are placed in a team where they are required to complete these projects independently or through teamwork. During interviews, these projects will work as brownie points in your CV.\nElite domain: Domain specialization is a crucial factor as it allows better topic understanding and positive', 'result': {'fake': 0.0457, 'real': 0.9543}, 'status': 'success'}, {'text': 'skill enhancement. Some of the domains offered by Learnbay are Project management, Web 3.0, Web development, and DevOps & Clouds. With the right knowledge about the domain, you will be able to crack tough interviews and be placed in top MNCs.\nJob Assistance: Their job assistance feature includes mock interviews, guaranteed interview calls, career guidance, resume optimization, and more.\nIBM Certification: Learnbay offers IBM certification to its students. Students receive course completion certificates from IBM.\n\nIn conclusion, you can learn the DSA from an online institute and improve your knowledge in the specific domain. Comparing the two above-mentioned institutes, it is recommended to opt for Learnbay because it will help you to crack MAANG and increase your chances of being placed in a top MNC.\n\nThank you for reading!', 'result': {'fake': 1, 'real': 0}, 'status': 'success'}], 'credits_used': 7, 'credits': 1986302, 'subscription': 0, 'content': 'For Data structure and algorithms, C and C++ are some of the popular programs around the world. This is because it involves the active usage of skills and software that is necessary for the IT industry. However, it is recommended to opt for an entire course instead of just learning one particular programming language. This will help you to gain various career opportunities comparatively.\n\nWhere can you learn more about DSA?\n\nYou can learn through self-learning from different YouTube videos, which are free of cost. Many popular channels like Gaurav Sen, Abdul Bari, Tushar Roy, Rachit Jain, GeeksforGeeks, etc. They will teach you basic programming and data structures from basics. If you go to their website, you will find many subscribers who are learning these programs from their videos for free.\nYou can opt for online institutes, which will give you hand-holding experience in the field of Data structures and algorithms by industry experts. These institutes are designed to educate you on different topics with real-life projects and assignments. Some of these institutes also offer teamwork where they place you in a team so that you can have hands-on experience in your chosen domain.\n\nHaving proper domain knowledge is always a plus point for any candidate aiming to grow in their career. Because most companies worldwide look for individuals who have strong knowledge about their domain or have a topic understanding.\n\nHence, it is recommended to always look for institutes or channels that offer domain-specialized education and not in general. However, there are very rare channels online that offer domain-specialized courses in Full-Stack.\n\nMoving on, let’s discuss some of the popular institutes that will offer domain-based knowledge in the Full-Stack development course that includes training for DSA. Some of the institutes that are found after evaluation are Simplilearn, and Learnbay.\n\nThe features of these institutes are discussed below:\n\nThis institute has different courses that will help you to develop skills and knowledge in the field of software development that has training for DSA. Furthermore, their experts are well-trained and have industry experience, which will help you to gain various insights about the chosen specialization.\n\nHowever, the eligibility criteria for the Full-Stack development course require individuals to have a mandatory background in Computer Science and prior experience in the IT industry which is not provided by Simplilearn.\n\nThey offer domain-specialized courses and they even train individuals who are looking for career transition but belong to a non-IT background. The institute is located in different cities where they provide offline training to the students through projects and assignments.\n\nFull-Stack Software development includes Data Structure and Algorithms.\n\nCourse details-\n\nWeekend batch: 9 months (Saturday-Sunday)\nWeekday batch: 8 months (Monday-Friday)\nThe duration of the Full-Stack Software development course is 300+ hours.\n\nCourse highlights-\n\nReal-time projects: Various real-time projects are offered to students as per their domain such as workout applications, food delivery applications, chatting or messaging applications, etc. Students are placed in a team where they are required to complete these projects independently or through teamwork. During interviews, these projects will work as brownie points in your CV.\nElite domain: Domain specialization is a crucial factor as it allows better topic understanding and positive skill enhancement. Some of the domains offered by Learnbay are Project management, Web 3.0, Web development, and DevOps & Clouds. With the right knowledge about the domain, you will be able to crack tough interviews and be placed in top MNCs.\nJob Assistance: Their job assistance feature includes mock interviews, guaranteed interview calls, career guidance, resume optimization, and more.\nIBM Certification: Learnbay offers IBM certification to its students. Students receive course completion certificates from IBM.\n\nIn conclusion, you can learn the DSA from an online institute and improve your knowledge in the specific domain. Comparing the two above-mentioned institutes, it is recommended to opt for Learnbay because it will help you to crack MAANG and increase your chances of being placed in a top MNC.\n\nThank you for reading!', 'aiModelVersion': '1'}",0.47775
Håkon Hapnes Strand,1y,"Which is better in chess, an anti cheat algorithm that catches 100% of cheaters but produces 0.01% false positives or one that produces no false positives but misses 0.01% of cheaters?","I think it's pretty clear that a false positive is worse than a false negative. If someone has devoted themself to chess and you take that away from them while also publicly shaming them, you could essentially ruin their life.

As a side note, those are totally unrealistic numbers. It's fully possible to cheat without getting caught. It's rare that someone gets away with it, but I still believe it's a lot more common than people think. We'd probably be lucky to catch 99% of cheaters, let alone 99.99%.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/j0r3kq5wat4vxl78', 'title': 'Which is better in chess, an anti cheat algorithm that catches 100% of cheaters but produces 0.01% false positives or one that produces no false positives but misses 0.01% of cheaters?', 'score': {'original': 0.9825, 'ai': 0.0175}, 'blocks': [{'text': ""I think it's pretty clear that a false positive is worse than a false negative. If someone has devoted themself to chess and you take that away from them while also publicly shaming them, you could essentially ruin their life.\n\nAs a side note, those are totally unrealistic numbers. It's fully possible to cheat without getting caught. It's rare that someone gets away with it, but I still believe it's a lot more common than people think. We'd probably be lucky to catch 99% of cheaters, let alone 99.99%."", 'result': {'fake': 0.0175, 'real': 0.9825}, 'status': 'success'}], 'credits_used': 1, 'credits': 1986301, 'subscription': 0, 'content': ""I think it's pretty clear that a false positive is worse than a false negative. If someone has devoted themself to chess and you take that away from them while also publicly shaming them, you could essentially ruin their life.\n\nAs a side note, those are totally unrealistic numbers. It's fully possible to cheat without getting caught. It's rare that someone gets away with it, but I still believe it's a lot more common than people think. We'd probably be lucky to catch 99% of cheaters, let alone 99.99%."", 'aiModelVersion': '1'}",0.9825
Thomas Cormen,3y,"Why is Introduction to Algorithms by Thomas Cormen not a beginner’s book, despite its name?","Question: “why Introduction to Algorithms by Thomas Cormen is not beginner’s book, despite its name?”

A2A

(Note: Let’s give credit where credit is due. I am not the only author of Introduction to Algorithms. My coauthors are Charles Leiserson, Ronald Rivest, and Cliff Stein.)

I have answered a similar question elsewhere on Quora, but I’m too lazy to use Quora’s lame search function to find it. Here’s the gist of what I wrote.

Introduction to Algorithms is just that. An introduction to algorithms. It is not an introduction to computer science or to programming, and we never intended it to be. It starts out with basic concepts and simple algorithms, but it does assume that you’ve done some programming. It really helps to have already seen recursion, which just about any introductory programming course should cover.

Yes, the book contains quite a bit of mathematics, but it is also self contained. If you don’t know how to solve summations, if you don’t know basic concepts of discrete mathematics, if you don’t know probability, or if you don’t know much about matrices, then read the appendices. Other mathematical techniques are covered in the chapters, e.g., solving recurrence equations, using potential functions for amortized analysis, and basics of number theory.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/bk7fpy1iosj9raql', 'title': 'Why is Introduction to Algorithms by Thomas Cormen not a beginner’s book, despite its name?', 'score': {'original': 0.999, 'ai': 0.001}, 'blocks': [{'text': 'Question: “why Introduction to Algorithms by Thomas Cormen is not beginner’s book, despite its name?”\n\nA2A\n\n(Note: Let’s give credit where credit is due. I am not the only author of Introduction to Algorithms. My coauthors are Charles Leiserson, Ronald Rivest, and Cliff Stein.)\n\nI have answered a similar question elsewhere on Quora, but I’m too lazy to use Quora’s lame search function to find it. Here’s the gist of what I wrote.\n\nIntroduction to Algorithms is just that. An introduction to algorithms. It is not an introduction to computer science or to programming, and we never intended it to be. It starts out with basic concepts and simple algorithms, but it does assume that you’ve done some programming. It really helps to have already seen recursion, which just about any introductory programming course should cover.\n\nYes, the book contains quite a bit of mathematics, but it is also self contained. If you don’t know how to solve summations, if you don’t know basic concepts of discrete mathematics, if you don’t know probability, or if you don’t know much about matrices, then read the appendices. Other mathematical techniques are covered in the chapters, e.g., solving recurrence equations, using potential functions for amortized analysis, and basics of number theory.', 'result': {'fake': 0.001, 'real': 0.999}, 'status': 'success'}], 'credits_used': 3, 'credits': 1986298, 'subscription': 0, 'content': 'Question: “why Introduction to Algorithms by Thomas Cormen is not beginner’s book, despite its name?”\n\nA2A\n\n(Note: Let’s give credit where credit is due. I am not the only author of Introduction to Algorithms. My coauthors are Charles Leiserson, Ronald Rivest, and Cliff Stein.)\n\nI have answered a similar question elsewhere on Quora, but I’m too lazy to use Quora’s lame search function to find it. Here’s the gist of what I wrote.\n\nIntroduction to Algorithms is just that. An introduction to algorithms. It is not an introduction to computer science or to programming, and we never intended it to be. It starts out with basic concepts and simple algorithms, but it does assume that you’ve done some programming. It really helps to have already seen recursion, which just about any introductory programming course should cover.\n\nYes, the book contains quite a bit of mathematics, but it is also self contained. If you don’t know how to solve summations, if you don’t know basic concepts of discrete mathematics, if you don’t know probability, or if you don’t know much about matrices, then read the appendices. Other mathematical techniques are covered in the chapters, e.g., solving recurrence equations, using potential functions for amortized analysis, and basics of number theory.', 'aiModelVersion': '1'}",0.999
Joshua Gross,Updated 7mo,"As we all know, DeepMind has discovered faster sorting algorithms, so is the algorithm I learned in computer science at university still useful, and can I not learn it?","I’ll tell you what I tell my computer science students:

When you walk into my classroom, you’re a computer scientist.
Sure, you aren’t a very knowledgeable computer scientist at the start; we all start that way. What makes you a computer scientist is your goal to understand.
In contrast, a programmer is only trying to produce working code, and that is necessary but not sufficient to be a computer scientist.
You shouldn’t implement any of the algorithms or data structures we cover for a real-world system unless backed into a corner. Use libraries whenever possible.
However, you will will learn the building blocks of the algorithms and data structures (and their applications) that you will use in your future as a computer scientist in other computer science courses, and as a software developer, if you choose that professional route.

The sorting algorithms most students start with (e.g., bubble, selection, and insertion, the major 
O
(
n
2
)
O(n2)
 sorts) teach students to apply concepts like looping (to repeat behavior), nested loops (to repeat repeated behavior), linear search (to find a relevant element), and transposition (like swapping or shifting). We get a lot of bang for our buck with sorting algorithms, in part because there are many of them and each operates differently, showing different applications of the same concepts.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/e7v6wid5u8cbpg24', 'title': 'As we all know, DeepMind has discovered faster sorting algorithms, so is the algorithm I learned in computer science at university still useful, and can I not learn it?', 'score': {'original': 0.9921, 'ai': 0.0079}, 'blocks': [{'text': 'I’ll tell you what I tell my computer science students:\n\nWhen you walk into my classroom, you’re a computer scientist.\nSure, you aren’t a very knowledgeable computer scientist at the start; we all start that way. What makes you a computer scientist is your goal to understand.\nIn contrast, a programmer is only trying to produce working code, and that is necessary but not sufficient to be a computer scientist.\nYou shouldn’t implement any of the algorithms or data structures we cover for a real-world system unless backed into a corner. Use libraries whenever possible.\nHowever, you will will learn the building blocks of the algorithms and data structures (and their applications) that you will use in your future as a computer scientist in other computer science courses, and as a software developer, if you choose that professional route.\n\nThe sorting algorithms most students start with (e.g., bubble, selection, and insertion, the major \nO\n(\nn\n2\n)\nO(n2)\n sorts) teach students to apply concepts like looping (to repeat behavior), nested loops (to repeat repeated behavior), linear search (to find a relevant element), and transposition (like swapping or shifting). We get a lot of bang for our buck with sorting algorithms, in part because there are many of them and each operates differently, showing different applications of the same concepts.', 'result': {'fake': 0.0079, 'real': 0.9921}, 'status': 'success'}], 'credits_used': 3, 'credits': 1986295, 'subscription': 0, 'content': 'I’ll tell you what I tell my computer science students:\n\nWhen you walk into my classroom, you’re a computer scientist.\nSure, you aren’t a very knowledgeable computer scientist at the start; we all start that way. What makes you a computer scientist is your goal to understand.\nIn contrast, a programmer is only trying to produce working code, and that is necessary but not sufficient to be a computer scientist.\nYou shouldn’t implement any of the algorithms or data structures we cover for a real-world system unless backed into a corner. Use libraries whenever possible.\nHowever, you will will learn the building blocks of the algorithms and data structures (and their applications) that you will use in your future as a computer scientist in other computer science courses, and as a software developer, if you choose that professional route.\n\nThe sorting algorithms most students start with (e.g., bubble, selection, and insertion, the major \nO\n(\nn\n2\n)\nO(n2)\n sorts) teach students to apply concepts like looping (to repeat behavior), nested loops (to repeat repeated behavior), linear search (to find a relevant element), and transposition (like swapping or shifting). We get a lot of bang for our buck with sorting algorithms, in part because there are many of them and each operates differently, showing different applications of the same concepts.', 'aiModelVersion': '1'}",0.9921
Arindam Khan,Updated 4y,What is the contribution of India in the field of algorithms and complexity?,"“Indian Mathematics is predominantly algorithmic. ” — M. S. Sriram.

India and the genesis of the word ‘Algorithms’:
The word “Algorithm” is derived from the name of Al-Khwārizmī (from 9th Century). Al-Khwārizmī was heavily influenced by systematic and procedural methods of Indian mathematics. Al-Khwarizmi’s book ‘Kitab-al-hisab-al-Hindi’ (translated into Latin as Algoritmi de numero Indorum) was instrumental in the transmission of Indian algorithmic procedures and the Hindu-Arabic numeral system throughout the middle east and Europe.

Ancient India and Algorithms:
Both Indian mathematics and astronomy were influenced by algorithmic viewpoint. Some of the seminal results:

Geometrical construction in Sulbasutras by Baudhayana, Apastamba, Katyayana, et al. during 800–200 BC: Procedures for dividing a line into equal parts, drawing perpendiculars, constructing squares and rectangles;
Algorithms for square and the cube root by Aryabhata
 (c. 499). Variants of these algorithms were used by Indian mathematicians such as Siddhasena Gani (550 CE), Bhaskara I (600 CE), Sridhara (750 CE) and Bhaskara II (1150 CE), as well as by numerous Arab and European mathematicians. Aryabhata also devised Kuttaka or pulverizer method to solve first order indeterminate equations.
Recursion and Divide-and-Conquer by Pingala: Pingala made fundamental contributions such as the calculation of the binomial coefficients, use of repeated partial sums of sequences and the formula for summing a geometric series. He studied the formal theory of Sanskrit meters and consistently used recursion in his algorithms, a tradition which stretches from Pānini (6th century BCE) to Āryabhata (5th century CE) and Mādhava (14th century CE). He also devised a divide-and-conquer based algorithm for the computation of the powers of 2. Śridhara (750 CE) generalized many of his works later.
Varga-Prakriti: Quadratic indeterminate equations (Pell’s equation):
Bhaskaracarya II, in his work Bjaganita (1150 CE) describes an algorithm Cakravala to solve equations of the form 
x
2
−
n
y
2
=
1
x2−ny2=1
. Later Fermat and others in 17th century studied such equations which is the genesis of modern Arithmetic Geometry. Mathematician A. Weil said: “What would have been Fermat's astonishment if some missionary just back from India had told him that his problem had been successfully tackled there by the native Indians almost six centuries earlier?”
Brahmagupta’s interpolation formula in Khandakhadyaka (665 CE):
To determine sine function for an arbitrary angle, from the set of tabulated values of sine given at fixed intervals.
Accurate computation of 
π
π
using an error-minimization algorithm Madhava of Sangamagrama (1340 - 1425 CE).
Algorithm for finding the time from shadow (by Nilakantha in Tantrasangraha 1500 CE),
Algorithm for finding eclipse duration (Avisesakarma).

Hemacandra, Kedara, Jayadeva, Jayakirti, Mahavira, Virahanka, Janasraya, etc. many other Indian mathematicians contributed to many such algorithmic procedures. Unfortunately, many of such manuscripts (e.g. Bakhshali manuscript
 ) are either lost or partially damaged.

Independent India and Algorithms:
Computer science and algorithms research started quite late in India. Around 50 years back, the first computer science department was founded in IISc Bangalore. As Engineering studies are preferred in India because of the surge in private sector jobs, most of the good students (with strong mathematical foundations) went for computer science, especially in IITs. Later many of them went abroad and continued research in algorithms and complexity.

One of the biggest results in algorithms in India was AKS primality test
 (by Manidra Agrawal, Neeraj Kayal, Nitin Saxena), which gave the first (deterministic) polynomial time algorithm for primality testing.
I already wrote about it here: In the last 50 years, what is the top research achievement in India?

(Manindra Agrawal, Neeraj Kayal, Nitin Saxena from IIT Kanpur)

Another big result was the result on Kadison-Singer problem proven by Nikhil Srivastava
, with Adam Marcus
 and Daniel Spielman
. They received Polya prize in 2014 for their contribution. Nikhil was a researcher at Microsoft Research India at that time and now a Math Professor at UC Berkeley. Read more here: Computer Scientists Solve Kadison-Singer Problem | Quanta Magazine

Indian computer scientists abroad:

The modern era is an era of collaborations. Many Indian computer scientists, especially in the USA, along with co-authors made seminal contributions to the field.

Ravindran Kannan
 was one of the first Indian theoretical computer scientists. He received Knuth prize and Fulkerson prize for his major contributions for algorithms for integer programming
 and the geometry of numbers
, random walks
 in n
-space
, randomized algorithms
 for linear algebra
, algorithms for approximating the volume of convex bodies
 and an algorithmic version for Szemerédi regularity partition
.

The Vazirani brothers (Umesh Vazirani 
and Vijay Vazirani
) were the next stalwarts. They made an enormous contribution to the field of algorithms (especially approximation algorithms, online algorithms, algorithmic game theory and quantum computation). Some of their major results include: Ranking algorithm for online matching, Micali-Vazirani algorithm, Valiant–Vazirani theorem,
 quantum Fourier transform algorithm, ARV sparsest cut algorithm etc.). Vijay was a Prof. at IIT Delhi for some time and influenced algorithms research in India significantly during his stay.

(Ravi Kannan, Vijay and Umesh Vazirani)

Narendra Karmarkar
 invented Karmarkar's algorithm
, one of the first provably polynomial time algorithms (interior point method) for linear programming. He received Fulkerson prize for this landmark result.

Ketan Mulmuley
 has laid the foundation of geometric complexity theory, a possible approach for P vs NP problem.

Sanjeev Arora
, Madhu Sudan, 
and Rajeev Motwani along with co-authors got Godel prize for their work on Probabilistically checkable proof 
(PCP Theorem), one of the most beautiful results of last century. Rajeev Motwani
 was also instrumental in the development of Google in its early phase. Sanjeev Arora got another Godel prize for his approximation algorithm for Euclidean Traveling Salesman Problem. Sanjeev Arora’s student Subhash Khot received Nevanlinna Prize
 in 2014 for his work on Unique games conjecture
.

Sanjeev Arora and Subhash Khot (Both were AIR 1 in IITJEE)

(Ketan Mulmuley and Narendra Karmarkar)

(Madhu Sudan, Rajeev Motwani)

Numerous other Indian theoretical computer scientists are making contributions to the field. You can check the list of publications in the recent top theory conferences and see many Indian names there.

(Naveen Garg and Amit Kumar from IIT Delhi, both are Shanti Swarup Bhatnagar awardees)

(Jaikumar Radhakrishnan (TIFR), one of the first computer scientists to receive Shanti Swarup Bhatnagar Award and Saket Saurabh (IMSc), author of a textbook on parameterized complexity)

(Moses Charikar and Nikhil Bansal)

(Anupam Gupta and Santosh Vempala)

(Venkatesan Guruswami and Prasad Raghavendra)

(Salil Vadhan and Aravind Srinivasan)

( Pankaj Agarwal and Kamal Jain)

(Sanjeev Khanna and Chandra Chekuri)

[Images are taken from Google.
Apologies for nonuniform pictures.
This is of course not a comprehensive list and I wish I could add more pictures of other prominent Indian computer scientists.]

[1A] Sriram, M. S. ""Algorithms in Indian Mathematics."" Contributions to the History of Indian Mathematics. Hindustan Book Agency, 2005. 153-182.
[1B] K.Ramasubramanian, “Algorithms in Indian Astronomy.” Contributions to the History of Indian Mathematics. Hindustan Book Agency, 2005. 182–208.
[2] https://web.northeastern.edu/shah/papers/Pingala.pdf

[3] Ancient Indian square roots:
https://www.davidhbailey.com/dhbpapers/india-sqrt-encyc.pdf

[4] History of Algorithms

[5] HS 847 : Algorithms in Indian Astronomy

[6] The Origin and Evolution of Algorithms

[
7] http://www.ms.uky.edu/~sohum/ma330/files/chennai_talks/Emch_Sridharan_Srinivas%20-%20Contributions%20ot%20the%20History%20of%20Indian%20Mathematics%20%282005%29.pdf#page=152","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/hp04cyxn8ombek56', 'title': 'What is the contribution of India in the field of algorithms and complexity?', 'score': {'original': 0.67026666666667, 'ai': 0.32973333333333}, 'blocks': [{'text': ""“Indian Mathematics is predominantly algorithmic. ” — M. S. Sriram.\n\nIndia and the genesis of the word ‘Algorithms’:\nThe word “Algorithm” is derived from the name of Al-Khwārizmī (from 9th Century). Al-Khwārizmī was heavily influenced by systematic and procedural methods of Indian mathematics. Al-Khwarizmi’s book ‘Kitab-al-hisab-al-Hindi’ (translated into Latin as Algoritmi de numero Indorum) was instrumental in the transmission of Indian algorithmic procedures and the Hindu-Arabic numeral system throughout the middle east and Europe.\n\nAncient India and Algorithms:\nBoth Indian mathematics and astronomy were influenced by algorithmic viewpoint. Some of the seminal results:\n\nGeometrical construction in Sulbasutras by Baudhayana, Apastamba, Katyayana, et al. during 800–200 BC: Procedures for dividing a line into equal parts, drawing perpendiculars, constructing squares and rectangles;\nAlgorithms for square and the cube root by Aryabhata\n (c. 499). Variants of these algorithms were used by Indian mathematicians such as Siddhasena Gani (550 CE), Bhaskara I (600 CE), Sridhara (750 CE) and Bhaskara II (1150 CE), as well as by numerous Arab and European mathematicians. Aryabhata also devised Kuttaka or pulverizer method to solve first order indeterminate equations.\nRecursion and Divide-and-Conquer by Pingala: Pingala made fundamental contributions such as the calculation of the binomial coefficients, use of repeated partial sums of sequences and the formula for summing a geometric series. He studied the formal theory of Sanskrit meters and consistently used recursion in his algorithms, a tradition which stretches from Pānini (6th century BCE) to Āryabhata (5th century CE) and Mādhava (14th century CE). He also devised a divide-and-conquer based algorithm for the computation of the powers of 2. Śridhara (750 CE) generalized many of his works later.\nVarga-Prakriti: Quadratic indeterminate equations (Pell’s equation):\nBhaskaracarya II, in his work Bjaganita (1150 CE) describes an algorithm Cakravala to solve equations of the form \nx\n2\n−\nn\ny\n2\n=\n1\nx2−ny2=1\n. Later Fermat and others in 17th century studied such equations which is the genesis of modern Arithmetic Geometry. Mathematician A. Weil said: “What would have been Fermat's astonishment if some missionary just back from India had told him that his problem had been successfully tackled there by the native Indians almost six centuries earlier?”\nBrahmagupta’s interpolation formula in Khandakhadyaka (665 CE):\nTo determine sine function for an arbitrary angle, from the set of tabulated values of sine given at fixed intervals.\nAccurate computation of \nπ\nπ\nusing an error-minimization algorithm Madhava of Sangamagrama (1340 - 1425 CE).\nAlgorithm for finding the time from shadow (by Nilakantha in Tantrasangraha 1500 CE),\nAlgorithm for finding eclipse duration (Avisesakarma).\n\nHemacandra, Kedara, Jayadeva, Jayakirti, Mahavira, Virahanka, Janasraya, etc. many other Indian mathematicians contributed to many such algorithmic procedures. Unfortunately, many of such manuscripts (e.g. Bakhshali manuscript\n ) are either lost or partially damaged.\n\nIndependent India and Algorithms:\nComputer science and algorithms research started quite late in India. Around 50 years back, the first computer science department was founded in IISc Bangalore. As Engineering studies are preferred in India because of the surge in private sector jobs, most of the good students (with strong mathematical foundations) went for computer science, especially in IITs. Later many of them went abroad and continued research in algorithms and complexity.\n\nOne of the biggest results in algorithms in India was AKS primality test\n (by Manidra Agrawal,"", 'result': {'fake': 0.0078, 'real': 0.9922}, 'status': 'success'}, {'text': ""Neeraj Kayal, Nitin Saxena), which gave the first (deterministic) polynomial time algorithm for primality testing.\nI already wrote about it here: In the last 50 years, what is the top research achievement in India?\n\n(Manindra Agrawal, Neeraj Kayal, Nitin Saxena from IIT Kanpur)\n\nAnother big result was the result on Kadison-Singer problem proven by Nikhil Srivastava\n, with Adam Marcus\n and Daniel Spielman\n. They received Polya prize in 2014 for their contribution. Nikhil was a researcher at Microsoft Research India at that time and now a Math Professor at UC Berkeley. Read more here: Computer Scientists Solve Kadison-Singer Problem | Quanta Magazine\n\nIndian computer scientists abroad:\n\nThe modern era is an era of collaborations. Many Indian computer scientists, especially in the USA, along with co-authors made seminal contributions to the field.\n\nRavindran Kannan\n was one of the first Indian theoretical computer scientists. He received Knuth prize and Fulkerson prize for his major contributions for algorithms for integer programming\n and the geometry of numbers\n, random walks\n in n\n-space\n, randomized algorithms\n for linear algebra\n, algorithms for approximating the volume of convex bodies\n and an algorithmic version for Szemerédi regularity partition\n.\n\nThe Vazirani brothers (Umesh Vazirani \nand Vijay Vazirani\n) were the next stalwarts. They made an enormous contribution to the field of algorithms (especially approximation algorithms, online algorithms, algorithmic game theory and quantum computation). Some of their major results include: Ranking algorithm for online matching, Micali-Vazirani algorithm, Valiant–Vazirani theorem,\n quantum Fourier transform algorithm, ARV sparsest cut algorithm etc.). Vijay was a Prof. at IIT Delhi for some time and influenced algorithms research in India significantly during his stay.\n\n(Ravi Kannan, Vijay and Umesh Vazirani)\n\nNarendra Karmarkar\n invented Karmarkar's algorithm\n, one of the first provably polynomial time algorithms (interior point method) for linear programming. He received Fulkerson prize for this landmark result.\n\nKetan Mulmuley\n has laid the foundation of geometric complexity theory, a possible approach for P vs NP problem.\n\nSanjeev Arora\n, Madhu Sudan, \nand Rajeev Motwani along with co-authors got Godel prize for their work on Probabilistically checkable proof \n(PCP Theorem), one of the most beautiful results of last century. Rajeev Motwani\n was also instrumental in the development of Google in its early phase. Sanjeev Arora got another Godel prize for his approximation algorithm for Euclidean Traveling Salesman Problem. Sanjeev Arora’s student Subhash Khot received Nevanlinna Prize\n in 2014 for his work on Unique games conjecture\n.\n\nSanjeev Arora and Subhash Khot (Both were AIR 1 in IITJEE)\n\n(Ketan Mulmuley and Narendra Karmarkar)\n\n(Madhu Sudan, Rajeev Motwani)\n\nNumerous other Indian theoretical computer scientists are making contributions to the field. You can check the list of publications in the recent top theory conferences and see many Indian names there.\n\n(Naveen Garg and Amit Kumar from IIT Delhi, both are Shanti Swarup Bhatnagar awardees)\n\n(Jaikumar Radhakrishnan (TIFR), one of the first computer scientists to receive Shanti Swarup Bhatnagar Award and Saket Saurabh (IMSc), author of a textbook on parameterized complexity)\n\n(Moses Charikar and Nikhil Bansal)\n\n(Anupam Gupta and Santosh Vempala)\n\n(Venkatesan Guruswami and Prasad Raghavendra)\n\n(Salil Vadhan and Aravind Srinivasan)\n\n( Pankaj Agarwal and Kamal Jain)\n\n(Sanjeev Khanna and Chandra Chekuri)\n\n[Images are taken from Google.\nApologies for nonuniform pictures.\nThis is of course not a comprehensive list and I wish I could add more"", 'result': {'fake': 0.0032, 'real': 0.9968}, 'status': 'success'}, {'text': 'pictures of other prominent Indian computer scientists.]\n\n[1A] Sriram, M. S. ""Algorithms in Indian Mathematics."" Contributions to the History of Indian Mathematics. Hindustan Book Agency, 2005. 153-182.\n[1B] K.Ramasubramanian, “Algorithms in Indian Astronomy.” Contributions to the History of Indian Mathematics. Hindustan Book Agency, 2005. 182–208.\n[2] https://web.northeastern.edu/shah/papers/Pingala.pdf\n\n[3] Ancient Indian square roots:\nhttps://www.davidhbailey.com/dhbpapers/india-sqrt-encyc.pdf\n\n[4] History of Algorithms\n\n[5] HS 847 : Algorithms in Indian Astronomy\n\n[6] The Origin and Evolution of Algorithms\n\n[\n7] http://www.ms.uky.edu/~sohum/ma330/files/chennai_talks/Emch_Sridharan_Srinivas%20-%20Contributions%20ot%20the%20History%20of%20Indian%20Mathematics%20%282005%29.pdf#page=152', 'result': {'fake': 0.931, 'real': 0.069}, 'status': 'success'}], 'credits_used': 12, 'credits': 1986283, 'subscription': 0, 'content': '“Indian Mathematics is predominantly algorithmic. ” — M. S. Sriram.\n\nIndia and the genesis of the word ‘Algorithms’:\nThe word “Algorithm” is derived from the name of Al-Khwārizmī (from 9th Century). Al-Khwārizmī was heavily influenced by systematic and procedural methods of Indian mathematics. Al-Khwarizmi’s book ‘Kitab-al-hisab-al-Hindi’ (translated into Latin as Algoritmi de numero Indorum) was instrumental in the transmission of Indian algorithmic procedures and the Hindu-Arabic numeral system throughout the middle east and Europe.\n\nAncient India and Algorithms:\nBoth Indian mathematics and astronomy were influenced by algorithmic viewpoint. Some of the seminal results:\n\nGeometrical construction in Sulbasutras by Baudhayana, Apastamba, Katyayana, et al. during 800–200 BC: Procedures for dividing a line into equal parts, drawing perpendiculars, constructing squares and rectangles;\nAlgorithms for square and the cube root by Aryabhata\n (c. 499). Variants of these algorithms were used by Indian mathematicians such as Siddhasena Gani (550 CE), Bhaskara I (600 CE), Sridhara (750 CE) and Bhaskara II (1150 CE), as well as by numerous Arab and European mathematicians. Aryabhata also devised Kuttaka or pulverizer method to solve first order indeterminate equations.\nRecursion and Divide-and-Conquer by Pingala: Pingala made fundamental contributions such as the calculation of the binomial coefficients, use of repeated partial sums of sequences and the formula for summing a geometric series. He studied the formal theory of Sanskrit meters and consistently used recursion in his algorithms, a tradition which stretches from Pānini (6th century BCE) to Āryabhata (5th century CE) and Mādhava (14th century CE). He also devised a divide-and-conquer based algorithm for the computation of the powers of 2. Śridhara (750 CE) generalized many of his works later.\nVarga-Prakriti: Quadratic indeterminate equations (Pell’s equation):\nBhaskaracarya II, in his work Bjaganita (1150 CE) describes an algorithm Cakravala to solve equations of the form \nx\n2\n−\nn\ny\n2\n=\n1\nx2−ny2=1\n. Later Fermat and others in 17th century studied such equations which is the genesis of modern Arithmetic Geometry. Mathematician A. Weil said: “What would have been Fermat\'s astonishment if some missionary just back from India had told him that his problem had been successfully tackled there by the native Indians almost six centuries earlier?”\nBrahmagupta’s interpolation formula in Khandakhadyaka (665 CE):\nTo determine sine function for an arbitrary angle, from the set of tabulated values of sine given at fixed intervals.\nAccurate computation of \nπ\nπ\nusing an error-minimization algorithm Madhava of Sangamagrama (1340 - 1425 CE).\nAlgorithm for finding the time from shadow (by Nilakantha in Tantrasangraha 1500 CE),\nAlgorithm for finding eclipse duration (Avisesakarma).\n\nHemacandra, Kedara, Jayadeva, Jayakirti, Mahavira, Virahanka, Janasraya, etc. many other Indian mathematicians contributed to many such algorithmic procedures. Unfortunately, many of such manuscripts (e.g. Bakhshali manuscript\n ) are either lost or partially damaged.\n\nIndependent India and Algorithms:\nComputer science and algorithms research started quite late in India. Around 50 years back, the first computer science department was founded in IISc Bangalore. As Engineering studies are preferred in India because of the surge in private sector jobs, most of the good students (with strong mathematical foundations) went for computer science, especially in IITs. Later many of them went abroad and continued research in algorithms and complexity.\n\nOne of the biggest results in algorithms in India was AKS primality test\n (by Manidra Agrawal, Neeraj Kayal, Nitin Saxena), which gave the first (deterministic) polynomial time algorithm for primality testing.\nI already wrote about it here: In the last 50 years, what is the top research achievement in India?\n\n(Manindra Agrawal, Neeraj Kayal, Nitin Saxena from IIT Kanpur)\n\nAnother big result was the result on Kadison-Singer problem proven by Nikhil Srivastava\n, with Adam Marcus\n and Daniel Spielman\n. They received Polya prize in 2014 for their contribution. Nikhil was a researcher at Microsoft Research India at that time and now a Math Professor at UC Berkeley. Read more here: Computer Scientists Solve Kadison-Singer Problem | Quanta Magazine\n\nIndian computer scientists abroad:\n\nThe modern era is an era of collaborations. Many Indian computer scientists, especially in the USA, along with co-authors made seminal contributions to the field.\n\nRavindran Kannan\n was one of the first Indian theoretical computer scientists. He received Knuth prize and Fulkerson prize for his major contributions for algorithms for integer programming\n and the geometry of numbers\n, random walks\n in n\n-space\n, randomized algorithms\n for linear algebra\n, algorithms for approximating the volume of convex bodies\n and an algorithmic version for Szemerédi regularity partition\n.\n\nThe Vazirani brothers (Umesh Vazirani \nand Vijay Vazirani\n) were the next stalwarts. They made an enormous contribution to the field of algorithms (especially approximation algorithms, online algorithms, algorithmic game theory and quantum computation). Some of their major results include: Ranking algorithm for online matching, Micali-Vazirani algorithm, Valiant–Vazirani theorem,\n quantum Fourier transform algorithm, ARV sparsest cut algorithm etc.). Vijay was a Prof. at IIT Delhi for some time and influenced algorithms research in India significantly during his stay.\n\n(Ravi Kannan, Vijay and Umesh Vazirani)\n\nNarendra Karmarkar\n invented Karmarkar\'s algorithm\n, one of the first provably polynomial time algorithms (interior point method) for linear programming. He received Fulkerson prize for this landmark result.\n\nKetan Mulmuley\n has laid the foundation of geometric complexity theory, a possible approach for P vs NP problem.\n\nSanjeev Arora\n, Madhu Sudan, \nand Rajeev Motwani along with co-authors got Godel prize for their work on Probabilistically checkable proof \n(PCP Theorem), one of the most beautiful results of last century. Rajeev Motwani\n was also instrumental in the development of Google in its early phase. Sanjeev Arora got another Godel prize for his approximation algorithm for Euclidean Traveling Salesman Problem. Sanjeev Arora’s student Subhash Khot received Nevanlinna Prize\n in 2014 for his work on Unique games conjecture\n.\n\nSanjeev Arora and Subhash Khot (Both were AIR 1 in IITJEE)\n\n(Ketan Mulmuley and Narendra Karmarkar)\n\n(Madhu Sudan, Rajeev Motwani)\n\nNumerous other Indian theoretical computer scientists are making contributions to the field. You can check the list of publications in the recent top theory conferences and see many Indian names there.\n\n(Naveen Garg and Amit Kumar from IIT Delhi, both are Shanti Swarup Bhatnagar awardees)\n\n(Jaikumar Radhakrishnan (TIFR), one of the first computer scientists to receive Shanti Swarup Bhatnagar Award and Saket Saurabh (IMSc), author of a textbook on parameterized complexity)\n\n(Moses Charikar and Nikhil Bansal)\n\n(Anupam Gupta and Santosh Vempala)\n\n(Venkatesan Guruswami and Prasad Raghavendra)\n\n(Salil Vadhan and Aravind Srinivasan)\n\n( Pankaj Agarwal and Kamal Jain)\n\n(Sanjeev Khanna and Chandra Chekuri)\n\n[Images are taken from Google.\nApologies for nonuniform pictures.\nThis is of course not a comprehensive list and I wish I could add more pictures of other prominent Indian computer scientists.]\n\n[1A] Sriram, M. S. ""Algorithms in Indian Mathematics."" Contributions to the History of Indian Mathematics. Hindustan Book Agency, 2005. 153-182.\n[1B] K.Ramasubramanian, “Algorithms in Indian Astronomy.” Contributions to the History of Indian Mathematics. Hindustan Book Agency, 2005. 182–208.\n[2] https://web.northeastern.edu/shah/papers/Pingala.pdf\n\n[3] Ancient Indian square roots:\nhttps://www.davidhbailey.com/dhbpapers/india-sqrt-encyc.pdf\n\n[4] History of Algorithms\n\n[5] HS 847 : Algorithms in Indian Astronomy\n\n[6] The Origin and Evolution of Algorithms\n\n[\n7] http://www.ms.uky.edu/~sohum/ma330/files/chennai_talks/Emch_Sridharan_Srinivas%20-%20Contributions%20ot%20the%20History%20of%20Indian%20Mathematics%20%282005%29.pdf#page=152', 'aiModelVersion': '1'}",0.67026666666667
Alex Flint,Updated 6y,"What are P, NP, NP-complete, and NP-hard?","Complexity classes are one way to talk about how difficult or easy a problem is. Complexity theory gets very technical but the basics are actually extraordinarily intuitive, and it's possible to understand the P versus NP issue with very little math background.

The kinds of problems we deal with in complexity theory come in pairs: a ""search"" version and a ""verification"" version. For example --

Problem: sorting.
Search version: input a list of numbers X and output the same list in sorted order (call it Y).
Verification version: input a list of numbers X and another list Y, and output ""YES"" if Y is the sorted version of X and ""NO"" otherwise.
Problem: graph coloring.
Search version: input a network of nodes and edges X, and output colors Y for each node such that no adjacent nodes have the same color.
Verification version: input a network X and a set of colors Y and output ""YES"" if all adjacent nodes have different colors and ""NO"" otherwise.
Problem: partition.
Search version: input some numbers X and divide the numbers into two groups that add up to exactly the same value (call the assignment of numbers to their group Y).
Verification version: input some numbers X and the groupings Y and output ""YES"" if the two groups add up to the same value, or ""NO"" otherwise.

This is the P versus NP problem:

Are there any problems for which the verification version can be solved efficiently but for which there is no efficient solution to the search version?

If there is a fast solution to the search version of a problem then the problem is said to be Polynomial-time, or P for short. If there is a fast solution to the verification version of a problem then the problem is said to be Nondeterministic Polynomial-time, or NP for short. The question of ""P=NP"" is then the question of whether these sets are identical.

(The ""nondeterministic polynomial-time"" terminology is terribly counter-intuitive in my opinion. It was used originally because whenever a Turing machine can efficiently solve the verification version of a problem, a non-deterministic Turing machine can efficiently solve the corresponding search problem. But this is really not at all important to understanding P vs NP.)

In the case of the sorting problem above, there are fast algorithms for both the search and verification versions. But for the other two problems, the verification versions are easy (heck, my grandmother could probably write a computer program to check that two lists of numbers add up to the same value) but the search versions are difficult, and indeed there are no fast solutions known. So all three problems are in NP, but only the first is (known to be) in P.

Some problems can be translated into one another in such a way that a fast solution to one problem would automatically give us a fast solution to the other. There are some problems that every single problem in NP can be translated into, and a fast solution to such a problem would automatically give us a fast solution to every problem in NP. This group of problems are known as NP-Hard. Some problems in NP-Hard are actually not themselves in NP; the group of problems that are in both NP and NP-Hard is called NP-Complete.

You start to see the far-reaching implications of a fast solution to any one problem in NP-Hard: we would automatically get a fast solution to every problem in NP, which would mean that whenever there is a fast solution to the verification version of a problem then there is always a fast solution to the corresponding search version.

Remember how the verification versions of those problems seemed easy but the search versions seemed hard? A fast solution to any NP-Complete problem would mean that as long as you can verify proposed solutions to a problem you would never need to search through a substantial fraction of the search space to find solutions; there would always be a faster way. This seems implausible to most mathematicians (and for deeper reasons that I've listed here) and that is why most mathematicians think that there are no fast solutions to NP-complete problems. But we haven't proved it yet.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/2mntolv3dex86qwc', 'title': 'What are P, NP, NP-complete, and NP-hard?', 'score': {'original': 0.5508, 'ai': 0.4492}, 'blocks': [{'text': 'Complexity classes are one way to talk about how difficult or easy a problem is. Complexity theory gets very technical but the basics are actually extraordinarily intuitive, and it\'s possible to understand the P versus NP issue with very little math background.\n\nThe kinds of problems we deal with in complexity theory come in pairs: a ""search"" version and a ""verification"" version. For example --\n\nProblem: sorting.\nSearch version: input a list of numbers X and output the same list in sorted order (call it Y).\nVerification version: input a list of numbers X and another list Y, and output ""YES"" if Y is the sorted version of X and ""NO"" otherwise.\nProblem: graph coloring.\nSearch version: input a network of nodes and edges X, and output colors Y for each node such that no adjacent nodes have the same color.\nVerification version: input a network X and a set of colors Y and output ""YES"" if all adjacent nodes have different colors and ""NO"" otherwise.\nProblem: partition.\nSearch version: input some numbers X and divide the numbers into two groups that add up to exactly the same value (call the assignment of numbers to their group Y).\nVerification version: input some numbers X and the groupings Y and output ""YES"" if the two groups add up to the same value, or ""NO"" otherwise.\n\nThis is the P versus NP problem:\n\nAre there any problems for which the verification version can be solved efficiently but for which there is no efficient solution to the search version?\n\nIf there is a fast solution to the search version of a problem then the problem is said to be Polynomial-time, or P for short. If there is a fast solution to the verification version of a problem then the problem is said to be Nondeterministic Polynomial-time, or NP for short. The question of ""P=NP"" is then the question of whether these sets are identical.\n\n(The ""nondeterministic polynomial-time"" terminology is terribly counter-intuitive in my opinion. It was used originally because whenever a Turing machine can efficiently solve the verification version of a problem, a non-deterministic Turing machine can efficiently solve the corresponding search problem. But this is really not at all important to understanding P vs NP.)\n\nIn the case of the sorting problem above, there are fast algorithms for both the search and verification versions. But for the other two problems, the verification versions are easy (heck, my grandmother could probably write a computer program to check that two lists of numbers add up to the same value) but the search versions are difficult, and indeed there are no fast solutions known. So all three problems are in NP, but only the first is (known to be) in P.\n\nSome problems can be translated into one another in such a way that a fast solution to one problem would automatically give us a fast solution to the other. There are some problems that every single problem in NP can be translated into, and a fast solution to such a problem would automatically give us a fast solution to every problem in NP. This group of problems are known as NP-Hard. Some', 'result': {'fake': 0.1072, 'real': 0.8928}, 'status': 'success'}, {'text': ""problems in NP-Hard are actually not themselves in NP; the group of problems that are in both NP and NP-Hard is called NP-Complete.\n\nYou start to see the far-reaching implications of a fast solution to any one problem in NP-Hard: we would automatically get a fast solution to every problem in NP, which would mean that whenever there is a fast solution to the verification version of a problem then there is always a fast solution to the corresponding search version.\n\nRemember how the verification versions of those problems seemed easy but the search versions seemed hard? A fast solution to any NP-Complete problem would mean that as long as you can verify proposed solutions to a problem you would never need to search through a substantial fraction of the search space to find solutions; there would always be a faster way. This seems implausible to most mathematicians (and for deeper reasons that I've listed here) and that is why most mathematicians think that there are no fast solutions to NP-complete problems. But we haven't proved it yet."", 'result': {'fake': 0.9232, 'real': 0.0768}, 'status': 'success'}], 'credits_used': 8, 'credits': 1986275, 'subscription': 0, 'content': 'Complexity classes are one way to talk about how difficult or easy a problem is. Complexity theory gets very technical but the basics are actually extraordinarily intuitive, and it\'s possible to understand the P versus NP issue with very little math background.\n\nThe kinds of problems we deal with in complexity theory come in pairs: a ""search"" version and a ""verification"" version. For example --\n\nProblem: sorting.\nSearch version: input a list of numbers X and output the same list in sorted order (call it Y).\nVerification version: input a list of numbers X and another list Y, and output ""YES"" if Y is the sorted version of X and ""NO"" otherwise.\nProblem: graph coloring.\nSearch version: input a network of nodes and edges X, and output colors Y for each node such that no adjacent nodes have the same color.\nVerification version: input a network X and a set of colors Y and output ""YES"" if all adjacent nodes have different colors and ""NO"" otherwise.\nProblem: partition.\nSearch version: input some numbers X and divide the numbers into two groups that add up to exactly the same value (call the assignment of numbers to their group Y).\nVerification version: input some numbers X and the groupings Y and output ""YES"" if the two groups add up to the same value, or ""NO"" otherwise.\n\nThis is the P versus NP problem:\n\nAre there any problems for which the verification version can be solved efficiently but for which there is no efficient solution to the search version?\n\nIf there is a fast solution to the search version of a problem then the problem is said to be Polynomial-time, or P for short. If there is a fast solution to the verification version of a problem then the problem is said to be Nondeterministic Polynomial-time, or NP for short. The question of ""P=NP"" is then the question of whether these sets are identical.\n\n(The ""nondeterministic polynomial-time"" terminology is terribly counter-intuitive in my opinion. It was used originally because whenever a Turing machine can efficiently solve the verification version of a problem, a non-deterministic Turing machine can efficiently solve the corresponding search problem. But this is really not at all important to understanding P vs NP.)\n\nIn the case of the sorting problem above, there are fast algorithms for both the search and verification versions. But for the other two problems, the verification versions are easy (heck, my grandmother could probably write a computer program to check that two lists of numbers add up to the same value) but the search versions are difficult, and indeed there are no fast solutions known. So all three problems are in NP, but only the first is (known to be) in P.\n\nSome problems can be translated into one another in such a way that a fast solution to one problem would automatically give us a fast solution to the other. There are some problems that every single problem in NP can be translated into, and a fast solution to such a problem would automatically give us a fast solution to every problem in NP. This group of problems are known as NP-Hard. Some problems in NP-Hard are actually not themselves in NP; the group of problems that are in both NP and NP-Hard is called NP-Complete.\n\nYou start to see the far-reaching implications of a fast solution to any one problem in NP-Hard: we would automatically get a fast solution to every problem in NP, which would mean that whenever there is a fast solution to the verification version of a problem then there is always a fast solution to the corresponding search version.\n\nRemember how the verification versions of those problems seemed easy but the search versions seemed hard? A fast solution to any NP-Complete problem would mean that as long as you can verify proposed solutions to a problem you would never need to search through a substantial fraction of the search space to find solutions; there would always be a faster way. This seems implausible to most mathematicians (and for deeper reasons that I\'ve listed here) and that is why most mathematicians think that there are no fast solutions to NP-complete problems. But we haven\'t proved it yet.', 'aiModelVersion': '1'}",0.5508
Matthew Lai,3y,What algorithms do FAANG employees work with on a day to day basis that are more difficult than the usual CRUD stuff? Is it math intensive? Please provide examples.,"We are not technically part of Google anymore, but we are still a sister company under Alphabet, and we used to be part of Google, so I hope that counts?

I worked on the AlphaGo / AlphaZero series of projects, mostly focusing on tree search. We tried building search trees in many different ways, storing them in different ways (we routinely use hundreds of GBs of memory, so space efficiency is as important as speed), and updating them in different ways. We were also searching with 100+ concurrent threads, and we cannot use mutexes on the critical path for performance reasons, so it was a combination of atomic operations and memory barriers. If you thought writing correct multithreaded programs based on locks is hard, try lock-free algorithms and data structures! Earlier iterations of the system were also distributed over hundreds of machines, totalling thousands of cores. We ended up publishing our variants of Monte-Carlo Tree Search over a series of papers, and as far as we know, it’s the state of the art in many settings.

I also worked on protein folding. Not as much I am allowed to share at this time, but also a lot of novel algorithms.

Currently working in combining machine learning with classical robotics. Classical robotics is also full of non-trivial algorithms - RRT
, inverse kinematics (iteratively solving for joint angles required to place the end of an arm at some specific cartesian coordinates), probabilistic algorithms for sampling, etc.

That’s all without getting into machine learning… which is the focus of our ACTUAL work, and we have published a large portion of the current state of the art machine learning algorithms.

Also, I am not sure what you mean by CRUD. If you think building a triple-redundant geographically distributed database system with relatively unreliable and high latency links between them, while guaranteeing fast access from anywhere in the world with hard correctness and consistency guarantees, even if one data centre is just nuked out of the planet is easy, Google is probably interested in hiring you. And yes, Googlers built all those systems. Sure, writing a SQL query is easy. But who wrote the code that runs your queries?","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/dro9fe63xc5sigzl', 'title': 'What algorithms do FAANG employees work with on a day to day basis that are more difficult than the usual CRUD stuff? Is it math intensive? Please provide examples.', 'score': {'original': 0.9998, 'ai': 0.0002}, 'blocks': [{'text': 'We are not technically part of Google anymore, but we are still a sister company under Alphabet, and we used to be part of Google, so I hope that counts?\n\nI worked on the AlphaGo / AlphaZero series of projects, mostly focusing on tree search. We tried building search trees in many different ways, storing them in different ways (we routinely use hundreds of GBs of memory, so space efficiency is as important as speed), and updating them in different ways. We were also searching with 100+ concurrent threads, and we cannot use mutexes on the critical path for performance reasons, so it was a combination of atomic operations and memory barriers. If you thought writing correct multithreaded programs based on locks is hard, try lock-free algorithms and data structures! Earlier iterations of the system were also distributed over hundreds of machines, totalling thousands of cores. We ended up publishing our variants of Monte-Carlo Tree Search over a series of papers, and as far as we know, it’s the state of the art in many settings.\n\nI also worked on protein folding. Not as much I am allowed to share at this time, but also a lot of novel algorithms.\n\nCurrently working in combining machine learning with classical robotics. Classical robotics is also full of non-trivial algorithms - RRT\n, inverse kinematics (iteratively solving for joint angles required to place the end of an arm at some specific cartesian coordinates), probabilistic algorithms for sampling, etc.\n\nThat’s all without getting into machine learning… which is the focus of our ACTUAL work, and we have published a large portion of the current state of the art machine learning algorithms.\n\nAlso, I am not sure what you mean by CRUD. If you think building a triple-redundant geographically distributed database system with relatively unreliable and high latency links between them, while guaranteeing fast access from anywhere in the world with hard correctness and consistency guarantees, even if one data centre is just nuked out of the planet is easy, Google is probably interested in hiring you. And yes, Googlers built all those systems. Sure, writing a SQL query is easy. But who wrote the code that runs your queries?', 'result': {'fake': 0.0002, 'real': 0.9998}, 'status': 'success'}], 'credits_used': 4, 'credits': 1986271, 'subscription': 0, 'content': 'We are not technically part of Google anymore, but we are still a sister company under Alphabet, and we used to be part of Google, so I hope that counts?\n\nI worked on the AlphaGo / AlphaZero series of projects, mostly focusing on tree search. We tried building search trees in many different ways, storing them in different ways (we routinely use hundreds of GBs of memory, so space efficiency is as important as speed), and updating them in different ways. We were also searching with 100+ concurrent threads, and we cannot use mutexes on the critical path for performance reasons, so it was a combination of atomic operations and memory barriers. If you thought writing correct multithreaded programs based on locks is hard, try lock-free algorithms and data structures! Earlier iterations of the system were also distributed over hundreds of machines, totalling thousands of cores. We ended up publishing our variants of Monte-Carlo Tree Search over a series of papers, and as far as we know, it’s the state of the art in many settings.\n\nI also worked on protein folding. Not as much I am allowed to share at this time, but also a lot of novel algorithms.\n\nCurrently working in combining machine learning with classical robotics. Classical robotics is also full of non-trivial algorithms - RRT\n, inverse kinematics (iteratively solving for joint angles required to place the end of an arm at some specific cartesian coordinates), probabilistic algorithms for sampling, etc.\n\nThat’s all without getting into machine learning… which is the focus of our ACTUAL work, and we have published a large portion of the current state of the art machine learning algorithms.\n\nAlso, I am not sure what you mean by CRUD. If you think building a triple-redundant geographically distributed database system with relatively unreliable and high latency links between them, while guaranteeing fast access from anywhere in the world with hard correctness and consistency guarantees, even if one data centre is just nuked out of the planet is easy, Google is probably interested in hiring you. And yes, Googlers built all those systems. Sure, writing a SQL query is easy. But who wrote the code that runs your queries?', 'aiModelVersion': '1'}",0.9998
Gautam,Jan 17,How do I master data structures and algorithms (DSA) to improve my problem solving skills which will eventually be helpful in interviews?,"Hey there coding enthusiast!

Mastering Data Structures and Algorithms (DSA) is a pivotal step toward sharpening problem-solving skills, a crucial asset for interview success.

Don’t worry, here's a comprehensive guide to help you master data structures and algorithms (DSA) to improve my problem-solving skills which will eventually be helpful in interviews.

1. Build a Strong Foundation:

You should begin with understanding the basics of data structures (arrays, linked lists, stacks, queues) and algorithms (sorting, searching). Books like ""Introduction to Algorithms"" by Cormen et al. can provide a solid foundation.

2. Online Courses for DSA:

You can choose to learn through online courses which provide a more flexible and structured way of learning.

Some reputed online courses for DSA are mentioned below:

edX - ""Algorithmic Design and Techniques"":

This edX professional certificate program provides a deep dive into algorithmic design using Java. It's an excellent choice for those seeking a more rigorous and university-style learning experience.

Learnbay- “Software Development Certification Program”:

This comprehensive course made in collaboration with tech giants like IBM and Microsoft covers the entire programming concepts from basics to advanced level including basic programming, computer science fundamentals, data structures, and algorithms along with system design and specialization.

Udacity- “Data Structures and Algorithms Nanodegree Certification”:

It is a comprehensive course covering DSA in Java. It includes practical examples and coding exercises and is suitable for both beginners and intermediate learners. It helps you build a strong foundation in the fundamentals of programming and DSA.

3. Problem-solving Practice:

Platforms like LeetCode, HackerRank, and CodeChef offer a plethora of problems ranging from easy to advanced levels. You can regularly practice on these platforms to hone your problem-solving skills and build confidence.

4. Regularly Review and Reinforce:

You should regularly revisit key concepts and problems to reinforce learning. You should create a systematic study schedule to ensure consistent progress. Online courses can help you in this regard by providing a structured way of learning.

Happy coding!","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/81ovkyafxj2ntcd0', 'title': 'How do I master data structures and algorithms (DSA) to improve my problem solving skills which will eventually be helpful in interviews?', 'score': {'original': 0, 'ai': 1}, 'blocks': [{'text': 'Hey there coding enthusiast!\n\nMastering Data Structures and Algorithms (DSA) is a pivotal step toward sharpening problem-solving skills, a crucial asset for interview success.\n\nDon’t worry, here\'s a comprehensive guide to help you master data structures and algorithms (DSA) to improve my problem-solving skills which will eventually be helpful in interviews.\n\n1. Build a Strong Foundation:\n\nYou should begin with understanding the basics of data structures (arrays, linked lists, stacks, queues) and algorithms (sorting, searching). Books like ""Introduction to Algorithms"" by Cormen et al. can provide a solid foundation.\n\n2. Online Courses for DSA:\n\nYou can choose to learn through online courses which provide a more flexible and structured way of learning.\n\nSome reputed online courses for DSA are mentioned below:\n\nedX - ""Algorithmic Design and Techniques"":\n\nThis edX professional certificate program provides a deep dive into algorithmic design using Java. It\'s an excellent choice for those seeking a more rigorous and university-style learning experience.\n\nLearnbay- “Software Development Certification Program”:\n\nThis comprehensive course made in collaboration with tech giants like IBM and Microsoft covers the entire programming concepts from basics to advanced level including basic programming, computer science fundamentals, data structures, and algorithms along with system design and specialization.\n\nUdacity- “Data Structures and Algorithms Nanodegree Certification”:\n\nIt is a comprehensive course covering DSA in Java. It includes practical examples and coding exercises and is suitable for both beginners and intermediate learners. It helps you build a strong foundation in the fundamentals of programming and DSA.\n\n3. Problem-solving Practice:\n\nPlatforms like LeetCode, HackerRank, and CodeChef offer a plethora of problems ranging from easy to advanced levels. You can regularly practice on these platforms to hone your problem-solving skills and build confidence.\n\n4. Regularly Review and Reinforce:\n\nYou should regularly revisit key concepts and problems to reinforce learning. You should create a systematic study schedule to ensure consistent progress. Online courses can help you in this regard by providing a structured way of learning.\n\nHappy coding!', 'result': {'fake': 1, 'real': 0}, 'status': 'success'}], 'credits_used': 4, 'credits': 1986267, 'subscription': 0, 'content': 'Hey there coding enthusiast!\n\nMastering Data Structures and Algorithms (DSA) is a pivotal step toward sharpening problem-solving skills, a crucial asset for interview success.\n\nDon’t worry, here\'s a comprehensive guide to help you master data structures and algorithms (DSA) to improve my problem-solving skills which will eventually be helpful in interviews.\n\n1. Build a Strong Foundation:\n\nYou should begin with understanding the basics of data structures (arrays, linked lists, stacks, queues) and algorithms (sorting, searching). Books like ""Introduction to Algorithms"" by Cormen et al. can provide a solid foundation.\n\n2. Online Courses for DSA:\n\nYou can choose to learn through online courses which provide a more flexible and structured way of learning.\n\nSome reputed online courses for DSA are mentioned below:\n\nedX - ""Algorithmic Design and Techniques"":\n\nThis edX professional certificate program provides a deep dive into algorithmic design using Java. It\'s an excellent choice for those seeking a more rigorous and university-style learning experience.\n\nLearnbay- “Software Development Certification Program”:\n\nThis comprehensive course made in collaboration with tech giants like IBM and Microsoft covers the entire programming concepts from basics to advanced level including basic programming, computer science fundamentals, data structures, and algorithms along with system design and specialization.\n\nUdacity- “Data Structures and Algorithms Nanodegree Certification”:\n\nIt is a comprehensive course covering DSA in Java. It includes practical examples and coding exercises and is suitable for both beginners and intermediate learners. It helps you build a strong foundation in the fundamentals of programming and DSA.\n\n3. Problem-solving Practice:\n\nPlatforms like LeetCode, HackerRank, and CodeChef offer a plethora of problems ranging from easy to advanced levels. You can regularly practice on these platforms to hone your problem-solving skills and build confidence.\n\n4. Regularly Review and Reinforce:\n\nYou should regularly revisit key concepts and problems to reinforce learning. You should create a systematic study schedule to ensure consistent progress. Online courses can help you in this regard by providing a structured way of learning.\n\nHappy coding!', 'aiModelVersion': '1'}",0.0
Raziman T.V.,9y,How does Tomohiko Sakamoto's algorithm to find the week day of the date work?,"Let us start with the simple scenario in which leap years did not exist and every year had 365 days. Knowing  what day January 1 falls on a certain year, it is easy to find which  day any other date falls. This is how you go about it : January has 31 =  7 × 4 + 3 days, so February 1 will fall on the day which follows three  days after January 1. Similarly, March 1 will fall on the day three days  after the day corresponding to January 1, April 1 will fall 6 days  after, and so on. Thus, the first days of each month are offset with  respect to January 1 by the array {0, 3, 3, 6, 1, 4, 6, 2, 5, 0, 3, 5}.  This array is essentially what t[] is. Notice that it is slightly  different from the t[] given in the question, but that is due to leap  years and will be explained later. Once the day corresponding to the  first date of the month is known, finding the day for any other date is  just a matter of addition. Since  365 = 7 × 52 + 1, the day corresponding to a given date will become  incremented by 1 every year. For example, July 14, 2014 is a Monday and  July 14, 2015 will be a Tuesday. Hence adding the difference between  year numbers allows us to switch from the day of a reference year to any  other year. At this stage, the leap-year free dow function can be written as such:int dow(int y, int m, int d){    static int t[] = {0, 3, 3, 6, 1, 4, 6, 2, 5, 0, 3, 5};    return (y + t[m-1] + d + c) % 7; }  Here  c is a constant which corresponds to setting the ""origin"" of the day  system : y, t[m] and d only tell us how many days to shift by; we need a  reference to start the shifting and which is provided by c. Now  let us look at the real case when there are leap years. Every 4 years,  our calculation will gain one extra day. Except every 100 years when it  doesn't. Except every 400 years when it does (Seriously, what kind of  intelligent designer comes up with this stuff? Couldn't the duration of  the year have been an integer multiple of the synodic day?). How do we  put in these additional days? Well, just add y/4 - y/100 + y/400. Note  that all division is integer division. This adds exactly the required  number of leap days. Except  there is a tiny problem. The leap day is not January 0, it is February  29. This means that the current year should not be counted for the leap  day calculation for the first two months. How  do we do this? Well, there are probably many intuitive ways to go about  this. But this piece of code sacrifices intuition for brevity. Suppose  that if the month were January or February, we subtracted 1 from the  year. This means that during these months, the y/4 value would be that  of the previous year and would not be counted. Smart,  right? Except for a tiny problem. We are subtracting 1 from the year  for January and February for non-leap years too. This means that there  would be a ""blank"" day between February 28 and March 1, that is, we have  made every non-leap year a leap year, and leap years double-leap years.  Hm, so what if we subtracted 1 from the t[] values of every month after  February? That would fill the gap, and the leap year problem is solved.  That is, we need to make the following changes:t[] now becomes {0, 3, 2, 5, 0, 3, 5, 1, 4, 6, 2, 4}if m corresponds to Jan/Feb (that is, m<3) we decrement y by 1the annual increment inside the modulus is now y + y/4 - y/100 + y/400 in place of yThat's it, we get the full solution int dow(int y, int m, int d){    static int t[] = {0, 3, 2, 5, 0, 3, 5, 1, 4, 6, 2, 4};    y -= m < 3;   return (y + y/4 - y/100 + y/400 + t[m-1] + d + c) % 7; }  Coincidentially, c just happens to be 0 - this is an empirical fact and cannot be ""derived"" from anything we have done till now - and we get back the function in the question. PS: If I were you, I would substitute this for something way simpler. Say, hardcode the day value of January 1, 2000 and propagate differences over years, months and days. If a 3 line code requires a 1 page explanation, it is not really ""simple""","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/lab4xnqumphry6k7', 'title': ""How does Tomohiko Sakamoto's algorithm to find the week day of the date work?"", 'score': {'original': 0.38995, 'ai': 0.61005}, 'blocks': [{'text': 'Let us start with the simple scenario in which leap years did not exist and every year had 365 days. Knowing  what day January 1 falls on a certain year, it is easy to find which  day any other date falls. This is how you go about it : January has 31 =  7 × 4 + 3 days, so February 1 will fall on the day which follows three  days after January 1. Similarly, March 1 will fall on the day three days  after the day corresponding to January 1, April 1 will fall 6 days  after, and so on. Thus, the first days of each month are offset with  respect to January 1 by the array {0, 3, 3, 6, 1, 4, 6, 2, 5, 0, 3, 5}.  This array is essentially what t[] is. Notice that it is slightly  different from the t[] given in the question, but that is due to leap  years and will be explained later. Once the day corresponding to the  first date of the month is known, finding the day for any other date is  just a matter of addition. Since  365 = 7 × 52 + 1, the day corresponding to a given date will become  incremented by 1 every year. For example, July 14, 2014 is a Monday and  July 14, 2015 will be a Tuesday. Hence adding the difference between  year numbers allows us to switch from the day of a reference year to any  other year. At this stage, the leap-year free dow function can be written as such:int dow(int y, int m, int d){ \xa0  static int t[] = {0, 3, 3, 6, 1, 4, 6, 2, 5, 0, 3, 5}; \xa0  return (y + t[m-1] + d + c) % 7;\xa0}\xa0 Here  c is a constant which corresponds to setting the ""origin"" of the day  system : y, t[m] and d only tell us how many days to shift by; we need a  reference to start the shifting and which is provided by c. Now  let us look at the real case when there are leap years. Every 4 years,  our calculation will gain one extra day. Except every 100 years when it  doesn\'t. Except every 400 years when it does (Seriously, what kind of  intelligent designer comes up with this stuff? Couldn\'t the duration of  the year have been an integer multiple of the synodic day?). How do we  put in these additional days? Well, just add y/4 - y/100 + y/400. Note  that all division is integer division. This adds exactly the required  number of leap days. Except  there is a tiny problem. The leap day is not January 0, it is February  29. This means that the current year should not be counted for the leap  day calculation for the first two months. How  do we do this? Well, there are', 'result': {'fake': 0.6999, 'real': 0.3001}, 'status': 'success'}, {'text': 'probably many intuitive ways to go about  this. But this piece of code sacrifices intuition for brevity. Suppose  that if the month were January or February, we subtracted 1 from the  year. This means that during these months, the y/4 value would be that  of the previous year and would not be counted. Smart,  right? Except for a tiny problem. We are subtracting 1 from the year  for January and February for non-leap years too. This means that there  would be a ""blank"" day between February 28 and March 1, that is, we have  made every non-leap year a leap year, and leap years double-leap years.  Hm, so what if we subtracted 1 from the t[] values of every month after  February? That would fill the gap, and the leap year problem is solved.  That is, we need to make the following changes:t[] now becomes {0, 3, 2, 5, 0, 3, 5, 1, 4, 6, 2, 4}if m corresponds to Jan/Feb (that is, m<3) we decrement y by 1the annual increment inside the modulus is now y + y/4 - y/100 + y/400 in place of yThat\'s it, we get the full solution int dow(int y, int m, int d){ \xa0  static int t[] = {0, 3, 2, 5, 0, 3, 5, 1, 4, 6, 2, 4}; \xa0  y -= m < 3;\xa0  return (y + y/4 - y/100 + y/400 + t[m-1] + d + c) % 7;\xa0}\xa0 Coincidentially, c just happens to be 0 - this is an empirical fact and cannot be ""derived"" from anything we have done till now - and we get back the function in the question. PS: If I were you, I would substitute this for something way simpler. Say, hardcode the day value of January 1, 2000 and propagate differences over years, months and days. If a 3 line code requires a 1 page explanation, it is not really ""simple""', 'result': {'fake': 0.0249, 'real': 0.9751}, 'status': 'success'}], 'credits_used': 7, 'credits': 1986260, 'subscription': 0, 'content': 'Let us start with the simple scenario in which leap years did not exist and every year had 365 days. Knowing  what day January 1 falls on a certain year, it is easy to find which  day any other date falls. This is how you go about it : January has 31 =  7 × 4 + 3 days, so February 1 will fall on the day which follows three  days after January 1. Similarly, March 1 will fall on the day three days  after the day corresponding to January 1, April 1 will fall 6 days  after, and so on. Thus, the first days of each month are offset with  respect to January 1 by the array {0, 3, 3, 6, 1, 4, 6, 2, 5, 0, 3, 5}.  This array is essentially what t[] is. Notice that it is slightly  different from the t[] given in the question, but that is due to leap  years and will be explained later. Once the day corresponding to the  first date of the month is known, finding the day for any other date is  just a matter of addition. Since  365 = 7 × 52 + 1, the day corresponding to a given date will become  incremented by 1 every year. For example, July 14, 2014 is a Monday and  July 14, 2015 will be a Tuesday. Hence adding the difference between  year numbers allows us to switch from the day of a reference year to any  other year. At this stage, the leap-year free dow function can be written as such:int dow(int y, int m, int d){ \xa0  static int t[] = {0, 3, 3, 6, 1, 4, 6, 2, 5, 0, 3, 5}; \xa0  return (y + t[m-1] + d + c) % 7;\xa0}\xa0 Here  c is a constant which corresponds to setting the ""origin"" of the day  system : y, t[m] and d only tell us how many days to shift by; we need a  reference to start the shifting and which is provided by c. Now  let us look at the real case when there are leap years. Every 4 years,  our calculation will gain one extra day. Except every 100 years when it  doesn\'t. Except every 400 years when it does (Seriously, what kind of  intelligent designer comes up with this stuff? Couldn\'t the duration of  the year have been an integer multiple of the synodic day?). How do we  put in these additional days? Well, just add y/4 - y/100 + y/400. Note  that all division is integer division. This adds exactly the required  number of leap days. Except  there is a tiny problem. The leap day is not January 0, it is February  29. This means that the current year should not be counted for the leap  day calculation for the first two months. How  do we do this? Well, there are probably many intuitive ways to go about  this. But this piece of code sacrifices intuition for brevity. Suppose  that if the month were January or February, we subtracted 1 from the  year. This means that during these months, the y/4 value would be that  of the previous year and would not be counted. Smart,  right? Except for a tiny problem. We are subtracting 1 from the year  for January and February for non-leap years too. This means that there  would be a ""blank"" day between February 28 and March 1, that is, we have  made every non-leap year a leap year, and leap years double-leap years.  Hm, so what if we subtracted 1 from the t[] values of every month after  February? That would fill the gap, and the leap year problem is solved.  That is, we need to make the following changes:t[] now becomes {0, 3, 2, 5, 0, 3, 5, 1, 4, 6, 2, 4}if m corresponds to Jan/Feb (that is, m<3) we decrement y by 1the annual increment inside the modulus is now y + y/4 - y/100 + y/400 in place of yThat\'s it, we get the full solution int dow(int y, int m, int d){ \xa0  static int t[] = {0, 3, 2, 5, 0, 3, 5, 1, 4, 6, 2, 4}; \xa0  y -= m < 3;\xa0  return (y + y/4 - y/100 + y/400 + t[m-1] + d + c) % 7;\xa0}\xa0 Coincidentially, c just happens to be 0 - this is an empirical fact and cannot be ""derived"" from anything we have done till now - and we get back the function in the question. PS: If I were you, I would substitute this for something way simpler. Say, hardcode the day value of January 1, 2000 and propagate differences over years, months and days. If a 3 line code requires a 1 page explanation, it is not really ""simple""', 'aiModelVersion': '1'}",0.38995
Terry Lambert,1y,Why is the YouTube algorithm so much better at finding similar music compared to Spotify and other music providers?,"Google has better programmers, and they’ve been working on the problem space longer than either Spotify or the other providers have existed.

YouTube has a year and a half on Spotify, for example, and they’ve been employing a lot of “organ bank” engineers from Google proper, for various problems — like the “similar to this one“ problem — and the engineers doing the work are working on much larger teams, overall.

Spotify is resource starved, because they really aren’t raking in the same ratio of money that YouTube does.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/ohv24u3seacgplfm', 'title': 'Why is the YouTube algorithm so much better at finding similar music compared to Spotify and other music providers?', 'score': {'original': 0.996, 'ai': 0.004}, 'blocks': [{'text': 'Google has better programmers, and they’ve been working on the problem space longer than either Spotify or the other providers have existed.\n\nYouTube has a year and a half on Spotify, for example, and they’ve been employing a lot of “organ bank” engineers from Google proper, for various problems — like the “similar to this one“ problem — and the engineers doing the work are working on much larger teams, overall.\n\nSpotify is resource starved, because they really aren’t raking in the same ratio of money that YouTube does.', 'result': {'fake': 0.004, 'real': 0.996}, 'status': 'success'}], 'credits_used': 1, 'credits': 1986259, 'subscription': 0, 'content': 'Google has better programmers, and they’ve been working on the problem space longer than either Spotify or the other providers have existed.\n\nYouTube has a year and a half on Spotify, for example, and they’ve been employing a lot of “organ bank” engineers from Google proper, for various problems — like the “similar to this one“ problem — and the engineers doing the work are working on much larger teams, overall.\n\nSpotify is resource starved, because they really aren’t raking in the same ratio of money that YouTube does.', 'aiModelVersion': '1'}",0.996
Alon Amit,6y,How do you invent your own algorithms to solve different cubes without watching tutorials?,"For most cube-like puzzles, the key trick is commutators.

A physical puzzle like Rubik’s Cube allows you to perform various moves, like twisting this or that face of the cube. It is usually the case that moves are reversible, meaning you can undo a move right after doing it. So if R means “twist the right face a quarter-turn clockwise”, you can use R’ to mean “twist the right face a quarter-turn counterclockwise.” Then, of course, doing R and then R’ is doing nothing: you twist the face and then twist it right back.

RR’ = <nothing>

This isn’t very exciting, but it gets interesting when you combine it with another move such as F, which is like R but twisting the front face.

What happens if we do R, then F, then R’, then F’?

RFR’F’ = ?

This is a commutator. The idea is that if the R move and the F move were independent, not mixing the same little cubes, then the commutator would again be “do nothing”, because we are twisting each face and then twisting it back. For example, since the right face and the left face don’t touch, then RLR’L’ really is doing nothing.

But of course R and F are not independent, and as a result the RFR’F’ move does not do nothing. However, because it tries hard to revert things, in many puzzles it has a relatively small effect.

To determine this effect it’s easiest to start with a solved cube, perform RFR’F’, and write down exactly what happened. Sometimes a solved cube is not available, so patiently note the precise state of the cube, do the move, and observe what went where.

For many puzzles, commutators like this are enough to build to a small arsenal of simple moves with which you can solve the whole thing. Rubik’s Cube is a more elaborate puzzle, so you may have to go a level deeper: give RFR’F’ its own name, like X, use X’ for doing X in reverse (which means FRF’R’ – see why?), and now experiment with things like XYX’Y’.

It takes patience, perseverance, experience and some creativity, but with sufficient time you will find those “golden sequences” that have a really small effect: they merely flip and reorient two or three small pieces of the puzzle. With those, you can often easily solve the entire thing.

This approach doesn’t always yield the most efficient solving algorithms, but with many puzzles it provides a methodical approach for finding a solution.

The underlying mathematical reason for this is related to the notion of “solvability” in the theory of groups, which strangely enough originated with solving polynomials, not cubes. Many mechanical puzzles like Rubik’s Cube are physical manifestations of abstract groups, and many groups can be decomposed into simpler and simpler parts by using the commutator subgroups, made up of those commutators. Rubik-like puzzles are a fun way to get acquainted with abstract groups.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/qkh38eumpyflr7at', 'title': 'How do you invent your own algorithms to solve different cubes without watching tutorials?', 'score': {'original': 0.9994, 'ai': 0.0006}, 'blocks': [{'text': 'For most cube-like puzzles, the key trick is commutators.\n\nA physical puzzle like Rubik’s Cube allows you to perform various moves, like twisting this or that face of the cube. It is usually the case that moves are reversible, meaning you can undo a move right after doing it. So if R means “twist the right face a quarter-turn clockwise”, you can use R’ to mean “twist the right face a quarter-turn counterclockwise.” Then, of course, doing R and then R’ is doing nothing: you twist the face and then twist it right back.\n\nRR’ = <nothing>\n\nThis isn’t very exciting, but it gets interesting when you combine it with another move such as F, which is like R but twisting the front face.\n\nWhat happens if we do R, then F, then R’, then F’?\n\nRFR’F’ = ?\n\nThis is a commutator. The idea is that if the R move and the F move were independent, not mixing the same little cubes, then the commutator would again be “do nothing”, because we are twisting each face and then twisting it back. For example, since the right face and the left face don’t touch, then RLR’L’ really is doing nothing.\n\nBut of course R and F are not independent, and as a result the RFR’F’ move does not do nothing. However, because it tries hard to revert things, in many puzzles it has a relatively small effect.\n\nTo determine this effect it’s easiest to start with a solved cube, perform RFR’F’, and write down exactly what happened. Sometimes a solved cube is not available, so patiently note the precise state of the cube, do the move, and observe what went where.\n\nFor many puzzles, commutators like this are enough to build to a small arsenal of simple moves with which you can solve the whole thing. Rubik’s Cube is a more elaborate puzzle, so you may have to go a level deeper: give RFR’F’ its own name, like X, use X’ for doing X in reverse (which means FRF’R’ – see why?), and now experiment with things like XYX’Y’.\n\nIt takes patience, perseverance, experience and some creativity, but with sufficient time you will find those “golden sequences” that have a really small effect: they merely flip and reorient two or three small pieces of the puzzle. With those, you can often easily solve the entire thing.\n\nThis approach doesn’t always yield the most efficient solving algorithms, but with many puzzles it provides a methodical approach for finding a solution.\n\nThe underlying mathematical reason for this is related to the notion of “solvability” in the theory of groups, which strangely enough originated with solving polynomials, not cubes. Many mechanical puzzles like Rubik’s Cube are physical manifestations of abstract groups, and many groups can be decomposed into simpler and simpler parts by using the commutator subgroups, made up of those commutators. Rubik-like puzzles are a fun way to get acquainted with abstract groups.', 'result': {'fake': 0.0007, 'real': 0.9993}, 'status': 'success'}], 'credits_used': 6, 'credits': 1986253, 'subscription': 0, 'content': 'For most cube-like puzzles, the key trick is commutators.\n\nA physical puzzle like Rubik’s Cube allows you to perform various moves, like twisting this or that face of the cube. It is usually the case that moves are reversible, meaning you can undo a move right after doing it. So if R means “twist the right face a quarter-turn clockwise”, you can use R’ to mean “twist the right face a quarter-turn counterclockwise.” Then, of course, doing R and then R’ is doing nothing: you twist the face and then twist it right back.\n\nRR’ = <nothing>\n\nThis isn’t very exciting, but it gets interesting when you combine it with another move such as F, which is like R but twisting the front face.\n\nWhat happens if we do R, then F, then R’, then F’?\n\nRFR’F’ = ?\n\nThis is a commutator. The idea is that if the R move and the F move were independent, not mixing the same little cubes, then the commutator would again be “do nothing”, because we are twisting each face and then twisting it back. For example, since the right face and the left face don’t touch, then RLR’L’ really is doing nothing.\n\nBut of course R and F are not independent, and as a result the RFR’F’ move does not do nothing. However, because it tries hard to revert things, in many puzzles it has a relatively small effect.\n\nTo determine this effect it’s easiest to start with a solved cube, perform RFR’F’, and write down exactly what happened. Sometimes a solved cube is not available, so patiently note the precise state of the cube, do the move, and observe what went where.\n\nFor many puzzles, commutators like this are enough to build to a small arsenal of simple moves with which you can solve the whole thing. Rubik’s Cube is a more elaborate puzzle, so you may have to go a level deeper: give RFR’F’ its own name, like X, use X’ for doing X in reverse (which means FRF’R’ – see why?), and now experiment with things like XYX’Y’.\n\nIt takes patience, perseverance, experience and some creativity, but with sufficient time you will find those “golden sequences” that have a really small effect: they merely flip and reorient two or three small pieces of the puzzle. With those, you can often easily solve the entire thing.\n\nThis approach doesn’t always yield the most efficient solving algorithms, but with many puzzles it provides a methodical approach for finding a solution.\n\nThe underlying mathematical reason for this is related to the notion of “solvability” in the theory of groups, which strangely enough originated with solving polynomials, not cubes. Many mechanical puzzles like Rubik’s Cube are physical manifestations of abstract groups, and many groups can be decomposed into simpler and simpler parts by using the commutator subgroups, made up of those commutators. Rubik-like puzzles are a fun way to get acquainted with abstract groups.', 'aiModelVersion': '1'}",0.9994
Subham Pal,4y,Will Amazon accept me if I am strong at data structures and algorithms but not very good at any frontend or backend technologies?,"Entirely depends on the role you are applying to. If you're applying for SDE2 role and you don't have any knowledge of fronted and backend technologies, it is very difficult for you to clear the interviews. In system design round you would be required to use your knowledge of full stack.

For SDE1 role as well, you do need some knowledge on these web development skills. Have zero knowledge makes you vulnerable to getting rejected by interviewer. But it is probable that you can clear SDE1 interview without frontend or backend knowledge.

Knowledge of Data Structures and Algorithms is important, but it is not the only thing that can help you sail through the interview. You need to have basic knowledge of backend systems like DBMS concepts, when to use what. Operating system, Networking and Linux also comes handy to answer the system design questions.

“Don't be master of one, but be a Jack of all trades.”

“BFS is always better than DFS.”

Signing off!!!

Subham Pal","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/ugy67bceq1aphznl', 'title': 'Will Amazon accept me if I am strong at data structures and algorithms but not very good at any frontend or backend technologies?', 'score': {'original': 0.9929, 'ai': 0.0071}, 'blocks': [{'text': ""Entirely depends on the role you are applying to. If you're applying for SDE2 role and you don't have any knowledge of fronted and backend technologies, it is very difficult for you to clear the interviews. In system design round you would be required to use your knowledge of full stack.\n\nFor SDE1 role as well, you do need some knowledge on these web development skills. Have zero knowledge makes you vulnerable to getting rejected by interviewer. But it is probable that you can clear SDE1 interview without frontend or backend knowledge.\n\nKnowledge of Data Structures and Algorithms is important, but it is not the only thing that can help you sail through the interview. You need to have basic knowledge of backend systems like DBMS concepts, when to use what. Operating system, Networking and Linux also comes handy to answer the system design questions.\n\n“Don't be master of one, but be a Jack of all trades.”\n\n“BFS is always better than DFS.”\n\nSigning off!!!\n\nSubham Pal"", 'result': {'fake': 0.0071, 'real': 0.9929}, 'status': 'success'}], 'credits_used': 2, 'credits': 1986251, 'subscription': 0, 'content': ""Entirely depends on the role you are applying to. If you're applying for SDE2 role and you don't have any knowledge of fronted and backend technologies, it is very difficult for you to clear the interviews. In system design round you would be required to use your knowledge of full stack.\n\nFor SDE1 role as well, you do need some knowledge on these web development skills. Have zero knowledge makes you vulnerable to getting rejected by interviewer. But it is probable that you can clear SDE1 interview without frontend or backend knowledge.\n\nKnowledge of Data Structures and Algorithms is important, but it is not the only thing that can help you sail through the interview. You need to have basic knowledge of backend systems like DBMS concepts, when to use what. Operating system, Networking and Linux also comes handy to answer the system design questions.\n\n“Don't be master of one, but be a Jack of all trades.”\n\n“BFS is always better than DFS.”\n\nSigning off!!!\n\nSubham Pal"", 'aiModelVersion': '1'}",0.9929
Anders Kaseorg,Updated 8y,What is the most efficient algorithm to check if a number is a Fibonacci Number?,"The Fibonacci recurrence can be solved using matrix exponentiation:   [Fi−1FiFiFi+1]=[0111]i[Fi−1FiFiFi+1]=[0111]i\displaystyle \begin{bmatrix}F_{i - 1} & F_i \\ F_i & F_{i + 1}\end{bmatrix} = \begin{bmatrix}0 & 1 \\ 1 & 1\end{bmatrix}^i, from which we derive these identities:   [Fi+j−1Fi+jFi+jFi+j+1]=[Fi−1FiFiFi+1]⋅[Fj−1FjFjFj+1][Fi+j−1Fi+jFi+jFi+j+1]=[Fi−1FiFiFi+1]⋅[Fj−1FjFjFj+1]\displaystyle \begin{bmatrix}F_{i + j - 1} & F_{i + j} \\ F_{i + j} & F_{i + j + 1}\end{bmatrix} = \begin{bmatrix}F_{i - 1} & F_i \\ F_i & F_{i + 1}\end{bmatrix} \cdot \begin{bmatrix}F_{j - 1} & F_j \\ F_j & F_{j + 1}\end{bmatrix},   Fi+j=Fi+1Fj+1−Fi−1Fj−1Fi+j=Fi+1Fj+1−Fi−1Fj−1F_{i + j} = F_{i + 1}F_{j + 1} - F_{i - 1}F_{j - 1},   Fi+j+1=FiFj+Fi+1Fj+1Fi+j+1=FiFj+Fi+1Fj+1F_{i + j + 1} = F_iF_j + F_{i + 1}F_{j + 1}. We can use this to quickly calculate F2r,F2r+1F2r,F2r+1F_{2^r}, F_{2^r + 1} for increasing 2r2r2^r, then extract the binary digits of the index kkk such that Fk≤n<Fk+1Fk≤n<Fk+1F_k \le n < F_{k + 1}, in O(loglogn)O(log⁡log⁡n)O(\log \log n) (big-integer) arithmetic operations. In Haskell:-- fibPlus (fib i, fib (i + 1)) (fib j, fib (j + 1)) == (fib (i + j), fib (i + j + 1)) fibPlus (a, b) (c, d) = (bd - (b - a)*(d - c), a*c + bd) where bd = b*d  -- unFib (fib i, fib (i + 1)) n == (k, fib (i*k), fib (i*k + 1)) --   such that fib (i*k) <= n < fib ((i + 1)*k) unFib (a, b) n   | n < a = (0, 0, 1)   | n < e = (2*k, c, d)   | otherwise = (2*k + 1, e, f) where     (k, c, d) = unFib (fibPlus (a, b) (a, b)) n     (e, f) = fibPlus (a, b) (c, d)  isFib n = n == a where (k, a, b) = unFib (1, 1) n This finds that F1000000F1000000F_{1\,000\,000} is a Fibonacci number in 45 ms. (That’s about 5 times as fast as an optimized implementation of John Kurlak’s answer, because computing an exact integer square root also involves a binary search or a similarly complicated iteration.)","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/hl0amybvq43zrdpj', 'title': 'What is the most efficient algorithm to check if a number is a Fibonacci Number?', 'score': {'original': 0.9626, 'ai': 0.0374}, 'blocks': [{'text': 'The Fibonacci recurrence can be solved using matrix exponentiation:   [Fi−1FiFiFi+1]=[0111]i[Fi−1FiFiFi+1]=[0111]i\\displaystyle \\begin{bmatrix}F_{i - 1} & F_i \\\\ F_i & F_{i + 1}\\end{bmatrix} = \\begin{bmatrix}0 & 1 \\\\ 1 & 1\\end{bmatrix}^i, from which we derive these identities:   [Fi+j−1Fi+jFi+jFi+j+1]=[Fi−1FiFiFi+1]⋅[Fj−1FjFjFj+1][Fi+j−1Fi+jFi+jFi+j+1]=[Fi−1FiFiFi+1]⋅[Fj−1FjFjFj+1]\\displaystyle \\begin{bmatrix}F_{i + j - 1} & F_{i + j} \\\\ F_{i + j} & F_{i + j + 1}\\end{bmatrix} = \\begin{bmatrix}F_{i - 1} & F_i \\\\ F_i & F_{i + 1}\\end{bmatrix} \\cdot \\begin{bmatrix}F_{j - 1} & F_j \\\\ F_j & F_{j + 1}\\end{bmatrix},   Fi+j=Fi+1Fj+1−Fi−1Fj−1Fi+j=Fi+1Fj+1−Fi−1Fj−1F_{i + j} = F_{i + 1}F_{j + 1} - F_{i - 1}F_{j - 1},   Fi+j+1=FiFj+Fi+1Fj+1Fi+j+1=FiFj+Fi+1Fj+1F_{i + j + 1} = F_iF_j + F_{i + 1}F_{j + 1}. We can use this to quickly calculate F2r,F2r+1F2r,F2r+1F_{2^r}, F_{2^r + 1} for increasing 2r2r2^r, then extract the binary digits of the index kkk such that Fk≤n<Fk+1Fk≤n<Fk+1F_k \\le n < F_{k + 1}, in O(loglogn)O(log\u2061log\u2061n)O(\\log \\log n) (big-integer) arithmetic operations. In Haskell:-- fibPlus (fib i, fib (i + 1)) (fib j, fib (j + 1)) == (fib (i + j), fib (i + j + 1))\xa0fibPlus (a, b) (c, d) = (bd - (b - a)*(d - c), a*c + bd) where bd = b*d\xa0\xa0-- unFib (fib i, fib (i + 1)) n == (k, fib (i*k), fib (i*k + 1))\xa0--   such that fib (i*k) <= n < fib ((i + 1)*k)\xa0unFib (a, b) n\xa0  | n < a = (0, 0, 1)\xa0  | n < e = (2*k, c, d)\xa0  | otherwise = (2*k + 1, e, f) where\xa0    (k, c, d) = unFib (fibPlus (a, b) (a, b)) n\xa0    (e, f) = fibPlus (a, b) (c, d)\xa0\xa0isFib n = n == a where (k, a, b) = unFib (1, 1) n\xa0This finds that F1000000F1000000F_{1\\,000\\,000} is a Fibonacci number in 45 ms. (That’s about 5 times as fast as an optimized implementation of John Kurlak’s answer, because computing an exact integer square root also involves a binary search or a similarly complicated iteration.)', 'result': {'fake': 0.0567, 'real': 0.9433}, 'status': 'success'}], 'credits_used': 4, 'credits': 1986247, 'subscription': 0, 'content': 'The Fibonacci recurrence can be solved using matrix exponentiation:   [Fi−1FiFiFi+1]=[0111]i[Fi−1FiFiFi+1]=[0111]i\\displaystyle \\begin{bmatrix}F_{i - 1} & F_i \\\\ F_i & F_{i + 1}\\end{bmatrix} = \\begin{bmatrix}0 & 1 \\\\ 1 & 1\\end{bmatrix}^i, from which we derive these identities:   [Fi+j−1Fi+jFi+jFi+j+1]=[Fi−1FiFiFi+1]⋅[Fj−1FjFjFj+1][Fi+j−1Fi+jFi+jFi+j+1]=[Fi−1FiFiFi+1]⋅[Fj−1FjFjFj+1]\\displaystyle \\begin{bmatrix}F_{i + j - 1} & F_{i + j} \\\\ F_{i + j} & F_{i + j + 1}\\end{bmatrix} = \\begin{bmatrix}F_{i - 1} & F_i \\\\ F_i & F_{i + 1}\\end{bmatrix} \\cdot \\begin{bmatrix}F_{j - 1} & F_j \\\\ F_j & F_{j + 1}\\end{bmatrix},   Fi+j=Fi+1Fj+1−Fi−1Fj−1Fi+j=Fi+1Fj+1−Fi−1Fj−1F_{i + j} = F_{i + 1}F_{j + 1} - F_{i - 1}F_{j - 1},   Fi+j+1=FiFj+Fi+1Fj+1Fi+j+1=FiFj+Fi+1Fj+1F_{i + j + 1} = F_iF_j + F_{i + 1}F_{j + 1}. We can use this to quickly calculate F2r,F2r+1F2r,F2r+1F_{2^r}, F_{2^r + 1} for increasing 2r2r2^r, then extract the binary digits of the index kkk such that Fk≤n<Fk+1Fk≤n<Fk+1F_k \\le n < F_{k + 1}, in O(loglogn)O(log\u2061log\u2061n)O(\\log \\log n) (big-integer) arithmetic operations. In Haskell:-- fibPlus (fib i, fib (i + 1)) (fib j, fib (j + 1)) == (fib (i + j), fib (i + j + 1))\xa0fibPlus (a, b) (c, d) = (bd - (b - a)*(d - c), a*c + bd) where bd = b*d\xa0\xa0-- unFib (fib i, fib (i + 1)) n == (k, fib (i*k), fib (i*k + 1))\xa0--   such that fib (i*k) <= n < fib ((i + 1)*k)\xa0unFib (a, b) n\xa0  | n < a = (0, 0, 1)\xa0  | n < e = (2*k, c, d)\xa0  | otherwise = (2*k + 1, e, f) where\xa0    (k, c, d) = unFib (fibPlus (a, b) (a, b)) n\xa0    (e, f) = fibPlus (a, b) (c, d)\xa0\xa0isFib n = n == a where (k, a, b) = unFib (1, 1) n\xa0This finds that F1000000F1000000F_{1\\,000\\,000} is a Fibonacci number in 45 ms. (That’s about 5 times as fast as an optimized implementation of John Kurlak’s answer, because computing an exact integer square root also involves a binary search or a similarly complicated iteration.)', 'aiModelVersion': '1'}",0.9626
Lawrence Stewart,4y,What was the most complicated piece of code that you were able to simplify down to a few lines?,"So about 18 years ago, I was hired to evaluate a proposed new cryptosystem invented by a math professor. He had an implementation of it coded in C by someone, which was about 35 pages of code. It was sort of tangled but I eventually figured out that the bulk of it was a set of functions to do arithmetic, in particular on multi-word numbers.

I decided to try and duplicate the logic in Scheme (a variant of LISP) because I knew Scheme has arbitrary precision arithmetic built in.

It took 11 lines of Scheme code to duplicate the algorithm, at which point it became obvious that the thing was linear, in that f(a+b)= f(a)+f(b), It took 23 lines of scheme to write a code-breaking function.

The two lessons are don’t try to develop your own crypto and really don’t try to use linear functions for crypto. They are trivial to break.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/zw6qbcmvnujxktpf', 'title': 'What was the most complicated piece of code that you were able to simplify down to a few lines?', 'score': {'original': 0.999, 'ai': 0.001}, 'blocks': [{'text': 'So about 18 years ago, I was hired to evaluate a proposed new cryptosystem invented by a math professor. He had an implementation of it coded in C by someone, which was about 35 pages of code. It was sort of tangled but I eventually figured out that the bulk of it was a set of functions to do arithmetic, in particular on multi-word numbers.\n\nI decided to try and duplicate the logic in Scheme (a variant of LISP) because I knew Scheme has arbitrary precision arithmetic built in.\n\nIt took 11 lines of Scheme code to duplicate the algorithm, at which point it became obvious that the thing was linear, in that f(a+b)= f(a)+f(b), It took 23 lines of scheme to write a code-breaking function.\n\nThe two lessons are don’t try to develop your own crypto and really don’t try to use linear functions for crypto. They are trivial to break.', 'result': {'fake': 0.001, 'real': 0.999}, 'status': 'success'}], 'credits_used': 2, 'credits': 1986245, 'subscription': 0, 'content': 'So about 18 years ago, I was hired to evaluate a proposed new cryptosystem invented by a math professor. He had an implementation of it coded in C by someone, which was about 35 pages of code. It was sort of tangled but I eventually figured out that the bulk of it was a set of functions to do arithmetic, in particular on multi-word numbers.\n\nI decided to try and duplicate the logic in Scheme (a variant of LISP) because I knew Scheme has arbitrary precision arithmetic built in.\n\nIt took 11 lines of Scheme code to duplicate the algorithm, at which point it became obvious that the thing was linear, in that f(a+b)= f(a)+f(b), It took 23 lines of scheme to write a code-breaking function.\n\nThe two lessons are don’t try to develop your own crypto and really don’t try to use linear functions for crypto. They are trivial to break.', 'aiModelVersion': '1'}",0.999
Senia Sheydvasser,4y,Will driverless technology someday make human drivers obsolete? Would you be willing to trust YOUR safety to an algorithm?,"The answer to both questions is “absolutely, yes.”

The average human reaction time is 
0.25
0.25
 seconds for visual stimulus. This sounds fast, I know, but consider the fact that at 
60
60
 miles per hour, in that fraction of a second, your car will travel 
5
−
10
5−10
 meters—this is before you even know that there is a problem, let alone have had any chance to do anything about it. Worse, this is assuming that you are fully alert and not, say, peering in the mirror because the bag of groceries in the back seat just fell over. In practice, you might be looking at a lag of as much as 
1.5
1.5
 seconds—this is now 
30
−
50
30−50
 meters that you have traveled before you have started doing anything.

In contrast, the reaction time of computers, while technically non-zero, might as well be in practice. When something goes wrong in an automobile, acting quickly is of paramount importance, and computers have humans completely outclassed in that department. Computers also don’t get tired, don’t get distracted, and can pull information from each of their connected sensors simultaneously, while a human can only concentrate on one or two things at a time.

The fact of the matter is, you already entrust your personal safety to countless different algorithms, in many different ways. For example, your car almost certainly has an anti-lock braking system
. Guess what? There is a little computer in your car running an algorithm that determines when to engage that system. It doesn’t wait for the human driver to decide that that is what is needed, because by the time that the human realizes what is up, it may well be too late. Similarly, your airbags are also probably governed by a computerized system. For sure, it is true that these algorithms are downright basic when compared with the much more sophisticated systems you need to have a fully automatic car. But the essential reasons why you would want such a thing still remain.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/w7ju8a51oifkcrpb', 'title': 'Will driverless technology someday make human drivers obsolete? Would you be willing to trust YOUR safety to an algorithm?', 'score': {'original': 0.9996, 'ai': 0.0004}, 'blocks': [{'text': 'The answer to both questions is “absolutely, yes.”\n\nThe average human reaction time is \n0.25\n0.25\n seconds for visual stimulus. This sounds fast, I know, but consider the fact that at \n60\n60\n miles per hour, in that fraction of a second, your car will travel \n5\n−\n10\n5−10\n meters—this is before you even know that there is a problem, let alone have had any chance to do anything about it. Worse, this is assuming that you are fully alert and not, say, peering in the mirror because the bag of groceries in the back seat just fell over. In practice, you might be looking at a lag of as much as \n1.5\n1.5\n seconds—this is now \n30\n−\n50\n30−50\n meters that you have traveled before you have started doing anything.\n\nIn contrast, the reaction time of computers, while technically non-zero, might as well be in practice. When something goes wrong in an automobile, acting quickly is of paramount importance, and computers have humans completely outclassed in that department. Computers also don’t get tired, don’t get distracted, and can pull information from each of their connected sensors simultaneously, while a human can only concentrate on one or two things at a time.\n\nThe fact of the matter is, you already entrust your personal safety to countless different algorithms, in many different ways. For example, your car almost certainly has an anti-lock braking system\n. Guess what? There is a little computer in your car running an algorithm that determines when to engage that system. It doesn’t wait for the human driver to decide that that is what is needed, because by the time that the human realizes what is up, it may well be too late. Similarly, your airbags are also probably governed by a computerized system. For sure, it is true that these algorithms are downright basic when compared with the much more sophisticated systems you need to have a fully automatic car. But the essential reasons why you would want such a thing still remain.', 'result': {'fake': 0.0004, 'real': 0.9996}, 'status': 'success'}], 'credits_used': 4, 'credits': 1986241, 'subscription': 0, 'content': 'The answer to both questions is “absolutely, yes.”\n\nThe average human reaction time is \n0.25\n0.25\n seconds for visual stimulus. This sounds fast, I know, but consider the fact that at \n60\n60\n miles per hour, in that fraction of a second, your car will travel \n5\n−\n10\n5−10\n meters—this is before you even know that there is a problem, let alone have had any chance to do anything about it. Worse, this is assuming that you are fully alert and not, say, peering in the mirror because the bag of groceries in the back seat just fell over. In practice, you might be looking at a lag of as much as \n1.5\n1.5\n seconds—this is now \n30\n−\n50\n30−50\n meters that you have traveled before you have started doing anything.\n\nIn contrast, the reaction time of computers, while technically non-zero, might as well be in practice. When something goes wrong in an automobile, acting quickly is of paramount importance, and computers have humans completely outclassed in that department. Computers also don’t get tired, don’t get distracted, and can pull information from each of their connected sensors simultaneously, while a human can only concentrate on one or two things at a time.\n\nThe fact of the matter is, you already entrust your personal safety to countless different algorithms, in many different ways. For example, your car almost certainly has an anti-lock braking system\n. Guess what? There is a little computer in your car running an algorithm that determines when to engage that system. It doesn’t wait for the human driver to decide that that is what is needed, because by the time that the human realizes what is up, it may well be too late. Similarly, your airbags are also probably governed by a computerized system. For sure, it is true that these algorithms are downright basic when compared with the much more sophisticated systems you need to have a fully automatic car. But the essential reasons why you would want such a thing still remain.', 'aiModelVersion': '1'}",0.9996
Keldon Alleyne,4y,What is the hardest programming problem you couldn't solve?,"The Eternity II edge matching puzzle.

There was a $2 million prize for anyone who could place all 256 tiles correctly.

The immediate problem is that brute force alone cannot help you in the slightest. If you were to try every possibility, by the time you’d finished the sun would have burned out.

I knew this, but was looking for weaknesses in the design, which is how the first Eternity challenge was solved. But this version was created by the mathematicians that solved it.

I came up with various forms of analysis to look for statistical biases, ways of reusing previous computational effort, and potential conversions to a more appropriate problem set.

Suffice to say I did not win that $2 million prize, but I learned a lot through the process.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/mwsqjxu930drlvgy', 'title': ""What is the hardest programming problem you couldn't solve?"", 'score': {'original': 0.994, 'ai': 0.006}, 'blocks': [{'text': 'The Eternity II edge matching puzzle.\n\nThere was a $2 million prize for anyone who could place all 256 tiles correctly.\n\nThe immediate problem is that brute force alone cannot help you in the slightest. If you were to try every possibility, by the time you’d finished the sun would have burned out.\n\nI knew this, but was looking for weaknesses in the design, which is how the first Eternity challenge was solved. But this version was created by the mathematicians that solved it.\n\nI came up with various forms of analysis to look for statistical biases, ways of reusing previous computational effort, and potential conversions to a more appropriate problem set.\n\nSuffice to say I did not win that $2 million prize, but I learned a lot through the process.', 'result': {'fake': 0.006, 'real': 0.994}, 'status': 'success'}], 'credits_used': 2, 'credits': 1986239, 'subscription': 0, 'content': 'The Eternity II edge matching puzzle.\n\nThere was a $2 million prize for anyone who could place all 256 tiles correctly.\n\nThe immediate problem is that brute force alone cannot help you in the slightest. If you were to try every possibility, by the time you’d finished the sun would have burned out.\n\nI knew this, but was looking for weaknesses in the design, which is how the first Eternity challenge was solved. But this version was created by the mathematicians that solved it.\n\nI came up with various forms of analysis to look for statistical biases, ways of reusing previous computational effort, and potential conversions to a more appropriate problem set.\n\nSuffice to say I did not win that $2 million prize, but I learned a lot through the process.', 'aiModelVersion': '1'}",0.994
Douglas Duncan Pickard,Updated 6y,Why couldn't anyone break the AES cipher algorithm until now?,"“Breaking” an encryption algorithm just means you find a way to solve it faster than via brute force (trying every possible key). What has happened is that the algorithm has been subjected to LOTS of intense mathematical analysis and some weak points have been discovered. While these weak points in theory allow the cipher to be decrypted faster than would be possible with a brute force attack the amount of processing power required to do so in practice is still totally implausible using any publicly known technology. It would require somewhere in the neighborhood of 225422542^{254} mathematical operations to recover a 256 bit AES key, as opposed to 225622562^{256} using brute force. That is a REALLY huge amount of computation. Even with all the computing power available on earth working to recover ONE 256 bit AES key, the sun would have burned out long before the key was recovered (on average. It’s always POSSIBLE that you find it on your first go, just mind-bogglingly unlikely). So yeah AES is “broken” in a technical sense. It’s also still perfectly safe against crypto attacks. Of course as xkcd tells us, that’s not REALLY what you need to worry about:","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/tf7w6qz5rdx2a93j', 'title': ""Why couldn't anyone break the AES cipher algorithm until now?"", 'score': {'original': 0.9996, 'ai': 0.0004}, 'blocks': [{'text': '“Breaking” an encryption algorithm just means you find a way to solve it faster than via brute force (trying every possible key). What has happened is that the algorithm has been subjected to LOTS of intense mathematical analysis and some weak points have been discovered. While these weak points in theory allow the cipher to be decrypted faster than would be possible with a brute force attack the amount of processing power required to do so in practice is still totally implausible using any publicly known technology. It would require somewhere in the neighborhood of 225422542^{254} mathematical operations to recover a 256 bit AES key, as opposed to 225622562^{256} using brute force. That is a REALLY huge amount of computation. Even with all the computing power available on earth working to recover ONE 256 bit AES key, the sun would have burned out long before the key was recovered (on average. It’s always POSSIBLE that you find it on your first go, just mind-bogglingly unlikely). So yeah AES is “broken” in a technical sense. It’s also still perfectly safe against crypto attacks. Of course as xkcd tells us, that’s not REALLY what you need to worry about:', 'result': {'fake': 0.0004, 'real': 0.9996}, 'status': 'success'}], 'credits_used': 2, 'credits': 1986237, 'subscription': 0, 'content': '“Breaking” an encryption algorithm just means you find a way to solve it faster than via brute force (trying every possible key). What has happened is that the algorithm has been subjected to LOTS of intense mathematical analysis and some weak points have been discovered. While these weak points in theory allow the cipher to be decrypted faster than would be possible with a brute force attack the amount of processing power required to do so in practice is still totally implausible using any publicly known technology. It would require somewhere in the neighborhood of 225422542^{254} mathematical operations to recover a 256 bit AES key, as opposed to 225622562^{256} using brute force. That is a REALLY huge amount of computation. Even with all the computing power available on earth working to recover ONE 256 bit AES key, the sun would have burned out long before the key was recovered (on average. It’s always POSSIBLE that you find it on your first go, just mind-bogglingly unlikely). So yeah AES is “broken” in a technical sense. It’s also still perfectly safe against crypto attacks. Of course as xkcd tells us, that’s not REALLY what you need to worry about:', 'aiModelVersion': '1'}",0.9996
Alon Amit,Updated 8mo,Is there a best way to optimize an algorithm that computes ,"This question leads to an absolutely delightful little theory which everyone should know about (and everyone would know about if everyone read Knuth’s TAOCP cover to cover, as everyone should). So let's say I give you some number xxx and I ask you to calculate x10x10x^{10}. At your disposal is some gizmo that can calculate products, but each calculation of a product costs you something – an arm, a leg, or a few milliseconds. Doesn't matter, as long as we agree that your goal is simply to minimize the number of multiplications. So. What do you do? A very reasonable solution goes like this: first calculate x2x2x^2 by multiplying x×xx×xx \times x. Then multiply x2x2x^2 by itself to obtain x4=x2×x2x4=x2×x2x^4=x^2\times x^2. Then do this again to get x8=x4×x4x8=x4×x4x^8=x^4\times x^4. Now to get x10x10x^{10}, all you need is to multiply x8x8x^8 by x2x2x^2, which luckily we have already calculated. So we managed to find x10x10x^{10} using four multiplications:xxx (given)x2=x×xx2=x×xx^2=x\times xx4=x2×x2x4=x2×x2x^4=x^2\times x^2x8=x4×x4x8=x4×x4x^8=x^4\times x^4x10=x8×x2x10=x8×x2x^{10}=x^8\times x^2.Let’s think about what's going on here. We see that it doesn't really matter what xxx is – it could be large, small, an integer, a floating point number, a large matrix or anything else that we can multiply. (For matrices there are useful shortcuts such as diagonalizing them first, or triangulating. But this is outside our main concern here). The only thing that matters is the sequence of exponents in our calculation, where at each step we produce a new exponent which is the sum of two previously calculated exponents. The starting point is simply 111.111 (given)2=1+12=1+12=1+14=2+24=2+24=2+28=4+48=4+48=4+410=8+210=8+210=8+2The sequence 1,2,4,8,101,2,4,8,101,2,4,8,10 is called an addition chain ending in 101010. An addition chain is just a sequence of numbers, starting with 111, where each number is the sum of two (not necessarily distinct) earlier numbers in the sequence. The length of the chain is how many numbers it has, excluding the 111 in the beginning (since we have it for free). In other words, the length is just the number of addition steps we need to take (or multiplication steps in the calculation of xnxnx^n). The challenge of calculating xnxnx^n efficiently is now seen to be simply this: find the shortest possible addition chain ending in nnn. The length of this optimal chain is called l(n)l(n)l(n). The number 101010 can also be achieved via 1,2,4,5,101,2,4,5,101,2,4,5,10, where instead of greedily doubling the 444 to get 888 we’ve added the 444 and the 111 to get 555; this “sacrifice” paid up in the next step where we were able to double the 555 to land straight on 101010. You can convince yourself that there’s no way to get to 101010 with fewer steps. So l(10)=4l(10)=4l(10)=4. But what is the shortest possible chain for 232323? For 191191191? For 31729317293^{1729}? The most efficient step in an addition chain is doubling, which is just multiplying the previous element by 222. The sequences for 101010 contain mostly doublings, and there’s an easy way to use the binary representation of a number to create an addition chain for that number that has lots of doublings: Write the number in binary; remove the leftmost “1”; replace each “1” with a “D1” and each “0” with a “D”; and interpret the result as a chain where “D” means “double” and “1” means “add 1”. For example, to make 212121, write 21=10101221=10101221=10101_2, erase the leading 111 to get 010101010101, and interpret this as DD1DD1DD1DD1D D1 D D1 which means “double, double, add one, double, double, add one”. Indeed, 1,2,4,5,10,20,211,2,4,5,10,20,211,2,4,5,10,20,21 is an addition chain for 212121, and it is the best possible. This “binary method” is quite efficient, and Knuth points out that some people actually claimed that it always produces the most efficient addition chain. But this is false. It is already false for 15=1111215=1111215=1111_2, where the binary method leads to 1,2,3,6,7,14,151,2,3,6,7,14,151,2,3,6,7,14,15 but you can do better: 1,2,3,6,12,151,2,3,6,12,151,2,3,6,12,15. (Good coding exercise: write a program that calculates an addition chain of shortest possible length for a given number nnn). Addition chains are incredibly subtle. Here are some surprises mentioned by Knuth:A “star chain” is one where every number utilizes its immediate predecessor. This seems like a very reasonable thing to do, and it is natural to assume that there’s always a star chain that achieves the minimum length. But this isn’t true. The first counterexample I know of is 26106+23048+22032+21016+126106+23048+22032+21016+12^{6106}+2^{3048}+2^{2032}+2^{1016}+1, a rather monstrous number. This was discovered by Hansen in 1958.If you’ve found the best addition chain for nnn, it is reasonable to expect that the best chain for 2n2n2n is just the best chain for nnn followed by a doubling. A doubling is, after all, the most efficient step. In other words, the conjecture is that l(2n)=l(n)+1l(2n)=l(n)+1l(2n)=l(n)+1. But this isn’t true. The shortest possible addition chain for 191191191 has 111111 steps, so l(191)=11l(191)=11l(191)=11, and amazingly, l(382)=11l(382)=11l(382)=11 as well. You can get to 382382382 in the same(!) number of steps as you can get to 191191191.(Use your code to verify those claims). Section 4.6.3 in vol. 2 of Knuth’s “The Art of Computer Programming” contains a very detailed analysis of the theory of addition chains, as an excursion off of the efficient computation of xnxnx^n. Those deep, surprising excursions are one of the wonders of this incredible sequence of books. There are still several open problems about addition chains, and some very clever associated algorithms. It’s amazing how a simple problem such as calculating xnxnx^n in the most efficient way leads to such unexpected depths.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/k4mo7htygpaesi8w', 'title': 'Is there a best way to optimize an algorithm that computes', 'score': {'original': 0.99865, 'ai': 0.00135}, 'blocks': [{'text': ""This question leads to an absolutely delightful little theory which everyone should know about (and everyone would know about if everyone read Knuth’s TAOCP cover to cover, as everyone should). So let's say I give you some number xxx and I ask you to calculate x10x10x^{10}. At your disposal is some gizmo that can calculate products, but each calculation of a product costs you something – an arm, a leg, or a few milliseconds. Doesn't matter, as long as we agree that your goal is simply to minimize the number of multiplications. So. What do you do? A very reasonable solution goes like this: first calculate x2x2x^2 by multiplying x×xx×xx \\times x. Then multiply x2x2x^2 by itself to obtain x4=x2×x2x4=x2×x2x^4=x^2\\times x^2. Then do this again to get x8=x4×x4x8=x4×x4x^8=x^4\\times x^4. Now to get x10x10x^{10}, all you need is to multiply x8x8x^8 by x2x2x^2, which luckily we have already calculated. So we managed to find x10x10x^{10} using four multiplications:xxx (given)x2=x×xx2=x×xx^2=x\\times xx4=x2×x2x4=x2×x2x^4=x^2\\times x^2x8=x4×x4x8=x4×x4x^8=x^4\\times x^4x10=x8×x2x10=x8×x2x^{10}=x^8\\times x^2.Let’s think about what's going on here. We see that it doesn't really matter what xxx is – it could be large, small, an integer, a floating point number, a large matrix or anything else that we can multiply. (For matrices there are useful shortcuts such as diagonalizing them first, or triangulating. But this is outside our main concern here). The only thing that matters is the sequence of exponents in our calculation, where at each step we produce a new exponent which is the sum of two previously calculated exponents. The starting point is simply 111.111 (given)2=1+12=1+12=1+14=2+24=2+24=2+28=4+48=4+48=4+410=8+210=8+210=8+2The sequence 1,2,4,8,101,2,4,8,101,2,4,8,10 is called an addition chain ending in 101010. An addition chain is just a sequence of numbers, starting with 111, where each number is the sum of two (not necessarily distinct) earlier numbers in the sequence. The length of the chain is how many numbers it has, excluding the 111 in the beginning (since we have it for free). In other words, the length is just the number of addition steps we need to take (or multiplication steps in the calculation of xnxnx^n). The challenge of calculating xnxnx^n efficiently is now seen to be simply this: find the shortest possible addition chain ending in nnn. The length of this optimal chain is called l(n)l(n)l(n). The number 101010 can also be achieved via 1,2,4,5,101,2,4,5,101,2,4,5,10, where instead of greedily doubling the 444 to get 888 we’ve added the 444 and the 111 to get 555; this “sacrifice” paid up in the next step where we were able to double the 555 to land straight on 101010. You can convince yourself that there’s no way to get to 101010 with fewer steps. So l(10)=4l(10)=4l(10)=4. But what is the shortest possible chain for 232323? For 191191191? For 31729317293^{1729}? The most efficient step in an addition chain is doubling, which is just multiplying the previous element by 222. The sequences for 101010 contain mostly doublings, and there’s an easy way to use the binary representation of a number to create an addition chain for that number that has lots of doublings: Write the number in binary;"", 'result': {'fake': 0.0012, 'real': 0.9988}, 'status': 'success'}, {'text': 'remove the leftmost “1”; replace each “1” with a “D1” and each “0” with a “D”; and interpret the result as a chain where “D” means “double” and “1” means “add 1”. For example, to make 212121, write 21=10101221=10101221=10101_2, erase the leading 111 to get 010101010101, and interpret this as DD1DD1DD1DD1D D1 D D1 which means “double, double, add one, double, double, add one”. Indeed, 1,2,4,5,10,20,211,2,4,5,10,20,211,2,4,5,10,20,21 is an addition chain for 212121, and it is the best possible. This “binary method” is quite efficient, and Knuth points out that some people actually claimed that it always produces the most efficient addition chain. But this is false. It is already false for 15=1111215=1111215=1111_2, where the binary method leads to 1,2,3,6,7,14,151,2,3,6,7,14,151,2,3,6,7,14,15 but you can do better: 1,2,3,6,12,151,2,3,6,12,151,2,3,6,12,15. (Good coding exercise: write a program that calculates an addition chain of shortest possible length for a given number nnn). Addition chains are incredibly subtle. Here are some surprises mentioned by Knuth:A “star chain” is one where every number utilizes its immediate predecessor. This seems like a very reasonable thing to do, and it is natural to assume that there’s always a star chain that achieves the minimum length. But this isn’t true. The first counterexample I know of is 26106+23048+22032+21016+126106+23048+22032+21016+12^{6106}+2^{3048}+2^{2032}+2^{1016}+1, a rather monstrous number. This was discovered by Hansen in 1958.If you’ve found the best addition chain for nnn, it is reasonable to expect that the best chain for 2n2n2n is just the best chain for nnn followed by a doubling. A doubling is, after all, the most efficient step. In other words, the conjecture is that l(2n)=l(n)+1l(2n)=l(n)+1l(2n)=l(n)+1. But this isn’t true. The shortest possible addition chain for 191191191 has 111111 steps, so l(191)=11l(191)=11l(191)=11, and amazingly, l(382)=11l(382)=11l(382)=11 as well. You can get to 382382382 in the same(!) number of steps as you can get to 191191191.(Use your code to verify those claims). Section 4.6.3 in vol. 2 of Knuth’s “The Art of Computer Programming” contains a very detailed analysis of the theory of addition chains, as an excursion off of the efficient computation of xnxnx^n. Those deep, surprising excursions are one of the wonders of this incredible sequence of books. There are still several open problems about addition chains, and some very clever associated algorithms. It’s amazing how a simple problem such as calculating xnxnx^n in the most efficient way leads to such unexpected depths.', 'result': {'fake': 0.0015, 'real': 0.9985}, 'status': 'success'}], 'credits_used': 10, 'credits': 1986227, 'subscription': 0, 'content': ""This question leads to an absolutely delightful little theory which everyone should know about (and everyone would know about if everyone read Knuth’s TAOCP cover to cover, as everyone should). So let's say I give you some number xxx and I ask you to calculate x10x10x^{10}. At your disposal is some gizmo that can calculate products, but each calculation of a product costs you something – an arm, a leg, or a few milliseconds. Doesn't matter, as long as we agree that your goal is simply to minimize the number of multiplications. So. What do you do? A very reasonable solution goes like this: first calculate x2x2x^2 by multiplying x×xx×xx \\times x. Then multiply x2x2x^2 by itself to obtain x4=x2×x2x4=x2×x2x^4=x^2\\times x^2. Then do this again to get x8=x4×x4x8=x4×x4x^8=x^4\\times x^4. Now to get x10x10x^{10}, all you need is to multiply x8x8x^8 by x2x2x^2, which luckily we have already calculated. So we managed to find x10x10x^{10} using four multiplications:xxx (given)x2=x×xx2=x×xx^2=x\\times xx4=x2×x2x4=x2×x2x^4=x^2\\times x^2x8=x4×x4x8=x4×x4x^8=x^4\\times x^4x10=x8×x2x10=x8×x2x^{10}=x^8\\times x^2.Let’s think about what's going on here. We see that it doesn't really matter what xxx is – it could be large, small, an integer, a floating point number, a large matrix or anything else that we can multiply. (For matrices there are useful shortcuts such as diagonalizing them first, or triangulating. But this is outside our main concern here). The only thing that matters is the sequence of exponents in our calculation, where at each step we produce a new exponent which is the sum of two previously calculated exponents. The starting point is simply 111.111 (given)2=1+12=1+12=1+14=2+24=2+24=2+28=4+48=4+48=4+410=8+210=8+210=8+2The sequence 1,2,4,8,101,2,4,8,101,2,4,8,10 is called an addition chain ending in 101010. An addition chain is just a sequence of numbers, starting with 111, where each number is the sum of two (not necessarily distinct) earlier numbers in the sequence. The length of the chain is how many numbers it has, excluding the 111 in the beginning (since we have it for free). In other words, the length is just the number of addition steps we need to take (or multiplication steps in the calculation of xnxnx^n). The challenge of calculating xnxnx^n efficiently is now seen to be simply this: find the shortest possible addition chain ending in nnn. The length of this optimal chain is called l(n)l(n)l(n). The number 101010 can also be achieved via 1,2,4,5,101,2,4,5,101,2,4,5,10, where instead of greedily doubling the 444 to get 888 we’ve added the 444 and the 111 to get 555; this “sacrifice” paid up in the next step where we were able to double the 555 to land straight on 101010. You can convince yourself that there’s no way to get to 101010 with fewer steps. So l(10)=4l(10)=4l(10)=4. But what is the shortest possible chain for 232323? For 191191191? For 31729317293^{1729}? The most efficient step in an addition chain is doubling, which is just multiplying the previous element by 222. The sequences for 101010 contain mostly doublings, and there’s an easy way to use the binary representation of a number to create an addition chain for that number that has lots of doublings: Write the number in binary; remove the leftmost “1”; replace each “1” with a “D1” and each “0” with a “D”; and interpret the result as a chain where “D” means “double” and “1” means “add 1”. For example, to make 212121, write 21=10101221=10101221=10101_2, erase the leading 111 to get 010101010101, and interpret this as DD1DD1DD1DD1D D1 D D1 which means “double, double, add one, double, double, add one”. Indeed, 1,2,4,5,10,20,211,2,4,5,10,20,211,2,4,5,10,20,21 is an addition chain for 212121, and it is the best possible. This “binary method” is quite efficient, and Knuth points out that some people actually claimed that it always produces the most efficient addition chain. But this is false. It is already false for 15=1111215=1111215=1111_2, where the binary method leads to 1,2,3,6,7,14,151,2,3,6,7,14,151,2,3,6,7,14,15 but you can do better: 1,2,3,6,12,151,2,3,6,12,151,2,3,6,12,15. (Good coding exercise: write a program that calculates an addition chain of shortest possible length for a given number nnn). Addition chains are incredibly subtle. Here are some surprises mentioned by Knuth:A “star chain” is one where every number utilizes its immediate predecessor. This seems like a very reasonable thing to do, and it is natural to assume that there’s always a star chain that achieves the minimum length. But this isn’t true. The first counterexample I know of is 26106+23048+22032+21016+126106+23048+22032+21016+12^{6106}+2^{3048}+2^{2032}+2^{1016}+1, a rather monstrous number. This was discovered by Hansen in 1958.If you’ve found the best addition chain for nnn, it is reasonable to expect that the best chain for 2n2n2n is just the best chain for nnn followed by a doubling. A doubling is, after all, the most efficient step. In other words, the conjecture is that l(2n)=l(n)+1l(2n)=l(n)+1l(2n)=l(n)+1. But this isn’t true. The shortest possible addition chain for 191191191 has 111111 steps, so l(191)=11l(191)=11l(191)=11, and amazingly, l(382)=11l(382)=11l(382)=11 as well. You can get to 382382382 in the same(!) number of steps as you can get to 191191191.(Use your code to verify those claims). Section 4.6.3 in vol. 2 of Knuth’s “The Art of Computer Programming” contains a very detailed analysis of the theory of addition chains, as an excursion off of the efficient computation of xnxnx^n. Those deep, surprising excursions are one of the wonders of this incredible sequence of books. There are still several open problems about addition chains, and some very clever associated algorithms. It’s amazing how a simple problem such as calculating xnxnx^n in the most efficient way leads to such unexpected depths."", 'aiModelVersion': '1'}",0.99865
Indira Securities,2y,Can machine learning algorithms really help in trading?,"Compared to conventional algorithmic programs, machine learning has a range of major advantages. Through manual trading is often a time-consuming manual process, the process of machine learning algorithm will speed up the search for successful algo-trading strategies. It also increases the number of markets an individual can keep track of and respond to. You have a competitive advantage if you can automate a system that others do manually. You would have more options if you can increase the number of markets you invest in.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/4l8emop7v3uaqnch', 'title': 'Can machine learning algorithms really help in trading?', 'score': {'original': 0.4775, 'ai': 0.5225}, 'blocks': [{'text': 'Compared to conventional algorithmic programs, machine learning has a range of major advantages. Through manual trading is often a time-consuming manual process, the process of machine learning algorithm will speed up the search for successful algo-trading strategies. It also increases the number of markets an individual can keep track of and respond to. You have a competitive advantage if you can automate a system that others do manually. You would have more options if you can increase the number of markets you invest in.', 'result': {'fake': 0.5225, 'real': 0.4775}, 'status': 'success'}], 'credits_used': 1, 'credits': 1986226, 'subscription': 0, 'content': 'Compared to conventional algorithmic programs, machine learning has a range of major advantages. Through manual trading is often a time-consuming manual process, the process of machine learning algorithm will speed up the search for successful algo-trading strategies. It also increases the number of markets an individual can keep track of and respond to. You have a competitive advantage if you can automate a system that others do manually. You would have more options if you can increase the number of markets you invest in.', 'aiModelVersion': '1'}",0.4775
Jack Brennen,2y,What is code too complex to be compiled?,"The C++ template system is Turing complete and is evaluated at compile time. So it’s possible to write a legal C++ program with defined behavior, but which might take thousands or millions of years to actually compile.

For instance, you could write a C++ program using template metaprogramming which would compute — at compile time — the prime factorization of some huge positive integer. Once done compiling, the program would execute in small constant time, but the compile step would execute “forever” at least as perceived by a mortal human.

For a more literal answer, you could have the template metaprogramming look for something which is known not to exist, such as the smallest perfect number divisible by 10. That code would never complete the compilation step, and at some point it would exceed the internal limits of the compiler and probably fail due to some sort of internal assertion in the compiler.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/f670axho19u5j2wq', 'title': 'What is code too complex to be compiled?', 'score': {'original': 0.998, 'ai': 0.002}, 'blocks': [{'text': 'The C++ template system is Turing complete and is evaluated at compile time. So it’s possible to write a legal C++ program with defined behavior, but which might take thousands or millions of years to actually compile.\n\nFor instance, you could write a C++ program using template metaprogramming which would compute — at compile time — the prime factorization of some huge positive integer. Once done compiling, the program would execute in small constant time, but the compile step would execute “forever” at least as perceived by a mortal human.\n\nFor a more literal answer, you could have the template metaprogramming look for something which is known not to exist, such as the smallest perfect number divisible by 10. That code would never complete the compilation step, and at some point it would exceed the internal limits of the compiler and probably fail due to some sort of internal assertion in the compiler.', 'result': {'fake': 0.002, 'real': 0.998}, 'status': 'success'}], 'credits_used': 2, 'credits': 1986224, 'subscription': 0, 'content': 'The C++ template system is Turing complete and is evaluated at compile time. So it’s possible to write a legal C++ program with defined behavior, but which might take thousands or millions of years to actually compile.\n\nFor instance, you could write a C++ program using template metaprogramming which would compute — at compile time — the prime factorization of some huge positive integer. Once done compiling, the program would execute in small constant time, but the compile step would execute “forever” at least as perceived by a mortal human.\n\nFor a more literal answer, you could have the template metaprogramming look for something which is known not to exist, such as the smallest perfect number divisible by 10. That code would never complete the compilation step, and at some point it would exceed the internal limits of the compiler and probably fail due to some sort of internal assertion in the compiler.', 'aiModelVersion': '1'}",0.998
Anders Kaseorg,8y,How does a language like Python efficiently calculate a huge number like ,"2
50000
250000
 is really tiny as far as computers are concerned. Python uses exponentiation by squaring
 with Karatsuba multiplication
 to compute it in under 200 microseconds. The hard part happens after that computation: the result needs to be converted from binary to decimal for display. Python actually does this part much more slowly than it could with better conversion algorithms
.

Here we compare the running times using Python’s builtin arithmetic vs. using the GNU MP bignum library
 via the gmpy2
 bindings. You can see that the former grows quadratically and the latter is closer to linear.

Python 3.4.3 (default, Mar 26 2015, 22:03:40)  
IPython 2.3.0 -- An enhanced Interactive Python. 
 
In [1]: a, b = 2, 50000  # to prevent constant folding 
 
In [2]: %timeit repr(a**b) 
100 loops, best of 3: 7.64 ms per loop 
 
In [3]: a, b = 2, 500000 
 
In [4]: %timeit repr(a**b) 
1 loops, best of 3: 753 ms per loop 
 
In [5]: a, b = 2, 5000000 
 
In [6]: %timeit repr(a**b) 
1 loops, best of 3: 1min 15s per loop 
 
In [7]: from gmpy2 import mpz 
 
In [8]: a, b = mpz(2), mpz(50000) 
 
In [9]: %timeit repr(a**b) 
1000 loops, best of 3: 387 µs per loop 
 
In [10]: a, b = mpz(2), mpz(500000) 
 
In [11]: %timeit repr(a**b) 
100 loops, best of 3: 13.6 ms per loop 
 
In [12]: a, b = mpz(2), mpz(5000000) 
 
In [13]: %timeit repr(a**b) 
1 loops, best of 3: 325 ms per loop ","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/ezbtgnk85x6h93uj', 'title': 'How does a language like Python efficiently calculate a huge number like', 'score': {'original': 0.9974, 'ai': 0.0026}, 'blocks': [{'text': '2\n50000\n250000\n is really tiny as far as computers are concerned. Python uses exponentiation by squaring\n with Karatsuba multiplication\n to compute it in under 200 microseconds. The hard part happens after that computation: the result needs to be converted from binary to decimal for display. Python actually does this part much more slowly than it could with better conversion algorithms\n.\n\nHere we compare the running times using Python’s builtin arithmetic vs. using the GNU MP bignum library\n via the gmpy2\n bindings. You can see that the former grows quadratically and the latter is closer to linear.\n\nPython 3.4.3 (default, Mar 26 2015, 22:03:40) \xa0\nIPython 2.3.0 -- An enhanced Interactive Python.\xa0\n\xa0\nIn [1]: a, b = 2, 50000  # to prevent constant folding\xa0\n\xa0\nIn [2]: %timeit repr(a**b)\xa0\n100 loops, best of 3: 7.64 ms per loop\xa0\n\xa0\nIn [3]: a, b = 2, 500000\xa0\n\xa0\nIn [4]: %timeit repr(a**b)\xa0\n1 loops, best of 3: 753 ms per loop\xa0\n\xa0\nIn [5]: a, b = 2, 5000000\xa0\n\xa0\nIn [6]: %timeit repr(a**b)\xa0\n1 loops, best of 3: 1min 15s per loop\xa0\n\xa0\nIn [7]: from gmpy2 import mpz\xa0\n\xa0\nIn [8]: a, b = mpz(2), mpz(50000)\xa0\n\xa0\nIn [9]: %timeit repr(a**b)\xa0\n1000 loops, best of 3: 387 µs per loop\xa0\n\xa0\nIn [10]: a, b = mpz(2), mpz(500000)\xa0\n\xa0\nIn [11]: %timeit repr(a**b)\xa0\n100 loops, best of 3: 13.6 ms per loop\xa0\n\xa0\nIn [12]: a, b = mpz(2), mpz(5000000)\xa0\n\xa0\nIn [13]: %timeit repr(a**b)\xa0\n1 loops, best of 3: 325 ms per loop\xa0', 'result': {'fake': 0.0026, 'real': 0.9974}, 'status': 'success'}], 'credits_used': 3, 'credits': 1986221, 'subscription': 0, 'content': '2\n50000\n250000\n is really tiny as far as computers are concerned. Python uses exponentiation by squaring\n with Karatsuba multiplication\n to compute it in under 200 microseconds. The hard part happens after that computation: the result needs to be converted from binary to decimal for display. Python actually does this part much more slowly than it could with better conversion algorithms\n.\n\nHere we compare the running times using Python’s builtin arithmetic vs. using the GNU MP bignum library\n via the gmpy2\n bindings. You can see that the former grows quadratically and the latter is closer to linear.\n\nPython 3.4.3 (default, Mar 26 2015, 22:03:40) \xa0\nIPython 2.3.0 -- An enhanced Interactive Python.\xa0\n\xa0\nIn [1]: a, b = 2, 50000  # to prevent constant folding\xa0\n\xa0\nIn [2]: %timeit repr(a**b)\xa0\n100 loops, best of 3: 7.64 ms per loop\xa0\n\xa0\nIn [3]: a, b = 2, 500000\xa0\n\xa0\nIn [4]: %timeit repr(a**b)\xa0\n1 loops, best of 3: 753 ms per loop\xa0\n\xa0\nIn [5]: a, b = 2, 5000000\xa0\n\xa0\nIn [6]: %timeit repr(a**b)\xa0\n1 loops, best of 3: 1min 15s per loop\xa0\n\xa0\nIn [7]: from gmpy2 import mpz\xa0\n\xa0\nIn [8]: a, b = mpz(2), mpz(50000)\xa0\n\xa0\nIn [9]: %timeit repr(a**b)\xa0\n1000 loops, best of 3: 387 µs per loop\xa0\n\xa0\nIn [10]: a, b = mpz(2), mpz(500000)\xa0\n\xa0\nIn [11]: %timeit repr(a**b)\xa0\n100 loops, best of 3: 13.6 ms per loop\xa0\n\xa0\nIn [12]: a, b = mpz(2), mpz(5000000)\xa0\n\xa0\nIn [13]: %timeit repr(a**b)\xa0\n1 loops, best of 3: 325 ms per loop\xa0', 'aiModelVersion': '1'}",0.9974
Thomas Cormen,1y,"In order to learn Thomas Cormen's Introduction to Algorithms, should I study discrete mathematics first? I currently only have calculus and linear algebra background.","I suppose that I’m as qualified as anyone to answer this one.

I recommend that you study discrete math first. That’s what we do at Dartmouth. If you already know how to construct a rigorous proof, then you might be able to pick up the discrete math that you need from the appendices and Part I of the book.","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/95kym072nsfjwx1b', 'title': ""In order to learn Thomas Cormen's Introduction to Algorithms, should I study discrete mathematics first? I currently only have calculus and linear algebra background."", 'score': {'original': 0.0497, 'ai': 0.9503}, 'blocks': [{'text': 'I suppose that I’m as qualified as anyone to answer this one.\n\nI recommend that you study discrete math first. That’s what we do at Dartmouth. If you already know how to construct a rigorous proof, then you might be able to pick up the discrete math that you need from the appendices and Part I of the book.', 'result': {'fake': 0.9503, 'real': 0.0497}, 'status': 'success'}], 'credits_used': 1, 'credits': 1986220, 'subscription': 0, 'content': 'I suppose that I’m as qualified as anyone to answer this one.\n\nI recommend that you study discrete math first. That’s what we do at Dartmouth. If you already know how to construct a rigorous proof, then you might be able to pick up the discrete math that you need from the appendices and Part I of the book.', 'aiModelVersion': '1'}",0.0497
Scott Duke Kominers,Sep 11,What is Gale-Shapley algorithm?,"The Gale--Shapley algorithm
, also called deferred acceptance, is one of the most successful algorithms of all time. It gives a way for matching participants on two sides of a market -- students to schools, for example, or workers to firms -- so that the eventual outcome is stable in the sense that no one finds their match partner unacceptable, and no pair of agents mutually prefer each other to their assigned matches.

That is: at the end of the Gale--Shapley algorithm, everyone has an acceptable match, and if you've been assigned to your third choice job, then your first and second choice jobs have workers they prefer to you. And if you are your employer's second choice, then their first choice has a job they prefer.

This algorithm is used worldwide to match students to schools
 in various school choice programs, and versions of it have also been used to match doctors to their medical residencies
 in the US, England, and Japan.

""Stability"" of the match outcome is meaningful in practice because it literally stabilizes the market -- with such an outcome, no one has an incentive to get on the phone and try to negotiate a better job (or a better placement for their child), because if there were one available, the algorithm would have found it.

But it's not even obvious that stable outcomes should even exist, much less how you find them.

Here's how it works:

Imagine in the case of workers and firms that all the workers are standing on one side of a room and all the firms are standing on the other. (For simplicity, we'll assume that each firm wants to hire at most one worker, and each worker wants at most one job.) 
Now have each firm walk across and make an offer to its first choice worker. 
Each worker holds their best acceptable offer, if any, and rejects all the others. 
Now every firm that had an offer rejected walks across and proposes to their second-choice worker. 
Again, workers hold their best acceptable offers, if any, and reject all the others. (This means some workers might keep holding the same offer from before, or might reject an offer they held previously to take a new one received in the second round.) 
The algorithm continues like this, with firms gradually moving down their preference lists and workers holding their best acceptable offer, until every firms either has an offer currently being held by a worker or has run out of proposals to make. At that moment, we match the workers to the firms whose offers they are holding, and that outcome is stable. 

Why is the outcome stable?

First, no one has an unacceptable partner because firms only made offers to workers they wanted to hire, and workers only held acceptable offers.
And if there were a worker and a firm who preferred each other to their assigned matches, then something must have gone wrong with the algorithm: The fact that they didn't end up matched to each other means either the firm didn't make an offer to the worker or the worker rejected it. But if the firm didn't offer, then it would have to end up with a worker it preferred, since it was moving down its preference list in order. And if the worker rejected, then it must have received an offer it preferred, which means it ended up with a job it preferred.

The original paper is the most-cited article in the history of the American Mathematical Monthly. And it's super readable – check it out
!","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/a96xglp3jvmibzre', 'title': 'What is Gale-Shapley algorithm?', 'score': {'original': 0.43015, 'ai': 0.56985}, 'blocks': [{'text': 'The Gale--Shapley algorithm\n, also called deferred acceptance, is one of the most successful algorithms of all time. It gives a way for matching participants on two sides of a market -- students to schools, for example, or workers to firms -- so that the eventual outcome is stable in the sense that no one finds their match partner unacceptable, and no pair of agents mutually prefer each other to their assigned matches.\n\nThat is: at the end of the Gale--Shapley algorithm, everyone has an acceptable match, and if you\'ve been assigned to your third choice job, then your first and second choice jobs have workers they prefer to you. And if you are your employer\'s second choice, then their first choice has a job they prefer.\n\nThis algorithm is used worldwide to match students to schools\n in various school choice programs, and versions of it have also been used to match doctors to their medical residencies\n in the US, England, and Japan.\n\n""Stability"" of the match outcome is meaningful in practice because it literally stabilizes the market -- with such an outcome, no one has an incentive to get on the phone and try to negotiate a better job (or a better placement for their child), because if there were one available, the algorithm would have found it.\n\nBut it\'s not even obvious that stable outcomes should even exist, much less how you find them.\n\nHere\'s how it works:\n\nImagine in the case of workers and firms that all the workers are standing on one side of a room and all the firms are standing on the other. (For simplicity, we\'ll assume that each firm wants to hire at most one worker, and each worker wants at most one job.)\xa0\nNow have each firm walk across and make an offer to its first choice worker.\xa0\nEach worker holds their best acceptable offer, if any, and rejects all the others.\xa0\nNow every firm that had an offer rejected walks across and proposes to their second-choice worker.\xa0\nAgain, workers hold their best acceptable offers, if any, and reject all the others. (This means some workers might keep holding the same offer from before, or might reject an offer they held previously to take a new one received in the second round.)\xa0\nThe algorithm continues like this, with firms gradually moving down their preference lists and workers holding their best acceptable offer, until every firms either has an offer currently being held by a worker or has run out of proposals to make. At that moment, we match the workers to the firms whose offers they are holding, and that outcome is stable.\xa0\n\nWhy is the outcome stable?\n\nFirst, no one has an unacceptable partner because firms only made offers to workers they wanted to hire, and workers only held acceptable offers.\nAnd if there were a worker and a firm who preferred each other to their assigned matches, then something must have gone wrong with the algorithm: The fact that they didn\'t end up matched to each other means either the firm didn\'t make an offer to the worker or the worker rejected it. But if the firm', 'result': {'fake': 0.0936, 'real': 0.9064}, 'status': 'success'}, {'text': ""didn't offer, then it would have to end up with a worker it preferred, since it was moving down its preference list in order. And if the worker rejected, then it must have received an offer it preferred, which means it ended up with a job it preferred.\n\nThe original paper is the most-cited article in the history of the American Mathematical Monthly. And it's super readable – check it out\n!"", 'result': {'fake': 0.9961, 'real': 0.0039}, 'status': 'success'}], 'credits_used': 6, 'credits': 1986214, 'subscription': 0, 'content': 'The Gale--Shapley algorithm\n, also called deferred acceptance, is one of the most successful algorithms of all time. It gives a way for matching participants on two sides of a market -- students to schools, for example, or workers to firms -- so that the eventual outcome is stable in the sense that no one finds their match partner unacceptable, and no pair of agents mutually prefer each other to their assigned matches.\n\nThat is: at the end of the Gale--Shapley algorithm, everyone has an acceptable match, and if you\'ve been assigned to your third choice job, then your first and second choice jobs have workers they prefer to you. And if you are your employer\'s second choice, then their first choice has a job they prefer.\n\nThis algorithm is used worldwide to match students to schools\n in various school choice programs, and versions of it have also been used to match doctors to their medical residencies\n in the US, England, and Japan.\n\n""Stability"" of the match outcome is meaningful in practice because it literally stabilizes the market -- with such an outcome, no one has an incentive to get on the phone and try to negotiate a better job (or a better placement for their child), because if there were one available, the algorithm would have found it.\n\nBut it\'s not even obvious that stable outcomes should even exist, much less how you find them.\n\nHere\'s how it works:\n\nImagine in the case of workers and firms that all the workers are standing on one side of a room and all the firms are standing on the other. (For simplicity, we\'ll assume that each firm wants to hire at most one worker, and each worker wants at most one job.)\xa0\nNow have each firm walk across and make an offer to its first choice worker.\xa0\nEach worker holds their best acceptable offer, if any, and rejects all the others.\xa0\nNow every firm that had an offer rejected walks across and proposes to their second-choice worker.\xa0\nAgain, workers hold their best acceptable offers, if any, and reject all the others. (This means some workers might keep holding the same offer from before, or might reject an offer they held previously to take a new one received in the second round.)\xa0\nThe algorithm continues like this, with firms gradually moving down their preference lists and workers holding their best acceptable offer, until every firms either has an offer currently being held by a worker or has run out of proposals to make. At that moment, we match the workers to the firms whose offers they are holding, and that outcome is stable.\xa0\n\nWhy is the outcome stable?\n\nFirst, no one has an unacceptable partner because firms only made offers to workers they wanted to hire, and workers only held acceptable offers.\nAnd if there were a worker and a firm who preferred each other to their assigned matches, then something must have gone wrong with the algorithm: The fact that they didn\'t end up matched to each other means either the firm didn\'t make an offer to the worker or the worker rejected it. But if the firm didn\'t offer, then it would have to end up with a worker it preferred, since it was moving down its preference list in order. And if the worker rejected, then it must have received an offer it preferred, which means it ended up with a job it preferred.\n\nThe original paper is the most-cited article in the history of the American Mathematical Monthly. And it\'s super readable – check it out\n!', 'aiModelVersion': '1'}",0.43015
Joe Zbiciak,1y,"Has anyone tried to ""compress"" the binary equivalent of the PI value, to a decent amount of decimal places, using a popular, non-destructive compression algorithm? (please show the result)","I happened to have a file with 1 million hexadecimal digits of ππ\pi laying around. I converted that to pure binary. With the leading byte (0x03), the original file is 500,001 bytes long. Results with four popular compressors: CommandFile Size (bytes)Original500001gzip -9500109bzip2 -9502729xz -9e5000887z -t7z -m0=LZMA2 -mx9500155CommandFile Size (bytes)Original500001gzip -9500109bzip2 -9502729xz -9e5000887z -t7z -m0=LZMA2 -mx9500155\begin{array}{c|c}\sf Command & \textsf{File Size (bytes)} \\ \hline \text{Original} & 500\,001 \\ \texttt{gzip -9} & 500\,109 \\ \texttt{bzip2 -9} & 502\,729 \\ \texttt{xz -9e} & 500\,088 \\ \texttt{7z -t7z -m0=LZMA2 -mx9} & 500\,155 \end{array}\tag*{} None of the four lossless compressors made the file any smaller. They all made it larger. This is an unsurprising result. Traditional lossless compressors that aren’t tuned for a specific type of data usually look for redundancy at the byte level, and there really is none in the binary representation of ππ\pi.Addendum I just found a source for the first 1,000,000,000 hexadecimal digits of π.π.\pi. Repeating the experiment above, now with an input 1000× as large, I get: CommandFile Size (bytes)Original500000001gzip -9500080747bzip2 -9502215315xz -9e5000248207z -t7z -m0=LZMA2 -mx9500026652CommandFile Size (bytes)Original500000001gzip -9500080747bzip2 -9502215315xz -9e5000248207z -t7z -m0=LZMA2 -mx9500026652\begin{array}{c|c} \sf Command & \textsf{File Size (bytes)} \\ \hline \text{Original} & 500\,000\,001 \\ \texttt{gzip -9} & 500\,080\,747 \\ \texttt{bzip2 -9} & 502\,215\,315 \\ \texttt{xz -9e} & 500\,024\,820 \\ \texttt{7z -t7z -m0=LZMA2 -mx9} & 500\,026\,652 \end{array}\tag*{} In case you’re wondering, I used the following quick and dirty Perl script to convert the hexadecimal representation into binary. I did a quick visual inspection of a hex dump of the binary conversion to verify it translated as expected.#!/usr/bin/env perl  while (<>) {   chomp($_);   s/^3\./03/;   print pack(""H*"", $_); } I then just provided the pi_hex_1b.txt on stdin and redirected stdout to pi_hex_1b.bin. Feel free to reproduce my experiment, or try other compressors.Addendum 2: Binary representation of ππ\pi I’ve received a couple comments, one here, and one on another thread, that make it clear not everyone understands what I mean by hexadecimal and binary representations of π.π.\pi. There are no decimal digits involved at any point. I started with an ASCII text file that looks something that looks like this…3.243f6a8885a308d313198a2e03 707344a4093822299f31d0082efa 98ec4e6c89452821e638d01377be ... …only without the line breaks. Each hexadecimal digit in that file corresponds to 4 bits of ππ\pi in binary. If I ask bc to compute ππ\pi in binary for me, the output looks something like this:$ bc -l bc 1.06.95 Copyright 1991-1994, 1997, 1998, 2000, 2004, 2006 Free Software Foundation, Inc. This is free software with ABSOLUTELY NO WARRANTY. For details type `warranty'.  scale=50 obase=2 4*a(1) 11.00100100001111110110101010001000100001011010001100001000110100110\ 00100110001100110001010001011100000001101110000011100110100010010100\ 1000000100100111000001000100001111 Now, bc does actually compute in decimal under the hood, and then it converts to proper binary, so the last few binary digits might be dodgy. But, if we take the first line and line it up with the hexadecimal data, you can see they match one-for-one: 3   2    4    3    f    6    a    8 11.0010 0100 0011 1111 0110 1010 1000 When I packed the hexadecimal digits into a binary file, each pair of hexadecimal digits becomes a single byte. Because of the order I packed everything, the resulting representation is big endian, both at bit and byte level.As you can see, each byte corresponds to two hex digits from the source file, in the same reading order. As a result, for bytes after the first one, bit nnn (in big-endian order) corresponds mathematically to the positional weighted value 2n−1.2n−1.2^{n-1}. If you include the starting byte, then bit nnn in the file corresponds to 27−n.27−n.2^{7-n}. There is no decimal involved anywhere here. This is simply the most direct uncompressed pure binary representation of π.π.\pi. OK, you might quibble that I wasted 6 bits at the front, spending an entire byte on the integer portion. Is that really where you want to go with this?Still, folks have an overwhelming fascination with decimal, and that leads to the question “Approximately how many decimal digits is each file equivalent to?” Well, let’s start with this: log210≈3.321928…log2⁡10≈3.321928…\log_2 10 \approx 3.321928\dots \tag*{} That means you get approximately 1 decimal digit for every ~3.321928 bits. 4000000/log210≈1204119.984000000000/log210≈1204119982.664000000/log2⁡10≈1204119.984000000000/log2⁡10≈1204119982.66\begin{eqnarray} 4\,000\,000\mathbin{/}\log_2 10 &\approx& 1\,204\,119.98 \\ 4\,000\,000\,000\mathbin{/}\log_2 10 &\approx& 1\,204\,119\,982.66 \end{eqnarray}\tag*{} Or more concisely, about 1.2M and 1.2B decimal digits of π,π,\pi, respectively. If you want to convert one of these files into a decimal representation, pop into your favorite arbitrary precision calculator, slurp in the entire file as a giant integer, and then divide by either 24000000240000002^{4\,000\,000} or 24000000000,24000000000,2^{4\,000\,000\,000}, depending on which file you loaded. That’s right, these are fixed point numbers with either 4M or 4B fractional bits. As for that division: It might take a moment or two for the computer to complete the request. ;-)LaTeX Addendum For folks who are currently unable to see LaTeX, here’s a screencap of the tables:…And for the bits to decimal digits conversion:","{'success': True, 'disclaimer': 'If you are trying to scan content that is under 50 words in length, you will run into AI accuracy issues.', 'public_link': 'https://app.originality.ai/share/oabhjdk3ctyimf2n', 'title': 'Has anyone tried to ""compress"" the binary equivalent of the PI value, to a decent amount of decimal places, using a popular, non-destructive compression algorithm? (please show the result)', 'score': {'original': 0.99075, 'ai': 0.00925}, 'blocks': [{'text': 'I happened to have a file with 1 million hexadecimal digits of ππ\\pi laying around. I converted that to pure binary. With the leading byte (0x03), the original file is 500,001 bytes long. Results with four popular compressors: CommandFile Size (bytes)Original500001gzip -9500109bzip2 -9502729xz -9e5000887z -t7z -m0=LZMA2 -mx9500155CommandFile Size (bytes)Original500001gzip -9500109bzip2 -9502729xz -9e5000887z -t7z -m0=LZMA2 -mx9500155\\begin{array}{c|c}\\sf Command & \\textsf{File Size (bytes)} \\\\ \\hline \\text{Original} & 500\\,001 \\\\ \\texttt{gzip -9} & 500\\,109 \\\\ \\texttt{bzip2 -9} & 502\\,729 \\\\ \\texttt{xz -9e} & 500\\,088 \\\\ \\texttt{7z -t7z -m0=LZMA2 -mx9} & 500\\,155 \\end{array}\\tag*{} None of the four lossless compressors made the file any smaller. They all made it larger. This is an unsurprising result. Traditional lossless compressors that aren’t tuned for a specific type of data usually look for redundancy at the byte level, and there really is none in the binary representation of ππ\\pi.Addendum I just found a source for the first 1,000,000,000 hexadecimal digits of π.π.\\pi. Repeating the experiment above, now with an input 1000× as large, I get: CommandFile Size (bytes)Original500000001gzip -9500080747bzip2 -9502215315xz -9e5000248207z -t7z -m0=LZMA2 -mx9500026652CommandFile Size (bytes)Original500000001gzip -9500080747bzip2 -9502215315xz -9e5000248207z -t7z -m0=LZMA2 -mx9500026652\\begin{array}{c|c} \\sf Command & \\textsf{File Size (bytes)} \\\\ \\hline \\text{Original} & 500\\,000\\,001 \\\\ \\texttt{gzip -9} & 500\\,080\\,747 \\\\ \\texttt{bzip2 -9} & 502\\,215\\,315 \\\\ \\texttt{xz -9e} & 500\\,024\\,820 \\\\ \\texttt{7z -t7z -m0=LZMA2 -mx9} & 500\\,026\\,652 \\end{array}\\tag*{} In case you’re wondering, I used the following quick and dirty Perl script to convert the hexadecimal representation into binary. I did a quick visual inspection of a hex dump of the binary conversion to verify it translated as expected.#!/usr/bin/env perl\xa0\xa0while (<>) {\xa0  chomp($_);\xa0  s/^3\\./03/;\xa0  print pack(""H*"", $_);\xa0}\xa0I then just provided the pi_hex_1b.txt on stdin and redirected stdout to pi_hex_1b.bin. Feel free to reproduce my experiment, or try other compressors.Addendum 2: Binary representation of ππ\\pi I’ve received a couple comments, one here, and one on another thread, that make it clear not everyone understands what I mean by hexadecimal and binary representations of π.π.\\pi. There are no decimal digits involved at any point. I started with an ASCII text file that looks something that looks like this…3.243f6a8885a308d313198a2e03\xa0707344a4093822299f31d0082efa\xa098ec4e6c89452821e638d01377be\xa0...\xa0…only without the line breaks. Each hexadecimal digit in that file corresponds to 4 bits of ππ\\pi in binary. If I ask bc to compute ππ\\pi in binary for me, the output looks something like this:$ bc -l\xa0bc 1.06.95\xa0Copyright 1991-1994, 1997, 1998, 2000, 2004, 2006 Free Software Foundation, Inc.\xa0This is free software with ABSOLUTELY NO WARRANTY.\xa0For details type `warranty\'. \xa0scale=50\xa0obase=2\xa04*a(1)\xa011.00100100001111110110101010001000100001011010001100001000110100110\\\xa000100110001100110001010001011100000001101110000011100110100010010100\\\xa01000000100100111000001000100001111\xa0Now, bc does actually compute in decimal under the hood, and then it converts to proper binary, so the last few binary digits might be dodgy. But, if we take the first line and line it up with the hexadecimal data, you can see they match one-for-one: 3   2    4    3    f    6    a    8\xa011.0010 0100 0011 1111 0110 1010 1000\xa0When I packed the hexadecimal digits into a binary file, each pair of hexadecimal digits becomes a single byte. Because of the order I packed everything, the', 'result': {'fake': 0.0026, 'real': 0.9974}, 'status': 'success'}, {'text': 'resulting representation is big endian, both at bit and byte level.As you can see, each byte corresponds to two hex digits from the source file, in the same reading order. As a result, for bytes after the first one, bit nnn (in big-endian order) corresponds mathematically to the positional weighted value 2n−1.2n−1.2^{n-1}. If you include the starting byte, then bit nnn in the file corresponds to 27−n.27−n.2^{7-n}. There is no decimal involved anywhere here. This is simply the most direct uncompressed pure binary representation of π.π.\\pi. OK, you might quibble that I wasted 6 bits at the front, spending an entire byte on the integer portion. Is that really where you want to go with this?Still, folks have an overwhelming fascination with decimal, and that leads to the question “Approximately how many decimal digits is each file equivalent to?” Well, let’s start with this: log210≈3.321928…log2\u206110≈3.321928…\\log_2 10 \\approx 3.321928\\dots \\tag*{} That means you get approximately 1 decimal digit for every ~3.321928 bits. 4000000/log210≈1204119.984000000000/log210≈1204119982.664000000/log2\u206110≈1204119.984000000000/log2\u206110≈1204119982.66\\begin{eqnarray} 4\\,000\\,000\\mathbin{/}\\log_2 10 &\\approx& 1\\,204\\,119.98 \\\\ 4\\,000\\,000\\,000\\mathbin{/}\\log_2 10 &\\approx& 1\\,204\\,119\\,982.66 \\end{eqnarray}\\tag*{} Or more concisely, about 1.2M and 1.2B decimal digits of π,π,\\pi, respectively. If you want to convert one of these files into a decimal representation, pop into your favorite arbitrary precision calculator, slurp in the entire file as a giant integer, and then divide by either 24000000240000002^{4\\,000\\,000} or 24000000000,24000000000,2^{4\\,000\\,000\\,000}, depending on which file you loaded. That’s right, these are fixed point numbers with either 4M or 4B fractional bits. As for that division: It might take a moment or two for the computer to complete the request. ;-)LaTeX Addendum For folks who are currently unable to see LaTeX, here’s a screencap of the tables:…And for the bits to decimal digits conversion:', 'result': {'fake': 0.002, 'real': 0.998}, 'status': 'success'}], 'credits_used': 9, 'credits': 1986205, 'subscription': 0, 'content': 'I happened to have a file with 1 million hexadecimal digits of ππ\\pi laying around. I converted that to pure binary. With the leading byte (0x03), the original file is 500,001 bytes long. Results with four popular compressors: CommandFile Size (bytes)Original500001gzip -9500109bzip2 -9502729xz -9e5000887z -t7z -m0=LZMA2 -mx9500155CommandFile Size (bytes)Original500001gzip -9500109bzip2 -9502729xz -9e5000887z -t7z -m0=LZMA2 -mx9500155\\begin{array}{c|c}\\sf Command & \\textsf{File Size (bytes)} \\\\ \\hline \\text{Original} & 500\\,001 \\\\ \\texttt{gzip -9} & 500\\,109 \\\\ \\texttt{bzip2 -9} & 502\\,729 \\\\ \\texttt{xz -9e} & 500\\,088 \\\\ \\texttt{7z -t7z -m0=LZMA2 -mx9} & 500\\,155 \\end{array}\\tag*{} None of the four lossless compressors made the file any smaller. They all made it larger. This is an unsurprising result. Traditional lossless compressors that aren’t tuned for a specific type of data usually look for redundancy at the byte level, and there really is none in the binary representation of ππ\\pi.Addendum I just found a source for the first 1,000,000,000 hexadecimal digits of π.π.\\pi. Repeating the experiment above, now with an input 1000× as large, I get: CommandFile Size (bytes)Original500000001gzip -9500080747bzip2 -9502215315xz -9e5000248207z -t7z -m0=LZMA2 -mx9500026652CommandFile Size (bytes)Original500000001gzip -9500080747bzip2 -9502215315xz -9e5000248207z -t7z -m0=LZMA2 -mx9500026652\\begin{array}{c|c} \\sf Command & \\textsf{File Size (bytes)} \\\\ \\hline \\text{Original} & 500\\,000\\,001 \\\\ \\texttt{gzip -9} & 500\\,080\\,747 \\\\ \\texttt{bzip2 -9} & 502\\,215\\,315 \\\\ \\texttt{xz -9e} & 500\\,024\\,820 \\\\ \\texttt{7z -t7z -m0=LZMA2 -mx9} & 500\\,026\\,652 \\end{array}\\tag*{} In case you’re wondering, I used the following quick and dirty Perl script to convert the hexadecimal representation into binary. I did a quick visual inspection of a hex dump of the binary conversion to verify it translated as expected.#!/usr/bin/env perl\xa0\xa0while (<>) {\xa0  chomp($_);\xa0  s/^3\\./03/;\xa0  print pack(""H*"", $_);\xa0}\xa0I then just provided the pi_hex_1b.txt on stdin and redirected stdout to pi_hex_1b.bin. Feel free to reproduce my experiment, or try other compressors.Addendum 2: Binary representation of ππ\\pi I’ve received a couple comments, one here, and one on another thread, that make it clear not everyone understands what I mean by hexadecimal and binary representations of π.π.\\pi. There are no decimal digits involved at any point. I started with an ASCII text file that looks something that looks like this…3.243f6a8885a308d313198a2e03\xa0707344a4093822299f31d0082efa\xa098ec4e6c89452821e638d01377be\xa0...\xa0…only without the line breaks. Each hexadecimal digit in that file corresponds to 4 bits of ππ\\pi in binary. If I ask bc to compute ππ\\pi in binary for me, the output looks something like this:$ bc -l\xa0bc 1.06.95\xa0Copyright 1991-1994, 1997, 1998, 2000, 2004, 2006 Free Software Foundation, Inc.\xa0This is free software with ABSOLUTELY NO WARRANTY.\xa0For details type `warranty\'. \xa0scale=50\xa0obase=2\xa04*a(1)\xa011.00100100001111110110101010001000100001011010001100001000110100110\\\xa000100110001100110001010001011100000001101110000011100110100010010100\\\xa01000000100100111000001000100001111\xa0Now, bc does actually compute in decimal under the hood, and then it converts to proper binary, so the last few binary digits might be dodgy. But, if we take the first line and line it up with the hexadecimal data, you can see they match one-for-one: 3   2    4    3    f    6    a    8\xa011.0010 0100 0011 1111 0110 1010 1000\xa0When I packed the hexadecimal digits into a binary file, each pair of hexadecimal digits becomes a single byte. Because of the order I packed everything, the resulting representation is big endian, both at bit and byte level.As you can see, each byte corresponds to two hex digits from the source file, in the same reading order. As a result, for bytes after the first one, bit nnn (in big-endian order) corresponds mathematically to the positional weighted value 2n−1.2n−1.2^{n-1}. If you include the starting byte, then bit nnn in the file corresponds to 27−n.27−n.2^{7-n}. There is no decimal involved anywhere here. This is simply the most direct uncompressed pure binary representation of π.π.\\pi. OK, you might quibble that I wasted 6 bits at the front, spending an entire byte on the integer portion. Is that really where you want to go with this?Still, folks have an overwhelming fascination with decimal, and that leads to the question “Approximately how many decimal digits is each file equivalent to?” Well, let’s start with this: log210≈3.321928…log2\u206110≈3.321928…\\log_2 10 \\approx 3.321928\\dots \\tag*{} That means you get approximately 1 decimal digit for every ~3.321928 bits. 4000000/log210≈1204119.984000000000/log210≈1204119982.664000000/log2\u206110≈1204119.984000000000/log2\u206110≈1204119982.66\\begin{eqnarray} 4\\,000\\,000\\mathbin{/}\\log_2 10 &\\approx& 1\\,204\\,119.98 \\\\ 4\\,000\\,000\\,000\\mathbin{/}\\log_2 10 &\\approx& 1\\,204\\,119\\,982.66 \\end{eqnarray}\\tag*{} Or more concisely, about 1.2M and 1.2B decimal digits of π,π,\\pi, respectively. If you want to convert one of these files into a decimal representation, pop into your favorite arbitrary precision calculator, slurp in the entire file as a giant integer, and then divide by either 24000000240000002^{4\\,000\\,000} or 24000000000,24000000000,2^{4\\,000\\,000\\,000}, depending on which file you loaded. That’s right, these are fixed point numbers with either 4M or 4B fractional bits. As for that division: It might take a moment or two for the computer to complete the request. ;-)LaTeX Addendum For folks who are currently unable to see LaTeX, here’s a screencap of the tables:…And for the bits to decimal digits conversion:', 'aiModelVersion': '1'}",0.99075
